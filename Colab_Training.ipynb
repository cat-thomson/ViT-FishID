{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a643cc05",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/cat-thomson/ViT-FishID/blob/main/Colab_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff015a55",
   "metadata": {},
   "source": [
    "# ğŸŸ ViT-FishID: Semi-Supervised Fish Classification in Google Colab\n",
    "\n",
    "This notebook runs the ViT-FishID semi-supervised learning pipeline in Google Colab with images stored in Google Drive.\n",
    "\n",
    "## Setup Requirements:\n",
    "1. **GitHub Repository**: Your code should be in a GitHub repo (images excluded via .gitignore)\n",
    "2. **Google Drive**: Your fish images should be organized in Google Drive\n",
    "3. **GPU Runtime**: Enable GPU in Runtime â†’ Change runtime type â†’ Hardware accelerator â†’ GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ca7738",
   "metadata": {},
   "source": [
    "## ğŸ”§ Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b67ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"âš ï¸ No GPU detected. Enable GPU: Runtime â†’ Change runtime type â†’ Hardware accelerator â†’ GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c142378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone your GitHub repository\n",
    "import os\n",
    "\n",
    "# Replace with your actual GitHub repository URL\n",
    "REPO_URL = \"https://github.com/cat-thomson/ViT-FishID.git\"\n",
    "REPO_NAME = \"ViT-FishID\"\n",
    "\n",
    "# Clone repository if not already cloned\n",
    "if not os.path.exists(REPO_NAME):\n",
    "    !git clone {REPO_URL}\n",
    "    print(f\"âœ… Cloned {REPO_NAME}\")\n",
    "else:\n",
    "    print(f\"ğŸ“ {REPO_NAME} already exists\")\n",
    "\n",
    "# Change to repository directory\n",
    "os.chdir(REPO_NAME)\n",
    "print(f\"ğŸ“‚ Current directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59f60d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install -q timm transformers\n",
    "!pip install -q wandb\n",
    "!pip install -q pillow opencv-python\n",
    "!pip install -q scikit-learn matplotlib seaborn\n",
    "!pip install -q tqdm\n",
    "\n",
    "print(\"âœ… Dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0f6965",
   "metadata": {},
   "source": [
    "## ğŸ“ Google Drive Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc103b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Set your Google Drive paths\n",
    "# UPDATE THESE PATHS TO MATCH YOUR GOOGLE DRIVE STRUCTURE\n",
    "DRIVE_ROOT = \"/content/drive/MyDrive\"\n",
    "FISH_IMAGES_PATH = f\"{DRIVE_ROOT}/Fish_Images\"  # âš ï¸ UPDATE THIS PATH\n",
    "OUTPUT_PATH = f\"{DRIVE_ROOT}/Fish_Training_Output\"  # Where to save results\n",
    "\n",
    "print(f\"ğŸ“ Drive mounted at: {DRIVE_ROOT}\")\n",
    "print(f\"ğŸŸ Fish images path: {FISH_IMAGES_PATH}\")\n",
    "print(f\"ğŸ’¾ Output path: {OUTPUT_PATH}\")\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "# List contents of fish images directory\n",
    "if os.path.exists(FISH_IMAGES_PATH):\n",
    "    print(f\"\\nğŸ“‹ Contents of {FISH_IMAGES_PATH}:\")\n",
    "    !ls -la \"{FISH_IMAGES_PATH}\"\n",
    "else:\n",
    "    print(f\"âš ï¸ Path {FISH_IMAGES_PATH} not found. Please update FISH_IMAGES_PATH variable above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656291a7",
   "metadata": {},
   "source": [
    "## ğŸ“Š Data Organization and Preparation\n",
    "\n",
    "This section helps you organize your fish images from Google Drive into the proper structure for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8af4bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if data is already organized\n",
    "ORGANIZED_DATA_PATH = f\"{OUTPUT_PATH}/organized_fish_dataset\"\n",
    "\n",
    "def check_data_structure(path):\n",
    "    \"\"\"Check if data is properly organized for training.\"\"\"\n",
    "    labeled_path = os.path.join(path, \"labeled\")\n",
    "    unlabeled_path = os.path.join(path, \"unlabeled\")\n",
    "    \n",
    "    if os.path.exists(labeled_path) and os.path.exists(unlabeled_path):\n",
    "        print(f\"âœ… Organized dataset found at: {path}\")\n",
    "        \n",
    "        # Count labeled species\n",
    "        species = [d for d in os.listdir(labeled_path) if os.path.isdir(os.path.join(labeled_path, d))]\n",
    "        print(f\"ğŸ“‹ Labeled species ({len(species)}): {species}\")\n",
    "        \n",
    "        # Count images\n",
    "        labeled_count = sum([len(os.listdir(os.path.join(labeled_path, s))) for s in species if os.path.isdir(os.path.join(labeled_path, s))])\n",
    "        unlabeled_files = [f for f in os.listdir(unlabeled_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        unlabeled_count = len(unlabeled_files)\n",
    "        \n",
    "        print(f\"ğŸ·ï¸ Labeled images: {labeled_count}\")\n",
    "        print(f\"ğŸ”„ Unlabeled images: {unlabeled_count}\")\n",
    "        print(f\"ğŸ“Š Total images: {labeled_count + unlabeled_count}\")\n",
    "        \n",
    "        return True\n",
    "    else:\n",
    "        print(f\"âŒ No organized dataset found at: {path}\")\n",
    "        return False\n",
    "\n",
    "data_organized = check_data_structure(ORGANIZED_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bb7726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize data if not already done\n",
    "if not data_organized:\n",
    "    print(\"ğŸ”„ Organizing fish data...\")\n",
    "    \n",
    "    # Run the organize script with your fish images\n",
    "    # You may need to adjust these parameters based on your data structure\n",
    "    # Update the species list below based on your fish species\n",
    "    !python organize_fish_data.py \\\n",
    "        --input_dir \"{FISH_IMAGES_PATH}\" \\\n",
    "        --output_dir \"{ORGANIZED_DATA_PATH}\" \\\n",
    "        --labeled_species bass trout salmon tuna cod \\\n",
    "        --no-interactive\n",
    "    \n",
    "    # Check if organization was successful\n",
    "    data_organized = check_data_structure(ORGANIZED_DATA_PATH)\n",
    "    \n",
    "    if data_organized:\n",
    "        print(\"âœ… Data organization complete!\")\n",
    "    else:\n",
    "        print(\"âŒ Data organization failed. Please check your input path and data structure.\")\n",
    "        print(\"\\nTroubleshooting tips:\")\n",
    "        print(\"1. Make sure FISH_IMAGES_PATH points to your fish images in Google Drive\")\n",
    "        print(\"2. Update the --labeled_species list to match your fish species\")\n",
    "        print(\"3. Your images should be in common formats (jpg, jpeg, png)\")\n",
    "else:\n",
    "    print(\"âœ… Data already organized, skipping organization step.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12430b9",
   "metadata": {},
   "source": [
    "## ğŸ¯ Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02c587f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Weights & Biases (optional but recommended)\n",
    "import wandb\n",
    "\n",
    "# Login to wandb (you'll need to enter your API key)\n",
    "print(\"ğŸ”‘ Setting up Weights & Biases...\")\n",
    "print(\"If you don't have a W&B account, create one at https://wandb.ai/\")\n",
    "print(\"Get your API key from https://wandb.ai/authorize\")\n",
    "\n",
    "try:\n",
    "    wandb.login()\n",
    "    USE_WANDB = True\n",
    "    print(\"âœ… W&B login successful!\")\n",
    "except:\n",
    "    print(\"âš ï¸ W&B login failed. Training will continue without logging.\")\n",
    "    USE_WANDB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315a0e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration optimized for Google Colab\n",
    "from datetime import datetime\n",
    "\n",
    "TRAINING_CONFIG = {\n",
    "    # Data settings\n",
    "    'data_dir': ORGANIZED_DATA_PATH,\n",
    "    'batch_size': 16,  # Reduced for Colab memory limitations\n",
    "    'image_size': 224,\n",
    "    'num_workers': 2,  # Reduced for Colab\n",
    "    'unlabeled_ratio': 2.0,\n",
    "    \n",
    "    # Model settings\n",
    "    'model_name': 'vit_base_patch16_224',\n",
    "    'pretrained': True,\n",
    "    'dropout_rate': 0.1,\n",
    "    \n",
    "    # Training settings (optimized for Colab)\n",
    "    'epochs': 50,  # Reduced for faster training\n",
    "    'learning_rate': 1e-4,\n",
    "    'weight_decay': 0.05,\n",
    "    'warmup_epochs': 5,  # Reduced\n",
    "    'ramp_up_epochs': 10,  # Reduced\n",
    "    \n",
    "    # Semi-supervised settings\n",
    "    'ema_momentum': 0.999,\n",
    "    'consistency_loss': 'mse',\n",
    "    'consistency_weight': 1.0,\n",
    "    'pseudo_label_threshold': 0.95,\n",
    "    'temperature': 4.0,\n",
    "    \n",
    "    # System settings\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'seed': 42,\n",
    "    \n",
    "    # Saving settings\n",
    "    'save_dir': f'{OUTPUT_PATH}/checkpoints',\n",
    "    'save_frequency': 5,  # Save every 5 epochs\n",
    "    'use_wandb': USE_WANDB,\n",
    "    'wandb_project': 'vit-fish-colab',\n",
    "    'wandb_run_name': f'colab-run-{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\n",
    "}\n",
    "\n",
    "print(\"ğŸ¯ Training Configuration:\")\n",
    "for key, value in TRAINING_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Create checkpoint directory\n",
    "os.makedirs(TRAINING_CONFIG['save_dir'], exist_ok=True)\n",
    "print(f\"\\nğŸ“ Checkpoints will be saved to: {TRAINING_CONFIG['save_dir']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d5a063",
   "metadata": {},
   "source": [
    "## ğŸš€ Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37e5bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run semi-supervised training\n",
    "print(f\"ğŸš€ Starting semi-supervised training at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"ğŸ“Š Training for {TRAINING_CONFIG['epochs']} epochs with batch size {TRAINING_CONFIG['batch_size']}\")\n",
    "print(f\"ğŸ¯ Using device: {TRAINING_CONFIG['device']}\")\n",
    "\n",
    "# Build command arguments\n",
    "args = [\n",
    "    f\"--data_dir \\\"{TRAINING_CONFIG['data_dir']}\\\"\",\n",
    "    f\"--batch_size {TRAINING_CONFIG['batch_size']}\",\n",
    "    f\"--image_size {TRAINING_CONFIG['image_size']}\",\n",
    "    f\"--num_workers {TRAINING_CONFIG['num_workers']}\",\n",
    "    f\"--unlabeled_ratio {TRAINING_CONFIG['unlabeled_ratio']}\",\n",
    "    f\"--model_name {TRAINING_CONFIG['model_name']}\",\n",
    "    f\"--epochs {TRAINING_CONFIG['epochs']}\",\n",
    "    f\"--learning_rate {TRAINING_CONFIG['learning_rate']}\",\n",
    "    f\"--weight_decay {TRAINING_CONFIG['weight_decay']}\",\n",
    "    f\"--warmup_epochs {TRAINING_CONFIG['warmup_epochs']}\",\n",
    "    f\"--ramp_up_epochs {TRAINING_CONFIG['ramp_up_epochs']}\",\n",
    "    f\"--ema_momentum {TRAINING_CONFIG['ema_momentum']}\",\n",
    "    f\"--consistency_loss {TRAINING_CONFIG['consistency_loss']}\",\n",
    "    f\"--consistency_weight {TRAINING_CONFIG['consistency_weight']}\",\n",
    "    f\"--pseudo_label_threshold {TRAINING_CONFIG['pseudo_label_threshold']}\",\n",
    "    f\"--temperature {TRAINING_CONFIG['temperature']}\",\n",
    "    f\"--device {TRAINING_CONFIG['device']}\",\n",
    "    f\"--seed {TRAINING_CONFIG['seed']}\",\n",
    "    f\"--save_dir \\\"{TRAINING_CONFIG['save_dir']}\\\"\",\n",
    "    f\"--save_frequency {TRAINING_CONFIG['save_frequency']}\"\n",
    "]\n",
    "\n",
    "if TRAINING_CONFIG['use_wandb']:\n",
    "    args.extend([\n",
    "        \"--use_wandb\",\n",
    "        f\"--wandb_project {TRAINING_CONFIG['wandb_project']}\",\n",
    "        f\"--wandb_run_name {TRAINING_CONFIG['wandb_run_name']}\"\n",
    "    ])\n",
    "\n",
    "cmd = f\"python main_semi_supervised.py {' '.join(args)}\"\n",
    "\n",
    "print(\"\\nExecuting command:\")\n",
    "print(cmd)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Execute training\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3350e3",
   "metadata": {},
   "source": [
    "## ğŸ“Š Training Monitoring and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3f5ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check training results\n",
    "import glob\n",
    "from datetime import datetime\n",
    "\n",
    "checkpoint_dir = TRAINING_CONFIG['save_dir']\n",
    "checkpoints = glob.glob(os.path.join(checkpoint_dir, \"*.pth\"))\n",
    "\n",
    "print(f\"ğŸ” Checking results in: {checkpoint_dir}\")\n",
    "\n",
    "if checkpoints:\n",
    "    print(f\"âœ… Training completed! Found {len(checkpoints)} checkpoints:\")\n",
    "    for ckpt in sorted(checkpoints):\n",
    "        size_mb = os.path.getsize(ckpt) / (1024 * 1024)\n",
    "        mod_time = datetime.fromtimestamp(os.path.getmtime(ckpt)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        print(f\"  ğŸ“ {os.path.basename(ckpt)} ({size_mb:.1f} MB, modified: {mod_time})\")\n",
    "    \n",
    "    # Find best model\n",
    "    best_models = [ckpt for ckpt in checkpoints if 'best' in ckpt]\n",
    "    if best_models:\n",
    "        print(f\"\\nğŸ† Best model: {os.path.basename(best_models[0])}\")\n",
    "        \n",
    "    # Find latest model\n",
    "    latest_models = [ckpt for ckpt in checkpoints if 'latest' in ckpt or 'final' in ckpt]\n",
    "    if latest_models:\n",
    "        print(f\"ğŸ“Š Latest model: {os.path.basename(latest_models[0])}\")\n",
    "        \n",
    "else:\n",
    "    print(\"âŒ No checkpoints found. Training may have failed or is still running.\")\n",
    "    print(\"Check the output above for any error messages.\")\n",
    "\n",
    "# Check if W&B was used\n",
    "if USE_WANDB:\n",
    "    print(f\"\\nğŸ“ˆ View training metrics at: https://wandb.ai/{wandb.api.default_entity}/{TRAINING_CONFIG['wandb_project']}\")\n",
    "    print(f\"ğŸ”— Run name: {TRAINING_CONFIG['wandb_run_name']}\")\n",
    "\n",
    "# Check for log files\n",
    "log_files = glob.glob(os.path.join(checkpoint_dir, \"*.json\")) + glob.glob(os.path.join(checkpoint_dir, \"*.txt\"))\n",
    "if log_files:\n",
    "    print(f\"\\nğŸ“‹ Found {len(log_files)} log files:\")\n",
    "    for log in log_files:\n",
    "        print(f\"  ğŸ“„ {os.path.basename(log)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa2075b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training results (if available)\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Look for training history/log files\n",
    "checkpoint_dir = TRAINING_CONFIG['save_dir']\n",
    "log_files = glob.glob(os.path.join(checkpoint_dir, \"*history*.json\")) + \\\n",
    "           glob.glob(os.path.join(checkpoint_dir, \"*log*.json\")) + \\\n",
    "           glob.glob(os.path.join(checkpoint_dir, \"training_*.json\"))\n",
    "\n",
    "if log_files:\n",
    "    print(\"ğŸ“Š Plotting training results...\")\n",
    "    \n",
    "    try:\n",
    "        # Load the most recent log file\n",
    "        latest_log = max(log_files, key=os.path.getmtime)\n",
    "        print(f\"ğŸ“„ Loading results from: {os.path.basename(latest_log)}\")\n",
    "        \n",
    "        with open(latest_log, 'r') as f:\n",
    "            history = json.load(f)\n",
    "        \n",
    "        # Create subplots\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        fig.suptitle('ViT-FishID Training Results', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # Plot 1: Training and Validation Loss\n",
    "        ax1 = axes[0, 0]\n",
    "        if 'train_loss' in history and 'val_loss' in history:\n",
    "            epochs = range(1, len(history['train_loss']) + 1)\n",
    "            ax1.plot(epochs, history['train_loss'], 'b-', label='Training Loss', linewidth=2)\n",
    "            ax1.plot(epochs, history['val_loss'], 'r-', label='Validation Loss', linewidth=2)\n",
    "            ax1.set_title('Training and Validation Loss', fontweight='bold')\n",
    "            ax1.set_xlabel('Epoch')\n",
    "            ax1.set_ylabel('Loss')\n",
    "            ax1.legend()\n",
    "            ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 2: Validation Accuracy\n",
    "        ax2 = axes[0, 1]\n",
    "        if 'val_acc_student' in history or 'val_acc' in history:\n",
    "            val_acc_key = 'val_acc_student' if 'val_acc_student' in history else 'val_acc'\n",
    "            epochs = range(1, len(history[val_acc_key]) + 1)\n",
    "            ax2.plot(epochs, [acc * 100 for acc in history[val_acc_key]], 'g-', linewidth=2, label='Student')\n",
    "            \n",
    "            if 'val_acc_teacher' in history:\n",
    "                ax2.plot(epochs, [acc * 100 for acc in history['val_acc_teacher']], 'orange', linewidth=2, label='Teacher')\n",
    "                ax2.legend()\n",
    "            \n",
    "            ax2.set_title('Validation Accuracy', fontweight='bold')\n",
    "            ax2.set_xlabel('Epoch')\n",
    "            ax2.set_ylabel('Accuracy (%)')\n",
    "            ax2.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Show best accuracy\n",
    "            best_acc = max(history[val_acc_key]) * 100\n",
    "            ax2.axhline(y=best_acc, color='red', linestyle='--', alpha=0.7)\n",
    "            ax2.text(0.02, 0.98, f'Best: {best_acc:.1f}%', transform=ax2.transAxes, \n",
    "                    verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "        \n",
    "        # Plot 3: Consistency Loss\n",
    "        ax3 = axes[1, 0]\n",
    "        if 'consistency_loss' in history:\n",
    "            epochs = range(1, len(history['consistency_loss']) + 1)\n",
    "            ax3.plot(epochs, history['consistency_loss'], 'purple', linewidth=2)\n",
    "            ax3.set_title('Consistency Loss (Teacher-Student)', fontweight='bold')\n",
    "            ax3.set_xlabel('Epoch')\n",
    "            ax3.set_ylabel('Consistency Loss')\n",
    "            ax3.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 4: Learning Rate Schedule\n",
    "        ax4 = axes[1, 1]\n",
    "        if 'learning_rate' in history:\n",
    "            epochs = range(1, len(history['learning_rate']) + 1)\n",
    "            ax4.plot(epochs, history['learning_rate'], 'brown', linewidth=2)\n",
    "            ax4.set_title('Learning Rate Schedule', fontweight='bold')\n",
    "            ax4.set_xlabel('Epoch')\n",
    "            ax4.set_ylabel('Learning Rate')\n",
    "            ax4.set_yscale('log')\n",
    "            ax4.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print summary statistics\n",
    "        print(\"\\nğŸ“ˆ Training Summary:\")\n",
    "        if 'val_acc_student' in history or 'val_acc' in history:\n",
    "            val_acc_key = 'val_acc_student' if 'val_acc_student' in history else 'val_acc'\n",
    "            best_acc = max(history[val_acc_key]) * 100\n",
    "            final_acc = history[val_acc_key][-1] * 100\n",
    "            print(f\"  ğŸ¯ Best Validation Accuracy: {best_acc:.2f}%\")\n",
    "            print(f\"  ğŸ“Š Final Validation Accuracy: {final_acc:.2f}%\")\n",
    "        \n",
    "        if 'train_loss' in history:\n",
    "            initial_loss = history['train_loss'][0]\n",
    "            final_loss = history['train_loss'][-1]\n",
    "            print(f\"  ğŸ“‰ Loss Reduction: {initial_loss:.3f} â†’ {final_loss:.3f} ({((initial_loss - final_loss) / initial_loss * 100):.1f}% improvement)\")\n",
    "        \n",
    "        print(f\"  â±ï¸ Total Epochs Completed: {len(history.get('train_loss', []))}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Could not plot results: {e}\")\n",
    "        print(\"Available keys in history:\", list(history.keys()) if 'history' in locals() else \"No history loaded\")\n",
    "else:\n",
    "    print(\"ğŸ“Š No training log files found for plotting.\")\n",
    "    print(\"Training logs are typically saved as JSON files in the checkpoint directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864d3b1f",
   "metadata": {},
   "source": [
    "## ğŸ’¾ Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4af045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and download a zip file with all training results\n",
    "from google.colab import files\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "\n",
    "# Create a timestamped zip file\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "results_zip = f\"{OUTPUT_PATH}/vit_fish_results_{timestamp}.zip\"\n",
    "\n",
    "print(\"ğŸ“¦ Packaging training results...\")\n",
    "\n",
    "with zipfile.ZipFile(results_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    files_added = 0\n",
    "    \n",
    "    # Add model checkpoints\n",
    "    checkpoint_dir = TRAINING_CONFIG['save_dir']\n",
    "    for ckpt in glob.glob(os.path.join(checkpoint_dir, \"*.pth\")):\n",
    "        arcname = f\"checkpoints/{os.path.basename(ckpt)}\"\n",
    "        zipf.write(ckpt, arcname)\n",
    "        files_added += 1\n",
    "        print(f\"  âœ… Added checkpoint: {os.path.basename(ckpt)}\")\n",
    "    \n",
    "    # Add log files\n",
    "    for log in glob.glob(os.path.join(checkpoint_dir, \"*.json\")):\n",
    "        arcname = f\"logs/{os.path.basename(log)}\"\n",
    "        zipf.write(log, arcname)\n",
    "        files_added += 1\n",
    "        print(f\"  âœ… Added log: {os.path.basename(log)}\")\n",
    "    \n",
    "    # Add text files (training logs, etc.)\n",
    "    for txt in glob.glob(os.path.join(checkpoint_dir, \"*.txt\")):\n",
    "        arcname = f\"logs/{os.path.basename(txt)}\"\n",
    "        zipf.write(txt, arcname)\n",
    "        files_added += 1\n",
    "        print(f\"  âœ… Added text file: {os.path.basename(txt)}\")\n",
    "    \n",
    "    # Add dataset info if available\n",
    "    dataset_info = os.path.join(ORGANIZED_DATA_PATH, \"dataset_info.json\")\n",
    "    if os.path.exists(dataset_info):\n",
    "        zipf.write(dataset_info, \"dataset_info.json\")\n",
    "        files_added += 1\n",
    "        print(f\"  âœ… Added dataset info\")\n",
    "    \n",
    "    # Add a summary file\n",
    "    summary_content = f\"\"\"ViT-FishID Training Results Summary\n",
    "Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "Configuration:\n",
    "- Model: {TRAINING_CONFIG['model_name']}\n",
    "- Epochs: {TRAINING_CONFIG['epochs']}\n",
    "- Batch Size: {TRAINING_CONFIG['batch_size']}\n",
    "- Learning Rate: {TRAINING_CONFIG['learning_rate']}\n",
    "- Device: {TRAINING_CONFIG['device']}\n",
    "- Dataset: {TRAINING_CONFIG['data_dir']}\n",
    "\n",
    "Files included:\n",
    "- {len(glob.glob(os.path.join(checkpoint_dir, '*.pth')))} model checkpoints\n",
    "- {len(glob.glob(os.path.join(checkpoint_dir, '*.json')))} JSON log files\n",
    "- {len(glob.glob(os.path.join(checkpoint_dir, '*.txt')))} text log files\n",
    "\n",
    "Usage:\n",
    "1. Extract the zip file\n",
    "2. Load the best model checkpoint with PyTorch\n",
    "3. Use for inference on new fish images\n",
    "\n",
    "For questions or support, refer to the ViT-FishID repository.\n",
    "\"\"\"\n",
    "    \n",
    "    zipf.writestr(\"README.txt\", summary_content)\n",
    "    files_added += 1\n",
    "\n",
    "print(f\"\\nğŸ“¦ Results packaged successfully!\")\n",
    "print(f\"ğŸ“ File: {os.path.basename(results_zip)}\")\n",
    "print(f\"ğŸ“Š Size: {os.path.getsize(results_zip) / (1024*1024):.1f} MB\")\n",
    "print(f\"ğŸ“‹ Files included: {files_added}\")\n",
    "\n",
    "# Download the zip file\n",
    "if files_added > 0:\n",
    "    print(\"\\nâ¬‡ï¸ Downloading results to your computer...\")\n",
    "    files.download(results_zip)\n",
    "    print(\"âœ… Download complete!\")\n",
    "else:\n",
    "    print(\"âš ï¸ No files to download. Training may not have completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a61133",
   "metadata": {},
   "source": [
    "## ğŸ”® Quick Inference Demo (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e80d6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test of the trained model (if checkpoints exist)\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "checkpoint_dir = TRAINING_CONFIG['save_dir']\n",
    "best_models = glob.glob(os.path.join(checkpoint_dir, \"*best*.pth\"))\n",
    "\n",
    "if best_models and os.path.exists(ORGANIZED_DATA_PATH):\n",
    "    print(\"ğŸ”® Testing the trained model...\")\n",
    "    \n",
    "    try:\n",
    "        # Load the best model\n",
    "        model_path = best_models[0]\n",
    "        print(f\"ğŸ“ Loading model: {os.path.basename(model_path)}\")\n",
    "        \n",
    "        # Load model (you might need to adjust this based on how the model was saved)\n",
    "        checkpoint = torch.load(model_path, map_location='cpu')\n",
    "        \n",
    "        # Get some test images\n",
    "        test_images = []\n",
    "        labeled_dir = os.path.join(ORGANIZED_DATA_PATH, \"labeled\")\n",
    "        \n",
    "        if os.path.exists(labeled_dir):\n",
    "            for species_dir in os.listdir(labeled_dir)[:3]:  # Test first 3 species\n",
    "                species_path = os.path.join(labeled_dir, species_dir)\n",
    "                if os.path.isdir(species_path):\n",
    "                    images = [f for f in os.listdir(species_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))][:2]\n",
    "                    for img in images:\n",
    "                        test_images.append((os.path.join(species_path, img), species_dir))\n",
    "        \n",
    "        if test_images:\n",
    "            print(f\"ğŸŸ Testing on {len(test_images)} sample images...\")\n",
    "            \n",
    "            # Define transforms\n",
    "            transform = transforms.Compose([\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "            \n",
    "            for img_path, true_species in test_images[:3]:  # Show first 3 results\n",
    "                try:\n",
    "                    # Load and preprocess image\n",
    "                    image = Image.open(img_path).convert('RGB')\n",
    "                    input_tensor = transform(image).unsqueeze(0)\n",
    "                    \n",
    "                    print(f\"  ğŸ“¸ {os.path.basename(img_path)} (True: {true_species})\")\n",
    "                    print(f\"    âœ… Image loaded and preprocessed successfully\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"    âŒ Error processing {img_path}: {e}\")\n",
    "        else:\n",
    "            print(\"ğŸ” No test images found in labeled directory\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error testing model: {e}\")\n",
    "        print(\"This is normal - the demo requires the exact model architecture to be loaded.\")\n",
    "        \n",
    "else:\n",
    "    print(\"ğŸ”® Skipping inference demo (no trained model or dataset found)\")\n",
    "    \n",
    "print(\"\\nğŸ’¡ To use your trained model for inference:\")\n",
    "print(\"1. Download the results zip file\")\n",
    "print(\"2. Load the best checkpoint with your ViT model architecture\")\n",
    "print(\"3. Use the same preprocessing transforms as during training\")\n",
    "print(\"4. Run inference on new fish images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd314a70",
   "metadata": {},
   "source": [
    "## ğŸ§¹ Cleanup (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5a2b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up temporary files to free Google Drive space (optional)\n",
    "import shutil\n",
    "\n",
    "print(\"ğŸ§¹ Cleanup options to free Google Drive space:\")\n",
    "print(\"1. Keep everything (recommended if you want to resume training)\")\n",
    "print(\"2. Remove organized dataset (saves space, keep only results)\")\n",
    "print(\"3. Remove checkpoints (keep only the downloaded zip)\")\n",
    "print(\"4. Remove everything except results zip\")\n",
    "\n",
    "# Calculate current usage\n",
    "def get_directory_size(path):\n",
    "    if not os.path.exists(path):\n",
    "        return 0\n",
    "    total = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            filepath = os.path.join(dirpath, filename)\n",
    "            try:\n",
    "                total += os.path.getsize(filepath)\n",
    "            except (OSError, IOError):\n",
    "                pass\n",
    "    return total\n",
    "\n",
    "dataset_size = get_directory_size(ORGANIZED_DATA_PATH) / (1024**3)\n",
    "checkpoint_size = get_directory_size(TRAINING_CONFIG['save_dir']) / (1024**3)\n",
    "total_size = dataset_size + checkpoint_size\n",
    "\n",
    "print(f\"\\nğŸ“Š Current usage:\")\n",
    "print(f\"  ğŸ“ Organized dataset: {dataset_size:.2f} GB\")\n",
    "print(f\"  ğŸ’¾ Checkpoints: {checkpoint_size:.2f} GB\")\n",
    "print(f\"  ğŸ“Š Total: {total_size:.2f} GB\")\n",
    "\n",
    "cleanup_choice = input(\"\\nEnter choice (1-4): \")\n",
    "\n",
    "if cleanup_choice == \"2\":\n",
    "    if os.path.exists(ORGANIZED_DATA_PATH):\n",
    "        shutil.rmtree(ORGANIZED_DATA_PATH)\n",
    "        print(f\"ğŸ—‘ï¸ Removed organized dataset: {ORGANIZED_DATA_PATH}\")\n",
    "        print(f\"ğŸ’¾ Freed ~{dataset_size:.2f} GB of space\")\n",
    "        \n",
    "elif cleanup_choice == \"3\":\n",
    "    checkpoint_dir = TRAINING_CONFIG['save_dir']\n",
    "    if os.path.exists(checkpoint_dir):\n",
    "        shutil.rmtree(checkpoint_dir)\n",
    "        print(f\"ğŸ—‘ï¸ Removed checkpoints: {checkpoint_dir}\")\n",
    "        print(f\"ğŸ’¾ Freed ~{checkpoint_size:.2f} GB of space\")\n",
    "        \n",
    "elif cleanup_choice == \"4\":\n",
    "    if os.path.exists(ORGANIZED_DATA_PATH):\n",
    "        shutil.rmtree(ORGANIZED_DATA_PATH)\n",
    "    checkpoint_dir = TRAINING_CONFIG['save_dir']\n",
    "    if os.path.exists(checkpoint_dir):\n",
    "        shutil.rmtree(checkpoint_dir)\n",
    "    print(\"ğŸ—‘ï¸ Cleaned up all temporary files\")\n",
    "    print(f\"ğŸ’¾ Freed ~{total_size:.2f} GB of space\")\n",
    "    print(\"ğŸ“¦ Your results are still available in the downloaded zip file\")\n",
    "    \n",
    "else:\n",
    "    print(\"âœ… No cleanup performed - all files retained\")\n",
    "\n",
    "print(\"\\nğŸ‰ Training complete!\")\n",
    "print(\"\\nğŸ“‹ Summary of what you have:\")\n",
    "print(\"  âœ… Trained ViT model for fish classification\")\n",
    "print(\"  âœ… Training logs and metrics\")\n",
    "print(\"  âœ… Downloaded results zip file\")\n",
    "if USE_WANDB:\n",
    "    print(f\"  âœ… W&B dashboard: https://wandb.ai/{wandb.api.default_entity}/{TRAINING_CONFIG['wandb_project']}\")\n",
    "print(\"\\nğŸš€ Ready to classify fish with your trained model!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
