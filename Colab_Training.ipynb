{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a643cc05",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/cat-thomson/ViT-FishID/blob/main/Colab_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff015a55",
   "metadata": {},
   "source": [
    "# üêü ViT-FishID: Semi-Supervised Fish Classification in Google Colab\n",
    "\n",
    "This notebook runs the ViT-FishID semi-supervised learning pipeline in Google Colab with images stored in Google Drive.\n",
    "\n",
    "## Setup Requirements:\n",
    "1. **GitHub Repository**: Your code should be in a GitHub repo (images excluded via .gitignore)\n",
    "2. **Google Drive**: Your fish images should be organized in Google Drive\n",
    "3. **GPU Runtime**: Enable GPU in Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator ‚Üí GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ca7738",
   "metadata": {},
   "source": [
    "## üîß Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b67ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No GPU detected. Enable GPU: Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator ‚Üí GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c142378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone your GitHub repository\n",
    "import os\n",
    "\n",
    "# Replace with your actual GitHub repository URL\n",
    "REPO_URL = \"https://github.com/cat-thomson/ViT-FishID.git\"\n",
    "REPO_NAME = \"ViT-FishID\"\n",
    "\n",
    "# Clone repository if not already cloned\n",
    "if not os.path.exists(REPO_NAME):\n",
    "    !git clone {REPO_URL}\n",
    "    print(f\"‚úÖ Cloned {REPO_NAME}\")\n",
    "else:\n",
    "    print(f\"üìÅ {REPO_NAME} already exists\")\n",
    "\n",
    "# Change to repository directory\n",
    "os.chdir(REPO_NAME)\n",
    "print(f\"üìÇ Current directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59f60d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install -q timm transformers\n",
    "!pip install -q wandb\n",
    "!pip install -q pillow opencv-python\n",
    "!pip install -q scikit-learn matplotlib seaborn\n",
    "!pip install -q tqdm\n",
    "\n",
    "print(\"‚úÖ Dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0f6965",
   "metadata": {},
   "source": [
    "## üìÅ Google Drive Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc103b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Set your Google Drive paths\n",
    "# UPDATE THESE PATHS TO MATCH YOUR GOOGLE DRIVE STRUCTURE\n",
    "DRIVE_ROOT = \"/content/drive/MyDrive\"\n",
    "FISH_IMAGES_PATH = f\"{DRIVE_ROOT}/Fish_Images\"  # ‚ö†Ô∏è UPDATE THIS PATH\n",
    "OUTPUT_PATH = f\"{DRIVE_ROOT}/Fish_Training_Output\"  # Where to save results\n",
    "\n",
    "print(f\"üìÅ Drive mounted at: {DRIVE_ROOT}\")\n",
    "print(f\"üêü Fish images path: {FISH_IMAGES_PATH}\")\n",
    "print(f\"üíæ Output path: {OUTPUT_PATH}\")\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "# List contents of fish images directory\n",
    "if os.path.exists(FISH_IMAGES_PATH):\n",
    "    print(f\"\\nüìã Contents of {FISH_IMAGES_PATH}:\")\n",
    "    !ls -la \"{FISH_IMAGES_PATH}\"\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Path {FISH_IMAGES_PATH} not found. Please update FISH_IMAGES_PATH variable above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656291a7",
   "metadata": {},
   "source": [
    "## üìä Data Organization and Preparation\n",
    "\n",
    "This section helps you organize your fish images from Google Drive into the proper structure for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8af4bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if data is already organized\n",
    "ORGANIZED_DATA_PATH = f\"{OUTPUT_PATH}/organized_fish_dataset\"\n",
    "\n",
    "def check_data_structure(path):\n",
    "    \"\"\"Check if data is properly organized for training.\"\"\"\n",
    "    labeled_path = os.path.join(path, \"labeled\")\n",
    "    unlabeled_path = os.path.join(path, \"unlabeled\")\n",
    "    \n",
    "    if os.path.exists(labeled_path) and os.path.exists(unlabeled_path):\n",
    "        print(f\"‚úÖ Organized dataset found at: {path}\")\n",
    "        \n",
    "        # Count labeled species\n",
    "        species = [d for d in os.listdir(labeled_path) if os.path.isdir(os.path.join(labeled_path, d))]\n",
    "        print(f\"üìã Labeled species ({len(species)}): {species}\")\n",
    "        \n",
    "        # Count images\n",
    "        labeled_count = sum([len(os.listdir(os.path.join(labeled_path, s))) for s in species if os.path.isdir(os.path.join(labeled_path, s))])\n",
    "        unlabeled_files = [f for f in os.listdir(unlabeled_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        unlabeled_count = len(unlabeled_files)\n",
    "        \n",
    "        print(f\"üè∑Ô∏è Labeled images: {labeled_count}\")\n",
    "        print(f\"üîÑ Unlabeled images: {unlabeled_count}\")\n",
    "        print(f\"üìä Total images: {labeled_count + unlabeled_count}\")\n",
    "        \n",
    "        return True\n",
    "    else:\n",
    "        print(f\"‚ùå No organized dataset found at: {path}\")\n",
    "        return False\n",
    "\n",
    "data_organized = check_data_structure(ORGANIZED_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bb7726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize data if not already done\n",
    "if not data_organized:\n",
    "    print(\"üîÑ Organizing fish data...\")\n",
    "    \n",
    "    # Run the organize script with your fish images\n",
    "    # You may need to adjust these parameters based on your data structure\n",
    "    # Update the species list below based on your fish species\n",
    "    !python organize_fish_data.py \\\n",
    "        --input_dir \"{FISH_IMAGES_PATH}\" \\\n",
    "        --output_dir \"{ORGANIZED_DATA_PATH}\" \\\n",
    "        --labeled_species bass trout salmon tuna cod \\\n",
    "        --no-interactive\n",
    "    \n",
    "    # Check if organization was successful\n",
    "    data_organized = check_data_structure(ORGANIZED_DATA_PATH)\n",
    "    \n",
    "    if data_organized:\n",
    "        print(\"‚úÖ Data organization complete!\")\n",
    "    else:\n",
    "        print(\"‚ùå Data organization failed. Please check your input path and data structure.\")\n",
    "        print(\"\\nTroubleshooting tips:\")\n",
    "        print(\"1. Make sure FISH_IMAGES_PATH points to your fish images in Google Drive\")\n",
    "        print(\"2. Update the --labeled_species list to match your fish species\")\n",
    "        print(\"3. Your images should be in common formats (jpg, jpeg, png)\")\n",
    "else:\n",
    "    print(\"‚úÖ Data already organized, skipping organization step.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12430b9",
   "metadata": {},
   "source": [
    "## üéØ Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02c587f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Weights & Biases (optional but recommended)\n",
    "import wandb\n",
    "\n",
    "# Login to wandb (you'll need to enter your API key)\n",
    "print(\"üîë Setting up Weights & Biases...\")\n",
    "print(\"If you don't have a W&B account, create one at https://wandb.ai/\")\n",
    "print(\"Get your API key from https://wandb.ai/authorize\")\n",
    "\n",
    "try:\n",
    "    wandb.login()\n",
    "    USE_WANDB = True\n",
    "    print(\"‚úÖ W&B login successful!\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è W&B login failed. Training will continue without logging.\")\n",
    "    USE_WANDB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315a0e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration optimized for Google Colab\n",
    "from datetime import datetime\n",
    "\n",
    "TRAINING_CONFIG = {\n",
    "    # Data settings\n",
    "    'data_dir': ORGANIZED_DATA_PATH,\n",
    "    'batch_size': 16,  # Reduced for Colab memory limitations\n",
    "    'image_size': 224,\n",
    "    'num_workers': 2,  # Reduced for Colab\n",
    "    'unlabeled_ratio': 2.0,\n",
    "    \n",
    "    # Model settings\n",
    "    'model_name': 'vit_base_patch16_224',\n",
    "    'pretrained': True,\n",
    "    'dropout_rate': 0.1,\n",
    "    \n",
    "    # Training settings (optimized for Colab)\n",
    "    'epochs': 50,  # Reduced for faster training\n",
    "    'learning_rate': 1e-4,\n",
    "    'weight_decay': 0.05,\n",
    "    'warmup_epochs': 5,  # Reduced\n",
    "    'ramp_up_epochs': 10,  # Reduced\n",
    "    \n",
    "    # Semi-supervised settings\n",
    "    'ema_momentum': 0.999,\n",
    "    'consistency_loss': 'mse',\n",
    "    'consistency_weight': 1.0,\n",
    "    'pseudo_label_threshold': 0.95,\n",
    "    'temperature': 4.0,\n",
    "    \n",
    "    # System settings\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'seed': 42,\n",
    "    \n",
    "    # Saving settings\n",
    "    'save_dir': f'{OUTPUT_PATH}/checkpoints',\n",
    "    'save_frequency': 5,  # Save every 5 epochs\n",
    "    'use_wandb': USE_WANDB,\n",
    "    'wandb_project': 'vit-fish-colab',\n",
    "    'wandb_run_name': f'colab-run-{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\n",
    "}\n",
    "\n",
    "print(\"üéØ Training Configuration:\")\n",
    "for key, value in TRAINING_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Create checkpoint directory\n",
    "os.makedirs(TRAINING_CONFIG['save_dir'], exist_ok=True)\n",
    "print(f\"\\nüìÅ Checkpoints will be saved to: {TRAINING_CONFIG['save_dir']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d5a063",
   "metadata": {},
   "source": [
    "## üöÄ Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37e5bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run semi-supervised training\n",
    "print(f\"üöÄ Starting semi-supervised training at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"üìä Training for {TRAINING_CONFIG['epochs']} epochs with batch size {TRAINING_CONFIG['batch_size']}\")\n",
    "print(f\"üéØ Using device: {TRAINING_CONFIG['device']}\")\n",
    "\n",
    "# Build command arguments\n",
    "args = [\n",
    "    f\"--data_dir \\\"{TRAINING_CONFIG['data_dir']}\\\"\",\n",
    "    f\"--batch_size {TRAINING_CONFIG['batch_size']}\",\n",
    "    f\"--image_size {TRAINING_CONFIG['image_size']}\",\n",
    "    f\"--num_workers {TRAINING_CONFIG['num_workers']}\",\n",
    "    f\"--unlabeled_ratio {TRAINING_CONFIG['unlabeled_ratio']}\",\n",
    "    f\"--model_name {TRAINING_CONFIG['model_name']}\",\n",
    "    f\"--epochs {TRAINING_CONFIG['epochs']}\",\n",
    "    f\"--learning_rate {TRAINING_CONFIG['learning_rate']}\",\n",
    "    f\"--weight_decay {TRAINING_CONFIG['weight_decay']}\",\n",
    "    f\"--warmup_epochs {TRAINING_CONFIG['warmup_epochs']}\",\n",
    "    f\"--ramp_up_epochs {TRAINING_CONFIG['ramp_up_epochs']}\",\n",
    "    f\"--ema_momentum {TRAINING_CONFIG['ema_momentum']}\",\n",
    "    f\"--consistency_loss {TRAINING_CONFIG['consistency_loss']}\",\n",
    "    f\"--consistency_weight {TRAINING_CONFIG['consistency_weight']}\",\n",
    "    f\"--pseudo_label_threshold {TRAINING_CONFIG['pseudo_label_threshold']}\",\n",
    "    f\"--temperature {TRAINING_CONFIG['temperature']}\",\n",
    "    f\"--device {TRAINING_CONFIG['device']}\",\n",
    "    f\"--seed {TRAINING_CONFIG['seed']}\",\n",
    "    f\"--save_dir \\\"{TRAINING_CONFIG['save_dir']}\\\"\",\n",
    "    f\"--save_frequency {TRAINING_CONFIG['save_frequency']}\"\n",
    "]\n",
    "\n",
    "if TRAINING_CONFIG['use_wandb']:\n",
    "    args.extend([\n",
    "        \"--use_wandb\",\n",
    "        f\"--wandb_project {TRAINING_CONFIG['wandb_project']}\",\n",
    "        f\"--wandb_run_name {TRAINING_CONFIG['wandb_run_name']}\"\n",
    "    ])\n",
    "\n",
    "cmd = f\"python main_semi_supervised.py {' '.join(args)}\"\n",
    "\n",
    "print(\"\\nExecuting command:\")\n",
    "print(cmd)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Execute training\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3350e3",
   "metadata": {},
   "source": [
    "## üìä Training Monitoring and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3f5ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check training results\n",
    "import glob\n",
    "from datetime import datetime\n",
    "\n",
    "checkpoint_dir = TRAINING_CONFIG['save_dir']\n",
    "checkpoints = glob.glob(os.path.join(checkpoint_dir, \"*.pth\"))\n",
    "\n",
    "print(f\"üîç Checking results in: {checkpoint_dir}\")\n",
    "\n",
    "if checkpoints:\n",
    "    print(f\"‚úÖ Training completed! Found {len(checkpoints)} checkpoints:\")\n",
    "    for ckpt in sorted(checkpoints):\n",
    "        size_mb = os.path.getsize(ckpt) / (1024 * 1024)\n",
    "        mod_time = datetime.fromtimestamp(os.path.getmtime(ckpt)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        print(f\"  üìÅ {os.path.basename(ckpt)} ({size_mb:.1f} MB, modified: {mod_time})\")\n",
    "    \n",
    "    # Find best model\n",
    "    best_models = [ckpt for ckpt in checkpoints if 'best' in ckpt]\n",
    "    if best_models:\n",
    "        print(f\"\\nüèÜ Best model: {os.path.basename(best_models[0])}\")\n",
    "        \n",
    "    # Find latest model\n",
    "    latest_models = [ckpt for ckpt in checkpoints if 'latest' in ckpt or 'final' in ckpt]\n",
    "    if latest_models:\n",
    "        print(f\"üìä Latest model: {os.path.basename(latest_models[0])}\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå No checkpoints found. Training may have failed or is still running.\")\n",
    "    print(\"Check the output above for any error messages.\")\n",
    "\n",
    "# Check if W&B was used\n",
    "if USE_WANDB:\n",
    "    print(f\"\\nüìà View training metrics at: https://wandb.ai/{wandb.api.default_entity}/{TRAINING_CONFIG['wandb_project']}\")\n",
    "    print(f\"üîó Run name: {TRAINING_CONFIG['wandb_run_name']}\")\n",
    "\n",
    "# Check for log files\n",
    "log_files = glob.glob(os.path.join(checkpoint_dir, \"*.json\")) + glob.glob(os.path.join(checkpoint_dir, \"*.txt\"))\n",
    "if log_files:\n",
    "    print(f\"\\nüìã Found {len(log_files)} log files:\")\n",
    "    for log in log_files:\n",
    "        print(f\"  üìÑ {os.path.basename(log)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa2075b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training results (if available)\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Look for training history/log files\n",
    "checkpoint_dir = TRAINING_CONFIG['save_dir']\n",
    "log_files = glob.glob(os.path.join(checkpoint_dir, \"*history*.json\")) + \\\n",
    "           glob.glob(os.path.join(checkpoint_dir, \"*log*.json\")) + \\\n",
    "           glob.glob(os.path.join(checkpoint_dir, \"training_*.json\"))\n",
    "\n",
    "if log_files:\n",
    "    print(\"üìä Plotting training results...\")\n",
    "    \n",
    "    try:\n",
    "        # Load the most recent log file\n",
    "        latest_log = max(log_files, key=os.path.getmtime)\n",
    "        print(f\"üìÑ Loading results from: {os.path.basename(latest_log)}\")\n",
    "        \n",
    "        with open(latest_log, 'r') as f:\n",
    "            history = json.load(f)\n",
    "        \n",
    "        # Create subplots\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        fig.suptitle('ViT-FishID Training Results', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # Plot 1: Training and Validation Loss\n",
    "        ax1 = axes[0, 0]\n",
    "        if 'train_loss' in history and 'val_loss' in history:\n",
    "            epochs = range(1, len(history['train_loss']) + 1)\n",
    "            ax1.plot(epochs, history['train_loss'], 'b-', label='Training Loss', linewidth=2)\n",
    "            ax1.plot(epochs, history['val_loss'], 'r-', label='Validation Loss', linewidth=2)\n",
    "            ax1.set_title('Training and Validation Loss', fontweight='bold')\n",
    "            ax1.set_xlabel('Epoch')\n",
    "            ax1.set_ylabel('Loss')\n",
    "            ax1.legend()\n",
    "            ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 2: Validation Accuracy\n",
    "        ax2 = axes[0, 1]\n",
    "        if 'val_acc_student' in history or 'val_acc' in history:\n",
    "            val_acc_key = 'val_acc_student' if 'val_acc_student' in history else 'val_acc'\n",
    "            epochs = range(1, len(history[val_acc_key]) + 1)\n",
    "            ax2.plot(epochs, [acc * 100 for acc in history[val_acc_key]], 'g-', linewidth=2, label='Student')\n",
    "            \n",
    "            if 'val_acc_teacher' in history:\n",
    "                ax2.plot(epochs, [acc * 100 for acc in history['val_acc_teacher']], 'orange', linewidth=2, label='Teacher')\n",
    "                ax2.legend()\n",
    "            \n",
    "            ax2.set_title('Validation Accuracy', fontweight='bold')\n",
    "            ax2.set_xlabel('Epoch')\n",
    "            ax2.set_ylabel('Accuracy (%)')\n",
    "            ax2.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Show best accuracy\n",
    "            best_acc = max(history[val_acc_key]) * 100\n",
    "            ax2.axhline(y=best_acc, color='red', linestyle='--', alpha=0.7)\n",
    "            ax2.text(0.02, 0.98, f'Best: {best_acc:.1f}%', transform=ax2.transAxes, \n",
    "                    verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "        \n",
    "        # Plot 3: Consistency Loss\n",
    "        ax3 = axes[1, 0]\n",
    "        if 'consistency_loss' in history:\n",
    "            epochs = range(1, len(history['consistency_loss']) + 1)\n",
    "            ax3.plot(epochs, history['consistency_loss'], 'purple', linewidth=2)\n",
    "            ax3.set_title('Consistency Loss (Teacher-Student)', fontweight='bold')\n",
    "            ax3.set_xlabel('Epoch')\n",
    "            ax3.set_ylabel('Consistency Loss')\n",
    "            ax3.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 4: Learning Rate Schedule\n",
    "        ax4 = axes[1, 1]\n",
    "        if 'learning_rate' in history:\n",
    "            epochs = range(1, len(history['learning_rate']) + 1)\n",
    "            ax4.plot(epochs, history['learning_rate'], 'brown', linewidth=2)\n",
    "            ax4.set_title('Learning Rate Schedule', fontweight='bold')\n",
    "            ax4.set_xlabel('Epoch')\n",
    "            ax4.set_ylabel('Learning Rate')\n",
    "            ax4.set_yscale('log')\n",
    "            ax4.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print summary statistics\n",
    "        print(\"\\nüìà Training Summary:\")\n",
    "        if 'val_acc_student' in history or 'val_acc' in history:\n",
    "            val_acc_key = 'val_acc_student' if 'val_acc_student' in history else 'val_acc'\n",
    "            best_acc = max(history[val_acc_key]) * 100\n",
    "            final_acc = history[val_acc_key][-1] * 100\n",
    "            print(f\"  üéØ Best Validation Accuracy: {best_acc:.2f}%\")\n",
    "            print(f\"  üìä Final Validation Accuracy: {final_acc:.2f}%\")\n",
    "        \n",
    "        if 'train_loss' in history:\n",
    "            initial_loss = history['train_loss'][0]\n",
    "            final_loss = history['train_loss'][-1]\n",
    "            print(f\"  üìâ Loss Reduction: {initial_loss:.3f} ‚Üí {final_loss:.3f} ({((initial_loss - final_loss) / initial_loss * 100):.1f}% improvement)\")\n",
    "        \n",
    "        print(f\"  ‚è±Ô∏è Total Epochs Completed: {len(history.get('train_loss', []))}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Could not plot results: {e}\")\n",
    "        print(\"Available keys in history:\", list(history.keys()) if 'history' in locals() else \"No history loaded\")\n",
    "else:\n",
    "    print(\"üìä No training log files found for plotting.\")\n",
    "    print(\"Training logs are typically saved as JSON files in the checkpoint directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864d3b1f",
   "metadata": {},
   "source": [
    "## üíæ Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4af045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and download a zip file with all training results\n",
    "from google.colab import files\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "\n",
    "# Create a timestamped zip file\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "results_zip = f\"{OUTPUT_PATH}/vit_fish_results_{timestamp}.zip\"\n",
    "\n",
    "print(\"üì¶ Packaging training results...\")\n",
    "\n",
    "with zipfile.ZipFile(results_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    files_added = 0\n",
    "    \n",
    "    # Add model checkpoints\n",
    "    checkpoint_dir = TRAINING_CONFIG['save_dir']\n",
    "    for ckpt in glob.glob(os.path.join(checkpoint_dir, \"*.pth\")):\n",
    "        arcname = f\"checkpoints/{os.path.basename(ckpt)}\"\n",
    "        zipf.write(ckpt, arcname)\n",
    "        files_added += 1\n",
    "        print(f\"  ‚úÖ Added checkpoint: {os.path.basename(ckpt)}\")\n",
    "    \n",
    "    # Add log files\n",
    "    for log in glob.glob(os.path.join(checkpoint_dir, \"*.json\")):\n",
    "        arcname = f\"logs/{os.path.basename(log)}\"\n",
    "        zipf.write(log, arcname)\n",
    "        files_added += 1\n",
    "        print(f\"  ‚úÖ Added log: {os.path.basename(log)}\")\n",
    "    \n",
    "    # Add text files (training logs, etc.)\n",
    "    for txt in glob.glob(os.path.join(checkpoint_dir, \"*.txt\")):\n",
    "        arcname = f\"logs/{os.path.basename(txt)}\"\n",
    "        zipf.write(txt, arcname)\n",
    "        files_added += 1\n",
    "        print(f\"  ‚úÖ Added text file: {os.path.basename(txt)}\")\n",
    "    \n",
    "    # Add dataset info if available\n",
    "    dataset_info = os.path.join(ORGANIZED_DATA_PATH, \"dataset_info.json\")\n",
    "    if os.path.exists(dataset_info):\n",
    "        zipf.write(dataset_info, \"dataset_info.json\")\n",
    "        files_added += 1\n",
    "        print(f\"  ‚úÖ Added dataset info\")\n",
    "    \n",
    "    # Add a summary file\n",
    "    summary_content = f\"\"\"ViT-FishID Training Results Summary\n",
    "Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "Configuration:\n",
    "- Model: {TRAINING_CONFIG['model_name']}\n",
    "- Epochs: {TRAINING_CONFIG['epochs']}\n",
    "- Batch Size: {TRAINING_CONFIG['batch_size']}\n",
    "- Learning Rate: {TRAINING_CONFIG['learning_rate']}\n",
    "- Device: {TRAINING_CONFIG['device']}\n",
    "- Dataset: {TRAINING_CONFIG['data_dir']}\n",
    "\n",
    "Files included:\n",
    "- {len(glob.glob(os.path.join(checkpoint_dir, '*.pth')))} model checkpoints\n",
    "- {len(glob.glob(os.path.join(checkpoint_dir, '*.json')))} JSON log files\n",
    "- {len(glob.glob(os.path.join(checkpoint_dir, '*.txt')))} text log files\n",
    "\n",
    "Usage:\n",
    "1. Extract the zip file\n",
    "2. Load the best model checkpoint with PyTorch\n",
    "3. Use for inference on new fish images\n",
    "\n",
    "For questions or support, refer to the ViT-FishID repository.\n",
    "\"\"\"\n",
    "    \n",
    "    zipf.writestr(\"README.txt\", summary_content)\n",
    "    files_added += 1\n",
    "\n",
    "print(f\"\\nüì¶ Results packaged successfully!\")\n",
    "print(f\"üìÅ File: {os.path.basename(results_zip)}\")\n",
    "print(f\"üìä Size: {os.path.getsize(results_zip) / (1024*1024):.1f} MB\")\n",
    "print(f\"üìã Files included: {files_added}\")\n",
    "\n",
    "# Download the zip file\n",
    "if files_added > 0:\n",
    "    print(\"\\n‚¨áÔ∏è Downloading results to your computer...\")\n",
    "    files.download(results_zip)\n",
    "    print(\"‚úÖ Download complete!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No files to download. Training may not have completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a61133",
   "metadata": {},
   "source": [
    "## üîÆ Quick Inference Demo (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e80d6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test of the trained model (if checkpoints exist)\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "checkpoint_dir = TRAINING_CONFIG['save_dir']\n",
    "best_models = glob.glob(os.path.join(checkpoint_dir, \"*best*.pth\"))\n",
    "\n",
    "if best_models and os.path.exists(ORGANIZED_DATA_PATH):\n",
    "    print(\"üîÆ Testing the trained model...\")\n",
    "    \n",
    "    try:\n",
    "        # Load the best model\n",
    "        model_path = best_models[0]\n",
    "        print(f\"üìÅ Loading model: {os.path.basename(model_path)}\")\n",
    "        \n",
    "        # Load model (you might need to adjust this based on how the model was saved)\n",
    "        checkpoint = torch.load(model_path, map_location='cpu')\n",
    "        \n",
    "        # Get some test images\n",
    "        test_images = []\n",
    "        labeled_dir = os.path.join(ORGANIZED_DATA_PATH, \"labeled\")\n",
    "        \n",
    "        if os.path.exists(labeled_dir):\n",
    "            for species_dir in os.listdir(labeled_dir)[:3]:  # Test first 3 species\n",
    "                species_path = os.path.join(labeled_dir, species_dir)\n",
    "                if os.path.isdir(species_path):\n",
    "                    images = [f for f in os.listdir(species_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))][:2]\n",
    "                    for img in images:\n",
    "                        test_images.append((os.path.join(species_path, img), species_dir))\n",
    "        \n",
    "        if test_images:\n",
    "            print(f\"üêü Testing on {len(test_images)} sample images...\")\n",
    "            \n",
    "            # Define transforms\n",
    "            transform = transforms.Compose([\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "            \n",
    "            for img_path, true_species in test_images[:3]:  # Show first 3 results\n",
    "                try:\n",
    "                    # Load and preprocess image\n",
    "                    image = Image.open(img_path).convert('RGB')\n",
    "                    input_tensor = transform(image).unsqueeze(0)\n",
    "                    \n",
    "                    print(f\"  üì∏ {os.path.basename(img_path)} (True: {true_species})\")\n",
    "                    print(f\"    ‚úÖ Image loaded and preprocessed successfully\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"    ‚ùå Error processing {img_path}: {e}\")\n",
    "        else:\n",
    "            print(\"üîç No test images found in labeled directory\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error testing model: {e}\")\n",
    "        print(\"This is normal - the demo requires the exact model architecture to be loaded.\")\n",
    "        \n",
    "else:\n",
    "    print(\"üîÆ Skipping inference demo (no trained model or dataset found)\")\n",
    "    \n",
    "print(\"\\nüí° To use your trained model for inference:\")\n",
    "print(\"1. Download the results zip file\")\n",
    "print(\"2. Load the best checkpoint with your ViT model architecture\")\n",
    "print(\"3. Use the same preprocessing transforms as during training\")\n",
    "print(\"4. Run inference on new fish images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd314a70",
   "metadata": {},
   "source": [
    "## üßπ Cleanup (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5a2b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up temporary files to free Google Drive space (optional)\n",
    "import shutil\n",
    "\n",
    "print(\"üßπ Cleanup options to free Google Drive space:\")\n",
    "print(\"1. Keep everything (recommended if you want to resume training)\")\n",
    "print(\"2. Remove organized dataset (saves space, keep only results)\")\n",
    "print(\"3. Remove checkpoints (keep only the downloaded zip)\")\n",
    "print(\"4. Remove everything except results zip\")\n",
    "\n",
    "# Calculate current usage\n",
    "def get_directory_size(path):\n",
    "    if not os.path.exists(path):\n",
    "        return 0\n",
    "    total = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            filepath = os.path.join(dirpath, filename)\n",
    "            try:\n",
    "                total += os.path.getsize(filepath)\n",
    "            except (OSError, IOError):\n",
    "                pass\n",
    "    return total\n",
    "\n",
    "dataset_size = get_directory_size(ORGANIZED_DATA_PATH) / (1024**3)\n",
    "checkpoint_size = get_directory_size(TRAINING_CONFIG['save_dir']) / (1024**3)\n",
    "total_size = dataset_size + checkpoint_size\n",
    "\n",
    "print(f\"\\nüìä Current usage:\")\n",
    "print(f\"  üìÅ Organized dataset: {dataset_size:.2f} GB\")\n",
    "print(f\"  üíæ Checkpoints: {checkpoint_size:.2f} GB\")\n",
    "print(f\"  üìä Total: {total_size:.2f} GB\")\n",
    "\n",
    "cleanup_choice = input(\"\\nEnter choice (1-4): \")\n",
    "\n",
    "if cleanup_choice == \"2\":\n",
    "    if os.path.exists(ORGANIZED_DATA_PATH):\n",
    "        shutil.rmtree(ORGANIZED_DATA_PATH)\n",
    "        print(f\"üóëÔ∏è Removed organized dataset: {ORGANIZED_DATA_PATH}\")\n",
    "        print(f\"üíæ Freed ~{dataset_size:.2f} GB of space\")\n",
    "        \n",
    "elif cleanup_choice == \"3\":\n",
    "    checkpoint_dir = TRAINING_CONFIG['save_dir']\n",
    "    if os.path.exists(checkpoint_dir):\n",
    "        shutil.rmtree(checkpoint_dir)\n",
    "        print(f\"üóëÔ∏è Removed checkpoints: {checkpoint_dir}\")\n",
    "        print(f\"üíæ Freed ~{checkpoint_size:.2f} GB of space\")\n",
    "        \n",
    "elif cleanup_choice == \"4\":\n",
    "    if os.path.exists(ORGANIZED_DATA_PATH):\n",
    "        shutil.rmtree(ORGANIZED_DATA_PATH)\n",
    "    checkpoint_dir = TRAINING_CONFIG['save_dir']\n",
    "    if os.path.exists(checkpoint_dir):\n",
    "        shutil.rmtree(checkpoint_dir)\n",
    "    print(\"üóëÔ∏è Cleaned up all temporary files\")\n",
    "    print(f\"üíæ Freed ~{total_size:.2f} GB of space\")\n",
    "    print(\"üì¶ Your results are still available in the downloaded zip file\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚úÖ No cleanup performed - all files retained\")\n",
    "\n",
    "print(\"\\nüéâ Training complete!\")\n",
    "print(\"\\nüìã Summary of what you have:\")\n",
    "print(\"  ‚úÖ Trained ViT model for fish classification\")\n",
    "print(\"  ‚úÖ Training logs and metrics\")\n",
    "print(\"  ‚úÖ Downloaded results zip file\")\n",
    "if USE_WANDB:\n",
    "    print(f\"  ‚úÖ W&B dashboard: https://wandb.ai/{wandb.api.default_entity}/{TRAINING_CONFIG['wandb_project']}\")\n",
    "print(\"\\nüöÄ Ready to classify fish with your trained model!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
