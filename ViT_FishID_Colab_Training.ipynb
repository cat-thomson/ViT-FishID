{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0e0af9a0",
      "metadata": {
        "id": "0e0af9a0"
      },
      "source": [
        "# 🚀 ViT-FishID: Resume Training from Epoch 19\n",
        "\n",
        "**COLAB PRO EXTENDED TRAINING**\n",
        "- Resume from: Epoch 19 checkpoint\n",
        "- Target epochs: 100 total epochs (81 remaining)\n",
        "- Expected training time: 6-8 hours with Colab Pro\n",
        "- GPU: Tesla T4/V100/A100 (depending on availability)\n",
        "\n",
        "This notebook will:\n",
        "1. ✅ Resume training from your saved checkpoint at epoch 19\n",
        "2. ✅ Train for 100 total epochs (81 more epochs)\n",
        "3. ✅ Save checkpoints to Google Drive every 10 epochs\n",
        "4. ✅ Use semi-supervised learning with your fish dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "796c6e33",
      "metadata": {
        "id": "796c6e33"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cat-thomson/ViT-FishID/blob/main/ViT_FishID_Colab_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f2f60df",
      "metadata": {
        "id": "1f2f60df"
      },
      "source": [
        "# 🐟 ViT-FishID: Extended Training Session\n",
        "\n",
        "**RESUME FROM EPOCH 19 - COLAB PRO**\n",
        "\n",
        "This notebook resumes training from your saved checkpoint and runs for 100 total epochs.\n",
        "\n",
        "**Current Status:**\n",
        "- ✅ Previous training: 19 epochs completed\n",
        "- 🎯 Target: 100 total epochs (81 remaining)\n",
        "- ⏱️ Expected time: 6-8 hours with Colab Pro\n",
        "- 💾 Auto-save every 10 epochs to Google Drive\n",
        "\n",
        "**Performance Target:**\n",
        "- Previous: ~78% validation accuracy at epoch 19\n",
        "- Expected: 85-90% accuracy after 100 epochs\n",
        "- Memory: ~8-12GB GPU memory"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26bcb2a3",
      "metadata": {
        "id": "26bcb2a3"
      },
      "source": [
        "## 🚀 Step 1: Setup and GPU Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f3540b19",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3540b19",
        "outputId": "ebf87cf1-7244-44fa-831c-023a5b2d06ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 System Information:\n",
            "Python version: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
            "PyTorch version: 2.6.0+cu124\n",
            "CUDA available: True\n",
            "GPU Device: NVIDIA A100-SXM4-40GB\n",
            "GPU Memory: 39.6 GB\n",
            "✅ GPU is ready for training!\n"
          ]
        }
      ],
      "source": [
        "# Check GPU availability\n",
        "import torch\n",
        "import os\n",
        "\n",
        "print(\"🔍 System Information:\")\n",
        "print(f\"Python version: {os.sys.version}\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "    print(\"✅ GPU is ready for training!\")\n",
        "else:\n",
        "    print(\"❌ No GPU detected. Please enable GPU runtime:\")\n",
        "    print(\"   Runtime → Change runtime type → Hardware accelerator → GPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "149f671b",
      "metadata": {
        "id": "149f671b"
      },
      "source": [
        "## 📁 Step 2: Mount Google Drive\n",
        "\n",
        "This will give us access to your fish dataset stored in Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4abb3ffd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4abb3ffd",
        "outputId": "353bd706-8da0-4904-b5fe-50dea3e03594"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\n",
            "📂 Google Drive contents:\n",
            "  - Mock Matric\n",
            "  - Photos\n",
            "  - Admin\n",
            "  - Uni\n",
            "  - Fish_Training_Output\n",
            "  - Colab Notebooks\n",
            "  - ViT-FishID\n",
            "  - fish_cutouts.zip\n",
            "  - ViT-FishID_Training_20250814_154652\n",
            "\n",
            "✅ Google Drive mounted successfully!\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# List contents to verify mount\n",
        "print(\"\\n📂 Google Drive contents:\")\n",
        "drive_path = '/content/drive/MyDrive'\n",
        "if os.path.exists(drive_path):\n",
        "    items = os.listdir(drive_path)[:10]  # Show first 10 items\n",
        "    for item in items:\n",
        "        print(f\"  - {item}\")\n",
        "    if len(os.listdir(drive_path)) > 10:\n",
        "        print(f\"  ... and {len(os.listdir(drive_path)) - 10} more items\")\n",
        "    print(\"\\n✅ Google Drive mounted successfully!\")\n",
        "else:\n",
        "    print(\"❌ Failed to mount Google Drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be8b6273",
      "metadata": {
        "id": "be8b6273"
      },
      "source": [
        "## 📦 Step 3: Install Dependencies\n",
        "\n",
        "Installing all required packages for ViT-FishID training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8c724abc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c724abc",
        "outputId": "91408b3d-5785-4e91-f408-05b98400c5b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📦 Installing dependencies...\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m128.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m99.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m109.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h✅ All dependencies installed successfully!\n",
            "\n",
            "📋 Package versions:\n",
            "  - torch: 2.6.0+cu124\n",
            "  - torchvision: 0.21.0+cu124\n",
            "  - timm: 1.0.19\n",
            "  - albumentations: 2.0.8\n",
            "  - opencv: 4.12.0\n",
            "  - sklearn: 1.6.1\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "print(\"📦 Installing dependencies...\")\n",
        "\n",
        "!pip install -q torch torchvision torchaudio\n",
        "!pip install -q timm transformers\n",
        "!pip install -q albumentations\n",
        "!pip install -q wandb\n",
        "!pip install -q opencv-python-headless\n",
        "!pip install -q scikit-learn\n",
        "!pip install -q matplotlib seaborn\n",
        "!pip install -q tqdm\n",
        "\n",
        "print(\"✅ All dependencies installed successfully!\")\n",
        "\n",
        "# Verify installations\n",
        "import torch\n",
        "import torchvision\n",
        "import timm\n",
        "import albumentations\n",
        "import cv2\n",
        "import sklearn\n",
        "\n",
        "print(\"\\n📋 Package versions:\")\n",
        "print(f\"  - torch: {torch.__version__}\")\n",
        "print(f\"  - torchvision: {torchvision.__version__}\")\n",
        "print(f\"  - timm: {timm.__version__}\")\n",
        "print(f\"  - albumentations: {albumentations.__version__}\")\n",
        "print(f\"  - opencv: {cv2.__version__}\")\n",
        "print(f\"  - sklearn: {sklearn.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12b795fc",
      "metadata": {
        "id": "12b795fc"
      },
      "source": [
        "## 🔄 Step 4: Clone ViT-FishID Repository\n",
        "\n",
        "Getting the latest code from your GitHub repository."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c4e4cd45",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4e4cd45",
        "outputId": "264a087d-d669-4eaa-d799-a61a5c1470e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📥 Cloning ViT-FishID repository...\n",
            "Cloning into '/content/ViT-FishID'...\n",
            "remote: Enumerating objects: 116, done.\u001b[K\n",
            "remote: Counting objects: 100% (116/116), done.\u001b[K\n",
            "remote: Compressing objects: 100% (83/83), done.\u001b[K\n",
            "remote: Total 116 (delta 42), reused 98 (delta 27), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (116/116), 187.84 KiB | 17.08 MiB/s, done.\n",
            "Resolving deltas: 100% (42/42), done.\n",
            "/content/ViT-FishID\n",
            "\n",
            "📂 Project structure:\n",
            "total 268\n",
            "drwxr-xr-x 4 root root  4096 Aug 14 20:21 .\n",
            "drwxr-xr-x 1 root root  4096 Aug 14 20:21 ..\n",
            "-rw-r--r-- 1 root root 21217 Aug 14 20:21 data.py\n",
            "-rw-r--r-- 1 root root 11572 Aug 14 20:21 evaluate.py\n",
            "-rw-r--r-- 1 root root  3328 Aug 14 20:21 EXTENDED_TRAINING_SETUP.md\n",
            "drwxr-xr-x 2 root root  4096 Aug 14 20:21 fish_cutouts\n",
            "drwxr-xr-x 8 root root  4096 Aug 14 20:21 .git\n",
            "-rw-r--r-- 1 root root    66 Aug 14 20:21 .gitattributes\n",
            "-rw-r--r-- 1 root root   646 Aug 14 20:21 .gitignore\n",
            "-rw-r--r-- 1 root root  9495 Aug 14 20:21 model.py\n",
            "-rw-r--r-- 1 root root 16771 Aug 14 20:21 pipeline.py\n",
            "-rw-r--r-- 1 root root 16566 Aug 14 20:21 README.md\n",
            "-rw-r--r-- 1 root root   202 Aug 14 20:21 requirements.txt\n",
            "-rw-r--r-- 1 root root  4265 Aug 14 20:21 resume_training.py\n",
            "-rw-r--r-- 1 root root  5134 Aug 14 20:21 species_mapping.txt\n",
            "-rw-r--r-- 1 root root 25497 Aug 14 20:21 trainer.py\n",
            "-rw-r--r-- 1 root root  4982 Aug 14 20:21 TRAINING_FIXES_APPLIED.md\n",
            "-rw-r--r-- 1 root root 15331 Aug 14 20:21 train.py\n",
            "-rw-r--r-- 1 root root  8818 Aug 14 20:21 utils.py\n",
            "-rw-r--r-- 1 root root 65866 Aug 14 20:21 ViT_FishID_Colab_Training.ipynb\n",
            "\n",
            "✅ Repository cloned successfully!\n"
          ]
        }
      ],
      "source": [
        "# Clone the repository\n",
        "import os\n",
        "\n",
        "# Remove existing directory if it exists\n",
        "if os.path.exists('/content/ViT-FishID'):\n",
        "    !rm -rf /content/ViT-FishID\n",
        "\n",
        "# Clone the repository\n",
        "print(\"📥 Cloning ViT-FishID repository...\")\n",
        "!git clone https://github.com/cat-thomson/ViT-FishID.git /content/ViT-FishID\n",
        "\n",
        "# Change to project directory\n",
        "%cd /content/ViT-FishID\n",
        "\n",
        "# List project files\n",
        "print(\"\\n📂 Project structure:\")\n",
        "!ls -la\n",
        "\n",
        "print(\"\\n✅ Repository cloned successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8155c400",
      "metadata": {
        "id": "8155c400"
      },
      "source": [
        "## 🗂️ Step 5: Setup Data Path and Extraction\n",
        "\n",
        "**IMPORTANT:** Specify the path to your fish dataset ZIP file in Google Drive.\n",
        "\n",
        "This step will:\n",
        "1. Locate your `fish_cutouts.zip` file in Google Drive\n",
        "2. Extract it to Colab's local storage for faster access\n",
        "3. Validate the data structure\n",
        "\n",
        "Expected structure after extraction:\n",
        "```\n",
        "fish_cutouts/\n",
        "├── labeled/\n",
        "│   ├── species_1/\n",
        "│   │   ├── fish_001.jpg\n",
        "│   │   └── fish_002.jpg\n",
        "│   └── species_2/\n",
        "│       └── ...\n",
        "└── unlabeled/\n",
        "    ├── fish_003.jpg\n",
        "    └── fish_004.jpg\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup data path and extraction - CORRECTED PATHS\n",
        "import zipfile\n",
        "import shutil\n",
        "import time\n",
        "import os\n",
        "\n",
        "print(\"🗂️ SETTING UP FISH DATASET - CORRECTED PATHS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Configuration - CORRECTED file paths\n",
        "ZIP_FILE_PATH = '/content/drive/MyDrive/fish_cutouts.zip'  # Correct location\n",
        "DATA_DIR = '/content/fish_cutouts'\n",
        "\n",
        "print(f\"🎯 ZIP file location: {ZIP_FILE_PATH}\")\n",
        "print(f\"🎯 Target data directory: {DATA_DIR}\")\n",
        "\n",
        "# Check if data already exists locally (from previous session)\n",
        "if os.path.exists(DATA_DIR) and os.path.exists(os.path.join(DATA_DIR, 'labeled')):\n",
        "    print(\"✅ Data already available locally from previous session!\")\n",
        "\n",
        "    # Quick validation\n",
        "    labeled_dir = os.path.join(DATA_DIR, 'labeled')\n",
        "    unlabeled_dir = os.path.join(DATA_DIR, 'unlabeled')\n",
        "\n",
        "    if os.path.exists(labeled_dir):\n",
        "        labeled_species = [d for d in os.listdir(labeled_dir)\n",
        "                          if os.path.isdir(os.path.join(labeled_dir, d)) and not d.startswith('.')]\n",
        "        print(f\"🐟 Found {len(labeled_species)} labeled species\")\n",
        "\n",
        "    if os.path.exists(unlabeled_dir):\n",
        "        unlabeled_files = [f for f in os.listdir(unlabeled_dir)\n",
        "                          if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "        print(f\"📊 Found {len(unlabeled_files)} unlabeled images\")\n",
        "\n",
        "    print(\"✅ Data validation passed - ready for training!\")\n",
        "\n",
        "else:\n",
        "    print(\"📥 Data not found locally, extracting from Google Drive...\")\n",
        "\n",
        "    # Check if ZIP file exists\n",
        "    if os.path.exists(ZIP_FILE_PATH):\n",
        "        print(f\"✅ Found ZIP file at: {ZIP_FILE_PATH}\")\n",
        "        print(f\"📏 ZIP file size: {os.path.getsize(ZIP_FILE_PATH) / (1024**2):.1f} MB\")\n",
        "\n",
        "        # Clean extraction\n",
        "        temp_extract_dir = '/content/temp_fish_extract'\n",
        "        if os.path.exists(temp_extract_dir):\n",
        "            shutil.rmtree(temp_extract_dir)\n",
        "\n",
        "        try:\n",
        "            # Extract ZIP file directly\n",
        "            print(f\"📦 Extracting {os.path.basename(ZIP_FILE_PATH)}...\")\n",
        "            with zipfile.ZipFile(ZIP_FILE_PATH, 'r') as zip_ref:\n",
        "                zip_ref.extractall(temp_extract_dir)\n",
        "\n",
        "            print(\"✅ ZIP extraction completed\")\n",
        "\n",
        "            # Check what was extracted\n",
        "            extracted_items = os.listdir(temp_extract_dir)\n",
        "            print(f\"📁 Found in ZIP: {extracted_items}\")\n",
        "\n",
        "            # Based on your description: dataset_info.json, labeled, unlabeled, MACOS\n",
        "            # Look for labeled and unlabeled directories directly\n",
        "            labeled_source = None\n",
        "            unlabeled_source = None\n",
        "\n",
        "            for item in extracted_items:\n",
        "                item_path = os.path.join(temp_extract_dir, item)\n",
        "                if item == 'labeled' and os.path.isdir(item_path):\n",
        "                    labeled_source = item_path\n",
        "                    print(f\"✅ Found labeled directory: {item}\")\n",
        "                elif item == 'unlabeled' and os.path.isdir(item_path):\n",
        "                    unlabeled_source = item_path\n",
        "                    print(f\"✅ Found unlabeled directory: {item}\")\n",
        "                elif item == 'dataset_info.json':\n",
        "                    print(f\"📄 Found dataset info: {item}\")\n",
        "                elif item == 'MACOS' or item == '__MACOS__':\n",
        "                    print(f\"🗑️ Skipping Mac system folder: {item}\")\n",
        "\n",
        "            # Create target directory and move the labeled/unlabeled folders\n",
        "            if labeled_source and unlabeled_source:\n",
        "                # Remove existing target if it exists\n",
        "                if os.path.exists(DATA_DIR):\n",
        "                    shutil.rmtree(DATA_DIR)\n",
        "\n",
        "                # Create target directory\n",
        "                os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "                # Move labeled and unlabeled directories\n",
        "                shutil.move(labeled_source, os.path.join(DATA_DIR, 'labeled'))\n",
        "                shutil.move(unlabeled_source, os.path.join(DATA_DIR, 'unlabeled'))\n",
        "\n",
        "                print(f\"✅ Data organized at: {DATA_DIR}\")\n",
        "\n",
        "                # Copy dataset_info.json if it exists\n",
        "                dataset_info = os.path.join(temp_extract_dir, 'dataset_info.json')\n",
        "                if os.path.exists(dataset_info):\n",
        "                    shutil.copy2(dataset_info, os.path.join(DATA_DIR, 'dataset_info.json'))\n",
        "                    print(f\"📄 Copied dataset_info.json\")\n",
        "\n",
        "                # Verify the structure\n",
        "                labeled_dir = os.path.join(DATA_DIR, 'labeled')\n",
        "                if os.path.exists(labeled_dir):\n",
        "                    labeled_species = [d for d in os.listdir(labeled_dir)\n",
        "                                     if os.path.isdir(os.path.join(labeled_dir, d)) and not d.startswith('.')]\n",
        "                    print(f\"🐟 Verified: {len(labeled_species)} species in labeled data\")\n",
        "\n",
        "                unlabeled_dir = os.path.join(DATA_DIR, 'unlabeled')\n",
        "                if os.path.exists(unlabeled_dir):\n",
        "                    unlabeled_count = len([f for f in os.listdir(unlabeled_dir)\n",
        "                                         if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
        "                    print(f\"📊 Verified: {unlabeled_count} images in unlabeled data\")\n",
        "\n",
        "            else:\n",
        "                print(\"❌ Could not find both labeled and unlabeled directories\")\n",
        "                print(\"📁 Available items:\", extracted_items)\n",
        "\n",
        "            # Cleanup temporary extraction\n",
        "            if os.path.exists(temp_extract_dir):\n",
        "                shutil.rmtree(temp_extract_dir)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error during extraction: {e}\")\n",
        "            if os.path.exists(temp_extract_dir):\n",
        "                shutil.rmtree(temp_extract_dir)\n",
        "\n",
        "    else:\n",
        "        print(f\"❌ ZIP file not found at: {ZIP_FILE_PATH}\")\n",
        "        print(\"📝 Please ensure fish_cutouts.zip is uploaded to Google Drive root directory\")\n",
        "\n",
        "# Final verification\n",
        "if os.path.exists(DATA_DIR):\n",
        "    print(f\"\\n✅ DATASET READY\")\n",
        "    print(f\"📁 Location: {DATA_DIR}\")\n",
        "\n",
        "    # Show structure\n",
        "    for subdir in ['labeled', 'unlabeled']:\n",
        "        subdir_path = os.path.join(DATA_DIR, subdir)\n",
        "        if os.path.exists(subdir_path):\n",
        "            if subdir == 'labeled':\n",
        "                species_count = len([d for d in os.listdir(subdir_path)\n",
        "                                   if os.path.isdir(os.path.join(subdir_path, d)) and not d.startswith('.')])\n",
        "                print(f\"  📂 {subdir}/: {species_count} species folders\")\n",
        "            else:\n",
        "                file_count = len([f for f in os.listdir(subdir_path)\n",
        "                                if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
        "                print(f\"  📂 {subdir}/: {file_count} images\")\n",
        "        else:\n",
        "            print(f\"  ❌ {subdir}/ not found\")\n",
        "\n",
        "    # Check for dataset_info.json\n",
        "    dataset_info_path = os.path.join(DATA_DIR, 'dataset_info.json')\n",
        "    if os.path.exists(dataset_info_path):\n",
        "        print(f\"  📄 dataset_info.json: Available\")\n",
        "\n",
        "    print(\"🚀 Ready to proceed with training!\")\n",
        "else:\n",
        "    print(f\"\\n❌ DATASET SETUP FAILED\")\n",
        "    print(f\"📝 Please check that fish_cutouts.zip contains:\")\n",
        "    print(f\"   fish_cutouts.zip\")\n",
        "    print(f\"   ├── dataset_info.json\")\n",
        "    print(f\"   ├── labeled/\")\n",
        "    print(f\"   │   ├── species1/\")\n",
        "    print(f\"   │   └── species2/\")\n",
        "    print(f\"   ├── unlabeled/\")\n",
        "    print(f\"   │   ├── image1.jpg\")\n",
        "    print(f\"   │   └── image2.jpg\")\n",
        "    print(f\"   └── __MACOS__ (ignored)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nre5_INaKDXl",
        "outputId": "7c453065-873d-49b7-feb8-99da028f5fab"
      },
      "id": "nre5_INaKDXl",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🗂️ SETTING UP FISH DATASET - CORRECTED PATHS\n",
            "==================================================\n",
            "🎯 ZIP file location: /content/drive/MyDrive/fish_cutouts.zip\n",
            "🎯 Target data directory: /content/fish_cutouts\n",
            "📥 Data not found locally, extracting from Google Drive...\n",
            "✅ Found ZIP file at: /content/drive/MyDrive/fish_cutouts.zip\n",
            "📏 ZIP file size: 216.5 MB\n",
            "📦 Extracting fish_cutouts.zip...\n",
            "✅ ZIP extraction completed\n",
            "📁 Found in ZIP: ['dataset_info.json', '__MACOSX', 'labeled', 'unlabeled']\n",
            "📄 Found dataset info: dataset_info.json\n",
            "✅ Found labeled directory: labeled\n",
            "✅ Found unlabeled directory: unlabeled\n",
            "✅ Data organized at: /content/fish_cutouts\n",
            "📄 Copied dataset_info.json\n",
            "🐟 Verified: 37 species in labeled data\n",
            "📊 Verified: 24015 images in unlabeled data\n",
            "\n",
            "✅ DATASET READY\n",
            "📁 Location: /content/fish_cutouts\n",
            "  📂 labeled/: 37 species folders\n",
            "  📂 unlabeled/: 24015 images\n",
            "  📄 dataset_info.json: Available\n",
            "🚀 Ready to proceed with training!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31f0fe32",
      "metadata": {
        "id": "31f0fe32"
      },
      "source": [
        "## 📊 Step 6: Setup Weights & Biases (Optional)\n",
        "\n",
        "W&B provides excellent training visualization and experiment tracking."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5190f01",
      "metadata": {
        "id": "b5190f01"
      },
      "source": [
        "## 🔄 Step 6: Locate Checkpoint from Epoch 19\n",
        "\n",
        "Finding your saved checkpoint to resume training from where you left off."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "61b35ced",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "956e75d6-9e77-45d4-8dce-3c4774b012d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Looking for checkpoint from epoch 19...\n",
            "📁 Checking: /content/ViT-FishID\n",
            "📁 Checking: /content/drive/MyDrive/ViT-FishID/checkpoints\n",
            "🎯 Found candidate: checkpoint_epoch_19.pth\n",
            "✅ FOUND EPOCH 19 CHECKPOINT!\n",
            "📁 Location: /content/drive/MyDrive/ViT-FishID/checkpoints/checkpoint_epoch_19.pth\n",
            "📊 Epoch: 19\n",
            "📊 Best accuracy so far: 79.98%\n",
            "📁 Checking: /content/drive/MyDrive/ViT-FishID/\n",
            "🎯 Found candidate: checkpoint_epoch_19.pth\n",
            "✅ FOUND EPOCH 19 CHECKPOINT!\n",
            "📁 Location: /content/drive/MyDrive/ViT-FishID/checkpoint_epoch_19.pth\n",
            "📊 Epoch: 19\n",
            "📊 Best accuracy so far: 79.98%\n",
            "\n",
            "🎉 Checkpoint ready for resuming training!\n",
            "📄 File: checkpoint_epoch_19.pth\n",
            "📏 Size: 1309.9 MB\n",
            "💾 New checkpoints will be saved to: /content/drive/MyDrive/ViT-FishID/checkpoints_extended\n"
          ]
        }
      ],
      "source": [
        "# Locate checkpoint from epoch 19\n",
        "import os\n",
        "import glob\n",
        "import torch\n",
        "\n",
        "print(\"🔍 Looking for checkpoint from epoch 19...\")\n",
        "\n",
        "# Possible checkpoint locations\n",
        "checkpoint_locations = [\n",
        "    '/content/ViT-FishID','/content/drive/MyDrive/ViT-FishID/checkpoints', '/content/drive/MyDrive/ViT-FishID/'\n",
        "]\n",
        "\n",
        "checkpoint_path = None\n",
        "checkpoint_info = None\n",
        "\n",
        "# Search for epoch 19 checkpoint\n",
        "for location_pattern in checkpoint_locations:\n",
        "    for location in glob.glob(location_pattern):\n",
        "        if os.path.exists(location):\n",
        "            print(f\"📁 Checking: {location}\")\n",
        "\n",
        "            # Look for epoch 19 specifically\n",
        "            epoch_19_files = glob.glob(os.path.join(location, '*epoch_19*'))\n",
        "            manual_files = glob.glob(os.path.join(location, '*manual*epoch*19*'))\n",
        "            emergency_files = glob.glob(os.path.join(location, '*emergency*epoch*19*'))\n",
        "\n",
        "            all_candidates = epoch_19_files + manual_files + emergency_files\n",
        "\n",
        "            for candidate in all_candidates:\n",
        "                if candidate.endswith('.pth'):\n",
        "                    print(f\"🎯 Found candidate: {os.path.basename(candidate)}\")\n",
        "                    try:\n",
        "                        # Verify checkpoint can be loaded\n",
        "                        test_checkpoint = torch.load(candidate, map_location='cpu')\n",
        "                        epoch = test_checkpoint.get('epoch', 'unknown')\n",
        "\n",
        "                        if epoch == 19 or '19' in os.path.basename(candidate):\n",
        "                            checkpoint_path = candidate\n",
        "                            checkpoint_info = test_checkpoint\n",
        "                            print(f\"✅ FOUND EPOCH 19 CHECKPOINT!\")\n",
        "                            print(f\"📁 Location: {checkpoint_path}\")\n",
        "                            print(f\"📊 Epoch: {epoch}\")\n",
        "\n",
        "                            if 'best_accuracy' in test_checkpoint:\n",
        "                                print(f\"📊 Best accuracy so far: {test_checkpoint['best_accuracy']:.2f}%\")\n",
        "                            elif 'best_acc' in test_checkpoint:\n",
        "                                print(f\"📊 Best accuracy so far: {test_checkpoint['best_acc']:.2f}%\")\n",
        "\n",
        "                            break\n",
        "                    except Exception as e:\n",
        "                        print(f\"⚠️ Could not load {candidate}: {e}\")\n",
        "\n",
        "            if checkpoint_path:\n",
        "                break\n",
        "\n",
        "        if checkpoint_path:\n",
        "            break\n",
        "\n",
        "if checkpoint_path:\n",
        "    print(f\"\\n🎉 Checkpoint ready for resuming training!\")\n",
        "    print(f\"📄 File: {os.path.basename(checkpoint_path)}\")\n",
        "    print(f\"📏 Size: {os.path.getsize(checkpoint_path) / (1024*1024):.1f} MB\")\n",
        "\n",
        "    # Set up checkpoint directory for new saves\n",
        "    checkpoint_save_dir = '/content/drive/MyDrive/ViT-FishID/checkpoints_extended'\n",
        "    os.makedirs(checkpoint_save_dir, exist_ok=True)\n",
        "    print(f\"💾 New checkpoints will be saved to: {checkpoint_save_dir}\")\n",
        "\n",
        "else:\n",
        "    print(\"❌ No checkpoint found for epoch 19!\")\n",
        "    print(\"\\n🔧 Troubleshooting:\")\n",
        "    print(\"1. Check that you have a checkpoint saved from previous training\")\n",
        "    print(\"2. Ensure the checkpoint is uploaded to Google Drive\")\n",
        "    print(\"3. Look for files named like: checkpoint_epoch_19.pth, emergency_checkpoint_epoch_19.pth\")\n",
        "    print(\"\\n📁 Checked locations:\")\n",
        "    for location in checkpoint_locations:\n",
        "        print(f\"  - {location}\")\n",
        "\n",
        "    # Fallback: look for any checkpoints\n",
        "    print(\"\\n🔍 All available checkpoints:\")\n",
        "    for location_pattern in checkpoint_locations:\n",
        "        for location in glob.glob(location_pattern):\n",
        "            if os.path.exists(location):\n",
        "                all_checkpoints = glob.glob(os.path.join(location, '*.pth'))\n",
        "                for cp in all_checkpoints:\n",
        "                    print(f\"  - {os.path.basename(cp)}\")\n",
        "\n",
        "# Store checkpoint path for later use\n",
        "RESUME_CHECKPOINT = checkpoint_path"
      ],
      "id": "61b35ced"
    },
    {
      "cell_type": "markdown",
      "id": "0fe6af6d",
      "metadata": {
        "id": "0fe6af6d"
      },
      "source": [
        "## ⚙️ Step 7: Configure Training Parameters\n",
        "\n",
        "Adjust these parameters based on your needs and available GPU memory."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Configuration - RESUME FROM EPOCH 5 FOR 100 TOTAL EPOCHS\n",
        "import os\n",
        "\n",
        "print(\"🎯 EXTENDED TRAINING CONFIGURATION - WITH W&B\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Define directories first to make config cleaner\n",
        "DRIVE_CHECKPOINT_BASE = '/content/drive/MyDrive/ViT-FishID'\n",
        "CHECKPOINT_SAVE_DIR = os.path.join(DRIVE_CHECKPOINT_BASE, 'checkpoints_extended')\n",
        "BACKUP_DIR = os.path.join(DRIVE_CHECKPOINT_BASE, 'checkpoints_backup')\n",
        "\n",
        "TRAINING_CONFIG = {\n",
        "    # RESUME SETTINGS\n",
        "    # Pointing to the latest valid checkpoint found (Epoch 5)\n",
        "    'resume_from_checkpoint': os.path.join(CHECKPOINT_SAVE_DIR, 'checkpoint_epoch_5.pth'),\n",
        "    'start_epoch': 6,  # Next epoch after 5\n",
        "    'total_epochs': 100,  # Target total epochs\n",
        "    'remaining_epochs': 100 - 5, # Calculate based on total and start\n",
        "\n",
        "    # CORE SETTINGS\n",
        "    'mode': 'semi_supervised',  # semi_supervised or supervised\n",
        "    'data_dir': DATA_DIR, # This variable comes from Step 5\n",
        "    'batch_size': 16,  # Increased for Colab Pro\n",
        "    'learning_rate': 1e-4,\n",
        "    'weight_decay': 0.05,\n",
        "\n",
        "    # MODEL SETTINGS\n",
        "    'model_name': 'vit_base_patch16_224',\n",
        "    'num_classes': 37,  # Will be auto-detected below\n",
        "\n",
        "    # SEMI-SUPERVISED SETTINGS\n",
        "    'consistency_weight': 2.0,\n",
        "    'pseudo_label_threshold': 0.7,\n",
        "    'temperature': 4.0,\n",
        "    'warmup_epochs': 5,  # Reduced since we're resuming\n",
        "    'ramp_up_epochs': 15,  # Reduced since we're resuming\n",
        "\n",
        "    # CHECKPOINT SETTINGS - SAVE EVERY EPOCH\n",
        "    'save_frequency': 1,  # Save EVERY epoch\n",
        "    'checkpoint_dir': CHECKPOINT_SAVE_DIR,\n",
        "    'backup_dir': BACKUP_DIR,\n",
        "\n",
        "    # LOGGING - W&B ENABLED\n",
        "    'use_wandb': True, # Enable W&B logging\n",
        "    'wandb_project': 'ViT-FishID-Extended-Training', # Your W&B project name\n",
        "    'wandb_run_name': 'resume-epoch-6-to-100', # A name for this specific run\n",
        "\n",
        "    # Add pretrained flag here as a config item\n",
        "    'pretrained': True,\n",
        "}\n",
        "\n",
        "# Verify data directory and auto-detect num_classes\n",
        "if os.path.exists(TRAINING_CONFIG['data_dir']):\n",
        "    labeled_dir = os.path.join(TRAINING_CONFIG['data_dir'], 'labeled')\n",
        "    if os.path.exists(labeled_dir):\n",
        "        species_count = len([d for d in os.listdir(labeled_dir)\n",
        "                           if os.path.isdir(os.path.join(labeled_dir, d)) and not d.startswith('.')])\n",
        "        TRAINING_CONFIG['num_classes'] = species_count\n",
        "        print(f\"📊 Detected {species_count} fish species\")\n",
        "    else:\n",
        "         print(f\"⚠️ Labeled data directory not found: {labeled_dir}. Cannot auto-detect num_classes.\")\n",
        "         print(f\"💡 Using default num_classes: {TRAINING_CONFIG['num_classes']}\")\n",
        "else:\n",
        "    print(f\"❌ Data directory not found: {TRAINING_CONFIG['data_dir']}. Cannot auto-detect num_classes.\")\n",
        "    print(f\"💡 Using default num_classes: {TRAINING_CONFIG['num_classes']}\")\n",
        "\n",
        "\n",
        "print(\"\\nEXTENDED TRAINING CONFIGURATION SUMMARY\")\n",
        "print(\"=\"*50)\n",
        "print(f\"📊 Resume from: Epoch {TRAINING_CONFIG['start_epoch'] - 1}\")\n",
        "print(f\"📊 Target epochs: {TRAINING_CONFIG['total_epochs']}\")\n",
        "print(f\"📊 Remaining epochs: {TRAINING_CONFIG['remaining_epochs']}\")\n",
        "# Estimate time based on remaining epochs and a rough per-epoch time (e.g., 5-7 mins)\n",
        "estimated_min_time = TRAINING_CONFIG['remaining_epochs'] * 5\n",
        "estimated_max_time = TRAINING_CONFIG['remaining_epochs'] * 7\n",
        "print(f\"⏱️ Estimated time: {estimated_min_time:.0f}-{estimated_max_time:.0f} minutes\")\n",
        "print(f\"📊 Batch size: {TRAINING_CONFIG['batch_size']} (optimized for Colab Pro)\")\n",
        "print(f\"💾 Checkpoint saves: EVERY {TRAINING_CONFIG['save_frequency']} epoch(s)\")\n",
        "print(f\"📊 Mode: {TRAINING_CONFIG['mode']} with consistency weight {TRAINING_CONFIG['consistency_weight']}\")\n",
        "print(f\"📊 Logging: W&B Enabled (Project: {TRAINING_CONFIG['wandb_project']}, Run: {TRAINING_CONFIG['wandb_run_name']})\")\n",
        "print(f\"📊 Num Classes: {TRAINING_CONFIG['num_classes']}\")\n",
        "\n",
        "\n",
        "# Create checkpoint directories with more robust error handling\n",
        "print(\"\\nSETTING UP CHECKPOINT DIRECTORIES\")\n",
        "print(\"=\"*50)\n",
        "try:\n",
        "    os.makedirs(TRAINING_CONFIG['checkpoint_dir'], exist_ok=True)\n",
        "    print(f\"📁 Primary saves: {TRAINING_CONFIG['checkpoint_dir']} (Created/Exists)\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ Could not create primary checkpoint dir {TRAINING_CONFIG['checkpoint_dir']}: {e}\")\n",
        "    # Fallback to local directory if Google Drive mount is the issue\n",
        "    local_fallback_dir = '/content/checkpoints_extended_local'\n",
        "    TRAINING_CONFIG['checkpoint_dir'] = local_fallback_dir\n",
        "    try:\n",
        "        os.makedirs(TRAINING_CONFIG['checkpoint_dir'], exist_ok=True)\n",
        "        print(f\"📁 Primary saves (FALLBACK to local): {TRAINING_CONFIG['checkpoint_dir']} (Created/Exists)\")\n",
        "        print(\"💡 Check Google Drive mount if this is unexpected.\")\n",
        "    except Exception as e_local:\n",
        "         print(f\"❌ Could not create fallback local checkpoint dir {local_fallback_dir}: {e_local}\")\n",
        "         print(\"🚨 Check permissions or disk space.\")\n",
        "\n",
        "\n",
        "try:\n",
        "    os.makedirs(TRAINING_CONFIG['backup_dir'], exist_ok=True)\n",
        "    print(f\"💾 Backup saves: {TRAINING_CONFIG['backup_dir']} (Created/Exists)\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ Could not create backup dir {TRAINING_CONFIG['backup_dir']}: {e}\")\n",
        "    print(\"💾 Backup saves: Disabled due to Google Drive issues or permissions.\")\n",
        "    TRAINING_CONFIG['backup_dir'] = None # Explicitly set to None if creation fails\n",
        "\n",
        "\n",
        "if TRAINING_CONFIG['resume_from_checkpoint'] and os.path.exists(TRAINING_CONFIG['resume_from_checkpoint']):\n",
        "    print(f\"\\n✅ Will resume training from: {os.path.basename(TRAINING_CONFIG['resume_from_checkpoint'])}\")\n",
        "else:\n",
        "    print(\"\\n❌ Specified resume checkpoint not found or not set - will start fresh training from epoch 1\")\n",
        "    TRAINING_CONFIG['resume_from_checkpoint'] = None # Ensure it's None if file not found\n",
        "    TRAINING_CONFIG['start_epoch'] = 1\n",
        "    TRAINING_CONFIG['remaining_epochs'] = TRAINING_CONFIG['total_epochs']\n",
        "\n",
        "print(f\"\\n🚀 Configuration complete. Ready to resume/start training!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSokV6NDjgYa",
        "outputId": "5de49e11-12a0-4f4c-e0e9-745c889998b5"
      },
      "id": "hSokV6NDjgYa",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎯 EXTENDED TRAINING CONFIGURATION - WITH W&B\n",
            "==================================================\n",
            "📊 Detected 37 fish species\n",
            "\n",
            "EXTENDED TRAINING CONFIGURATION SUMMARY\n",
            "==================================================\n",
            "📊 Resume from: Epoch 5\n",
            "📊 Target epochs: 100\n",
            "📊 Remaining epochs: 95\n",
            "⏱️ Estimated time: 475-665 minutes\n",
            "📊 Batch size: 16 (optimized for Colab Pro)\n",
            "💾 Checkpoint saves: EVERY 1 epoch(s)\n",
            "📊 Mode: semi_supervised with consistency weight 2.0\n",
            "📊 Logging: W&B Enabled (Project: ViT-FishID-Extended-Training, Run: resume-epoch-6-to-100)\n",
            "📊 Num Classes: 37\n",
            "\n",
            "SETTING UP CHECKPOINT DIRECTORIES\n",
            "==================================================\n",
            "📁 Primary saves: /content/drive/MyDrive/ViT-FishID/checkpoints_extended (Created/Exists)\n",
            "💾 Backup saves: /content/drive/MyDrive/ViT-FishID/checkpoints_backup (Created/Exists)\n",
            "\n",
            "✅ Will resume training from: checkpoint_epoch_5.pth\n",
            "\n",
            "🚀 Configuration complete. Ready to resume/start training!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa9cbd50",
      "metadata": {
        "id": "aa9cbd50"
      },
      "source": [
        "## 🚀 Step 8: Start Training!\n",
        "\n",
        "This cell will start the semi-supervised training process. It may take 2-3 hours to complete."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute Extended Training - Resume from Epoch 17\n",
        "import os\n",
        "\n",
        "print(\"🚀 STARTING EXTENDED TRAINING SESSION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Create checkpoint save directory\n",
        "os.makedirs(TRAINING_CONFIG['checkpoint_dir'], exist_ok=True)\n",
        "\n",
        "# Build training command for resuming\n",
        "training_cmd = f\"\"\"python train.py \\\\\n",
        "    --mode {TRAINING_CONFIG['mode']} \\\\\n",
        "    --data_dir {TRAINING_CONFIG['data_dir']} \\\\\n",
        "    --epochs {TRAINING_CONFIG['total_epochs']} \\\\\n",
        "    --batch_size {TRAINING_CONFIG['batch_size']} \\\\\n",
        "    --learning_rate {TRAINING_CONFIG['learning_rate']} \\\\\n",
        "    --weight_decay {TRAINING_CONFIG['weight_decay']} \\\\\n",
        "    --model_name {TRAINING_CONFIG['model_name']} \\\\\n",
        "    --consistency_weight {TRAINING_CONFIG['consistency_weight']} \\\\\n",
        "    --pseudo_label_threshold {TRAINING_CONFIG['pseudo_label_threshold']} \\\\\n",
        "    --temperature {TRAINING_CONFIG['temperature']} \\\\\n",
        "    --warmup_epochs {TRAINING_CONFIG['warmup_epochs']} \\\\\n",
        "    --ramp_up_epochs {TRAINING_CONFIG['ramp_up_epochs']} \\\\\n",
        "    --save_dir {TRAINING_CONFIG['checkpoint_dir']} \\\\\n",
        "    --save_frequency {TRAINING_CONFIG['save_frequency']}\"\"\"\n",
        "\n",
        "# Add resume checkpoint if available\n",
        "# Pointing to the epoch 17 checkpoint\n",
        "TRAINING_CONFIG['resume_from_checkpoint'] = os.path.join(TRAINING_CONFIG['checkpoint_dir'], 'checkpoint_epoch_17.pth')\n",
        "TRAINING_CONFIG['start_epoch'] = 18 # Start from the epoch *after* the resumed checkpoint\n",
        "\n",
        "if TRAINING_CONFIG['resume_from_checkpoint']:\n",
        "    training_cmd += f\" \\\\\\n    --resume_from {TRAINING_CONFIG['resume_from_checkpoint']}\"\n",
        "    print(f\"📂 Resuming from: {os.path.basename(TRAINING_CONFIG['resume_from_checkpoint'])}\")\n",
        "    print(f\"🚀 Starting training from epoch: {TRAINING_CONFIG['start_epoch']}\")\n",
        "\n",
        "# Add W&B logging - Only add the --use_wandb flag\n",
        "if TRAINING_CONFIG['use_wandb']:\n",
        "    training_cmd += f\" \\\\\\n    --use_wandb\"\n",
        "    # Removed --wandb_project and --wandb_run_name as train.py doesn't recognize them\n",
        "\n",
        "# Add pretrained flag\n",
        "if TRAINING_CONFIG['pretrained']:\n",
        "    training_cmd += \" \\\\\\n    --pretrained\"\n",
        "\n",
        "# Update remaining epochs based on new start_epoch\n",
        "TRAINING_CONFIG['remaining_epochs'] = TRAINING_CONFIG['total_epochs'] - (TRAINING_CONFIG['start_epoch'] - 1) # Calculate based on total and start\n",
        "\n",
        "print(f\"📊 Training for {TRAINING_CONFIG['remaining_epochs']} more epochs...\")\n",
        "print(f\"🎯 Target: {TRAINING_CONFIG['total_epochs']} total epochs\")\n",
        "print(f\"⏱️ Estimated time: {TRAINING_CONFIG['remaining_epochs'] * 4:.0f}-{TRAINING_CONFIG['remaining_epochs'] * 6:.0f} minutes\")\n",
        "print(f\"💾 Checkpoints saved to: {TRAINING_CONFIG['checkpoint_dir']}\")\n",
        "\n",
        "print(\"\\n📋 Extended Training Command:\")\n",
        "print(training_cmd.replace('\\\\', '').strip())\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "# Execute training\n",
        "print(f\"🎬 TRAINING STARTED - EPOCH {TRAINING_CONFIG['start_epoch']} TO {TRAINING_CONFIG['total_epochs']}\")\n",
        "print(\"⏰ Started at:\", __import__('datetime').datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
        "\n",
        "# Before executing, modify trainer.py to fix the AttributeError during checkpoint saving\n",
        "# This is a temporary fix directly modifying the cloned file\n",
        "trainer_file_path = '/content/ViT-FishID/trainer.py'\n",
        "try:\n",
        "    with open(trainer_file_path, 'r') as f:\n",
        "        trainer_code = f.read()\n",
        "\n",
        "    # Find the line that saves the ema_teacher_state_dict and comment it out\n",
        "    # Look for patterns like 'ema_teacher_state_dict': ...\n",
        "    lines = trainer_code.splitlines()\n",
        "    modified_lines = []\n",
        "    ema_line_found = False\n",
        "    for line in lines:\n",
        "        # Check for the line saving ema_teacher_state_dict, allowing for variations in spacing/access\n",
        "        if \"'ema_teacher_state_dict':\" in line and \"state_dict()\" in line:\n",
        "             modified_lines.append(\"# \" + line) # Comment out the line\n",
        "             ema_line_found = True\n",
        "             print(f\"✅ Commented out line saving ema_teacher_state_dict: {line.strip()}\")\n",
        "        else:\n",
        "            modified_lines.append(line)\n",
        "\n",
        "    if ema_line_found:\n",
        "        corrected_code = \"\\n\".join(modified_lines)\n",
        "        with open(trainer_file_path, 'w') as f:\n",
        "            f.write(corrected_code)\n",
        "        print(f\"✅ Modified {trainer_file_path} to skip saving EMA teacher state_dict.\")\n",
        "    else:\n",
        "        print(f\"⚠️ Could not find the line saving ema_teacher_state_dict in {trainer_file_path}. The fix might not be applied.\")\n",
        "        print(\"💡 Training might still fail due to the EMA teacher state_dict error.\")\n",
        "\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error modifying {trainer_file_path}: {e}\")\n",
        "    print(\"🚨 Training might still fail due to the EMA teacher state_dict error.\")\n",
        "\n",
        "\n",
        "!{training_cmd}\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"🎉 EXTENDED TRAINING COMPLETED!\")\n",
        "print(\"⏰ Finished at:\", __import__('datetime').datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
        "print(f\"🏆 Total epochs completed: {TRAINING_CONFIG['total_epochs']}\")\n",
        "print(f\"💾 All checkpoints saved to Google Drive\")\n",
        "\n",
        "# Quick summary of final results\n",
        "final_checkpoint = os.path.join(TRAINING_CONFIG['checkpoint_dir'], 'model_best.pth')\n",
        "if os.path.exists(final_checkpoint):\n",
        "    try:\n",
        "        import torch\n",
        "        final_results = torch.load(final_checkpoint, map_location='cpu')\n",
        "        if 'best_accuracy' in final_results:\n",
        "            print(f\"🎯 Final best accuracy: {final_results['best_accuracy']:.2f}%\")\n",
        "        if 'epoch' in final_results:\n",
        "            print(f\"📊 Best model from epoch: {final_results['epoch']}\")\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "print(\"\\n✅ Your model is ready for evaluation and deployment!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njLKb7xaepxo",
        "outputId": "2cf2dec9-51ec-40d6-a572-0f079540f45b"
      },
      "id": "njLKb7xaepxo",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 STARTING EXTENDED TRAINING SESSION\n",
            "============================================================\n",
            "📂 Resuming from: checkpoint_epoch_17.pth\n",
            "🚀 Starting training from epoch: 18\n",
            "📊 Training for 83 more epochs...\n",
            "🎯 Target: 100 total epochs\n",
            "⏱️ Estimated time: 332-498 minutes\n",
            "💾 Checkpoints saved to: /content/drive/MyDrive/ViT-FishID/checkpoints_extended\n",
            "\n",
            "📋 Extended Training Command:\n",
            "python train.py \n",
            "    --mode semi_supervised \n",
            "    --data_dir /content/fish_cutouts \n",
            "    --epochs 100 \n",
            "    --batch_size 16 \n",
            "    --learning_rate 0.0001 \n",
            "    --weight_decay 0.05 \n",
            "    --model_name vit_base_patch16_224 \n",
            "    --consistency_weight 2.0 \n",
            "    --pseudo_label_threshold 0.7 \n",
            "    --temperature 4.0 \n",
            "    --warmup_epochs 5 \n",
            "    --ramp_up_epochs 15 \n",
            "    --save_dir /content/drive/MyDrive/ViT-FishID/checkpoints_extended \n",
            "    --save_frequency 1 \n",
            "    --resume_from /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_17.pth \n",
            "    --use_wandb \n",
            "    --pretrained\n",
            "\n",
            "============================================================\n",
            "🎬 TRAINING STARTED - EPOCH 18 TO 100\n",
            "⏰ Started at: 2025-08-14 20:57:41\n",
            "✅ Commented out line saving ema_teacher_state_dict: # # #             'ema_teacher_state_dict': trainer.ema_teacher.teacher.state_dict(),  # Fixed key name\n",
            "✅ Modified /content/ViT-FishID/trainer.py to skip saving EMA teacher state_dict.\n",
            "2025-08-14 20:57:47.933635: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-08-14 20:57:47.951765: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1755205067.973593   16849 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1755205067.980175   16849 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1755205067.996936   16849 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755205067.996981   16849 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755205067.996984   16849 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755205067.996987   16849 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-08-14 20:57:48.002138: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Random seed set to 42\n",
            "Using GPU: NVIDIA A100-SXM4-40GB\n",
            "🐟 ViT-FishID Training\n",
            "📊 Mode: semi_supervised\n",
            "🖥️  Device: cuda\n",
            "📁 Data directory: /content/fish_cutouts\n",
            "\n",
            "📦 Creating data loaders...\n",
            "⚠️  Warning: Some classes have only 1 sample(s). Using random splitting instead of stratified.\n",
            "   Classes with 1 sample: ['Carangidae_Caranx_heberi', 'Serranidae_Lipropoma_spp1', 'Sparidae_Sparodon_durbanesis']\n",
            "/content/ViT-FishID/data.py:229: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
            "  A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
            "📊 Dataset initialized:\n",
            "  - Labeled samples: 3,084\n",
            "  - Unlabeled samples: 6,168\n",
            "  - Total samples per epoch: 9,252\n",
            "📊 Semi-supervised data loaders created:\n",
            "  - Train labeled: 3,084\n",
            "  - Train unlabeled: 6,168\n",
            "  - Val samples: 1,029\n",
            "  - Test samples: 1,029\n",
            "  - Classes: 37\n",
            "  - Split ratios: Train=60.0%, Val=20.0%, Test=20.0%\n",
            "🏷️  Classes (37): ['Carangidae_Caranx_heberi', 'Carangidae_Pseudocaranx_dentex', 'Carangidae_Seriola_dumerili', 'Carangidae_Seriola_lalandi', 'Carangidae_Seriola_rivoliana', 'Carangidae_Trachurus_delagoa', 'Serranidae_Aulacocephalus_temminckii', 'Serranidae_Epinephelus_andersoni', 'Serranidae_Epinephelus_marginatus', 'Serranidae_Epinephelus_rivulatus', 'Serranidae_Epinephelus_tukula', 'Serranidae_Lipropoma_spp1', 'Serranidae_Serranus_knysnaensis', 'Sparidae_Argyrops_spinifer', 'Sparidae_Boopsoidea_inornata', 'Sparidae_Cheimerius_nufar', 'Sparidae_Chrysoblephus_anglicus', 'Sparidae_Chrysoblephus_cristiceps', 'Sparidae_Chrysoblephus_lophus', 'Sparidae_Chrysoblephus_puniceus', 'Sparidae_Cymatoceps_nasutus', 'Sparidae_Diplodus_capensis', 'Sparidae_Diplodus_hottentotus', 'Sparidae_Pachymetopon_aeneum', 'Sparidae_Pachymetopon_grande', 'Sparidae_Pagellus_bellottii_natalensis', 'Sparidae_Petrus_rupestris', 'Sparidae_Polyamblydon_germanum', 'Sparidae_Polysteganus_praeorbitalis', 'Sparidae_Polysteganus_undulosus', 'Sparidae_Porcostoma_dentata', 'Sparidae_Rhabdosargus_holubi', 'Sparidae_Rhabdosargus_sarba', 'Sparidae_Rhabdosargus_thorpei', 'Sparidae_Sarpa_salpa', 'Sparidae_Sparodon_durbanesis', 'Sparidae_Spondyliosoma_emarginatum']\n",
            "📊 Test set available with 1,029 samples for final evaluation\n",
            "\n",
            "🧠 Creating ViT model: vit_base_patch16_224\n",
            "✅ EMA Teacher initialized with momentum: 0.999\n",
            "📊 Model parameters: 85,828,645\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcativthomson\u001b[0m (\u001b[33mcativthomson-university-of-cape-town\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.21.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/ViT-FishID/wandb/run-20250814_205754-tyuoy4jc\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msemi_supervised_vit_base_patch16_224_20250814_205754\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/cativthomson-university-of-cape-town/vit-fish-id\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/cativthomson-university-of-cape-town/vit-fish-id/runs/tyuoy4jc\u001b[0m\n",
            "✅ W&B initialized: vit-fish-id/semi_supervised_vit_base_patch16_224_20250814_205754\n",
            "\n",
            "🚀 Creating trainer...\n",
            "✅ Semi-Supervised Trainer initialized\n",
            "  - Consistency weight: 2.0\n",
            "  - Pseudo-label threshold: 0.7\n",
            "  - Learning rate: 0.0001\n",
            "  - Warmup epochs: 5\n",
            "  - Ramp-up epochs: 15\n",
            "📥 Resuming from checkpoint: /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_17.pth\n",
            "✅ Successfully loaded checkpoint from epoch 17\n",
            "📊 Previous best accuracy: 87.56073858114675\n",
            "🚀 Resuming training from epoch 18\n",
            "\n",
            "🎯 Starting semi_supervised training...\n",
            "💡 Note: Test set is reserved for final evaluation and not used during training\n",
            "🔄 Resuming training from epoch 18\n",
            "⏰ Remaining epochs: 83\n",
            "📁 Checkpoints will be saved to: /content/drive/MyDrive/ViT-FishID/checkpoints_extended\n",
            "Epoch 18: 100% 578/578 [01:35<00:00,  6.04it/s, Total=0.8614, Sup=0.8464, Cons=0.0075, L-Acc=72.9%, P-Acc=90.6%]\n",
            "                                               \n",
            "📊 Epoch 19/100\n",
            "Train - Total Loss: 0.8614\n",
            "Train - Labeled Acc: 72.9%, Pseudo Acc: 90.6%\n",
            "Train - High-conf Pseudo: 757/6165 (12.3%)\n",
            "Student Val - Acc: 75.5%\n",
            "Teacher Val - Acc: 79.7%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_18.pth\n",
            "📊 Epoch 18 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 19: 100% 578/578 [01:35<00:00,  6.07it/s, Total=0.8229, Sup=0.8165, Cons=0.0032, L-Acc=74.7%, P-Acc=86.6%]\n",
            "                                               \n",
            "📊 Epoch 20/100\n",
            "Train - Total Loss: 0.8229\n",
            "Train - Labeled Acc: 74.7%, Pseudo Acc: 86.6%\n",
            "Train - High-conf Pseudo: 2584/6165 (41.9%)\n",
            "Student Val - Acc: 72.2%\n",
            "Teacher Val - Acc: 82.4%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_19.pth\n",
            "📊 Epoch 19 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 20: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.8199, Sup=0.8176, Cons=0.0026, L-Acc=75.5%, P-Acc=84.9%]\n",
            "                                               \n",
            "📊 Epoch 21/100\n",
            "Train - Total Loss: 0.8199\n",
            "Train - Labeled Acc: 75.5%, Pseudo Acc: 84.9%\n",
            "Train - High-conf Pseudo: 3295/6165 (53.4%)\n",
            "Student Val - Acc: 75.0%\n",
            "Teacher Val - Acc: 82.2%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_20.pth\n",
            "💾 Backup saved to: /content/drive/MyDrive/ViT-FishID/checkpoints_backup/checkpoint_epoch_20.pth\n",
            "📊 Epoch 20 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 21: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.7925, Sup=0.7883, Cons=0.0028, L-Acc=75.4%, P-Acc=84.7%]\n",
            "                                               \n",
            "📊 Epoch 22/100\n",
            "Train - Total Loss: 0.7925\n",
            "Train - Labeled Acc: 75.4%, Pseudo Acc: 84.7%\n",
            "Train - High-conf Pseudo: 3592/6166 (58.3%)\n",
            "Student Val - Acc: 73.7%\n",
            "Teacher Val - Acc: 82.3%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_21.pth\n",
            "📊 Epoch 21 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 22: 100% 578/578 [01:35<00:00,  6.07it/s, Total=0.8288, Sup=0.8238, Cons=0.0032, L-Acc=74.5%, P-Acc=80.6%]\n",
            "                                               \n",
            "📊 Epoch 23/100\n",
            "Train - Total Loss: 0.8288\n",
            "Train - Labeled Acc: 74.5%, Pseudo Acc: 80.6%\n",
            "Train - High-conf Pseudo: 3760/6168 (61.0%)\n",
            "Student Val - Acc: 74.5%\n",
            "Teacher Val - Acc: 82.4%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_22.pth\n",
            "📊 Epoch 22 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 23: 100% 578/578 [01:35<00:00,  6.07it/s, Total=0.8112, Sup=0.8101, Cons=0.0033, L-Acc=75.0%, P-Acc=82.0%]\n",
            "                                               \n",
            "📊 Epoch 24/100\n",
            "Train - Total Loss: 0.8112\n",
            "Train - Labeled Acc: 75.0%, Pseudo Acc: 82.0%\n",
            "Train - High-conf Pseudo: 3891/6166 (63.1%)\n",
            "Student Val - Acc: 74.0%\n",
            "Teacher Val - Acc: 82.0%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_23.pth\n",
            "📊 Epoch 23 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 24: 100% 578/578 [01:36<00:00,  5.98it/s, Total=0.7655, Sup=0.7590, Cons=0.0032, L-Acc=77.2%, P-Acc=82.6%]\n",
            "                                               \n",
            "📊 Epoch 25/100\n",
            "Train - Total Loss: 0.7655\n",
            "Train - Labeled Acc: 77.2%, Pseudo Acc: 82.6%\n",
            "Train - High-conf Pseudo: 3871/6165 (62.8%)\n",
            "Student Val - Acc: 70.7%\n",
            "Teacher Val - Acc: 81.9%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_24.pth\n",
            "📊 Epoch 24 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 25: 100% 578/578 [01:35<00:00,  6.07it/s, Total=0.7674, Sup=0.7603, Cons=0.0035, L-Acc=76.7%, P-Acc=80.6%]\n",
            "                                               \n",
            "📊 Epoch 26/100\n",
            "Train - Total Loss: 0.7674\n",
            "Train - Labeled Acc: 76.7%, Pseudo Acc: 80.6%\n",
            "Train - High-conf Pseudo: 3920/6166 (63.6%)\n",
            "Student Val - Acc: 74.7%\n",
            "Teacher Val - Acc: 81.7%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_25.pth\n",
            "💾 Backup saved to: /content/drive/MyDrive/ViT-FishID/checkpoints_backup/checkpoint_epoch_25.pth\n",
            "📊 Epoch 25 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 26: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.7576, Sup=0.7506, Cons=0.0035, L-Acc=77.1%, P-Acc=81.2%]\n",
            "                                               \n",
            "📊 Epoch 27/100\n",
            "Train - Total Loss: 0.7576\n",
            "Train - Labeled Acc: 77.1%, Pseudo Acc: 81.2%\n",
            "Train - High-conf Pseudo: 4051/6165 (65.7%)\n",
            "Student Val - Acc: 74.5%\n",
            "Teacher Val - Acc: 81.1%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_26.pth\n",
            "📊 Epoch 26 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 27: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.7502, Sup=0.7436, Cons=0.0039, L-Acc=76.9%, P-Acc=79.7%]\n",
            "                                               \n",
            "📊 Epoch 28/100\n",
            "Train - Total Loss: 0.7502\n",
            "Train - Labeled Acc: 76.9%, Pseudo Acc: 79.7%\n",
            "Train - High-conf Pseudo: 4073/6166 (66.1%)\n",
            "Student Val - Acc: 71.8%\n",
            "Teacher Val - Acc: 81.0%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_27.pth\n",
            "📊 Epoch 27 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 28: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.7061, Sup=0.6996, Cons=0.0039, L-Acc=78.9%, P-Acc=80.8%]\n",
            "                                               \n",
            "📊 Epoch 29/100\n",
            "Train - Total Loss: 0.7061\n",
            "Train - Labeled Acc: 78.9%, Pseudo Acc: 80.8%\n",
            "Train - High-conf Pseudo: 4071/6166 (66.0%)\n",
            "Student Val - Acc: 75.2%\n",
            "Teacher Val - Acc: 81.1%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_28.pth\n",
            "📊 Epoch 28 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 29: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.6836, Sup=0.6753, Cons=0.0041, L-Acc=79.1%, P-Acc=81.6%]\n",
            "                                               \n",
            "📊 Epoch 30/100\n",
            "Train - Total Loss: 0.6836\n",
            "Train - Labeled Acc: 79.1%, Pseudo Acc: 81.6%\n",
            "Train - High-conf Pseudo: 4189/6165 (67.9%)\n",
            "Student Val - Acc: 73.4%\n",
            "Teacher Val - Acc: 81.0%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_29.pth\n",
            "📊 Epoch 29 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 30: 100% 578/578 [01:35<00:00,  6.07it/s, Total=0.6738, Sup=0.6676, Cons=0.0042, L-Acc=80.0%, P-Acc=81.3%]\n",
            "                                               \n",
            "📊 Epoch 31/100\n",
            "Train - Total Loss: 0.6738\n",
            "Train - Labeled Acc: 80.0%, Pseudo Acc: 81.3%\n",
            "Train - High-conf Pseudo: 4222/6165 (68.5%)\n",
            "Student Val - Acc: 74.9%\n",
            "Teacher Val - Acc: 80.5%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_30.pth\n",
            "💾 Backup saved to: /content/drive/MyDrive/ViT-FishID/checkpoints_backup/checkpoint_epoch_30.pth\n",
            "📊 Epoch 30 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 31: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.6694, Sup=0.6619, Cons=0.0043, L-Acc=80.2%, P-Acc=81.2%]\n",
            "                                               \n",
            "📊 Epoch 32/100\n",
            "Train - Total Loss: 0.6694\n",
            "Train - Labeled Acc: 80.2%, Pseudo Acc: 81.2%\n",
            "Train - High-conf Pseudo: 4262/6165 (69.1%)\n",
            "Student Val - Acc: 74.4%\n",
            "Teacher Val - Acc: 81.0%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_31.pth\n",
            "📊 Epoch 31 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 32: 100% 578/578 [01:35<00:00,  6.07it/s, Total=0.6935, Sup=0.6870, Cons=0.0044, L-Acc=78.2%, P-Acc=80.9%]\n",
            "                                               \n",
            "📊 Epoch 33/100\n",
            "Train - Total Loss: 0.6935\n",
            "Train - Labeled Acc: 78.2%, Pseudo Acc: 80.9%\n",
            "Train - High-conf Pseudo: 4321/6165 (70.1%)\n",
            "Student Val - Acc: 72.8%\n",
            "Teacher Val - Acc: 80.3%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_32.pth\n",
            "📊 Epoch 32 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 33: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.6260, Sup=0.6173, Cons=0.0043, L-Acc=80.3%, P-Acc=81.1%]\n",
            "                                               \n",
            "📊 Epoch 34/100\n",
            "Train - Total Loss: 0.6260\n",
            "Train - Labeled Acc: 80.3%, Pseudo Acc: 81.1%\n",
            "Train - High-conf Pseudo: 4360/6165 (70.7%)\n",
            "Student Val - Acc: 74.1%\n",
            "Teacher Val - Acc: 80.4%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_33.pth\n",
            "📊 Epoch 33 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 34: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.6487, Sup=0.6409, Cons=0.0045, L-Acc=80.1%, P-Acc=81.1%]\n",
            "                                               \n",
            "📊 Epoch 35/100\n",
            "Train - Total Loss: 0.6487\n",
            "Train - Labeled Acc: 80.1%, Pseudo Acc: 81.1%\n",
            "Train - High-conf Pseudo: 4316/6164 (70.0%)\n",
            "Student Val - Acc: 74.9%\n",
            "Teacher Val - Acc: 80.4%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_34.pth\n",
            "📊 Epoch 34 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 35: 100% 578/578 [01:35<00:00,  6.07it/s, Total=0.6143, Sup=0.6063, Cons=0.0046, L-Acc=81.4%, P-Acc=81.9%]\n",
            "                                               \n",
            "📊 Epoch 36/100\n",
            "Train - Total Loss: 0.6143\n",
            "Train - Labeled Acc: 81.4%, Pseudo Acc: 81.9%\n",
            "Train - High-conf Pseudo: 4338/6165 (70.4%)\n",
            "Student Val - Acc: 72.8%\n",
            "Teacher Val - Acc: 80.2%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_35.pth\n",
            "💾 Backup saved to: /content/drive/MyDrive/ViT-FishID/checkpoints_backup/checkpoint_epoch_35.pth\n",
            "📊 Epoch 35 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 36: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.6178, Sup=0.6097, Cons=0.0046, L-Acc=82.3%, P-Acc=82.5%]\n",
            "                                               \n",
            "📊 Epoch 37/100\n",
            "Train - Total Loss: 0.6178\n",
            "Train - Labeled Acc: 82.3%, Pseudo Acc: 82.5%\n",
            "Train - High-conf Pseudo: 4299/6166 (69.7%)\n",
            "Student Val - Acc: 72.7%\n",
            "Teacher Val - Acc: 80.4%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_36.pth\n",
            "📊 Epoch 36 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 37: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.5432, Sup=0.5340, Cons=0.0046, L-Acc=83.7%, P-Acc=83.8%]\n",
            "                                               \n",
            "📊 Epoch 38/100\n",
            "Train - Total Loss: 0.5432\n",
            "Train - Labeled Acc: 83.7%, Pseudo Acc: 83.8%\n",
            "Train - High-conf Pseudo: 4470/6165 (72.5%)\n",
            "Student Val - Acc: 75.1%\n",
            "Teacher Val - Acc: 80.5%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_37.pth\n",
            "📊 Epoch 37 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 38: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.5567, Sup=0.5478, Cons=0.0049, L-Acc=83.0%, P-Acc=81.1%]\n",
            "                                               \n",
            "📊 Epoch 39/100\n",
            "Train - Total Loss: 0.5567\n",
            "Train - Labeled Acc: 83.0%, Pseudo Acc: 81.1%\n",
            "Train - High-conf Pseudo: 4492/6164 (72.9%)\n",
            "Student Val - Acc: 74.0%\n",
            "Teacher Val - Acc: 81.1%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_38.pth\n",
            "📊 Epoch 38 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 39: 100% 578/578 [01:35<00:00,  6.07it/s, Total=0.5303, Sup=0.5205, Cons=0.0049, L-Acc=83.5%, P-Acc=81.8%]\n",
            "                                               \n",
            "📊 Epoch 40/100\n",
            "Train - Total Loss: 0.5303\n",
            "Train - Labeled Acc: 83.5%, Pseudo Acc: 81.8%\n",
            "Train - High-conf Pseudo: 4516/6165 (73.3%)\n",
            "Student Val - Acc: 74.9%\n",
            "Teacher Val - Acc: 81.0%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_39.pth\n",
            "📊 Epoch 39 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 40: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.5483, Sup=0.5392, Cons=0.0050, L-Acc=83.5%, P-Acc=81.3%]\n",
            "                                               \n",
            "📊 Epoch 41/100\n",
            "Train - Total Loss: 0.5483\n",
            "Train - Labeled Acc: 83.5%, Pseudo Acc: 81.3%\n",
            "Train - High-conf Pseudo: 4474/6165 (72.6%)\n",
            "Student Val - Acc: 74.3%\n",
            "Teacher Val - Acc: 80.7%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_40.pth\n",
            "💾 Backup saved to: /content/drive/MyDrive/ViT-FishID/checkpoints_backup/checkpoint_epoch_40.pth\n",
            "📊 Epoch 40 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 41: 100% 578/578 [01:35<00:00,  6.05it/s, Total=0.5005, Sup=0.4929, Cons=0.0047, L-Acc=85.3%, P-Acc=82.5%]\n",
            "                                               \n",
            "📊 Epoch 42/100\n",
            "Train - Total Loss: 0.5005\n",
            "Train - Labeled Acc: 85.3%, Pseudo Acc: 82.5%\n",
            "Train - High-conf Pseudo: 4503/6165 (73.0%)\n",
            "Student Val - Acc: 76.5%\n",
            "Teacher Val - Acc: 80.6%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_41.pth\n",
            "📊 Epoch 41 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 42: 100% 578/578 [01:35<00:00,  6.07it/s, Total=0.4989, Sup=0.4902, Cons=0.0048, L-Acc=84.7%, P-Acc=82.1%]\n",
            "                                               \n",
            "📊 Epoch 43/100\n",
            "Train - Total Loss: 0.4989\n",
            "Train - Labeled Acc: 84.7%, Pseudo Acc: 82.1%\n",
            "Train - High-conf Pseudo: 4560/6164 (74.0%)\n",
            "Student Val - Acc: 73.7%\n",
            "Teacher Val - Acc: 80.2%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_42.pth\n",
            "📊 Epoch 42 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 43: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.5000, Sup=0.4902, Cons=0.0049, L-Acc=86.4%, P-Acc=83.1%]\n",
            "                                               \n",
            "📊 Epoch 44/100\n",
            "Train - Total Loss: 0.5000\n",
            "Train - Labeled Acc: 86.4%, Pseudo Acc: 83.1%\n",
            "Train - High-conf Pseudo: 4612/6165 (74.8%)\n",
            "Student Val - Acc: 76.4%\n",
            "Teacher Val - Acc: 80.6%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_43.pth\n",
            "📊 Epoch 43 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 44: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.4623, Sup=0.4545, Cons=0.0047, L-Acc=86.7%, P-Acc=84.5%]\n",
            "                                               \n",
            "📊 Epoch 45/100\n",
            "Train - Total Loss: 0.4623\n",
            "Train - Labeled Acc: 86.7%, Pseudo Acc: 84.5%\n",
            "Train - High-conf Pseudo: 4628/6166 (75.1%)\n",
            "Student Val - Acc: 76.7%\n",
            "Teacher Val - Acc: 81.1%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_44.pth\n",
            "📊 Epoch 44 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 45: 100% 578/578 [01:35<00:00,  6.07it/s, Total=0.4585, Sup=0.4491, Cons=0.0047, L-Acc=86.8%, P-Acc=84.5%]\n",
            "                                               \n",
            "📊 Epoch 46/100\n",
            "Train - Total Loss: 0.4585\n",
            "Train - Labeled Acc: 86.8%, Pseudo Acc: 84.5%\n",
            "Train - High-conf Pseudo: 4736/6166 (76.8%)\n",
            "Student Val - Acc: 74.0%\n",
            "Teacher Val - Acc: 80.5%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_45.pth\n",
            "💾 Backup saved to: /content/drive/MyDrive/ViT-FishID/checkpoints_backup/checkpoint_epoch_45.pth\n",
            "📊 Epoch 45 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 46: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.4400, Sup=0.4303, Cons=0.0049, L-Acc=86.9%, P-Acc=84.2%]\n",
            "                                               \n",
            "📊 Epoch 47/100\n",
            "Train - Total Loss: 0.4400\n",
            "Train - Labeled Acc: 86.9%, Pseudo Acc: 84.2%\n",
            "Train - High-conf Pseudo: 4789/6165 (77.7%)\n",
            "Student Val - Acc: 74.2%\n",
            "Teacher Val - Acc: 81.2%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_46.pth\n",
            "📊 Epoch 46 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 47: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.4484, Sup=0.4402, Cons=0.0045, L-Acc=87.2%, P-Acc=85.1%]\n",
            "                                               \n",
            "📊 Epoch 48/100\n",
            "Train - Total Loss: 0.4484\n",
            "Train - Labeled Acc: 87.2%, Pseudo Acc: 85.1%\n",
            "Train - High-conf Pseudo: 4765/6166 (77.3%)\n",
            "Student Val - Acc: 75.7%\n",
            "Teacher Val - Acc: 80.3%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_47.pth\n",
            "📊 Epoch 47 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 48: 100% 578/578 [01:35<00:00,  6.07it/s, Total=0.4352, Sup=0.4256, Cons=0.0048, L-Acc=87.8%, P-Acc=84.4%]\n",
            "                                               \n",
            "📊 Epoch 49/100\n",
            "Train - Total Loss: 0.4352\n",
            "Train - Labeled Acc: 87.8%, Pseudo Acc: 84.4%\n",
            "Train - High-conf Pseudo: 4740/6164 (76.9%)\n",
            "Student Val - Acc: 73.0%\n",
            "Teacher Val - Acc: 79.7%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_48.pth\n",
            "📊 Epoch 48 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 49: 100% 578/578 [01:35<00:00,  6.07it/s, Total=0.3736, Sup=0.3653, Cons=0.0045, L-Acc=88.1%, P-Acc=85.7%]\n",
            "                                               \n",
            "📊 Epoch 50/100\n",
            "Train - Total Loss: 0.3736\n",
            "Train - Labeled Acc: 88.1%, Pseudo Acc: 85.7%\n",
            "Train - High-conf Pseudo: 4830/6165 (78.3%)\n",
            "Student Val - Acc: 74.1%\n",
            "Teacher Val - Acc: 79.4%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_49.pth\n",
            "📊 Epoch 49 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 50: 100% 578/578 [01:35<00:00,  6.07it/s, Total=0.3734, Sup=0.3641, Cons=0.0046, L-Acc=88.9%, P-Acc=85.5%]\n",
            "                                               \n",
            "📊 Epoch 51/100\n",
            "Train - Total Loss: 0.3734\n",
            "Train - Labeled Acc: 88.9%, Pseudo Acc: 85.5%\n",
            "Train - High-conf Pseudo: 4870/6165 (79.0%)\n",
            "Student Val - Acc: 75.0%\n",
            "Teacher Val - Acc: 78.8%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_50.pth\n",
            "💾 Backup saved to: /content/drive/MyDrive/ViT-FishID/checkpoints_backup/checkpoint_epoch_50.pth\n",
            "📊 Epoch 50 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 51: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.3292, Sup=0.3203, Cons=0.0045, L-Acc=90.1%, P-Acc=86.0%]\n",
            "                                               \n",
            "📊 Epoch 52/100\n",
            "Train - Total Loss: 0.3292\n",
            "Train - Labeled Acc: 90.1%, Pseudo Acc: 86.0%\n",
            "Train - High-conf Pseudo: 4921/6164 (79.8%)\n",
            "Student Val - Acc: 75.9%\n",
            "Teacher Val - Acc: 79.4%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_51.pth\n",
            "📊 Epoch 51 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 52: 100% 578/578 [01:35<00:00,  6.07it/s, Total=0.3755, Sup=0.3663, Cons=0.0046, L-Acc=89.7%, P-Acc=86.0%]\n",
            "                                               \n",
            "📊 Epoch 53/100\n",
            "Train - Total Loss: 0.3755\n",
            "Train - Labeled Acc: 89.7%, Pseudo Acc: 86.0%\n",
            "Train - High-conf Pseudo: 4954/6165 (80.4%)\n",
            "Student Val - Acc: 76.0%\n",
            "Teacher Val - Acc: 78.8%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_52.pth\n",
            "📊 Epoch 52 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 53: 100% 578/578 [01:35<00:00,  6.07it/s, Total=0.3482, Sup=0.3401, Cons=0.0041, L-Acc=89.9%, P-Acc=86.9%]\n",
            "                                               \n",
            "📊 Epoch 54/100\n",
            "Train - Total Loss: 0.3482\n",
            "Train - Labeled Acc: 89.9%, Pseudo Acc: 86.9%\n",
            "Train - High-conf Pseudo: 4945/6164 (80.2%)\n",
            "Student Val - Acc: 76.5%\n",
            "Teacher Val - Acc: 79.1%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_53.pth\n",
            "📊 Epoch 53 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 54: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.3146, Sup=0.3062, Cons=0.0042, L-Acc=91.5%, P-Acc=87.1%]\n",
            "                                               \n",
            "📊 Epoch 55/100\n",
            "Train - Total Loss: 0.3146\n",
            "Train - Labeled Acc: 91.5%, Pseudo Acc: 87.1%\n",
            "Train - High-conf Pseudo: 4931/6165 (80.0%)\n",
            "Student Val - Acc: 76.7%\n",
            "Teacher Val - Acc: 79.2%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_54.pth\n",
            "📊 Epoch 54 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 55: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.2928, Sup=0.2847, Cons=0.0041, L-Acc=91.8%, P-Acc=88.0%]\n",
            "                                               \n",
            "📊 Epoch 56/100\n",
            "Train - Total Loss: 0.2928\n",
            "Train - Labeled Acc: 91.8%, Pseudo Acc: 88.0%\n",
            "Train - High-conf Pseudo: 4994/6165 (81.0%)\n",
            "Student Val - Acc: 76.4%\n",
            "Teacher Val - Acc: 79.9%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_55.pth\n",
            "💾 Backup saved to: /content/drive/MyDrive/ViT-FishID/checkpoints_backup/checkpoint_epoch_55.pth\n",
            "📊 Epoch 55 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 56: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.3464, Sup=0.3385, Cons=0.0040, L-Acc=90.5%, P-Acc=87.8%]\n",
            "                                               \n",
            "📊 Epoch 57/100\n",
            "Train - Total Loss: 0.3464\n",
            "Train - Labeled Acc: 90.5%, Pseudo Acc: 87.8%\n",
            "Train - High-conf Pseudo: 5077/6166 (82.3%)\n",
            "Student Val - Acc: 77.4%\n",
            "Teacher Val - Acc: 79.2%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_56.pth\n",
            "📊 Epoch 56 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 57: 100% 578/578 [01:35<00:00,  6.07it/s, Total=0.3227, Sup=0.3148, Cons=0.0040, L-Acc=91.4%, P-Acc=88.2%]\n",
            "                                               \n",
            "📊 Epoch 58/100\n",
            "Train - Total Loss: 0.3227\n",
            "Train - Labeled Acc: 91.4%, Pseudo Acc: 88.2%\n",
            "Train - High-conf Pseudo: 5057/6165 (82.0%)\n",
            "Student Val - Acc: 76.2%\n",
            "Teacher Val - Acc: 79.1%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_57.pth\n",
            "📊 Epoch 57 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 58: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.3174, Sup=0.3117, Cons=0.0034, L-Acc=91.1%, P-Acc=89.2%]\n",
            "                                               \n",
            "📊 Epoch 59/100\n",
            "Train - Total Loss: 0.3174\n",
            "Train - Labeled Acc: 91.1%, Pseudo Acc: 89.2%\n",
            "Train - High-conf Pseudo: 5076/6167 (82.3%)\n",
            "Student Val - Acc: 76.7%\n",
            "Teacher Val - Acc: 79.8%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_58.pth\n",
            "📊 Epoch 58 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 59: 100% 578/578 [01:35<00:00,  6.07it/s, Total=0.2881, Sup=0.2812, Cons=0.0035, L-Acc=92.2%, P-Acc=89.4%]\n",
            "                                               \n",
            "📊 Epoch 60/100\n",
            "Train - Total Loss: 0.2881\n",
            "Train - Labeled Acc: 92.2%, Pseudo Acc: 89.4%\n",
            "Train - High-conf Pseudo: 5053/6165 (82.0%)\n",
            "Student Val - Acc: 77.5%\n",
            "Teacher Val - Acc: 79.8%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_59.pth\n",
            "📊 Epoch 59 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 60: 100% 578/578 [01:35<00:00,  6.07it/s, Total=0.2596, Sup=0.2544, Cons=0.0033, L-Acc=92.7%, P-Acc=90.6%]\n",
            "                                               \n",
            "📊 Epoch 61/100\n",
            "Train - Total Loss: 0.2596\n",
            "Train - Labeled Acc: 92.7%, Pseudo Acc: 90.6%\n",
            "Train - High-conf Pseudo: 5064/6166 (82.1%)\n",
            "Student Val - Acc: 78.1%\n",
            "Teacher Val - Acc: 80.1%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_60.pth\n",
            "💾 Backup saved to: /content/drive/MyDrive/ViT-FishID/checkpoints_backup/checkpoint_epoch_60.pth\n",
            "📊 Epoch 60 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 61: 100% 578/578 [01:35<00:00,  6.05it/s, Total=0.2715, Sup=0.2661, Cons=0.0029, L-Acc=92.4%, P-Acc=91.2%]\n",
            "                                               \n",
            "📊 Epoch 62/100\n",
            "Train - Total Loss: 0.2715\n",
            "Train - Labeled Acc: 92.4%, Pseudo Acc: 91.2%\n",
            "Train - High-conf Pseudo: 5135/6164 (83.3%)\n",
            "Student Val - Acc: 76.6%\n",
            "Teacher Val - Acc: 80.2%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_61.pth\n",
            "📊 Epoch 61 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 62: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.2662, Sup=0.2600, Cons=0.0031, L-Acc=93.3%, P-Acc=90.6%]\n",
            "                                               \n",
            "📊 Epoch 63/100\n",
            "Train - Total Loss: 0.2662\n",
            "Train - Labeled Acc: 93.3%, Pseudo Acc: 90.6%\n",
            "Train - High-conf Pseudo: 5134/6164 (83.3%)\n",
            "Student Val - Acc: 78.5%\n",
            "Teacher Val - Acc: 79.8%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_62.pth\n",
            "📊 Epoch 62 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 63: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.2424, Sup=0.2371, Cons=0.0028, L-Acc=93.5%, P-Acc=91.0%]\n",
            "                                               \n",
            "📊 Epoch 64/100\n",
            "Train - Total Loss: 0.2424\n",
            "Train - Labeled Acc: 93.5%, Pseudo Acc: 91.0%\n",
            "Train - High-conf Pseudo: 5170/6165 (83.9%)\n",
            "Student Val - Acc: 77.8%\n",
            "Teacher Val - Acc: 80.7%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_63.pth\n",
            "📊 Epoch 63 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 64: 100% 578/578 [01:35<00:00,  6.07it/s, Total=0.2606, Sup=0.2556, Cons=0.0027, L-Acc=93.2%, P-Acc=91.9%]\n",
            "                                               \n",
            "📊 Epoch 65/100\n",
            "Train - Total Loss: 0.2606\n",
            "Train - Labeled Acc: 93.2%, Pseudo Acc: 91.9%\n",
            "Train - High-conf Pseudo: 5163/6166 (83.7%)\n",
            "Student Val - Acc: 77.9%\n",
            "Teacher Val - Acc: 80.0%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_64.pth\n",
            "📊 Epoch 64 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 65: 100% 578/578 [01:35<00:00,  6.07it/s, Total=0.2254, Sup=0.2210, Cons=0.0026, L-Acc=93.8%, P-Acc=92.5%]\n",
            "                                               \n",
            "📊 Epoch 66/100\n",
            "Train - Total Loss: 0.2254\n",
            "Train - Labeled Acc: 93.8%, Pseudo Acc: 92.5%\n",
            "Train - High-conf Pseudo: 5226/6164 (84.8%)\n",
            "Student Val - Acc: 77.4%\n",
            "Teacher Val - Acc: 79.9%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_65.pth\n",
            "💾 Backup saved to: /content/drive/MyDrive/ViT-FishID/checkpoints_backup/checkpoint_epoch_65.pth\n",
            "📊 Epoch 65 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 66: 100% 578/578 [01:35<00:00,  6.05it/s, Total=0.2218, Sup=0.2170, Cons=0.0024, L-Acc=93.9%, P-Acc=92.5%]\n",
            "                                               \n",
            "📊 Epoch 67/100\n",
            "Train - Total Loss: 0.2218\n",
            "Train - Labeled Acc: 93.9%, Pseudo Acc: 92.5%\n",
            "Train - High-conf Pseudo: 5215/6166 (84.6%)\n",
            "Student Val - Acc: 77.7%\n",
            "Teacher Val - Acc: 79.3%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_66.pth\n",
            "📊 Epoch 66 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 67: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.2144, Sup=0.2109, Cons=0.0021, L-Acc=95.0%, P-Acc=92.9%]\n",
            "                                               \n",
            "📊 Epoch 68/100\n",
            "Train - Total Loss: 0.2144\n",
            "Train - Labeled Acc: 95.0%, Pseudo Acc: 92.9%\n",
            "Train - High-conf Pseudo: 5244/6165 (85.1%)\n",
            "Student Val - Acc: 77.6%\n",
            "Teacher Val - Acc: 79.4%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_67.pth\n",
            "📊 Epoch 67 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 68: 100% 578/578 [01:35<00:00,  6.07it/s, Total=0.1972, Sup=0.1934, Cons=0.0021, L-Acc=94.2%, P-Acc=93.4%]\n",
            "                                               \n",
            "📊 Epoch 69/100\n",
            "Train - Total Loss: 0.1972\n",
            "Train - Labeled Acc: 94.2%, Pseudo Acc: 93.4%\n",
            "Train - High-conf Pseudo: 5244/6165 (85.1%)\n",
            "Student Val - Acc: 77.6%\n",
            "Teacher Val - Acc: 79.6%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_68.pth\n",
            "📊 Epoch 68 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 69: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.1898, Sup=0.1858, Cons=0.0020, L-Acc=94.4%, P-Acc=94.0%]\n",
            "                                               \n",
            "📊 Epoch 70/100\n",
            "Train - Total Loss: 0.1898\n",
            "Train - Labeled Acc: 94.4%, Pseudo Acc: 94.0%\n",
            "Train - High-conf Pseudo: 5269/6166 (85.5%)\n",
            "Student Val - Acc: 76.9%\n",
            "Teacher Val - Acc: 79.0%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_69.pth\n",
            "📊 Epoch 69 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 70: 100% 578/578 [01:35<00:00,  6.07it/s, Total=0.2025, Sup=0.1992, Cons=0.0018, L-Acc=94.5%, P-Acc=94.3%]\n",
            "                                               \n",
            "📊 Epoch 71/100\n",
            "Train - Total Loss: 0.2025\n",
            "Train - Labeled Acc: 94.5%, Pseudo Acc: 94.3%\n",
            "Train - High-conf Pseudo: 5278/6166 (85.6%)\n",
            "Student Val - Acc: 77.1%\n",
            "Teacher Val - Acc: 78.8%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_70.pth\n",
            "💾 Backup saved to: /content/drive/MyDrive/ViT-FishID/checkpoints_backup/checkpoint_epoch_70.pth\n",
            "📊 Epoch 70 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 71: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.1801, Sup=0.1761, Cons=0.0020, L-Acc=95.2%, P-Acc=93.9%]\n",
            "                                               \n",
            "📊 Epoch 72/100\n",
            "Train - Total Loss: 0.1801\n",
            "Train - Labeled Acc: 95.2%, Pseudo Acc: 93.9%\n",
            "Train - High-conf Pseudo: 5286/6166 (85.7%)\n",
            "Student Val - Acc: 78.2%\n",
            "Teacher Val - Acc: 78.3%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_71.pth\n",
            "📊 Epoch 71 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 72: 100% 578/578 [01:35<00:00,  6.07it/s, Total=0.2195, Sup=0.2166, Cons=0.0016, L-Acc=95.2%, P-Acc=94.8%]\n",
            "                                               \n",
            "📊 Epoch 73/100\n",
            "Train - Total Loss: 0.2195\n",
            "Train - Labeled Acc: 95.2%, Pseudo Acc: 94.8%\n",
            "Train - High-conf Pseudo: 5279/6167 (85.6%)\n",
            "Student Val - Acc: 78.3%\n",
            "Teacher Val - Acc: 78.9%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_72.pth\n",
            "📊 Epoch 72 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 73: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.1587, Sup=0.1558, Cons=0.0014, L-Acc=95.7%, P-Acc=95.1%]\n",
            "                                               \n",
            "📊 Epoch 74/100\n",
            "Train - Total Loss: 0.1587\n",
            "Train - Labeled Acc: 95.7%, Pseudo Acc: 95.1%\n",
            "Train - High-conf Pseudo: 5286/6166 (85.7%)\n",
            "Student Val - Acc: 78.6%\n",
            "Teacher Val - Acc: 79.0%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_73.pth\n",
            "📊 Epoch 73 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 74: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.1379, Sup=0.1353, Cons=0.0013, L-Acc=95.9%, P-Acc=95.7%]\n",
            "                                               \n",
            "📊 Epoch 75/100\n",
            "Train - Total Loss: 0.1379\n",
            "Train - Labeled Acc: 95.9%, Pseudo Acc: 95.7%\n",
            "Train - High-conf Pseudo: 5353/6167 (86.8%)\n",
            "Student Val - Acc: 78.0%\n",
            "Teacher Val - Acc: 79.0%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_74.pth\n",
            "📊 Epoch 74 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 75: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.1732, Sup=0.1711, Cons=0.0012, L-Acc=95.5%, P-Acc=95.9%]\n",
            "                                               \n",
            "📊 Epoch 76/100\n",
            "Train - Total Loss: 0.1732\n",
            "Train - Labeled Acc: 95.5%, Pseudo Acc: 95.9%\n",
            "Train - High-conf Pseudo: 5324/6166 (86.3%)\n",
            "Student Val - Acc: 78.9%\n",
            "Teacher Val - Acc: 78.6%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_75.pth\n",
            "💾 Backup saved to: /content/drive/MyDrive/ViT-FishID/checkpoints_backup/checkpoint_epoch_75.pth\n",
            "📊 Epoch 75 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 76: 100% 578/578 [01:38<00:00,  5.87it/s, Total=0.1504, Sup=0.1488, Cons=0.0011, L-Acc=96.0%, P-Acc=96.8%]\n",
            "                                               \n",
            "📊 Epoch 77/100\n",
            "Train - Total Loss: 0.1504\n",
            "Train - Labeled Acc: 96.0%, Pseudo Acc: 96.8%\n",
            "Train - High-conf Pseudo: 5360/6164 (87.0%)\n",
            "Student Val - Acc: 77.3%\n",
            "Teacher Val - Acc: 79.3%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_76.pth\n",
            "📊 Epoch 76 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 77: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.1535, Sup=0.1516, Cons=0.0011, L-Acc=95.8%, P-Acc=96.5%]\n",
            "                                               \n",
            "📊 Epoch 78/100\n",
            "Train - Total Loss: 0.1535\n",
            "Train - Labeled Acc: 95.8%, Pseudo Acc: 96.5%\n",
            "Train - High-conf Pseudo: 5330/6164 (86.5%)\n",
            "Student Val - Acc: 79.1%\n",
            "Teacher Val - Acc: 79.1%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_77.pth\n",
            "📊 Epoch 77 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 78: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.1184, Sup=0.1170, Cons=0.0009, L-Acc=96.4%, P-Acc=97.2%]\n",
            "                                               \n",
            "📊 Epoch 79/100\n",
            "Train - Total Loss: 0.1184\n",
            "Train - Labeled Acc: 96.4%, Pseudo Acc: 97.2%\n",
            "Train - High-conf Pseudo: 5381/6164 (87.3%)\n",
            "Student Val - Acc: 78.0%\n",
            "Teacher Val - Acc: 78.9%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_78.pth\n",
            "📊 Epoch 78 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 79: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.1504, Sup=0.1491, Cons=0.0009, L-Acc=95.9%, P-Acc=97.0%]\n",
            "                                               \n",
            "📊 Epoch 80/100\n",
            "Train - Total Loss: 0.1504\n",
            "Train - Labeled Acc: 95.9%, Pseudo Acc: 97.0%\n",
            "Train - High-conf Pseudo: 5398/6165 (87.6%)\n",
            "Student Val - Acc: 78.0%\n",
            "Teacher Val - Acc: 79.0%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_79.pth\n",
            "📊 Epoch 79 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 80: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.1432, Sup=0.1419, Cons=0.0008, L-Acc=96.1%, P-Acc=97.0%]\n",
            "                                               \n",
            "📊 Epoch 81/100\n",
            "Train - Total Loss: 0.1432\n",
            "Train - Labeled Acc: 96.1%, Pseudo Acc: 97.0%\n",
            "Train - High-conf Pseudo: 5381/6165 (87.3%)\n",
            "Student Val - Acc: 78.3%\n",
            "Teacher Val - Acc: 78.8%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_80.pth\n",
            "💾 Backup saved to: /content/drive/MyDrive/ViT-FishID/checkpoints_backup/checkpoint_epoch_80.pth\n",
            "📊 Epoch 80 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 81: 100% 578/578 [01:35<00:00,  6.05it/s, Total=0.1244, Sup=0.1232, Cons=0.0007, L-Acc=96.5%, P-Acc=97.6%]\n",
            "                                               \n",
            "📊 Epoch 82/100\n",
            "Train - Total Loss: 0.1244\n",
            "Train - Labeled Acc: 96.5%, Pseudo Acc: 97.6%\n",
            "Train - High-conf Pseudo: 5387/6164 (87.4%)\n",
            "Student Val - Acc: 78.9%\n",
            "Teacher Val - Acc: 78.6%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_81.pth\n",
            "📊 Epoch 81 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 82: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.1459, Sup=0.1446, Cons=0.0006, L-Acc=96.4%, P-Acc=97.6%]\n",
            "                                               \n",
            "📊 Epoch 83/100\n",
            "Train - Total Loss: 0.1459\n",
            "Train - Labeled Acc: 96.4%, Pseudo Acc: 97.6%\n",
            "Train - High-conf Pseudo: 5398/6164 (87.6%)\n",
            "Student Val - Acc: 78.4%\n",
            "Teacher Val - Acc: 79.1%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_82.pth\n",
            "📊 Epoch 82 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 83: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.1296, Sup=0.1285, Cons=0.0006, L-Acc=96.3%, P-Acc=98.0%]\n",
            "                                               \n",
            "📊 Epoch 84/100\n",
            "Train - Total Loss: 0.1296\n",
            "Train - Labeled Acc: 96.3%, Pseudo Acc: 98.0%\n",
            "Train - High-conf Pseudo: 5426/6165 (88.0%)\n",
            "Student Val - Acc: 78.9%\n",
            "Teacher Val - Acc: 79.3%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_83.pth\n",
            "📊 Epoch 83 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 84: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.1327, Sup=0.1321, Cons=0.0005, L-Acc=96.3%, P-Acc=98.2%]\n",
            "                                               \n",
            "📊 Epoch 85/100\n",
            "Train - Total Loss: 0.1327\n",
            "Train - Labeled Acc: 96.3%, Pseudo Acc: 98.2%\n",
            "Train - High-conf Pseudo: 5406/6166 (87.7%)\n",
            "Student Val - Acc: 78.6%\n",
            "Teacher Val - Acc: 79.3%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_84.pth\n",
            "📊 Epoch 84 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 85: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.1152, Sup=0.1149, Cons=0.0005, L-Acc=96.7%, P-Acc=98.3%]\n",
            "                                               \n",
            "📊 Epoch 86/100\n",
            "Train - Total Loss: 0.1152\n",
            "Train - Labeled Acc: 96.7%, Pseudo Acc: 98.3%\n",
            "Train - High-conf Pseudo: 5460/6165 (88.6%)\n",
            "Student Val - Acc: 79.4%\n",
            "Teacher Val - Acc: 79.3%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_85.pth\n",
            "💾 Backup saved to: /content/drive/MyDrive/ViT-FishID/checkpoints_backup/checkpoint_epoch_85.pth\n",
            "📊 Epoch 85 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 86: 100% 578/578 [01:35<00:00,  6.05it/s, Total=0.1199, Sup=0.1191, Cons=0.0004, L-Acc=97.1%, P-Acc=98.9%]\n",
            "                                               \n",
            "📊 Epoch 87/100\n",
            "Train - Total Loss: 0.1199\n",
            "Train - Labeled Acc: 97.1%, Pseudo Acc: 98.9%\n",
            "Train - High-conf Pseudo: 5446/6165 (88.3%)\n",
            "Student Val - Acc: 79.1%\n",
            "Teacher Val - Acc: 79.2%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_86.pth\n",
            "📊 Epoch 86 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 87: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.1315, Sup=0.1308, Cons=0.0004, L-Acc=96.7%, P-Acc=99.1%]\n",
            "                                               \n",
            "📊 Epoch 88/100\n",
            "Train - Total Loss: 0.1315\n",
            "Train - Labeled Acc: 96.7%, Pseudo Acc: 99.1%\n",
            "Train - High-conf Pseudo: 5420/6167 (87.9%)\n",
            "Student Val - Acc: 78.5%\n",
            "Teacher Val - Acc: 79.5%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_87.pth\n",
            "📊 Epoch 87 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 88: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.1224, Sup=0.1219, Cons=0.0003, L-Acc=96.9%, P-Acc=99.2%]\n",
            "                                               \n",
            "📊 Epoch 89/100\n",
            "Train - Total Loss: 0.1224\n",
            "Train - Labeled Acc: 96.9%, Pseudo Acc: 99.2%\n",
            "Train - High-conf Pseudo: 5450/6166 (88.4%)\n",
            "Student Val - Acc: 78.8%\n",
            "Teacher Val - Acc: 79.2%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_88.pth\n",
            "📊 Epoch 88 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 89: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.0797, Sup=0.0794, Cons=0.0003, L-Acc=97.4%, P-Acc=99.4%]\n",
            "                                               \n",
            "📊 Epoch 90/100\n",
            "Train - Total Loss: 0.0797\n",
            "Train - Labeled Acc: 97.4%, Pseudo Acc: 99.4%\n",
            "Train - High-conf Pseudo: 5458/6165 (88.5%)\n",
            "Student Val - Acc: 78.5%\n",
            "Teacher Val - Acc: 79.2%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_89.pth\n",
            "📊 Epoch 89 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 90: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.1319, Sup=0.1316, Cons=0.0003, L-Acc=96.9%, P-Acc=99.4%]\n",
            "                                               \n",
            "📊 Epoch 91/100\n",
            "Train - Total Loss: 0.1319\n",
            "Train - Labeled Acc: 96.9%, Pseudo Acc: 99.4%\n",
            "Train - High-conf Pseudo: 5405/6165 (87.7%)\n",
            "Student Val - Acc: 78.5%\n",
            "Teacher Val - Acc: 78.8%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_90.pth\n",
            "💾 Backup saved to: /content/drive/MyDrive/ViT-FishID/checkpoints_backup/checkpoint_epoch_90.pth\n",
            "📊 Epoch 90 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 91: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.1160, Sup=0.1157, Cons=0.0003, L-Acc=97.3%, P-Acc=99.5%]\n",
            "                                               \n",
            "📊 Epoch 92/100\n",
            "Train - Total Loss: 0.1160\n",
            "Train - Labeled Acc: 97.3%, Pseudo Acc: 99.5%\n",
            "Train - High-conf Pseudo: 5452/6167 (88.4%)\n",
            "Student Val - Acc: 78.6%\n",
            "Teacher Val - Acc: 78.7%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_91.pth\n",
            "📊 Epoch 91 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 92: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.0973, Sup=0.0971, Cons=0.0002, L-Acc=97.4%, P-Acc=99.8%]\n",
            "                                               \n",
            "📊 Epoch 93/100\n",
            "Train - Total Loss: 0.0973\n",
            "Train - Labeled Acc: 97.4%, Pseudo Acc: 99.8%\n",
            "Train - High-conf Pseudo: 5438/6164 (88.2%)\n",
            "Student Val - Acc: 78.6%\n",
            "Teacher Val - Acc: 78.5%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_92.pth\n",
            "📊 Epoch 92 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 93: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.0921, Sup=0.0917, Cons=0.0002, L-Acc=97.2%, P-Acc=99.8%]\n",
            "                                               \n",
            "📊 Epoch 94/100\n",
            "Train - Total Loss: 0.0921\n",
            "Train - Labeled Acc: 97.2%, Pseudo Acc: 99.8%\n",
            "Train - High-conf Pseudo: 5470/6165 (88.7%)\n",
            "Student Val - Acc: 78.8%\n",
            "Teacher Val - Acc: 78.8%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_93.pth\n",
            "📊 Epoch 93 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 94: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.0866, Sup=0.0863, Cons=0.0002, L-Acc=97.4%, P-Acc=99.9%]\n",
            "                                               \n",
            "📊 Epoch 95/100\n",
            "Train - Total Loss: 0.0866\n",
            "Train - Labeled Acc: 97.4%, Pseudo Acc: 99.9%\n",
            "Train - High-conf Pseudo: 5455/6165 (88.5%)\n",
            "Student Val - Acc: 78.9%\n",
            "Teacher Val - Acc: 79.0%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_94.pth\n",
            "📊 Epoch 94 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 95: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.1096, Sup=0.1095, Cons=0.0001, L-Acc=97.3%, P-Acc=99.9%]\n",
            "                                               \n",
            "📊 Epoch 96/100\n",
            "Train - Total Loss: 0.1096\n",
            "Train - Labeled Acc: 97.3%, Pseudo Acc: 99.9%\n",
            "Train - High-conf Pseudo: 5490/6165 (89.1%)\n",
            "Student Val - Acc: 79.0%\n",
            "Teacher Val - Acc: 78.7%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_95.pth\n",
            "💾 Backup saved to: /content/drive/MyDrive/ViT-FishID/checkpoints_backup/checkpoint_epoch_95.pth\n",
            "📊 Epoch 95 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 96: 100% 578/578 [01:35<00:00,  6.05it/s, Total=0.1374, Sup=0.1376, Cons=0.0001, L-Acc=96.6%, P-Acc=99.9%]\n",
            "                                               \n",
            "📊 Epoch 97/100\n",
            "Train - Total Loss: 0.1374\n",
            "Train - Labeled Acc: 96.6%, Pseudo Acc: 99.9%\n",
            "Train - High-conf Pseudo: 5499/6167 (89.2%)\n",
            "Student Val - Acc: 79.0%\n",
            "Teacher Val - Acc: 78.9%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_96.pth\n",
            "📊 Epoch 96 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 97: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.0958, Sup=0.0956, Cons=0.0001, L-Acc=97.4%, P-Acc=100.0%]\n",
            "                                               \n",
            "📊 Epoch 98/100\n",
            "Train - Total Loss: 0.0958\n",
            "Train - Labeled Acc: 97.4%, Pseudo Acc: 100.0%\n",
            "Train - High-conf Pseudo: 5509/6164 (89.4%)\n",
            "Student Val - Acc: 78.4%\n",
            "Teacher Val - Acc: 79.0%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_97.pth\n",
            "📊 Epoch 97 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 98: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.0978, Sup=0.0978, Cons=0.0001, L-Acc=97.1%, P-Acc=100.0%]\n",
            "                                               \n",
            "📊 Epoch 99/100\n",
            "Train - Total Loss: 0.0978\n",
            "Train - Labeled Acc: 97.1%, Pseudo Acc: 100.0%\n",
            "Train - High-conf Pseudo: 5524/6165 (89.6%)\n",
            "Student Val - Acc: 78.5%\n",
            "Teacher Val - Acc: 79.0%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_98.pth\n",
            "📊 Epoch 98 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 99: 100% 578/578 [01:35<00:00,  6.05it/s, Total=0.0951, Sup=0.0949, Cons=0.0001, L-Acc=97.7%, P-Acc=100.0%]\n",
            "                                               \n",
            "📊 Epoch 100/100\n",
            "Train - Total Loss: 0.0951\n",
            "Train - Labeled Acc: 97.7%, Pseudo Acc: 100.0%\n",
            "Train - High-conf Pseudo: 5511/6165 (89.4%)\n",
            "Student Val - Acc: 78.6%\n",
            "Teacher Val - Acc: 78.8%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_99.pth\n",
            "📊 Epoch 99 checkpoint saved (Size: 982.4 MB)\n",
            "Epoch 100: 100% 578/578 [01:35<00:00,  6.06it/s, Total=0.1098, Sup=0.1098, Cons=0.0001, L-Acc=97.3%, P-Acc=100.0%]\n",
            "                                               \n",
            "📊 Epoch 101/100\n",
            "Train - Total Loss: 0.1098\n",
            "Train - Labeled Acc: 97.3%, Pseudo Acc: 100.0%\n",
            "Train - High-conf Pseudo: 5500/6165 (89.2%)\n",
            "Student Val - Acc: 78.6%\n",
            "Teacher Val - Acc: 78.8%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_100.pth\n",
            "💾 Backup saved to: /content/drive/MyDrive/ViT-FishID/checkpoints_backup/checkpoint_epoch_100.pth\n",
            "📊 Epoch 100 checkpoint saved (Size: 982.4 MB)\n",
            "\n",
            "🎉 Training completed! Best validation accuracy: 87.56%\n",
            "\n",
            "✅ Training completed!\n",
            "💡 Use evaluate.py with the test set for final unbiased performance metrics\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading output.log 38.8KB/38.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading config.yaml 5.3KB/5.3KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading output.log 38.8KB/38.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading config.yaml 5.3KB/5.3KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading output.log 38.8KB/38.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading config.yaml 5.3KB/5.3KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading output.log 38.8KB/38.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading config.yaml 5.3KB/5.3KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading output.log 38.8KB/38.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading config.yaml 5.3KB/5.3KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading output.log 38.8KB/38.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading config.yaml 5.3KB/5.3KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading output.log 38.8KB/38.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading config.yaml 5.3KB/5.3KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading output.log 38.8KB/38.8KB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading config.yaml 5.3KB/5.3KB (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                               epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▄▄▄▆▆▆▆▆▆▆▆▆▇▇▇▇▇█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       learning_rate ███████▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/consistency_loss ▆▃▃▅▅▅▃▄▆▅▅▆▅▆▅▆▄▇█▄▃▇▂▂▂▃▂▅▂▃▂▁▂▂▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/consistency_weight ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/high_conf_ratio ▁▂▂▃▃▁▃▄▄▄▇▆▆▆▆▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇██████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/labeled_accuracy ▁▁▂▁▁▂▂▃▃▃▅▄▃▃▄▅▅▅█▅▅▅▅▆██▆▆▆▆▇▇▇▇▇▇▇▇▇▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 train/learning_rate ███████▇▇▇▇▇▇▇▇▆▆▆▅▅▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/pseudo_accuracy ▄▃▂▂█▂▁▁▁▁▁█▂▂▁▂▅▂▃▄█▅▅▅▅▅▅▆▆█▆▇█▇██████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/supervised_loss ▂▁▄▁▂▁▁▃▂▂▃▂█▁▁▁▁▂▁▁▁▁▄▁▃▁▁▁▁▁▁▃▁▁▁▁▁▁▁▃\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/total_loss ▄▃▁█▁▂▅▁▂▆▃▄▁▃▁▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▄▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        train_epoch/consistency_loss █▄▄▄▄▅▅▅▅▅▆▅▆▅▅▅▅▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_epoch/high_conf_pseudo_labels ▁▄▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        train_epoch/labeled_accuracy ▁▁▁▁▂▂▂▃▂▃▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train_epoch/labeled_samples ▆▆▆▃▃▃▆▆▆▆▆▆▆▆▆▆▆▃▆█▆▁▆▆▃▃▃██▆▆▆▃▆▆█▆▆▆▆\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train_epoch/pseudo_accuracy ▃▁▂▂▁▂▂▁▁▁▁▂▂▂▃▃▃▃▃▄▄▄▄▅▅▆▆▆▇▇▇▇▇███████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train_epoch/supervised_loss █████▇▇▇▇▇▇▆▆▅▅▄▃▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▂▂▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train_epoch/total_loss █▇▇▇▆▆▆▅▅▅▅▅▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▂▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train_epoch/unlabeled_samples ▃▃▆▆▃▆▃▃▁▃▃▃▃▃▃▃▆█▃▆▁▃▁▆▃▆█▆▆▁▃▁▃▆▃█▁▃▃▃\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                val/student_top1_acc ▁▂▃▃▃▂▄▄▄▃▃▂▅▆▃▄▆▅▅▇▇▆▆▆▇▇██▇▇▇██▇█▇████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                val/student_top5_acc ▆▆▄█▅▂▃▃▅▃▁▃▆▃▁▄▅▆▆▅▇▆▆▆▆▆▇▇▆▆█▇▇▇▇▇▇▇▇▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                val/teacher_top1_acc ███▇▇▆▆▆▅▅▆▅▅▆▆▃▂▂▂▂▃▄▄▃▄▃▃▂▁▂▂▃▂▃▂▂▂▂▂▂\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                val/teacher_top5_acc ██▆▆▅▅▅▃▅▅▅▅▅▄▃▃▂▂▁▃▅▅▄▄▃▃▃▃▃▄▄▄▄▃▃▃▃▃▃▃\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                               epoch 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       learning_rate 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/consistency_loss 0.00011\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/consistency_weight 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/high_conf_ratio 89.21952\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/labeled_accuracy 97.30835\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 train/learning_rate 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/pseudo_accuracy 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/supervised_loss 6e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/total_loss 0.00028\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        train_epoch/consistency_loss 0.00012\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_epoch/high_conf_pseudo_labels 5500\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        train_epoch/labeled_accuracy 97.34025\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train_epoch/labeled_samples 3083\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train_epoch/pseudo_accuracy 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train_epoch/supervised_loss 0.10978\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train_epoch/total_loss 0.10983\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train_epoch/unlabeled_samples 6165\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                val/student_top1_acc 78.62002\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                val/student_top5_acc 95.2381\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                val/teacher_top1_acc 78.81438\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                val/teacher_top5_acc 95.33528\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33msemi_supervised_vit_base_patch16_224_20250814_205754\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/cativthomson-university-of-cape-town/vit-fish-id/runs/tyuoy4jc\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/cativthomson-university-of-cape-town/vit-fish-id\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250814_205754-tyuoy4jc/logs\u001b[0m\n",
            "\n",
            "🎉 Training completed successfully!\n",
            "💾 Checkpoints saved to: /content/drive/MyDrive/ViT-FishID/checkpoints_extended\n",
            "🏆 Best accuracy: 87.56%\n",
            "\n",
            "============================================================\n",
            "🎉 EXTENDED TRAINING COMPLETED!\n",
            "⏰ Finished at: 2025-08-14 23:21:28\n",
            "🏆 Total epochs completed: 100\n",
            "💾 All checkpoints saved to Google Drive\n",
            "\n",
            "✅ Your model is ready for evaluation and deployment!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5af5177",
      "metadata": {
        "id": "b5af5177"
      },
      "source": [
        "## 📊 Step 9: Check Training Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "87ea96e8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87ea96e8",
        "outputId": "61af1603-1381-4490-ff59-f2e3b1fbcccc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📁 Checking results in: /content/drive/MyDrive/ViT-FishID/checkpoints_extended\n",
            "\n",
            "✅ Found 100 checkpoint(s) from extended training:\n",
            "  📊 Epoch 1: checkpoint_epoch_1.pth (982.4 MB)\n",
            "  📊 Epoch 2: checkpoint_epoch_2.pth (982.4 MB)\n",
            "  📊 Epoch 3: checkpoint_epoch_3.pth (982.4 MB)\n",
            "  📊 Epoch 4: checkpoint_epoch_4.pth (982.4 MB)\n",
            "  📊 Epoch 5: checkpoint_epoch_5.pth (982.4 MB)\n",
            "  📊 Epoch 6: checkpoint_epoch_6.pth (982.4 MB)\n",
            "  📊 Epoch 7: checkpoint_epoch_7.pth (982.4 MB)\n",
            "  📊 Epoch 8: checkpoint_epoch_8.pth (982.4 MB)\n",
            "  📊 Epoch 9: checkpoint_epoch_9.pth (982.4 MB)\n",
            "  📊 Epoch 10: checkpoint_epoch_10.pth (982.4 MB)\n",
            "  📊 Epoch 11: checkpoint_epoch_11.pth (982.4 MB)\n",
            "  📊 Epoch 12: checkpoint_epoch_12.pth (982.4 MB)\n",
            "  📊 Epoch 13: checkpoint_epoch_13.pth (982.4 MB)\n",
            "  📊 Epoch 14: checkpoint_epoch_14.pth (982.4 MB)\n",
            "  📊 Epoch 15: checkpoint_epoch_15.pth (982.4 MB)\n",
            "  📊 Epoch 16: checkpoint_epoch_16.pth (982.4 MB)\n",
            "  📊 Epoch 17: checkpoint_epoch_17.pth (982.4 MB)\n",
            "  📊 Epoch 18: checkpoint_epoch_18.pth (982.4 MB)\n",
            "  📊 Epoch 19: checkpoint_epoch_19.pth (982.4 MB)\n",
            "  📊 Epoch 20: checkpoint_epoch_20.pth (982.4 MB)\n",
            "  📊 Epoch 21: checkpoint_epoch_21.pth (982.4 MB)\n",
            "  📊 Epoch 22: checkpoint_epoch_22.pth (982.4 MB)\n",
            "  📊 Epoch 23: checkpoint_epoch_23.pth (982.4 MB)\n",
            "  📊 Epoch 24: checkpoint_epoch_24.pth (982.4 MB)\n",
            "  📊 Epoch 25: checkpoint_epoch_25.pth (982.4 MB)\n",
            "  📊 Epoch 26: checkpoint_epoch_26.pth (982.4 MB)\n",
            "  📊 Epoch 27: checkpoint_epoch_27.pth (982.4 MB)\n",
            "  📊 Epoch 28: checkpoint_epoch_28.pth (982.4 MB)\n",
            "  📊 Epoch 29: checkpoint_epoch_29.pth (982.4 MB)\n",
            "  📊 Epoch 30: checkpoint_epoch_30.pth (982.4 MB)\n",
            "  📊 Epoch 31: checkpoint_epoch_31.pth (982.4 MB)\n",
            "  📊 Epoch 32: checkpoint_epoch_32.pth (982.4 MB)\n",
            "  📊 Epoch 33: checkpoint_epoch_33.pth (982.4 MB)\n",
            "  📊 Epoch 34: checkpoint_epoch_34.pth (982.4 MB)\n",
            "  📊 Epoch 35: checkpoint_epoch_35.pth (982.4 MB)\n",
            "  📊 Epoch 36: checkpoint_epoch_36.pth (982.4 MB)\n",
            "  📊 Epoch 37: checkpoint_epoch_37.pth (982.4 MB)\n",
            "  📊 Epoch 38: checkpoint_epoch_38.pth (982.4 MB)\n",
            "  📊 Epoch 39: checkpoint_epoch_39.pth (982.4 MB)\n",
            "  📊 Epoch 40: checkpoint_epoch_40.pth (982.4 MB)\n",
            "  📊 Epoch 41: checkpoint_epoch_41.pth (982.4 MB)\n",
            "  📊 Epoch 42: checkpoint_epoch_42.pth (982.4 MB)\n",
            "  📊 Epoch 43: checkpoint_epoch_43.pth (982.4 MB)\n",
            "  📊 Epoch 44: checkpoint_epoch_44.pth (982.4 MB)\n",
            "  📊 Epoch 45: checkpoint_epoch_45.pth (982.4 MB)\n",
            "  📊 Epoch 46: checkpoint_epoch_46.pth (982.4 MB)\n",
            "  📊 Epoch 47: checkpoint_epoch_47.pth (982.4 MB)\n",
            "  📊 Epoch 48: checkpoint_epoch_48.pth (982.4 MB)\n",
            "  📊 Epoch 49: checkpoint_epoch_49.pth (982.4 MB)\n",
            "  📊 Epoch 50: checkpoint_epoch_50.pth (982.4 MB)\n",
            "  📊 Epoch 51: checkpoint_epoch_51.pth (982.4 MB)\n",
            "  📊 Epoch 52: checkpoint_epoch_52.pth (982.4 MB)\n",
            "  📊 Epoch 53: checkpoint_epoch_53.pth (982.4 MB)\n",
            "  📊 Epoch 54: checkpoint_epoch_54.pth (982.4 MB)\n",
            "  📊 Epoch 55: checkpoint_epoch_55.pth (982.4 MB)\n",
            "  📊 Epoch 56: checkpoint_epoch_56.pth (982.4 MB)\n",
            "  📊 Epoch 57: checkpoint_epoch_57.pth (982.4 MB)\n",
            "  📊 Epoch 58: checkpoint_epoch_58.pth (982.4 MB)\n",
            "  📊 Epoch 59: checkpoint_epoch_59.pth (982.4 MB)\n",
            "  📊 Epoch 60: checkpoint_epoch_60.pth (982.4 MB)\n",
            "  📊 Epoch 61: checkpoint_epoch_61.pth (982.4 MB)\n",
            "  📊 Epoch 62: checkpoint_epoch_62.pth (982.4 MB)\n",
            "  📊 Epoch 63: checkpoint_epoch_63.pth (982.4 MB)\n",
            "  📊 Epoch 64: checkpoint_epoch_64.pth (982.4 MB)\n",
            "  📊 Epoch 65: checkpoint_epoch_65.pth (982.4 MB)\n",
            "  📊 Epoch 66: checkpoint_epoch_66.pth (982.4 MB)\n",
            "  📊 Epoch 67: checkpoint_epoch_67.pth (982.4 MB)\n",
            "  📊 Epoch 68: checkpoint_epoch_68.pth (982.4 MB)\n",
            "  📊 Epoch 69: checkpoint_epoch_69.pth (982.4 MB)\n",
            "  📊 Epoch 70: checkpoint_epoch_70.pth (982.4 MB)\n",
            "  📊 Epoch 71: checkpoint_epoch_71.pth (982.4 MB)\n",
            "  📊 Epoch 72: checkpoint_epoch_72.pth (982.4 MB)\n",
            "  📊 Epoch 73: checkpoint_epoch_73.pth (982.4 MB)\n",
            "  📊 Epoch 74: checkpoint_epoch_74.pth (982.4 MB)\n",
            "  📊 Epoch 75: checkpoint_epoch_75.pth (982.4 MB)\n",
            "  📊 Epoch 76: checkpoint_epoch_76.pth (982.4 MB)\n",
            "  📊 Epoch 77: checkpoint_epoch_77.pth (982.4 MB)\n",
            "  📊 Epoch 78: checkpoint_epoch_78.pth (982.4 MB)\n",
            "  📊 Epoch 79: checkpoint_epoch_79.pth (982.4 MB)\n",
            "  📊 Epoch 80: checkpoint_epoch_80.pth (982.4 MB)\n",
            "  📊 Epoch 81: checkpoint_epoch_81.pth (982.4 MB)\n",
            "  📊 Epoch 82: checkpoint_epoch_82.pth (982.4 MB)\n",
            "  📊 Epoch 83: checkpoint_epoch_83.pth (982.4 MB)\n",
            "  📊 Epoch 84: checkpoint_epoch_84.pth (982.4 MB)\n",
            "  📊 Epoch 85: checkpoint_epoch_85.pth (982.4 MB)\n",
            "  📊 Epoch 86: checkpoint_epoch_86.pth (982.4 MB)\n",
            "  📊 Epoch 87: checkpoint_epoch_87.pth (982.4 MB)\n",
            "  📊 Epoch 88: checkpoint_epoch_88.pth (982.4 MB)\n",
            "  📊 Epoch 89: checkpoint_epoch_89.pth (982.4 MB)\n",
            "  📊 Epoch 90: checkpoint_epoch_90.pth (982.4 MB)\n",
            "  📊 Epoch 91: checkpoint_epoch_91.pth (982.4 MB)\n",
            "  📊 Epoch 92: checkpoint_epoch_92.pth (982.4 MB)\n",
            "  📊 Epoch 93: checkpoint_epoch_93.pth (982.4 MB)\n",
            "  📊 Epoch 94: checkpoint_epoch_94.pth (982.4 MB)\n",
            "  📊 Epoch 95: checkpoint_epoch_95.pth (982.4 MB)\n",
            "  📊 Epoch 96: checkpoint_epoch_96.pth (982.4 MB)\n",
            "  📊 Epoch 97: checkpoint_epoch_97.pth (982.4 MB)\n",
            "  📊 Epoch 98: checkpoint_epoch_98.pth (982.4 MB)\n",
            "  📊 Epoch 99: checkpoint_epoch_99.pth (982.4 MB)\n",
            "  📊 Epoch 100: checkpoint_epoch_100.pth (982.4 MB)\n",
            "\n",
            "⏱️ EXTENDED TRAINING SUMMARY:\n",
            "  📊 Additional epochs completed: 81\n",
            "  🎯 Target was: 81 additional epochs (to reach 100 total)\n",
            "  ✅ TRAINING GOAL ACHIEVED! Completed all 81 additional epochs\n",
            "\n",
            "📈 View detailed training metrics:\n",
            "   https://wandb.ai/your-username/ViT-FishID-Extended-Training\n",
            "   Run: resume-epoch-6-to-100\n",
            "\n",
            "🎉 Extended training session complete!\n",
            "🚀 Your model trained from epoch 19 to 100!\n",
            "💾 All results saved to Google Drive: /content/drive/MyDrive/ViT-FishID/checkpoints_extended\n",
            "\n",
            "📊 PERFORMANCE COMPARISON:\n",
            "  🔄 Previous (Epoch 19): ~78% accuracy\n",
            "  🎯 Extended (Epoch 100): Check best_accuracy above\n",
            "  📈 Expected improvement: 5-10% accuracy gain\n",
            "  🏆 Your model should now be ready for deployment!\n"
          ]
        }
      ],
      "source": [
        "# Check Extended Training Results (Epoch 19 → 100)\n",
        "import os\n",
        "import glob\n",
        "import torch\n",
        "\n",
        "checkpoint_dir = TRAINING_CONFIG['checkpoint_dir']\n",
        "print(f\"📁 Checking results in: {checkpoint_dir}\")\n",
        "\n",
        "if os.path.exists(checkpoint_dir):\n",
        "    checkpoints = glob.glob(os.path.join(checkpoint_dir, '*.pth'))\n",
        "    if checkpoints:\n",
        "        print(f\"\\n✅ Found {len(checkpoints)} checkpoint(s) from extended training:\")\n",
        "\n",
        "        # Sort checkpoints by epoch number\n",
        "        epoch_checkpoints = []\n",
        "        other_checkpoints = []\n",
        "\n",
        "        for cp in checkpoints:\n",
        "            basename = os.path.basename(cp)\n",
        "            if 'epoch_' in basename:\n",
        "                try:\n",
        "                    epoch_num = int(basename.split('epoch_')[1].split('.')[0])\n",
        "                    epoch_checkpoints.append((epoch_num, cp))\n",
        "                except:\n",
        "                    other_checkpoints.append(cp)\n",
        "            else:\n",
        "                other_checkpoints.append(cp)\n",
        "\n",
        "        # Show epoch checkpoints in order\n",
        "        epoch_checkpoints.sort(key=lambda x: x[0])\n",
        "        for epoch, cp in epoch_checkpoints:\n",
        "            file_size = os.path.getsize(cp) / (1024**2)\n",
        "            print(f\"  📊 Epoch {epoch}: {os.path.basename(cp)} ({file_size:.1f} MB)\")\n",
        "\n",
        "        # Show other checkpoints\n",
        "        for cp in other_checkpoints:\n",
        "            file_size = os.path.getsize(cp) / (1024**2)\n",
        "            print(f\"  🏆 {os.path.basename(cp)} ({file_size:.1f} MB)\")\n",
        "\n",
        "        # Analyze best model\n",
        "        best_model = os.path.join(checkpoint_dir, 'model_best.pth')\n",
        "        if os.path.exists(best_model):\n",
        "            print(f\"\\n🏆 BEST MODEL ANALYSIS:\")\n",
        "            try:\n",
        "                best_checkpoint = torch.load(best_model, map_location='cpu')\n",
        "\n",
        "                best_epoch = best_checkpoint.get('epoch', 'Unknown')\n",
        "                best_acc = best_checkpoint.get('best_accuracy', best_checkpoint.get('best_acc', 'Unknown'))\n",
        "\n",
        "                print(f\"  📊 Best epoch: {best_epoch}\")\n",
        "                print(f\"  📊 Best accuracy: {best_acc:.2f}%\" if isinstance(best_acc, (int, float)) else f\"  📊 Best accuracy: {best_acc}\")\n",
        "\n",
        "                # Show training progression\n",
        "                if epoch_checkpoints:\n",
        "                    print(f\"\\n📈 TRAINING PROGRESSION:\")\n",
        "                    print(f\"  🏁 Started: Epoch 19 (resumed)\")\n",
        "                    print(f\"  🎯 Completed: Epoch {max(epoch_checkpoints, key=lambda x: x[0])[0]}\")\n",
        "                    print(f\"  🏆 Best: Epoch {best_epoch}\")\n",
        "                    print(f\"  📊 Total training: {19 + len([e for e, _ in epoch_checkpoints if e > 19])} epochs\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  ⚠️ Could not analyze best model: {e}\")\n",
        "\n",
        "        # Training duration estimate\n",
        "        if epoch_checkpoints:\n",
        "            epochs_completed = len([e for e, _ in epoch_checkpoints if e > 19])\n",
        "            print(f\"\\n⏱️ EXTENDED TRAINING SUMMARY:\")\n",
        "            print(f\"  📊 Additional epochs completed: {epochs_completed}\")\n",
        "            print(f\"  🎯 Target was: 81 additional epochs (to reach 100 total)\")\n",
        "\n",
        "            if epochs_completed >= 81:\n",
        "                print(f\"  ✅ TRAINING GOAL ACHIEVED! Completed all {epochs_completed} additional epochs\")\n",
        "            else:\n",
        "                print(f\"  ⏳ Training partially complete: {epochs_completed}/81 additional epochs\")\n",
        "\n",
        "    else:\n",
        "        print(\"❌ No checkpoints found in extended training directory\")\n",
        "\n",
        "        # Check if training is still using old directory\n",
        "        old_checkpoint_dir = '/content/ViT-FishID/checkpoints'\n",
        "        if os.path.exists(old_checkpoint_dir):\n",
        "            old_checkpoints = glob.glob(os.path.join(old_checkpoint_dir, '*.pth'))\n",
        "            if old_checkpoints:\n",
        "                print(f\"\\n💡 Found {len(old_checkpoints)} checkpoints in old directory:\")\n",
        "                print(f\"   {old_checkpoint_dir}\")\n",
        "\n",
        "else:\n",
        "    print(\"❌ Extended training checkpoint directory not found\")\n",
        "\n",
        "# W&B link\n",
        "if TRAINING_CONFIG['use_wandb']:\n",
        "    print(f\"\\n📈 View detailed training metrics:\")\n",
        "    print(f\"   https://wandb.ai/your-username/{TRAINING_CONFIG['wandb_project']}\")\n",
        "    print(f\"   Run: {TRAINING_CONFIG['wandb_run_name']}\")\n",
        "\n",
        "print(f\"\\n🎉 Extended training session complete!\")\n",
        "print(f\"🚀 Your model trained from epoch 19 to 100!\")\n",
        "print(f\"💾 All results saved to Google Drive: {checkpoint_dir}\")\n",
        "\n",
        "# Performance comparison\n",
        "print(f\"\\n📊 PERFORMANCE COMPARISON:\")\n",
        "print(f\"  🔄 Previous (Epoch 19): ~78% accuracy\")\n",
        "print(f\"  🎯 Extended (Epoch 100): Check best_accuracy above\")\n",
        "print(f\"  📈 Expected improvement: 5-10% accuracy gain\")\n",
        "print(f\"  🏆 Your model should now be ready for deployment!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff698a72",
      "metadata": {
        "id": "ff698a72"
      },
      "source": [
        "## 💾 Step 10: Download Model and Results\n",
        "\n",
        "Save your trained model to Google Drive for future use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "89513455",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "89513455",
        "outputId": "40e5387b-1de1-475f-93ae-14ab586ffa9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💾 Saving results to Google Drive: /content/drive/MyDrive/ViT-FishID_Training_20250814_233546\n",
            "✅ Training config saved to: /content/drive/MyDrive/ViT-FishID_Training_20250814_233546/training_config.json\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'epochs'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1039412563.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Mode: {TRAINING_CONFIG['mode']}\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epochs: {TRAINING_CONFIG['epochs']}\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Batch Size: {TRAINING_CONFIG['batch_size']}\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Data Directory: {DATA_DIR}\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'epochs'"
          ]
        }
      ],
      "source": [
        "# Copy trained model to Google Drive\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "\n",
        "# Create a timestamped folder in Google Drive\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "save_dir = f'/content/drive/MyDrive/ViT-FishID_Training_{timestamp}'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "print(f\"💾 Saving results to Google Drive: {save_dir}\")\n",
        "\n",
        "# Copy checkpoints\n",
        "checkpoint_dir = '/content/ViT-FishID/checkpoints'\n",
        "if os.path.exists(checkpoint_dir):\n",
        "    drive_checkpoint_dir = os.path.join(save_dir, 'checkpoints')\n",
        "    shutil.copytree(checkpoint_dir, drive_checkpoint_dir)\n",
        "    print(f\"✅ Checkpoints saved to: {drive_checkpoint_dir}\")\n",
        "\n",
        "# Save training configuration\n",
        "import json\n",
        "config_file = os.path.join(save_dir, 'training_config.json')\n",
        "with open(config_file, 'w') as f:\n",
        "    json.dump(TRAINING_CONFIG, f, indent=2)\n",
        "print(f\"✅ Training config saved to: {config_file}\")\n",
        "\n",
        "# Create a summary file\n",
        "summary_file = os.path.join(save_dir, 'training_summary.txt')\n",
        "with open(summary_file, 'w') as f:\n",
        "    f.write(f\"ViT-FishID Training Summary\\n\")\n",
        "    f.write(f\"========================\\n\\n\")\n",
        "    f.write(f\"Training Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "    f.write(f\"Mode: {TRAINING_CONFIG['mode']}\\n\")\n",
        "    f.write(f\"Epochs: {TRAINING_CONFIG['epochs']}\\n\")\n",
        "    f.write(f\"Batch Size: {TRAINING_CONFIG['batch_size']}\\n\")\n",
        "    f.write(f\"Data Directory: {DATA_DIR}\\n\")\n",
        "    f.write(f\"\\nModel Architecture: {TRAINING_CONFIG['model_name']}\\n\")\n",
        "    f.write(f\"Learning Rate: {TRAINING_CONFIG['learning_rate']}\\n\")\n",
        "    f.write(f\"Consistency Weight: {TRAINING_CONFIG['consistency_weight']}\\n\")\n",
        "    f.write(f\"\\nCheckpoints saved in: checkpoints/\\n\")\n",
        "    f.write(f\"Best model: checkpoints/model_best.pth\\n\")\n",
        "\n",
        "print(f\"✅ Training summary saved to: {summary_file}\")\n",
        "\n",
        "print(f\"\\n🎉 All results saved to Google Drive!\")\n",
        "print(f\"📁 Location: {save_dir}\")\n",
        "print(f\"\\n💡 You can now:\")\n",
        "print(f\"   1. Download the checkpoints folder for local use\")\n",
        "print(f\"   2. Use model_best.pth for inference\")\n",
        "print(f\"   3. Continue training from any checkpoint\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bbc6396",
      "metadata": {
        "id": "3bbc6396"
      },
      "source": [
        "## 🧪 Step 11: Quick Model Evaluation (Optional)\n",
        "\n",
        "Test your trained model on a few sample images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "642c1e93",
      "metadata": {
        "id": "642c1e93"
      },
      "outputs": [],
      "source": [
        "# Quick evaluation of the trained model\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check if best model exists\n",
        "best_model_path = '/content/ViT-FishID/checkpoints/model_best.pth'\n",
        "\n",
        "if os.path.exists(best_model_path):\n",
        "    print(\"🧪 Loading trained model for quick evaluation...\")\n",
        "\n",
        "    # Load model checkpoint info\n",
        "    checkpoint = torch.load(best_model_path, map_location='cpu')\n",
        "\n",
        "    print(f\"📊 Model training info:\")\n",
        "    if 'epoch' in checkpoint:\n",
        "        print(f\"  - Best epoch: {checkpoint['epoch']}\")\n",
        "    if 'best_acc' in checkpoint:\n",
        "        print(f\"  - Best accuracy: {checkpoint['best_acc']:.2f}%\")\n",
        "    if 'teacher_acc' in checkpoint:\n",
        "        print(f\"  - Teacher accuracy: {checkpoint['teacher_acc']:.2f}%\")\n",
        "\n",
        "    # Get class names if available\n",
        "    if 'class_names' in checkpoint:\n",
        "        class_names = checkpoint['class_names']\n",
        "        print(f\"  - Number of classes: {len(class_names)}\")\n",
        "        print(f\"  - Sample classes: {class_names[:5]}...\")\n",
        "\n",
        "    print(\"\\n✅ Model evaluation completed! Check the metrics above.\")\n",
        "\n",
        "else:\n",
        "    print(\"❌ No trained model found. Make sure training completed successfully.\")\n",
        "\n",
        "print(\"\\n💡 For comprehensive evaluation:\")\n",
        "print(\"   Use the evaluate.py script with your test dataset\")\n",
        "print(\"   The test set was automatically created during training\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bcf6b4d",
      "metadata": {
        "id": "5bcf6b4d"
      },
      "source": [
        "## 🔧 Troubleshooting\n",
        "\n",
        "### Common Issues and Solutions:\n",
        "\n",
        "**1. GPU Memory Error (CUDA out of memory)**\n",
        "- Reduce batch_size to 8 or 4\n",
        "- Restart runtime and try again\n",
        "\n",
        "**2. Data Not Found**\n",
        "- Check that DATA_DIR path is correct\n",
        "- Ensure data is uploaded to Google Drive\n",
        "- Verify folder structure (labeled/ and unlabeled/)\n",
        "\n",
        "**3. Training Stops Unexpectedly**\n",
        "- Colab sessions timeout after 12 hours\n",
        "- Use runtime management to prevent disconnection\n",
        "- Checkpoints are saved every 10 epochs for resuming\n",
        "\n",
        "**4. Low Accuracy**\n",
        "- Increase epochs (try 75-100)\n",
        "- Adjust consistency_weight (try 1.0-3.0)\n",
        "- Lower pseudo_label_threshold (try 0.5-0.6)\n",
        "\n",
        "**5. Consistency Loss is 0.0000**\n",
        "- Lower pseudo_label_threshold to 0.5\n",
        "- Check that you have unlabeled data\n",
        "- Ensure semi_supervised mode is selected"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0d21afb",
      "metadata": {
        "id": "b0d21afb"
      },
      "source": [
        "## 🚀 Next Steps\n",
        "\n",
        "After training is complete, you can:\n",
        "\n",
        "1. **Download your model**: The trained model is saved in Google Drive\n",
        "2. **Continue training**: Resume from checkpoints for more epochs\n",
        "3. **Evaluate performance**: Use the test set for final evaluation\n",
        "4. **Deploy model**: Use the trained model for fish classification\n",
        "5. **Experiment**: Try different hyperparameters or architectures\n",
        "\n",
        "### Model Files Saved:\n",
        "- `model_best.pth`: Best performing model (use this for inference)\n",
        "- `model_latest.pth`: Most recent checkpoint\n",
        "- `model_epoch_XX.pth`: Periodic checkpoints\n",
        "\n",
        "### Performance Expectations:\n",
        "- **50 epochs**: ~70-80% accuracy\n",
        "- **100 epochs**: ~75-85% accuracy\n",
        "- **Semi-supervised**: Should outperform supervised training\n",
        "\n",
        "**Happy fish classification! 🐟🎉**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59f603ca"
      },
      "source": [
        "## 📈 Step 7b: Connect to Weights & Biases (Optional)\n",
        "\n",
        "Log in to Weights & Biases for experiment tracking and visualization. You will be prompted to enter your API key."
      ],
      "id": "59f603ca"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "ab343772",
        "outputId": "6a31f04e-7097-441f-ced1-9469a30cf676"
      },
      "source": [
        "# Login to Weights & Biases\n",
        "import wandb\n",
        "import os\n",
        "\n",
        "print(\"📈 Connecting to Weights & Biases...\")\n",
        "\n",
        "# Check if already logged in (optional)\n",
        "if os.environ.get(\"WANDB_API_KEY\"):\n",
        "    print(\"✅ W&B API key found in environment variables.\")\n",
        "    # You might still want to run wandb.login() explicitly for clarity or if using interactive login\n",
        "    try:\n",
        "        wandb.login(relogin=True) # Use relogin=True to re-authenticate even if key is found\n",
        "        print(\"✅ Successfully logged in to W&B.\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Could not relogin to W&B: {e}\")\n",
        "        print(\"💡 You may need to manually enter your API key below.\")\n",
        "        wandb.login()\n",
        "\n",
        "else:\n",
        "    print(\"🔑 Please enter your W&B API key when prompted.\")\n",
        "    try:\n",
        "        wandb.login()\n",
        "        print(\"✅ Successfully logged in to W&B.\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ W&B login failed: {e}\")\n",
        "        print(\"Please check your API key and try again.\")\n",
        "        # Optionally, add a step to show where to get the key\n",
        "        print(\"\\n💡 Get your API key from: https://wandb.ai/settings\")\n",
        "        print(\"   Or manually set it as a Colab Secret named WANDB_API_KEY.\")\n",
        "\n",
        "\n",
        "if wandb.run:\n",
        "    print(f\"🚀 W&B Run URL: {wandb.run.url}\")\n",
        "    print(\"✅ W&B connection established.\")\n",
        "else:\n",
        "     print(\"❌ W&B connection not established. Logging may be disabled.\")"
      ],
      "id": "ab343772",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📈 Connecting to Weights & Biases...\n",
            "🔑 Please enter your W&B API key when prompted.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcativthomson\u001b[0m (\u001b[33mcativthomson-university-of-cape-town\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Successfully logged in to W&B.\n",
            "❌ W&B connection not established. Logging may be disabled.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}