{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0e0af9a0",
      "metadata": {
        "id": "0e0af9a0"
      },
      "source": [
        "# üêü ViT-FishID: Semi-Supervised Fish Classification\n",
        "\n",
        "**COMPLETE TRAINING PIPELINE WITH GOOGLE COLAB**\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/cat-thomson/ViT-FishID/blob/main/ViT_FishID_Colab_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "## üéØ What This Notebook Does\n",
        "\n",
        "This notebook implements a **complete semi-supervised learning pipeline** for fish species classification using:\n",
        "\n",
        "**ü§ñ Vision Transformer (ViT)**: State-of-the-art transformer architecture for image classification\n",
        "**üìä Semi-Supervised Learning**: Leverages both labeled and unlabeled fish images\n",
        "**üéì EMA Teacher-Student Framework**: Uses exponential moving averages for consistency training\n",
        "**‚òÅÔ∏è Google Colab**: Cloud-based training with GPU acceleration\n",
        "\n",
        "## üìä Expected Performance\n",
        "\n",
        "- **Training Time**: 4-6 hours for 100 epochs\n",
        "- **GPU Requirements**: T4/V100/A100 (Colab Pro recommended)\n",
        "- **Expected Accuracy**: 80-90% on fish species classification\n",
        "- **Data Efficiency**: Works well with limited labeled data\n",
        "\n",
        "## üõ†Ô∏è What You Need\n",
        "\n",
        "1. **Fish Dataset**: Labeled and unlabeled fish images (upload to Google Drive)\n",
        "2. **Google Colab Pro**: Recommended for longer training sessions\n",
        "3. **Weights & Biases Account**: Optional for experiment tracking"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26bcb2a3",
      "metadata": {
        "id": "26bcb2a3"
      },
      "source": [
        "## üîß Step 1: Environment Setup and GPU Check\n",
        "\n",
        "First, let's verify that we have GPU access and set up the optimal environment for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f3540b19",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3540b19",
        "outputId": "23cef4f3-72a1-4e63-de50-2c68d478e6b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç SYSTEM INFORMATION\n",
            "==================================================\n",
            "Python version: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
            "PyTorch version: 2.6.0+cu124\n",
            "CUDA available: True\n",
            "GPU Device: Tesla T4\n",
            "GPU Memory: 14.7 GB\n",
            "‚úÖ GPU is ready for training!\n",
            "üöÄ GPU optimized for training\n",
            "\n",
            "üéØ Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Check GPU availability and system information\n",
        "import torch\n",
        "import os\n",
        "import gc\n",
        "\n",
        "print(\"üîç SYSTEM INFORMATION\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Python version: {os.sys.version}\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device_name = torch.cuda.get_device_name(0)\n",
        "    device_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
        "    print(f\"GPU Device: {device_name}\")\n",
        "    print(f\"GPU Memory: {device_memory:.1f} GB\")\n",
        "    print(\"‚úÖ GPU is ready for training!\")\n",
        "\n",
        "    # Set optimal GPU settings\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "\n",
        "    # Clear GPU cache\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    print(\"üöÄ GPU optimized for training\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå No GPU detected!\")\n",
        "    print(\"üìù To enable GPU in Colab:\")\n",
        "    print(\"   Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator ‚Üí GPU\")\n",
        "    print(\"   Then restart this notebook\")\n",
        "\n",
        "# Set device for later use\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"\\nüéØ Using device: {DEVICE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "149f671b",
      "metadata": {
        "id": "149f671b"
      },
      "source": [
        "## üìÅ Step 2: Mount Google Drive\n",
        "\n",
        "This will give us access to your fish dataset stored in Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "4abb3ffd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4abb3ffd",
        "outputId": "8788f96b-035e-431d-85cf-aac9ad80ffad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to mount Google Drive...\n",
            "Clearing contents of mount point: /content/drive\n",
            "‚úÖ Mount point cleared.\n",
            "Mounted at /content/drive\n",
            "\n",
            "üìÇ Google Drive contents:\n",
            "  - Mock Matric\n",
            "  - Photos\n",
            "  - Admin\n",
            "  - Uni\n",
            "  - Fish_Training_Output\n",
            "  - Colab Notebooks\n",
            "  - ViT-FishID\n",
            "  - ViT-FishID_Training_20250814_154652\n",
            "  - ViT-FishID_Training_20250814_202307\n",
            "  - ViT-FishID_Training_20250814_205442\n",
            "  ... and 6 more items\n",
            "\n",
            "‚úÖ Google Drive mounted successfully!\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Mount Google Drive\n",
        "print(\"Attempting to mount Google Drive...\")\n",
        "\n",
        "# Ensure the mount point is clean before mounting\n",
        "mount_point = '/content/drive'\n",
        "if os.path.exists(mount_point) and os.path.isdir(mount_point):\n",
        "    print(f\"Clearing contents of mount point: {mount_point}\")\n",
        "    try:\n",
        "        # Use `rm -rf` via shell command for robustness in Colab environment\n",
        "        !rm -rf {mount_point}/*\n",
        "        # Recreate the directory structure if it was completely removed\n",
        "        if not os.path.exists(mount_point):\n",
        "             os.makedirs(mount_point)\n",
        "        print(\"‚úÖ Mount point cleared.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error clearing mount point: {e}\")\n",
        "        print(\"Attempting to proceed with mount anyway...\")\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# List contents to verify mount\n",
        "print(\"\\nüìÇ Google Drive contents:\")\n",
        "drive_path = '/content/drive/MyDrive'\n",
        "if os.path.exists(drive_path):\n",
        "    items = os.listdir(drive_path)[:10]  # Show first 10 items\n",
        "    for item in items:\n",
        "        print(f\"  - {item}\")\n",
        "    if len(os.listdir(drive_path)) > 10:\n",
        "        print(f\"  ... and {len(os.listdir(drive_path)) - 10} more items\")\n",
        "    print(\"\\n‚úÖ Google Drive mounted successfully!\")\n",
        "else:\n",
        "    print(\"‚ùå Failed to mount Google Drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be8b6273",
      "metadata": {
        "id": "be8b6273"
      },
      "source": [
        "## üì¶ Step 3: Install Dependencies\n",
        "\n",
        "Installing all required packages for ViT-FishID training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "8c724abc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c724abc",
        "outputId": "ee0d1d80-c1a2-43a0-97e5-f8bd530daaf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Installing dependencies...\n",
            "‚úÖ All dependencies installed successfully!\n",
            "\n",
            "üìã Package versions:\n",
            "  - torch: 2.6.0+cu124\n",
            "  - torchvision: 0.21.0+cu124\n",
            "  - timm: 1.0.19\n",
            "  - albumentations: 2.0.8\n",
            "  - opencv: 4.12.0\n",
            "  - sklearn: 1.6.1\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "print(\"üì¶ Installing dependencies...\")\n",
        "\n",
        "!pip install -q torch torchvision torchaudio\n",
        "!pip install -q timm transformers\n",
        "!pip install -q albumentations\n",
        "!pip install -q wandb\n",
        "!pip install -q opencv-python-headless\n",
        "!pip install -q scikit-learn\n",
        "!pip install -q matplotlib seaborn\n",
        "!pip install -q tqdm\n",
        "\n",
        "print(\"‚úÖ All dependencies installed successfully!\")\n",
        "\n",
        "# Verify installations\n",
        "import torch\n",
        "import torchvision\n",
        "import timm\n",
        "import albumentations\n",
        "import cv2\n",
        "import sklearn\n",
        "\n",
        "print(\"\\nüìã Package versions:\")\n",
        "print(f\"  - torch: {torch.__version__}\")\n",
        "print(f\"  - torchvision: {torchvision.__version__}\")\n",
        "print(f\"  - timm: {timm.__version__}\")\n",
        "print(f\"  - albumentations: {albumentations.__version__}\")\n",
        "print(f\"  - opencv: {cv2.__version__}\")\n",
        "print(f\"  - sklearn: {sklearn.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12b795fc",
      "metadata": {
        "id": "12b795fc"
      },
      "source": [
        "## üîÑ Step 4: Clone ViT-FishID Repository\n",
        "\n",
        "Getting the latest code from your GitHub repository."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "c4e4cd45",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4e4cd45",
        "outputId": "86085e4c-db2e-498e-8baa-f7c49ef7021b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Cloning ViT-FishID repository...\n",
            "Cloning into '/content/ViT-FishID'...\n",
            "remote: Enumerating objects: 164, done.\u001b[K\n",
            "remote: Counting objects: 100% (164/164), done.\u001b[K\n",
            "remote: Compressing objects: 100% (122/122), done.\u001b[K\n",
            "remote: Total 164 (delta 69), reused 124 (delta 35), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (164/164), 322.97 KiB | 1.32 MiB/s, done.\n",
            "Resolving deltas: 100% (69/69), done.\n",
            "/content/ViT-FishID\n",
            "\n",
            "üìÇ Project structure:\n",
            "total 612\n",
            "drwxr-xr-x 5 root root   4096 Aug 18 09:21 .\n",
            "drwxr-xr-x 1 root root   4096 Aug 18 09:21 ..\n",
            "-rw-r--r-- 1 root root   4182 Aug 18 09:21 COLAB_CRASH_FIXES.md\n",
            "-rw-r--r-- 1 root root  21217 Aug 18 09:21 data.py\n",
            "-rw-r--r-- 1 root root  11572 Aug 18 09:21 evaluate.py\n",
            "-rw-r--r-- 1 root root   3328 Aug 18 09:21 EXTENDED_TRAINING_SETUP.md\n",
            "drwxr-xr-x 3 root root   4096 Aug 18 09:21 fish_cutouts\n",
            "drwxr-xr-x 8 root root   4096 Aug 18 09:21 .git\n",
            "-rw-r--r-- 1 root root     66 Aug 18 09:21 .gitattributes\n",
            "-rw-r--r-- 1 root root    646 Aug 18 09:21 .gitignore\n",
            "drwxr-xr-x 2 root root   4096 Aug 18 09:21 local_checkpoints\n",
            "-rw-r--r-- 1 root root  13100 Aug 18 09:21 local_resume_training.py\n",
            "-rw-r--r-- 1 root root      0 Aug 18 09:21 MAE_INTEGRATION_GUIDE.md\n",
            "-rw-r--r-- 1 root root   9495 Aug 18 09:21 model.py\n",
            "-rw-r--r-- 1 root root  16771 Aug 18 09:21 pipeline.py\n",
            "-rw-r--r-- 1 root root  16566 Aug 18 09:21 README.md\n",
            "-rw-r--r-- 1 root root    202 Aug 18 09:21 requirements.txt\n",
            "-rw-r--r-- 1 root root   4271 Aug 18 09:21 resume_training.py\n",
            "-rw-r--r-- 1 root root   5134 Aug 18 09:21 species_mapping.txt\n",
            "-rw-r--r-- 1 root root  25503 Aug 18 09:21 trainer.py\n",
            "-rw-r--r-- 1 root root   4982 Aug 18 09:21 TRAINING_FIXES_APPLIED.md\n",
            "-rw-r--r-- 1 root root  15343 Aug 18 09:21 train.py\n",
            "-rw-r--r-- 1 root root   8818 Aug 18 09:21 utils.py\n",
            "-rw-r--r-- 1 root root 153962 Aug 18 09:21 ViT_FishID_Colab_Training.ipynb\n",
            "-rw-r--r-- 1 root root 234973 Aug 18 09:21 ViT_FishID_MAE_EMA_Training.ipynb\n",
            "\n",
            "‚úÖ Repository cloned successfully!\n"
          ]
        }
      ],
      "source": [
        "# Clone the repository\n",
        "import os\n",
        "\n",
        "# Remove existing directory if it exists\n",
        "if os.path.exists('/content/ViT-FishID'):\n",
        "    !rm -rf /content/ViT-FishID\n",
        "\n",
        "# Clone the repository\n",
        "print(\"üì• Cloning ViT-FishID repository...\")\n",
        "!git clone https://github.com/cat-thomson/ViT-FishID.git /content/ViT-FishID\n",
        "\n",
        "# Change to project directory\n",
        "%cd /content/ViT-FishID\n",
        "\n",
        "# List project files\n",
        "print(\"\\nüìÇ Project structure:\")\n",
        "!ls -la\n",
        "\n",
        "print(\"\\n‚úÖ Repository cloned successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8155c400",
      "metadata": {
        "id": "8155c400"
      },
      "source": [
        "## üê† Step 5: Setup Fish Dataset\n",
        "\n",
        "**Important**: Upload your `fish_cutouts.zip` file to Google Drive before running this step.\n",
        "\n",
        "Expected dataset structure:\n",
        "```\n",
        "fish_cutouts/\n",
        "‚îú‚îÄ‚îÄ labeled/\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ species_1/\n",
        "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fish_001.jpg\n",
        "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ fish_002.jpg\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ species_2/\n",
        "‚îÇ       ‚îî‚îÄ‚îÄ ...\n",
        "‚îî‚îÄ‚îÄ unlabeled/\n",
        "    ‚îú‚îÄ‚îÄ fish_003.jpg\n",
        "    ‚îî‚îÄ‚îÄ fish_004.jpg\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "nre5_INaKDXl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nre5_INaKDXl",
        "outputId": "f9e30750-e5ec-4cbe-8048-1cf712706717"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üê† SETTING UP FISH DATASET\n",
            "==================================================\n",
            "üìÇ Looking for dataset: /content/drive/MyDrive/fish_cutouts.zip\n",
            "üéØ Target directory: /content/fish_cutouts\n",
            "üì• Extracting dataset from Google Drive...\n",
            "‚úÖ Found dataset: 216.5 MB\n",
            "üìÅ Extracted: ['dataset_info.json', 'unlabeled', '__MACOSX', 'labeled']\n",
            "‚úÖ Dataset organized successfully!\n",
            "üêü Verified: 37 species\n",
            "üìä Verified: 24015 unlabeled images\n",
            "\n",
            "‚úÖ DATASET READY\n",
            "üìÅ Location: /content/fish_cutouts\n",
            "üöÄ Ready for training!\n"
          ]
        }
      ],
      "source": [
        "# Setup fish dataset from Google Drive\n",
        "import zipfile\n",
        "import shutil\n",
        "import os\n",
        "import glob\n",
        "\n",
        "print(\"üê† SETTING UP FISH DATASET\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Configuration\n",
        "ZIP_FILE_PATH = '/content/drive/MyDrive/fish_cutouts.zip'\n",
        "DATA_DIR = '/content/fish_cutouts'\n",
        "\n",
        "print(f\"üìÇ Looking for dataset: {ZIP_FILE_PATH}\")\n",
        "print(f\"üéØ Target directory: {DATA_DIR}\")\n",
        "\n",
        "# Check if data already exists locally\n",
        "if os.path.exists(DATA_DIR) and os.path.exists(os.path.join(DATA_DIR, 'labeled')):\n",
        "    print(\"‚úÖ Dataset already available locally!\")\n",
        "\n",
        "    # Quick validation\n",
        "    labeled_dir = os.path.join(DATA_DIR, 'labeled')\n",
        "    unlabeled_dir = os.path.join(DATA_DIR, 'unlabeled')\n",
        "\n",
        "    if os.path.exists(labeled_dir):\n",
        "        species_count = len([d for d in os.listdir(labeled_dir)\n",
        "                           if os.path.isdir(os.path.join(labeled_dir, d)) and not d.startswith('.')])\n",
        "        print(f\"üêü Found {species_count} labeled species\")\n",
        "\n",
        "    if os.path.exists(unlabeled_dir):\n",
        "        unlabeled_count = len([f for f in os.listdir(unlabeled_dir)\n",
        "                             if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
        "        print(f\"üìä Found {unlabeled_count} unlabeled images\")\n",
        "\n",
        "else:\n",
        "    print(\"üì• Extracting dataset from Google Drive...\")\n",
        "\n",
        "    # Check if ZIP file exists\n",
        "    if not os.path.exists(ZIP_FILE_PATH):\n",
        "        print(f\"‚ùå Dataset not found at: {ZIP_FILE_PATH}\")\n",
        "        print(\"üìù Please upload fish_cutouts.zip to Google Drive root directory\")\n",
        "    else:\n",
        "        print(f\"‚úÖ Found dataset: {os.path.getsize(ZIP_FILE_PATH) / (1024**2):.1f} MB\")\n",
        "\n",
        "        try:\n",
        "            # Extract to temporary directory\n",
        "            temp_dir = '/content/temp_extract'\n",
        "            if os.path.exists(temp_dir):\n",
        "                shutil.rmtree(temp_dir)\n",
        "\n",
        "            with zipfile.ZipFile(ZIP_FILE_PATH, 'r') as zip_ref:\n",
        "                zip_ref.extractall(temp_dir)\n",
        "\n",
        "            # Find and organize data\n",
        "            extracted_items = os.listdir(temp_dir)\n",
        "            print(f\"üìÅ Extracted: {extracted_items}\")\n",
        "\n",
        "            # Look for labeled and unlabeled directories\n",
        "            labeled_source = None\n",
        "            unlabeled_source = None\n",
        "\n",
        "            for item in extracted_items:\n",
        "                item_path = os.path.join(temp_dir, item)\n",
        "                if item == 'labeled' and os.path.isdir(item_path):\n",
        "                    labeled_source = item_path\n",
        "                elif item == 'unlabeled' and os.path.isdir(item_path):\n",
        "                    unlabeled_source = item_path\n",
        "\n",
        "            if labeled_source and unlabeled_source:\n",
        "                # Create target directory\n",
        "                if os.path.exists(DATA_DIR):\n",
        "                    shutil.rmtree(DATA_DIR)\n",
        "                os.makedirs(DATA_DIR)\n",
        "\n",
        "                # Move directories\n",
        "                shutil.move(labeled_source, os.path.join(DATA_DIR, 'labeled'))\n",
        "                shutil.move(unlabeled_source, os.path.join(DATA_DIR, 'unlabeled'))\n",
        "\n",
        "                print(\"‚úÖ Dataset organized successfully!\")\n",
        "\n",
        "                # Verify structure\n",
        "                labeled_dir = os.path.join(DATA_DIR, 'labeled')\n",
        "                species_count = len([d for d in os.listdir(labeled_dir)\n",
        "                                   if os.path.isdir(os.path.join(labeled_dir, d)) and not d.startswith('.')])\n",
        "\n",
        "                unlabeled_dir = os.path.join(DATA_DIR, 'unlabeled')\n",
        "                unlabeled_count = len([f for f in os.listdir(unlabeled_dir)\n",
        "                                     if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
        "\n",
        "                print(f\"üêü Verified: {species_count} species\")\n",
        "                print(f\"üìä Verified: {unlabeled_count} unlabeled images\")\n",
        "\n",
        "            else:\n",
        "                print(\"‚ùå Could not find labeled and unlabeled directories\")\n",
        "\n",
        "            # Cleanup\n",
        "            if os.path.exists(temp_dir):\n",
        "                shutil.rmtree(temp_dir)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error extracting dataset: {e}\")\n",
        "\n",
        "# Final verification\n",
        "if os.path.exists(DATA_DIR):\n",
        "    print(f\"\\n‚úÖ DATASET READY\")\n",
        "    print(f\"üìÅ Location: {DATA_DIR}\")\n",
        "    print(\"üöÄ Ready for training!\")\n",
        "else:\n",
        "    print(f\"\\n‚ùå DATASET SETUP FAILED\")\n",
        "    print(\"Please check that fish_cutouts.zip is uploaded to Google Drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31f0fe32",
      "metadata": {
        "id": "31f0fe32"
      },
      "source": [
        "## üìà Step 6: Setup Weights & Biases (Optional)\n",
        "\n",
        "Weights & Biases provides excellent training visualization and experiment tracking."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "ab343772",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab343772",
        "outputId": "5ecc5316-eef3-4af2-e01e-01987bf9c2a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìà SETTING UP WEIGHTS & BIASES\n",
            "========================================\n",
            "üîë Please enter your W&B API key when prompted\n",
            "üí° Get your API key from: https://wandb.ai/settings\n",
            "‚úÖ Successfully logged in to W&B\n",
            "üìä W&B not connected - training will continue without logging\n",
            "‚úÖ W&B setup complete (Enabled: False)\n"
          ]
        }
      ],
      "source": [
        "# Login to Weights & Biases for experiment tracking\n",
        "import wandb\n",
        "import os\n",
        "\n",
        "print(\"üìà SETTING UP WEIGHTS & BIASES\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# Check if API key is available\n",
        "if os.environ.get(\"WANDB_API_KEY\"):\n",
        "    print(\"‚úÖ W&B API key found in environment\")\n",
        "    try:\n",
        "        wandb.login(relogin=True)\n",
        "        print(\"‚úÖ Successfully logged in to W&B\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è W&B relogin failed: {e}\")\n",
        "        print(\"Trying manual login...\")\n",
        "        wandb.login()\n",
        "else:\n",
        "    print(\"üîë Please enter your W&B API key when prompted\")\n",
        "    print(\"üí° Get your API key from: https://wandb.ai/settings\")\n",
        "    try:\n",
        "        wandb.login()\n",
        "        print(\"‚úÖ Successfully logged in to W&B\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå W&B login failed: {e}\")\n",
        "        print(\"Continuing without W&B logging...\")\n",
        "\n",
        "# Check connection status\n",
        "if wandb.run:\n",
        "    print(f\"üöÄ W&B Run URL: {wandb.run.url}\")\n",
        "    USE_WANDB = True\n",
        "else:\n",
        "    print(\"üìä W&B not connected - training will continue without logging\")\n",
        "    USE_WANDB = False\n",
        "\n",
        "print(f\"‚úÖ W&B setup complete (Enabled: {USE_WANDB})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5190f01",
      "metadata": {
        "id": "b5190f01"
      },
      "source": [
        "## üîÑ Step 6: Locate Checkpoint from Epoch 19\n",
        "\n",
        "Finding your saved checkpoint to resume training from where you left off."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "61b35ced",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61b35ced",
        "outputId": "d584f10c-807c-4a0f-a05e-ac739c6b0bdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Looking for checkpoint from epoch 100...\n",
            "üíæ New checkpoints will be saved to: /content/drive/MyDrive/ViT-FishID/pretrained_checkpoints\n",
            "‚ùå No checkpoint found for epoch 19!\n",
            "üöÄ Starting fresh training from epoch 1\n"
          ]
        }
      ],
      "source": [
        "# Locate checkpoint from epoch 19\n",
        "import os\n",
        "import glob\n",
        "import torch\n",
        "\n",
        "print(\"üîç Looking for checkpoint from epoch 100...\")\n",
        "\n",
        "# Configuration\n",
        "# Always start from the beginning\n",
        "checkpoint_path = None\n",
        "checkpoint_info = None\n",
        "RESUME_CHECKPOINT = None # Ensure this is explicitly set to None\n",
        "\n",
        "# Set up checkpoint directory for new saves\n",
        "checkpoint_save_dir = '/content/drive/MyDrive/ViT-FishID/pretrained_checkpoints'\n",
        "os.makedirs(checkpoint_save_dir, exist_ok=True)\n",
        "print(f\"üíæ New checkpoints will be saved to: {checkpoint_save_dir}\")\n",
        "\n",
        "\n",
        "if checkpoint_path:\n",
        "    print(f\"\\nüéâ Checkpoint ready for resuming training!\")\n",
        "    print(f\"üìÑ File: {os.path.basename(checkpoint_path)}\")\n",
        "    print(f\"üìè Size: {os.path.getsize(checkpoint_path) / (1024*1024):.1f} MB\")\n",
        "    print(f\"üíæ New checkpoints will be saved to: {checkpoint_save_dir}\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå No checkpoint found for epoch 19!\")\n",
        "    print(\"üöÄ Starting fresh training from epoch 1\")\n",
        "\n",
        "# Store checkpoint path for later use\n",
        "RESUME_CHECKPOINT = checkpoint_path"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fe6af6d",
      "metadata": {
        "id": "0fe6af6d"
      },
      "source": [
        "## ‚öôÔ∏è Step 7: Configure Training Parameters\n",
        "\n",
        "Configure the training settings for your semi-supervised fish classification model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "hSokV6NDjgYa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSokV6NDjgYa",
        "outputId": "0c7b9d0c-3766-426c-8eb8-d80ae70f741d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚öôÔ∏è TRAINING CONFIGURATION\n",
            "==================================================\n",
            "üìÅ Checkpoints: /content/drive/MyDrive/ViT-FishID/pretrained_checkpoints\n",
            "üíæ Backups: /content/drive/MyDrive/ViT-FishID/pretrained_checkpoints_backup\n",
            "\n",
            "üìã TRAINING CONFIGURATION\n",
            "==================================================\n",
            "üéØ Training mode: semi_supervised\n",
            "üìä Total epochs: 100\n",
            "üì¶ Batch size: 16\n",
            "üß† Model: vit_base_patch16_224\n",
            "üêü Number of species: 37\n",
            "‚öñÔ∏è Consistency weight: 2.0\n",
            "üéØ Pseudo-label threshold: 0.7\n",
            "üíæ Save frequency: Every 10 epochs\n",
            "üìà W&B logging: False\n",
            "\n",
            "‚è±Ô∏è Estimated training time: 5.0 hours\n",
            "üí° Recommendation: Use Colab Pro for longer training sessions\n",
            "\n",
            "‚úÖ Configuration complete - ready to start training!\n"
          ]
        }
      ],
      "source": [
        "# Training Configuration for Semi-Supervised Fish Classification\n",
        "import os\n",
        "\n",
        "print(\"‚öôÔ∏è TRAINING CONFIGURATION\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Auto-detect number of species from dataset\n",
        "NUM_CLASSES = 37  # Default\n",
        "if 'DATA_DIR' in globals() and os.path.exists(DATA_DIR):\n",
        "    labeled_dir = os.path.join(DATA_DIR, 'labeled')\n",
        "    if os.path.exists(labeled_dir):\n",
        "        species_count = len([d for d in os.listdir(labeled_dir)\n",
        "                           if os.path.isdir(os.path.join(labeled_dir, d)) and not d.startswith('.')])\n",
        "        NUM_CLASSES = species_count\n",
        "        print(f\"üìä Auto-detected {species_count} fish species\")\n",
        "\n",
        "# Create checkpoint directories\n",
        "CHECKPOINT_DIR = '/content/drive/MyDrive/ViT-FishID/pretrained_checkpoints'\n",
        "BACKUP_DIR = '/content/drive/MyDrive/ViT-FishID/pretrained_checkpoints_backup'\n",
        "\n",
        "try:\n",
        "    os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "    os.makedirs(BACKUP_DIR, exist_ok=True)\n",
        "    print(f\"üìÅ Checkpoints: {CHECKPOINT_DIR}\")\n",
        "    print(f\"üíæ Backups: {BACKUP_DIR}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Could not create Google Drive directories: {e}\")\n",
        "    CHECKPOINT_DIR = '/content/pretraine_checkpoints'\n",
        "    BACKUP_DIR = '/content/pretrained_checkpoints_backup'\n",
        "    os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "    os.makedirs(BACKUP_DIR, exist_ok=True)\n",
        "    print(f\"üìÅ Using local checkpoints: {CHECKPOINT_DIR}\")\n",
        "\n",
        "# Training Configuration\n",
        "TRAINING_CONFIG = {\n",
        "    # BASIC SETTINGS\n",
        "    'mode': 'semi_supervised',\n",
        "    'data_dir': DATA_DIR if 'DATA_DIR' in globals() else '/content/fish_cutouts',\n",
        "    'epochs': 100,\n",
        "    'batch_size': 16,\n",
        "    'learning_rate': 1e-4,\n",
        "    'weight_decay': 0.05,\n",
        "\n",
        "    # MODEL SETTINGS\n",
        "    'model_name': 'vit_base_patch16_224',\n",
        "    'num_classes': NUM_CLASSES,\n",
        "    'pretrained': True,\n",
        "\n",
        "    # SEMI-SUPERVISED SETTINGS\n",
        "    'consistency_weight': 2.0,\n",
        "    'pseudo_label_threshold': 0.7,\n",
        "    'temperature': 4.0,\n",
        "    'warmup_epochs': 10,\n",
        "    'ramp_up_epochs': 30,\n",
        "\n",
        "    # CHECKPOINT SETTINGS\n",
        "    'save_frequency': 10,  # Save every 10 epochs\n",
        "    'checkpoint_dir': CHECKPOINT_DIR,\n",
        "    'backup_dir': BACKUP_DIR,\n",
        "\n",
        "    # LOGGING SETTINGS\n",
        "    'use_wandb': USE_WANDB if 'USE_WANDB' in globals() else False,\n",
        "    'wandb_project': 'ViT-FishID-Training',\n",
        "    'wandb_run_name': f'fish-classification-{NUM_CLASSES}-classes',\n",
        "}\n",
        "\n",
        "print(\"\\nüìã TRAINING CONFIGURATION\")\n",
        "print(\"=\"*50)\n",
        "print(f\"üéØ Training mode: {TRAINING_CONFIG['mode']}\")\n",
        "print(f\"üìä Total epochs: {TRAINING_CONFIG['epochs']}\")\n",
        "print(f\"üì¶ Batch size: {TRAINING_CONFIG['batch_size']}\")\n",
        "print(f\"üß† Model: {TRAINING_CONFIG['model_name']}\")\n",
        "print(f\"üêü Number of species: {TRAINING_CONFIG['num_classes']}\")\n",
        "print(f\"‚öñÔ∏è Consistency weight: {TRAINING_CONFIG['consistency_weight']}\")\n",
        "print(f\"üéØ Pseudo-label threshold: {TRAINING_CONFIG['pseudo_label_threshold']}\")\n",
        "print(f\"üíæ Save frequency: Every {TRAINING_CONFIG['save_frequency']} epochs\")\n",
        "print(f\"üìà W&B logging: {TRAINING_CONFIG['use_wandb']}\")\n",
        "\n",
        "# Time estimation\n",
        "estimated_time_hours = TRAINING_CONFIG['epochs'] * 3 / 60  # ~3 minutes per epoch\n",
        "print(f\"\\n‚è±Ô∏è Estimated training time: {estimated_time_hours:.1f} hours\")\n",
        "print(f\"üí° Recommendation: Use Colab Pro for longer training sessions\")\n",
        "\n",
        "print(\"\\n‚úÖ Configuration complete - ready to start training!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34762fd6",
      "metadata": {
        "id": "34762fd6"
      },
      "source": [
        "## ü§ñ Step 7a: Load MAE Pre-trained Model (Optional)\n",
        "\n",
        "**This step loads your pre-trained MAE model to initialize the ViT encoder with better features.**\n",
        "\n",
        "The MAE (Masked Autoencoder) model you trained provides much better initial weights for the Vision Transformer compared to ImageNet pretraining, especially for fish images since it was trained specifically on your fish dataset.\n",
        "\n",
        "Benefits of using MAE initialization:\n",
        "- **Better Feature Representations**: Learned specifically on fish images\n",
        "- **Faster Convergence**: Model starts with relevant features\n",
        "- **Improved Performance**: Often leads to 2-5% accuracy improvement\n",
        "\n",
        "### üìÅ MAE Model Locations\n",
        "\n",
        "Your MAE models should be in one of these locations:\n",
        "- **Local**: `/Users/catalinathomson/Desktop/Fish/ViT-FishID/mae_checkpoints/mae_final_model.pth`\n",
        "- **Google Drive**: `/content/drive/MyDrive/mae_checkpoints/mae_final_model.pth` (after upload)\n",
        "\n",
        "### üîß Setup Instructions\n",
        "\n",
        "1. **Upload MAE Model**: Upload your `mae_final_model.pth` or `mae_best_model.pth` to Google Drive\n",
        "2. **Update Path**: Modify `MAE_MODEL_PATH` in the next cell if needed\n",
        "3. **Enable/Disable**: Set `LOAD_MAE_PRETRAINED = True/False` to control MAE loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "02ef2d40",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02ef2d40",
        "outputId": "72342f81-6170-4362-dac4-7ad8f9b157b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü§ñ SETTING UP MAE-INITIALIZED ViT MODEL\n",
            "============================================================\n",
            "Configured MAE_MODEL_PATH: /content/drive/MyDrive/mae_checkpoints/mae_final_model.pth\n",
            "Configured LOAD_MAE_PRETRAINED: True\n",
            "Attempting to load MAE pretrained model from: /content/drive/MyDrive/mae_checkpoints/mae_final_model.pth\n",
            "‚úÖ Found MAE model: mae_final_model.pth\n",
            "üìè Size: 149.6 MB\n",
            "üì• Loading MAE checkpoint from: /content/drive/MyDrive/mae_checkpoints/mae_final_model.pth\n",
            "‚úÖ MAE checkpoint loaded in 0.27 seconds.\n",
            "üìä MAE trained for 50 epochs\n",
            "‚úÖ Found model state dictionary in checkpoint.\n",
            "Filtering MAE state dictionary for encoder weights...\n",
            "üìä Extracted 78 encoder parameters from MAE in 0.00 seconds.\n",
            "üéâ MAE encoder weights loaded successfully!\n",
            "‚úÖ TRAINING_CONFIG updated for MAE pretraining.\n",
            "\n",
            "üß™ Testing model creation...\n",
            "Using model_name: vit_base_patch16_224\n",
            "Using MAE weights for test model: True\n",
            "Using ImageNet pretrained for test model: False\n",
            "üèóÔ∏è Creating ViT model: vit_base_patch16_224\n",
            "Using ImageNet pretrained weights: False\n",
            "‚úÖ ViT model created in 1.43 seconds.\n",
            "‚ö° Initializing ViT backbone with MAE encoder weights...\n",
            "‚úÖ Successfully transferred 0 MAE encoder weights in 0.00 seconds.\n",
            "üéØ ViT model initialized with MAE-learned features!\n",
            "Moving test model to device: cuda\n",
            "‚úÖ Model test successful!\n",
            "üìä Input shape: torch.Size([1, 3, 224, 224])\n",
            "üìä Output shape: torch.Size([1, 37])\n",
            "üéØ Model ready for training!\n",
            "\n",
            "============================================================\n",
            "‚úÖ MAE INITIALIZATION SETUP COMPLETE!\n",
            "ü§ñ MAE pretrained: True\n",
            "üåê ImageNet pretrained: False\n",
            "üìä Model: vit_base_patch16_224 with 37 classes\n",
            "üéâ Your model will start with MAE-learned features specific to fish images!\n",
            "üöÄ This should lead to faster training and better performance!\n",
            "üéØ Ready to proceed to training!\n"
          ]
        }
      ],
      "source": [
        "# Load MAE Pre-trained Model and Create Custom ViT Model\n",
        "import torch\n",
        "import os\n",
        "import shutil\n",
        "from model import ViTForFishClassification\n",
        "import time # Import time for basic profiling\n",
        "\n",
        "print(\"ü§ñ SETTING UP MAE-INITIALIZED ViT MODEL\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Configuration for MAE loading\n",
        "MAE_MODEL_PATH = '/content/drive/MyDrive/mae_checkpoints/mae_final_model.pth'  # Update this path if needed\n",
        "LOAD_MAE_PRETRAINED = True  # Set to False to skip MAE loading\n",
        "\n",
        "# Global variable to store MAE state for later use\n",
        "MAE_ENCODER_WEIGHTS = None\n",
        "print(f\"Configured MAE_MODEL_PATH: {MAE_MODEL_PATH}\")\n",
        "print(f\"Configured LOAD_MAE_PRETRAINED: {LOAD_MAE_PRETRAINED}\")\n",
        "\n",
        "\n",
        "def load_mae_encoder_weights(mae_checkpoint_path):\n",
        "    \"\"\"\n",
        "    Load and extract encoder weights from MAE checkpoint.\n",
        "\n",
        "    Args:\n",
        "        mae_checkpoint_path: Path to MAE checkpoint file\n",
        "\n",
        "    Returns:\n",
        "        dict: Filtered encoder weights compatible with ViT backbone\n",
        "    \"\"\"\n",
        "    print(f\"üì• Loading MAE checkpoint from: {mae_checkpoint_path}\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    try:\n",
        "        # Load MAE checkpoint\n",
        "        # Use map_location='cpu' first, then move to GPU if needed later\n",
        "        # Added weights_only=False based on error message\n",
        "        checkpoint = torch.load(mae_checkpoint_path, map_location='cpu', weights_only=False)\n",
        "        print(f\"‚úÖ MAE checkpoint loaded in {time.time() - start_time:.2f} seconds.\")\n",
        "\n",
        "        # Print checkpoint info\n",
        "        if 'epoch' in checkpoint:\n",
        "            print(f\"üìä MAE trained for {checkpoint['epoch']} epochs\")\n",
        "        if 'train_loss' in checkpoint:\n",
        "            print(f\"üìâ Final MAE loss: {checkpoint['train_loss']:.4f}\")\n",
        "        if 'model_state_dict' in checkpoint or 'state_dict' in checkpoint:\n",
        "             print(\"‚úÖ Found model state dictionary in checkpoint.\")\n",
        "        else:\n",
        "             print(\"‚ö†Ô∏è Could not find 'model_state_dict' or 'state_dict' in checkpoint.\")\n",
        "\n",
        "\n",
        "        # Get model state dict\n",
        "        mae_state_dict = checkpoint.get('model_state_dict', checkpoint.get('state_dict', None))\n",
        "\n",
        "        if mae_state_dict is None:\n",
        "             print(\"‚ùå MAE state dictionary not found in checkpoint.\")\n",
        "             return None\n",
        "\n",
        "        # Filter encoder weights (remove decoder, mask token, and other non-encoder components)\n",
        "        encoder_weights = {}\n",
        "        filter_prefixes = ['patch_embed', 'pos_embed', 'cls_token', 'blocks', 'norm']\n",
        "        exclude_substrings = ['decoder', 'mask_token', 'head']\n",
        "\n",
        "        print(\"Filtering MAE state dictionary for encoder weights...\")\n",
        "        start_time = time.time()\n",
        "        for key, value in mae_state_dict.items():\n",
        "            # Keep only encoder-related weights\n",
        "            if any(prefix in key for prefix in filter_prefixes) and not any(exclude in key for exclude in exclude_substrings):\n",
        "                encoder_weights[key] = value\n",
        "\n",
        "        print(f\"üìä Extracted {len(encoder_weights)} encoder parameters from MAE in {time.time() - start_time:.2f} seconds.\")\n",
        "\n",
        "        if not encoder_weights:\n",
        "             print(\"‚ö†Ô∏è No encoder weights were extracted. Check filter logic or checkpoint structure.\")\n",
        "\n",
        "\n",
        "        return encoder_weights\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error loading or processing MAE checkpoint: {e}\")\n",
        "        return None\n",
        "\n",
        "def create_mae_initialized_model(num_classes, model_name='vit_base_patch16_224', mae_weights=None):\n",
        "    \"\"\"\n",
        "    Create ViT model and optionally initialize with MAE weights.\n",
        "\n",
        "    Args:\n",
        "        num_classes: Number of classification classes\n",
        "        model_name: ViT model architecture name\n",
        "        mae_weights: Optional MAE encoder weights dictionary\n",
        "\n",
        "    Returns:\n",
        "        ViTForFishClassification: Initialized model\n",
        "    \"\"\"\n",
        "    print(f\"üèóÔ∏è Creating ViT model: {model_name}\")\n",
        "\n",
        "    # Create ViT model (without ImageNet pretraining if we have MAE weights)\n",
        "    use_imagenet_pretrained = mae_weights is None\n",
        "    print(f\"Using ImageNet pretrained weights: {use_imagenet_pretrained}\")\n",
        "    start_time = time.time()\n",
        "    model = ViTForFishClassification(\n",
        "        num_classes=num_classes,\n",
        "        model_name=model_name,\n",
        "        pretrained=use_imagenet_pretrained,\n",
        "        dropout_rate=0.1\n",
        "    )\n",
        "    print(f\"‚úÖ ViT model created in {time.time() - start_time:.2f} seconds.\")\n",
        "\n",
        "    if mae_weights is not None:\n",
        "        print(\"‚ö° Initializing ViT backbone with MAE encoder weights...\")\n",
        "        start_time = time.time()\n",
        "        # Get current backbone state dict\n",
        "        backbone_state = model.backbone.state_dict()\n",
        "\n",
        "        # Update with MAE weights (only for matching keys and shapes)\n",
        "        updated_keys = []\n",
        "        shape_mismatches = []\n",
        "\n",
        "        for mae_key, mae_weight in mae_weights.items():\n",
        "            if mae_key in backbone_state:\n",
        "                if mae_weight.shape == backbone_state[mae_key].shape:\n",
        "                    backbone_state[mae_key] = mae_weight.clone()\n",
        "                    updated_keys.append(mae_key)\n",
        "                else:\n",
        "                    shape_mismatches.append(f\"{mae_key}: MAE{mae_weight.shape} != ViT{backbone_state[mae_key].shape}\")\n",
        "\n",
        "        # Load updated weights\n",
        "        try:\n",
        "            model.backbone.load_state_dict(backbone_state)\n",
        "            print(f\"‚úÖ Successfully transferred {len(updated_keys)} MAE encoder weights in {time.time() - start_time:.2f} seconds.\")\n",
        "\n",
        "            if shape_mismatches:\n",
        "                print(f\"‚ö†Ô∏è Found {len(shape_mismatches)} shape mismatches (using original weights for these):\")\n",
        "                for mismatch in shape_mismatches[:5]:  # Show first 5 mismatches\n",
        "                    print(f\"   {mismatch}\")\n",
        "\n",
        "            print(\"üéØ ViT model initialized with MAE-learned features!\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error loading MAE weights into ViT backbone: {e}\")\n",
        "            print(\"Continuing with potentially partially loaded weights or default ImageNet (if applicable).\")\n",
        "\n",
        "\n",
        "    else:\n",
        "        print(\"üåê Using ImageNet pretrained weights\")\n",
        "\n",
        "    return model\n",
        "\n",
        "# Main execution\n",
        "if LOAD_MAE_PRETRAINED:\n",
        "    print(f\"Attempting to load MAE pretrained model from: {MAE_MODEL_PATH}\")\n",
        "    # Check if MAE model exists in Google Drive\n",
        "    if os.path.exists(MAE_MODEL_PATH):\n",
        "        print(f\"‚úÖ Found MAE model: {os.path.basename(MAE_MODEL_PATH)}\")\n",
        "        try:\n",
        "            file_size = os.path.getsize(MAE_MODEL_PATH) / (1024**2)\n",
        "            print(f\"üìè Size: {file_size:.1f} MB\")\n",
        "        except Exception as e:\n",
        "             print(f\"‚ö†Ô∏è Could not get file size: {e}\")\n",
        "\n",
        "\n",
        "        try:\n",
        "            # Load MAE encoder weights\n",
        "            MAE_ENCODER_WEIGHTS = load_mae_encoder_weights(MAE_MODEL_PATH)\n",
        "\n",
        "            if MAE_ENCODER_WEIGHTS is not None:\n",
        "                 print(\"üéâ MAE encoder weights loaded successfully!\")\n",
        "\n",
        "                 # Update training config\n",
        "                 if 'TRAINING_CONFIG' in globals():\n",
        "                    TRAINING_CONFIG['mae_pretrained'] = True\n",
        "                    TRAINING_CONFIG['mae_model_path'] = MAE_MODEL_PATH\n",
        "                    TRAINING_CONFIG['pretrained'] = False  # Don't use ImageNet since we have MAE\n",
        "                    print(\"‚úÖ TRAINING_CONFIG updated for MAE pretraining.\")\n",
        "                 else:\n",
        "                    print(\"‚ö†Ô∏è TRAINING_CONFIG not found. Cannot update config with MAE settings.\")\n",
        "\n",
        "            else:\n",
        "                 print(\"‚ùå Failed to load MAE encoder weights. MAE_ENCODER_WEIGHTS is None.\")\n",
        "                 print(\"üîÑ Falling back to ImageNet pretrained weights...\")\n",
        "                 MAE_ENCODER_WEIGHTS = None\n",
        "                 if 'TRAINING_CONFIG' in globals():\n",
        "                    TRAINING_CONFIG['mae_pretrained'] = False\n",
        "                    TRAINING_CONFIG['pretrained'] = True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error during MAE loading process: {e}\")\n",
        "            print(\"üîÑ Falling back to ImageNet pretrained weights...\")\n",
        "            MAE_ENCODER_WEIGHTS = None\n",
        "            if 'TRAINING_CONFIG' in globals():\n",
        "                TRAINING_CONFIG['mae_pretrained'] = False\n",
        "                TRAINING_CONFIG['pretrained'] = True\n",
        "\n",
        "\n",
        "    else:\n",
        "        # MAE model not found, check alternative locations\n",
        "        print(f\"‚ùå MAE model not found at: {MAE_MODEL_PATH}\")\n",
        "\n",
        "        # Try to copy from local mae_checkpoints if exists\n",
        "        local_mae_path = f'/content/ViT-FishID/mae_checkpoints/{os.path.basename(MAE_MODEL_PATH)}'\n",
        "        print(f\"Checking local path: {local_mae_path}\")\n",
        "        if os.path.exists(local_mae_path):\n",
        "            print(f\"ÔøΩ Found MAE model in local repository: {local_mae_path}\")\n",
        "            try:\n",
        "                # Create directory and copy\n",
        "                print(f\"Attempting to create directory: {os.path.dirname(MAE_MODEL_PATH)}\")\n",
        "                os.makedirs(os.path.dirname(MAE_MODEL_PATH), exist_ok=True)\n",
        "                print(f\"Copying from {local_mae_path} to {MAE_MODEL_PATH}\")\n",
        "                shutil.copy2(local_mae_path, MAE_MODEL_PATH)\n",
        "                print(f\"‚úÖ Copied MAE model to Google Drive: {MAE_MODEL_PATH}\")\n",
        "\n",
        "                # Now load it\n",
        "                MAE_ENCODER_WEIGHTS = load_mae_encoder_weights(MAE_MODEL_PATH)\n",
        "                if MAE_ENCODER_WEIGHTS is not None:\n",
        "                    if 'TRAINING_CONFIG' in globals():\n",
        "                        TRAINING_CONFIG['mae_pretrained'] = True\n",
        "                        TRAINING_CONFIG['mae_model_path'] = MAE_MODEL_PATH\n",
        "                        TRAINING_CONFIG['pretrained'] = False\n",
        "                else:\n",
        "                     print(\"‚ùå Failed to load MAE encoder weights after copying.\")\n",
        "                     MAE_ENCODER_WEIGHTS = None\n",
        "                     if 'TRAINING_CONFIG' in globals():\n",
        "                        TRAINING_CONFIG['mae_pretrained'] = False\n",
        "                        TRAINING_CONFIG['pretrained'] = True\n",
        "\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Error copying/loading MAE model from local path: {e}\")\n",
        "                MAE_ENCODER_WEIGHTS = None\n",
        "                if 'TRAINING_CONFIG' in globals():\n",
        "                    TRAINING_CONFIG['mae_pretrained'] = False\n",
        "                    TRAINING_CONFIG['pretrained'] = True\n",
        "        else:\n",
        "            print(\"ÔøΩüìù MAE model not found in local repository either.\")\n",
        "            print(\"ÔøΩüìù Available options:\")\n",
        "            print(\"1. Upload mae_final_model.pth or mae_best_model.pth to /content/drive/MyDrive/mae_checkpoints/\")\n",
        "            print(\"2. Update MAE_MODEL_PATH variable to correct location\")\n",
        "            print(\"3. Set LOAD_MAE_PRETRAINED = False to use ImageNet weights\")\n",
        "            print(\"üîÑ Continuing with ImageNet pretrained weights...\")\n",
        "            MAE_ENCODER_WEIGHTS = None\n",
        "            if 'TRAINING_CONFIG' in globals():\n",
        "                TRAINING_CONFIG['mae_pretrained'] = False\n",
        "                TRAINING_CONFIG['pretrained'] = True\n",
        "\n",
        "else:\n",
        "    print(\"‚è≠Ô∏è LOAD_MAE_PRETRAINED is False. Skipping MAE loading - will use ImageNet pretrained weights\")\n",
        "    MAE_ENCODER_WEIGHTS = None\n",
        "    if 'TRAINING_CONFIG' in globals():\n",
        "        TRAINING_CONFIG['mae_pretrained'] = False\n",
        "        TRAINING_CONFIG['pretrained'] = True\n",
        "\n",
        "\n",
        "# Test model creation (optional - this creates a model to verify everything works)\n",
        "print(f\"\\nüß™ Testing model creation...\")\n",
        "if 'NUM_CLASSES' not in globals():\n",
        "    print(\"‚ö†Ô∏è NUM_CLASSES not defined. Skipping model creation test.\")\n",
        "else:\n",
        "    try:\n",
        "        # Ensure model name and pretrained flag are correctly picked up from TRAINING_CONFIG\n",
        "        model_name_for_test = TRAINING_CONFIG.get('model_name', 'vit_base_patch16_224')\n",
        "        use_imagenet_for_test = TRAINING_CONFIG.get('pretrained', True) # Use the updated flag\n",
        "\n",
        "        # If MAE weights were loaded, pass them, otherwise rely on TRAINING_CONFIG['pretrained']\n",
        "        weights_for_test = MAE_ENCODER_WEIGHTS if MAE_ENCODER_WEIGHTS is not None else None\n",
        "\n",
        "        print(f\"Using model_name: {model_name_for_test}\")\n",
        "        print(f\"Using MAE weights for test model: {weights_for_test is not None}\")\n",
        "        print(f\"Using ImageNet pretrained for test model: {use_imagenet_for_test}\")\n",
        "\n",
        "        test_model = create_mae_initialized_model(\n",
        "            num_classes=NUM_CLASSES,\n",
        "            model_name=model_name_for_test,\n",
        "            mae_weights=weights_for_test # Pass MAE weights if available\n",
        "        )\n",
        "\n",
        "        # Move model to device for testing (optional but good practice)\n",
        "        # Assuming DEVICE is defined globally from Step 1\n",
        "        if 'DEVICE' in globals():\n",
        "            print(f\"Moving test model to device: {DEVICE}\")\n",
        "            test_model.to(DEVICE)\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è DEVICE variable not found. Skipping moving test model to device.\")\n",
        "\n",
        "\n",
        "        # Test forward pass\n",
        "        test_input = torch.randn(1, 3, 224, 224)\n",
        "        # Move test input to the same device as the model\n",
        "        if 'DEVICE' in globals():\n",
        "            test_input = test_input.to(DEVICE)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            test_output = test_model(test_input)\n",
        "\n",
        "        print(f\"‚úÖ Model test successful!\")\n",
        "        print(f\"üìä Input shape: {test_input.shape}\")\n",
        "        print(f\"üìä Output shape: {test_output.shape}\")\n",
        "        print(f\"üéØ Model ready for training!\")\n",
        "\n",
        "        # Clean up test model\n",
        "        del test_model, test_input, test_output\n",
        "        if 'DEVICE' in globals():\n",
        "             torch.cuda.empty_cache() # Clear GPU cache after test if on GPU\n",
        "        import gc\n",
        "        gc.collect()\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Model test failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc() # Print full traceback for debugging\n",
        "\n",
        "\n",
        "print(f\"\\n\" + \"=\"*60)\n",
        "print(f\"‚úÖ MAE INITIALIZATION SETUP COMPLETE!\")\n",
        "if 'TRAINING_CONFIG' in globals():\n",
        "    print(f\"ü§ñ MAE pretrained: {TRAINING_CONFIG.get('mae_pretrained', False)}\")\n",
        "    print(f\"üåê ImageNet pretrained: {TRAINING_CONFIG.get('pretrained', True)}\")\n",
        "    print(f\"üìä Model: {TRAINING_CONFIG.get('model_name', 'N/A')} with {TRAINING_CONFIG.get('num_classes', 'N/A')} classes\")\n",
        "\n",
        "    if TRAINING_CONFIG.get('mae_pretrained', False):\n",
        "        print(\"üéâ Your model will start with MAE-learned features specific to fish images!\")\n",
        "        print(\"üöÄ This should lead to faster training and better performance!\")\n",
        "    else:\n",
        "        print(\"üåê Your model will use standard ImageNet pretrained features.\")\n",
        "else:\n",
        "     print(\"‚ö†Ô∏è TRAINING_CONFIG was not found, cannot provide detailed summary.\")\n",
        "\n",
        "\n",
        "print(\"üéØ Ready to proceed to training!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa9cbd50",
      "metadata": {
        "id": "aa9cbd50"
      },
      "source": [
        "## üöÄ Step 8: Start Semi-Supervised Training\n",
        "\n",
        "This cell will start the complete training process. Expected time: 4-6 hours for 100 epochs.\n",
        "\n",
        "**Training Process:**\n",
        "1. **Supervised Learning**: Uses labeled fish images with ground truth\n",
        "2. **Semi-Supervised Learning**: Leverages unlabeled images with pseudo-labels\n",
        "3. **EMA Teacher-Student**: Uses exponential moving average for consistency\n",
        "4. **Automatic Checkpointing**: Saves progress every 10 epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "njLKb7xaepxo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "njLKb7xaepxo",
        "outputId": "f24b78bd-885a-4bf5-e2b7-7891f97f884c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ STARTING SEMI-SUPERVISED FISH CLASSIFICATION TRAINING\n",
            "============================================================\n",
            "/content/ViT-FishID\n",
            "ü§ñ Preparing MAE-enhanced training script...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'args' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2801431964.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnum_classes_data\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m      \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"‚ö†Ô∏è Warning: Configured num_classes ({args.num_classes}) does not match detected data classes ({num_classes_data})\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m      \u001b[0;31m# Use the detected number of classes if they differ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m      \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_classes_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
          ]
        }
      ],
      "source": [
        "# Start Semi-Supervised Training with Optional MAE Initialization\n",
        "import os\n",
        "import glob\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"üöÄ STARTING SEMI-SUPERVISED FISH CLASSIFICATION TRAINING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Change to repository directory\n",
        "%cd /content/ViT-FishID\n",
        "\n",
        "# Check for existing checkpoints to resume from\n",
        "RESUME_FROM = None\n",
        "if os.path.exists(TRAINING_CONFIG['checkpoint_dir']):\n",
        "    checkpoints = glob.glob(os.path.join(TRAINING_CONFIG['checkpoint_dir'], 'checkpoint_epoch_*.pth'))\n",
        "    if checkpoints:\n",
        "        # Find the latest checkpoint\n",
        "        epoch_numbers = []\n",
        "        for cp in checkpoints:\n",
        "            try:\n",
        "                epoch_num = int(cp.split('epoch_')[1].split('.')[0])\n",
        "                epoch_numbers.append((epoch_num, cp))\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        if epoch_numbers:\n",
        "            epoch_numbers.sort(key=lambda x: x[0], reverse=True)  # Latest first\n",
        "            latest_epoch, latest_checkpoint = epoch_numbers[0]\n",
        "            print(f\"üîç Found existing checkpoints. Latest: Epoch {latest_epoch}\")\n",
        "\n",
        "            # Ask user if they want to resume (auto-skip in Colab for now)\n",
        "            # resume_choice = input(\"Do you want to resume from the latest checkpoint? (y/n): \").lower().strip()\n",
        "            resume_choice = 'n'  # Set to 'y' if you want to auto-resume\n",
        "\n",
        "            if resume_choice in ['y', 'yes']:\n",
        "                RESUME_FROM = latest_checkpoint\n",
        "                print(f\"‚úÖ Will resume from: {os.path.basename(latest_checkpoint)}\")\n",
        "            else:\n",
        "                print(\"üÜï Starting fresh training from epoch 1\")\n",
        "\n",
        "# Determine which training script to use\n",
        "use_mae_script = TRAINING_CONFIG.get('mae_pretrained', False) and 'MAE_ENCODER_WEIGHTS' in globals() and MAE_ENCODER_WEIGHTS is not None\n",
        "\n",
        "if use_mae_script:\n",
        "    print(\"ü§ñ Preparing MAE-enhanced training script...\")\n",
        "\n",
        "    # Generate the full training script with MAE initialization logic\n",
        "    training_script_content = f\"\"\"#!/usr/bin/env python3\n",
        "import sys\n",
        "sys.path.append('/content/ViT-FishID')\n",
        "\n",
        "import torch\n",
        "import argparse\n",
        "import os\n",
        "import glob\n",
        "import wandb\n",
        "from datetime import datetime\n",
        "\n",
        "from model import ViTForFishClassification\n",
        "from trainer import EMATrainer, SemiSupervisedTrainer # Ensure both trainers are imported here\n",
        "from data import create_dataloaders, create_semi_supervised_dataloaders\n",
        "from utils import get_device, set_seed\n",
        "\n",
        "# Function to create MAE-initialized model\n",
        "def create_mae_initialized_model(num_classes, model_name, mae_weights):\n",
        "    model = ViTForFishClassification(\n",
        "        num_classes=num_classes,\n",
        "        model_name=model_name,\n",
        "        pretrained=False,  # Don't use ImageNet\n",
        "        dropout_rate=0.1\n",
        "    )\n",
        "\n",
        "    # Initialize updated_keys here to ensure it's always defined\n",
        "    updated_keys = []\n",
        "\n",
        "    if mae_weights is not None:\n",
        "        backbone_state = model.backbone.state_dict()\n",
        "\n",
        "        # Define exclude_substrings inside the function where it's used\n",
        "        exclude_substrings = ['decoder', 'mask_token', 'head']\n",
        "        # Define filter_prefixes inside the function where it's used\n",
        "        filter_prefixes = ['patch_embed', 'pos_embed', 'cls_token', 'blocks', 'norm']\n",
        "\n",
        "        # Initialize encoder_weights before the loop\n",
        "        encoder_weights = {{}}\n",
        "\n",
        "        for mae_key, mae_weight in mae_weights.items():\n",
        "            # Keep only encoder-related weights and exclude specified substrings\n",
        "            # Rewritten filtering logic to avoid potential scope issues with 'exclude'\n",
        "            should_include_prefix = False\n",
        "            for prefix in filter_prefixes:\n",
        "                if prefix in mae_key:\n",
        "                    should_include_prefix = True\n",
        "                    break\n",
        "\n",
        "            should_exclude_substring = False\n",
        "            for exclude_str in exclude_substrings:\n",
        "                 if exclude_str in mae_key:\n",
        "                      should_exclude_substring = True\n",
        "                      break\n",
        "\n",
        "            if should_include_prefix and not should_exclude_substring:\n",
        "                 # Check if the key exists in the model's state dict and if shapes match\n",
        "                 if mae_key in backbone_state and mae_weight.shape == backbone_state[mae_key].shape:\n",
        "                      backbone_state[mae_key] = mae_weight.clone()\n",
        "                      updated_keys.append(mae_key)\n",
        "                 # elif mae_key not in backbone_state:\n",
        "                 #     print(f\"Skipping MAE weight '{{mae_key}}': not found in model backbone\")\n",
        "                 # else:\n",
        "                 #     print(f\"Skipping MAE weight '{{mae_key}}': shape mismatch (MAE:{{mae_weight.shape}} != Model:{{backbone_state[mae_key].shape}})\")\n",
        "\n",
        "\n",
        "        try:\n",
        "            model.backbone.load_state_dict(backbone_state, strict=False) # strict=False allows skipping mismatched keys\n",
        "            print(f\"‚úÖ Loaded {{len(updated_keys)}} MAE encoder weights into model\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error loading MAE weights into ViT backbone: {{e}}\")\n",
        "            print(\"Continuing with potentially partially loaded weights.\")\n",
        "\n",
        "\n",
        "    return model\n",
        "\n",
        "# Access the global MAE_ENCODER_WEIGHTS set in the Colab cell\n",
        "# This relies on the fact that the kernel state is preserved when executing the script this way\n",
        "# If running as a separate process, this would require saving/loading MAE_ENCODER_WEIGHTS\n",
        "global MAE_ENCODER_WEIGHTS\n",
        "mae_weights_from_global = MAE_ENCODER_WEIGHTS\n",
        "\n",
        "if mae_weights_from_global is not None:\n",
        "    print(f\"ü§ñ Loaded {{len(mae_weights_from_global)}} MAE encoder weights (from global scope in Colab)\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è MAE_ENCODER_WEIGHTS not found in global scope. Model will use ImageNet weights.\")\n",
        "\n",
        "\n",
        "# Define arguments directly (or parse if needed)\n",
        "# For simplicity, we are defining them based on the Colab cell's TRAINING_CONFIG\n",
        "class Args:\n",
        "    def __init__(self, config, resume_from, num_classes):\n",
        "        self.mode = config['mode']\n",
        "        self.data_dir = config['data_dir']\n",
        "        self.epochs = config['epochs']\n",
        "        self.batch_size = config['batch_size']\n",
        "        self.learning_rate = config['learning_rate']\n",
        "        self.weight_decay = config['weight_decay']\n",
        "        self.model_name = config['model_name']\n",
        "        self.consistency_weight = config['consistency_weight']\n",
        "        self.pseudo_label_threshold = config['pseudo_label_threshold']\n",
        "        self.temperature = config['temperature']\n",
        "        self.warmup_epochs = config['warmup_epochs']\n",
        "        self.ramp_up_epochs = config['ramp_up_epochs']\n",
        "        self.save_dir = config['checkpoint_dir']\n",
        "        self.save_frequency = config['save_frequency']\n",
        "        self.pretrained = False # Explicitly False when using MAE\n",
        "        self.use_wandb = config['use_wandb']\n",
        "        self.resume_from = resume_from\n",
        "        self.num_workers = 4 # Or get from config if available\n",
        "        self.image_size = 224 # Or get from config if available\n",
        "        self.dropout_rate = 0.1 # Or get from config if available\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "args = Args(TRAINING_CONFIG, RESUME_FROM, NUM_CLASSES) # Pass the global variables\n",
        "\n",
        "# Set up device and seed\n",
        "device = get_device()\n",
        "set_seed(42)\n",
        "\n",
        "# Create model\n",
        "print('ü§ñ Creating model for training...')\n",
        "# Check if MAE weights are available before attempting MAE initialization\n",
        "if mae_weights_from_global is not None:\n",
        "     student_model = create_mae_initialized_model(\n",
        "         num_classes=args.num_classes,\n",
        "         model_name=args.model_name,\n",
        "         mae_weights=mae_weights_from_global # Pass the loaded MAE weights\n",
        "     ).to(device)\n",
        "else: # Fallback if MAE was not loaded (this branch won't be taken if use_mae_script is True)\n",
        "     student_model = ViTForFishClassification(\n",
        "        num_classes=args.num_classes,\n",
        "        model_name=args.model_name,\n",
        "        pretrained=args.pretrained,\n",
        "        dropout_rate=args.dropout_rate\n",
        "     ).to(device)\n",
        "\n",
        "# Create teacher model for EMA (if needed)\n",
        "teacher_model = None\n",
        "if args.mode == 'semi_supervised':\n",
        "    try:\n",
        "        from trainer import EMATeacher # Import EMATeacher here if needed\n",
        "        teacher_model = EMATeacher(student_model).to(device) # Assuming EMATeacher takes student model\n",
        "        print('üéì EMA Teacher model created.')\n",
        "    except NameError:\n",
        "         print(\"‚ö†Ô∏è EMATeacher class not found. Semi-supervised training will not work correctly.\")\n",
        "         print(\"‚ùå Please ensure EMATeacher is defined or imported in trainer.py\")\n",
        "         sys.exit(1) # Exit if EMATeacher is needed but not found\n",
        "    except Exception as e:\n",
        "         print(f\"‚ö†Ô∏è Error creating EMATeacher model: {{e}}\")\n",
        "         import traceback\n",
        "         traceback.print_exc()\n",
        "         sys.exit(1) # Exit on other errors\n",
        "\n",
        "\n",
        "# Create data loaders\n",
        "print('Loading data...')\n",
        "if args.mode == 'supervised':\n",
        "    train_loader, val_loader, num_classes_data = create_dataloaders(\n",
        "        args.data_dir,\n",
        "        batch_size=args.batch_size,\n",
        "        image_size=args.image_size,\n",
        "        num_workers=args.num_workers\n",
        "    )\n",
        "    unlabeled_loader = None\n",
        "else:\n",
        "    train_loader, val_loader, unlabeled_loader, num_classes_data = create_semi_supervised_dataloaders(\n",
        "        args.data_dir,\n",
        "        batch_size=args.batch_size,\n",
        "        image_size=args.image_size,\n",
        "        num_workers=args.num_workers\n",
        "    )\n",
        "print('‚úÖ Data loaders created.')\n",
        "\n",
        "if num_classes_data != args.num_classes:\n",
        "     print(f\"‚ö†Ô∏è Warning: Configured num_classes ({args.num_classes}) does not match detected data classes ({num_classes_data})\")\n",
        "     # Use the detected number of classes if they differ\n",
        "     args.num_classes = num_classes_data\n",
        "     print(f\"‚úÖ Using {args.num_classes} detected classes for training.\")\n",
        "     # Need to re-create the model if num_classes changed (unlikely but safe)\n",
        "     # For this script, we'll assume num_classes is consistent\n",
        "\n",
        "print(f'üìä Number of classes: {{args.num_classes}}')\n",
        "print(f'üéØ Training mode: {{args.mode}}')\n",
        "\n",
        "# Create trainer\n",
        "print('Setting up trainer...')\n",
        "if args.mode == 'semi_supervised' and unlabeled_loader is not None and teacher_model is not None:\n",
        "    trainer = SemiSupervisedTrainer(\n",
        "        student_model=student_model,\n",
        "        device=device,\n",
        "        learning_rate=args.learning_rate,\n",
        "        weight_decay=args.weight_decay,\n",
        "        consistency_weight=args.consistency_weight,\n",
        "        pseudo_label_threshold=args.pseudo_label_threshold,\n",
        "        temperature=args.temperature,\n",
        "        warmup_epochs=args.warmup_epochs,\n",
        "        ramp_up_epochs=args.ramp_up_epochs,\n",
        "        teacher_model=teacher_model # Pass teacher model\n",
        "    )\n",
        "    print('‚úÖ SemiSupervisedTrainer created.')\n",
        "elif args.mode == 'supervised':\n",
        "    trainer = EMATrainer( # Using EMATrainer for supervised mode if needed, or could use a simple Trainer\n",
        "        student_model=student_model,\n",
        "        device=device,\n",
        "        learning_rate=args.learning_rate,\n",
        "        weight_decay=args.weight_decay\n",
        "    )\n",
        "    print('‚úÖ EMATrainer created (for supervised mode).')\n",
        "else:\n",
        "     print(\"‚ùå Cannot create trainer. Check mode and data loaders.\")\n",
        "     sys.exit(1)\n",
        "\n",
        "\n",
        "# Initialize W&B\n",
        "if args.use_wandb:\n",
        "    print('Initializing W&B...')\n",
        "    wandb.init(\n",
        "        project=TRAINING_CONFIG.get('wandb_project', 'ViT-FishID-Training'),\n",
        "        name=TRAINING_CONFIG.get('wandb_run_name', f'fish-classification-{{args.num_classes}}-classes'),\n",
        "        config=vars(args),\n",
        "        tags=['mae-initialized', 'fish-classification'] if use_mae_script else ['imagenet-pretrained', 'fish-classification']\n",
        "    )\n",
        "    print('‚úÖ W&B initialized.')\n",
        "\n",
        "# Resume from checkpoint if specified\n",
        "if args.resume_from and args.resume_from != 'None':\n",
        "    print(f'üì• Resuming from checkpoint: {{args.resume_from}}')\n",
        "    try:\n",
        "        checkpoint = torch.load(args.resume_from, map_location=device)\n",
        "        trainer.student_model.load_state_dict(checkpoint['student_state_dict'])\n",
        "        # Load teacher state dict if it exists and trainer has a teacher model\n",
        "        if hasattr(trainer, 'teacher_model') and trainer.teacher_model is not None and 'teacher_state_dict' in checkpoint:\n",
        "             try:\n",
        "                trainer.teacher_model.teacher_model.load_state_dict(checkpoint['teacher_state_dict'])\n",
        "                print('‚úÖ Teacher model state dict loaded.')\n",
        "             except Exception as e:\n",
        "                 print(f\"‚ö†Ô∏è Error loading teacher state dict: {{e}}\")\n",
        "\n",
        "        # Load optimizer state dict\n",
        "        if 'optimizer_state_dict' in checkpoint:\n",
        "             try:\n",
        "                 trainer.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "                 print('‚úÖ Optimizer state dict loaded.')\n",
        "             except Exception as e:\n",
        "                  print(f\"‚ö†Ô∏è Error loading optimizer state dict: {{e}}\")\n",
        "\n",
        "\n",
        "        start_epoch = checkpoint.get('epoch', 0) + 1\n",
        "        best_accuracy = checkpoint.get('best_accuracy', 0.0) # Resume best accuracy as well\n",
        "        print(f'‚úÖ Resumed from epoch {{start_epoch}} with best accuracy {{best_accuracy:.2f}}%')\n",
        "    except Exception as e:\n",
        "        print(f'‚ùå Error loading checkpoint: {{e}}')\n",
        "        import traceback\n",
        "        traceback.print_exc() # Print full traceback\n",
        "        print(\"Starting fresh training from epoch 1.\")\n",
        "        start_epoch = 1\n",
        "        best_accuracy = 0.0\n",
        "else:\n",
        "    start_epoch = 1\n",
        "    best_accuracy = 0.0\n",
        "\n",
        "print(f'üöÄ Starting training from epoch {{start_epoch}}')\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(start_epoch, args.epochs + 1):\n",
        "    print(f'\\\\nüìÖ Epoch {{epoch}}/{{args.epochs}}')\n",
        "\n",
        "    # Training step\n",
        "    try:\n",
        "        if args.mode == 'semi_supervised' and unlabeled_loader is not None:\n",
        "            train_loss = trainer.train_epoch(train_loader, unlabeled_loader, epoch)\n",
        "        elif args.mode == 'supervised':\n",
        "            train_loss = trainer.train_epoch(train_loader, epoch)\n",
        "        else:\n",
        "             print(\"‚ùå Invalid training mode or data loaders for training epoch.\")\n",
        "             break # Exit training loop if setup is wrong\n",
        "    except Exception as e:\n",
        "         print(f\"‚ùå Error during training epoch {{epoch}}: {{e}}\")\n",
        "         import traceback\n",
        "         traceback.print_exc()\n",
        "         break # Exit training loop on error\n",
        "\n",
        "\n",
        "    # Validation step\n",
        "    try:\n",
        "        val_accuracy = trainer.validate(val_loader)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error during validation epoch {{epoch}}: {{e}}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        val_accuracy = 0.0 # Set accuracy to 0 to avoid saving best model on error\n",
        "\n",
        "\n",
        "    # Update best accuracy\n",
        "    is_best = val_accuracy > best_accuracy\n",
        "    if is_best:\n",
        "        best_accuracy = val_accuracy\n",
        "\n",
        "    print(f'üìä Epoch {{epoch}} - Train Loss: {{train_loss:.4f}}, Val Acc: {{val_accuracy:.2f}}% (Best: {{best_accuracy:.2f}}%)')\n",
        "\n",
        "    # Save checkpoint\n",
        "    if epoch % args.save_frequency == 0 or is_best:\n",
        "        print(f'üíæ Saving checkpoint for epoch {{epoch}}...')\n",
        "        checkpoint_data = {{\n",
        "            'epoch': epoch,\n",
        "            'student_state_dict': trainer.student_model.state_dict(),\n",
        "            'optimizer_state_dict': trainer.optimizer.state_dict(), # Corrected: Access optimizer state dict\n",
        "            'best_accuracy': best_accuracy,\n",
        "            'train_loss': train_loss,\n",
        "            'val_accuracy': val_accuracy\n",
        "        }}\n",
        "\n",
        "        if hasattr(trainer, 'teacher_model') and trainer.teacher_model is not None:\n",
        "            try:\n",
        "                checkpoint_data['teacher_state_dict'] = trainer.teacher_model.teacher_model.state_dict() # Corrected: teacher_model.state_dict()\n",
        "                checkpoint_data['teacher_acc'] = getattr(trainer, 'teacher_accuracy', val_accuracy) # Use teacher_accuracy if available\n",
        "            except Exception as e:\n",
        "                 print(f\"‚ö†Ô∏è Could not save teacher state dict: {{e}}\")\n",
        "\n",
        "\n",
        "        # Ensure save directory exists\n",
        "        os.makedirs(args.save_dir, exist_ok=True)\n",
        "\n",
        "        # Save regular checkpoint\n",
        "        if epoch % args.save_frequency == 0:\n",
        "            checkpoint_path = os.path.join(args.save_dir, f'checkpoint_epoch_{{epoch}}.pth')\n",
        "            try:\n",
        "                torch.save(checkpoint_data, checkpoint_path)\n",
        "                print(f'‚úÖ Saved checkpoint: {{checkpoint_path}}')\n",
        "            except Exception as e:\n",
        "                 print(f\"‚ùå Error saving checkpoint {{checkpoint_path}}: {{e}}\")\n",
        "\n",
        "\n",
        "        # Save best model\n",
        "        if is_best:\n",
        "            best_path = os.path.join(args.save_dir, 'model_best.pth')\n",
        "            try:\n",
        "                torch.save(checkpoint_data, best_path)\n",
        "                print(f'üèÜ New best model saved: {{best_path}}')\n",
        "            except Exception as e:\n",
        "                 print(f\"‚ùå Error saving best model {{best_path}}: {{e}}\")\n",
        "\n",
        "\n",
        "    # W&B logging\n",
        "    if args.use_wandb:\n",
        "        try:\n",
        "            wandb.log({{\n",
        "                'epoch': epoch,\n",
        "                'train_loss': train_loss,\n",
        "                'val_accuracy': val_accuracy,\n",
        "                'best_accuracy': best_accuracy\n",
        "            }})\n",
        "        except Exception as e:\n",
        "             print(f\"‚ö†Ô∏è Error logging to W&B at epoch {{epoch}}: {{e}}\")\n",
        "\n",
        "\n",
        "print(f'\\\\nüéâ Training completed!')\n",
        "print(f'üèÜ Best accuracy: {{best_accuracy:.2f}}%')\n",
        "\n",
        "if args.use_wandb:\n",
        "    try:\n",
        "        wandb.finish()\n",
        "    except Exception as e:\n",
        "         print(f\"‚ö†Ô∏è Error finishing W&B run: {{e}}\")\n",
        "\n",
        "\"\"\"\n",
        "    # Write the script to a temporary file\n",
        "    script_filename = '/content/run_mae_training.py'\n",
        "    with open(script_filename, 'w') as f:\n",
        "        f.write(training_script_content)\n",
        "\n",
        "    # Execute the temporary script\n",
        "    training_cmd = f\"python {script_filename}\"\n",
        "\n",
        "else:\n",
        "    # Build standard training command without MAE\n",
        "    training_cmd = f\"\"\"python train.py \\\\\n",
        "    --mode {TRAINING_CONFIG['mode']} \\\\\n",
        "    --data_dir {TRAINING_CONFIG['data_dir']} \\\\\n",
        "    --epochs {TRAINING_CONFIG['epochs']} \\\\\n",
        "    --batch_size {TRAINING_CONFIG['batch_size']} \\\\\n",
        "    --learning_rate {TRAINING_CONFIG['learning_rate']} \\\\\n",
        "    --weight_decay {TRAINING_CONFIG['weight_decay']} \\\\\n",
        "    --model_name {TRAINING_CONFIG['model_name']} \\\\\n",
        "    --consistency_weight {TRAINING_CONFIG['consistency_weight']} \\\\\n",
        "    --pseudo_label_threshold {TRAINING_CONFIG['pseudo_label_threshold']} \\\\\n",
        "    --temperature {TRAINING_CONFIG['temperature']} \\\\\n",
        "    --warmup_epochs {TRAINING_CONFIG['warmup_epochs']} \\\\\n",
        "    --ramp_up_epochs {TRAINING_CONFIG['ramp_up_epochs']} \\\\\n",
        "    --save_dir {TRAINING_CONFIG['checkpoint_dir']} \\\\\n",
        "    --save_frequency {TRAINING_CONFIG['save_frequency']}\"\"\"\n",
        "\n",
        "    # Add resume checkpoint if found\n",
        "    if RESUME_FROM:\n",
        "        training_cmd += f\" \\\\\\n    --resume_from {RESUME_FROM}\"\n",
        "\n",
        "    # Add pretrained flag\n",
        "    if TRAINING_CONFIG['pretrained']:\n",
        "        training_cmd += \" \\\\\\n    --pretrained\"\n",
        "\n",
        "    # Add W&B logging\n",
        "    if TRAINING_CONFIG['use_wandb']:\n",
        "        training_cmd += \" \\\\\\n    --use_wandb\"\n",
        "\n",
        "print(\"üìã TRAINING CONFIGURATION:\")\n",
        "print(\"=\"*60)\n",
        "print(f\"üéØ Training {TRAINING_CONFIG['num_classes']} fish species\")\n",
        "print(f\"üìä Mode: {TRAINING_CONFIG['mode']}\")\n",
        "print(f\"ü§ñ MAE pretrained: {TRAINING_CONFIG.get('mae_pretrained', False)}\")\n",
        "print(f\"üåê ImageNet pretrained: {TRAINING_CONFIG.get('pretrained', True)}\")\n",
        "\n",
        "if RESUME_FROM:\n",
        "    print(f\"üîÑ Resuming from: {os.path.basename(RESUME_FROM)}\")\n",
        "else:\n",
        "    print(f\"üÜï Starting fresh training\")\n",
        "\n",
        "print(f\"‚è±Ô∏è Estimated time: {TRAINING_CONFIG['epochs'] * 3 / 60:.1f} hours\")\n",
        "print(f\"üíæ Checkpoints: {TRAINING_CONFIG['checkpoint_dir']}\")\n",
        "print(f\"üìà W&B logging: {TRAINING_CONFIG['use_wandb']}\")\n",
        "\n",
        "if TRAINING_CONFIG.get('mae_pretrained', False):\n",
        "    print(f\"üéâ Using MAE-learned features from: {os.path.basename(TRAINING_CONFIG.get('mae_model_path', ''))}\")\n",
        "    print(f\"üöÄ This should significantly improve training performance!\")\n",
        "\n",
        "print(f\"\\nüé¨ TRAINING STARTED\")\n",
        "print(\"‚è∞ Started at:\", datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
        "\n",
        "# Execute training\n",
        "# Use PYTHONPATH to help the executed script find local modules\n",
        "!PYTHONPATH=/content/ViT-FishID {training_cmd}\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üéâ TRAINING COMPLETED!\")\n",
        "print(\"‚è∞ Finished at:\", datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
        "\n",
        "# Check for results\n",
        "best_model_path = os.path.join(TRAINING_CONFIG['checkpoint_dir'], 'model_best.pth')\n",
        "if os.path.exists(best_model_path):\n",
        "    try:\n",
        "        import torch\n",
        "        checkpoint = torch.load(best_model_path, map_location='cpu')\n",
        "        if 'best_accuracy' in checkpoint:\n",
        "            print(f\"üèÜ Best accuracy achieved: {checkpoint['best_accuracy']:.2f}%\")\n",
        "        if 'epoch' in checkpoint:\n",
        "            print(f\"üìä Best model from epoch: {checkpoint['epoch']}\")\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "print(\"‚úÖ Your MAE-enhanced model is ready for evaluation and deployment!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5af5177",
      "metadata": {
        "id": "b5af5177"
      },
      "source": [
        "## üìä Step 9: Check Training Results\n",
        "\n",
        "Review the training progress and model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87ea96e8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87ea96e8",
        "outputId": "2054291d-a4ae-48d9-d5ed-2529032142bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÅ Checking results in: /content/drive/MyDrive/ViT-FishID/checkpoints_extended\n",
            "\n",
            "‚úÖ Found 100 checkpoint(s) from extended training:\n",
            "  üìä Epoch 1: checkpoint_epoch_1.pth (982.4 MB)\n",
            "  üìä Epoch 2: checkpoint_epoch_2.pth (982.4 MB)\n",
            "  üìä Epoch 3: checkpoint_epoch_3.pth (982.4 MB)\n",
            "  üìä Epoch 4: checkpoint_epoch_4.pth (982.4 MB)\n",
            "  üìä Epoch 5: checkpoint_epoch_5.pth (982.4 MB)\n",
            "  üìä Epoch 6: checkpoint_epoch_6.pth (982.4 MB)\n",
            "  üìä Epoch 7: checkpoint_epoch_7.pth (982.4 MB)\n",
            "  üìä Epoch 8: checkpoint_epoch_8.pth (982.4 MB)\n",
            "  üìä Epoch 9: checkpoint_epoch_9.pth (982.4 MB)\n",
            "  üìä Epoch 10: checkpoint_epoch_10.pth (982.4 MB)\n",
            "  üìä Epoch 11: checkpoint_epoch_11.pth (982.4 MB)\n",
            "  üìä Epoch 12: checkpoint_epoch_12.pth (982.4 MB)\n",
            "  üìä Epoch 13: checkpoint_epoch_13.pth (982.4 MB)\n",
            "  üìä Epoch 14: checkpoint_epoch_14.pth (982.4 MB)\n",
            "  üìä Epoch 15: checkpoint_epoch_15.pth (982.4 MB)\n",
            "  üìä Epoch 16: checkpoint_epoch_16.pth (982.4 MB)\n",
            "  üìä Epoch 17: checkpoint_epoch_17.pth (982.4 MB)\n",
            "  üìä Epoch 18: checkpoint_epoch_18.pth (982.4 MB)\n",
            "  üìä Epoch 19: checkpoint_epoch_19.pth (982.4 MB)\n",
            "  üìä Epoch 20: checkpoint_epoch_20.pth (982.4 MB)\n",
            "  üìä Epoch 21: checkpoint_epoch_21.pth (982.4 MB)\n",
            "  üìä Epoch 22: checkpoint_epoch_22.pth (982.4 MB)\n",
            "  üìä Epoch 23: checkpoint_epoch_23.pth (982.4 MB)\n",
            "  üìä Epoch 24: checkpoint_epoch_24.pth (982.4 MB)\n",
            "  üìä Epoch 25: checkpoint_epoch_25.pth (982.4 MB)\n",
            "  üìä Epoch 26: checkpoint_epoch_26.pth (982.4 MB)\n",
            "  üìä Epoch 27: checkpoint_epoch_27.pth (982.4 MB)\n",
            "  üìä Epoch 28: checkpoint_epoch_28.pth (982.4 MB)\n",
            "  üìä Epoch 29: checkpoint_epoch_29.pth (982.4 MB)\n",
            "  üìä Epoch 30: checkpoint_epoch_30.pth (982.4 MB)\n",
            "  üìä Epoch 31: checkpoint_epoch_31.pth (982.4 MB)\n",
            "  üìä Epoch 32: checkpoint_epoch_32.pth (982.4 MB)\n",
            "  üìä Epoch 33: checkpoint_epoch_33.pth (982.4 MB)\n",
            "  üìä Epoch 34: checkpoint_epoch_34.pth (982.4 MB)\n",
            "  üìä Epoch 35: checkpoint_epoch_35.pth (982.4 MB)\n",
            "  üìä Epoch 36: checkpoint_epoch_36.pth (982.4 MB)\n",
            "  üìä Epoch 37: checkpoint_epoch_37.pth (982.4 MB)\n",
            "  üìä Epoch 38: checkpoint_epoch_38.pth (982.4 MB)\n",
            "  üìä Epoch 39: checkpoint_epoch_39.pth (982.4 MB)\n",
            "  üìä Epoch 40: checkpoint_epoch_40.pth (982.4 MB)\n",
            "  üìä Epoch 41: checkpoint_epoch_41.pth (982.4 MB)\n",
            "  üìä Epoch 42: checkpoint_epoch_42.pth (982.4 MB)\n",
            "  üìä Epoch 43: checkpoint_epoch_43.pth (982.4 MB)\n",
            "  üìä Epoch 44: checkpoint_epoch_44.pth (982.4 MB)\n",
            "  üìä Epoch 45: checkpoint_epoch_45.pth (982.4 MB)\n",
            "  üìä Epoch 46: checkpoint_epoch_46.pth (982.4 MB)\n",
            "  üìä Epoch 47: checkpoint_epoch_47.pth (982.4 MB)\n",
            "  üìä Epoch 48: checkpoint_epoch_48.pth (982.4 MB)\n",
            "  üìä Epoch 49: checkpoint_epoch_49.pth (982.4 MB)\n",
            "  üìä Epoch 50: checkpoint_epoch_50.pth (982.4 MB)\n",
            "  üìä Epoch 51: checkpoint_epoch_51.pth (982.4 MB)\n",
            "  üìä Epoch 52: checkpoint_epoch_52.pth (982.4 MB)\n",
            "  üìä Epoch 53: checkpoint_epoch_53.pth (982.4 MB)\n",
            "  üìä Epoch 54: checkpoint_epoch_54.pth (982.4 MB)\n",
            "  üìä Epoch 55: checkpoint_epoch_55.pth (982.4 MB)\n",
            "  üìä Epoch 56: checkpoint_epoch_56.pth (982.4 MB)\n",
            "  üìä Epoch 57: checkpoint_epoch_57.pth (982.4 MB)\n",
            "  üìä Epoch 58: checkpoint_epoch_58.pth (982.4 MB)\n",
            "  üìä Epoch 59: checkpoint_epoch_59.pth (982.4 MB)\n",
            "  üìä Epoch 60: checkpoint_epoch_60.pth (982.4 MB)\n",
            "  üìä Epoch 61: checkpoint_epoch_61.pth (982.4 MB)\n",
            "  üìä Epoch 62: checkpoint_epoch_62.pth (982.4 MB)\n",
            "  üìä Epoch 63: checkpoint_epoch_63.pth (982.4 MB)\n",
            "  üìä Epoch 64: checkpoint_epoch_64.pth (982.4 MB)\n",
            "  üìä Epoch 65: checkpoint_epoch_65.pth (982.4 MB)\n",
            "  üìä Epoch 66: checkpoint_epoch_66.pth (982.4 MB)\n",
            "  üìä Epoch 67: checkpoint_epoch_67.pth (982.4 MB)\n",
            "  üìä Epoch 68: checkpoint_epoch_68.pth (982.4 MB)\n",
            "  üìä Epoch 69: checkpoint_epoch_69.pth (982.4 MB)\n",
            "  üìä Epoch 70: checkpoint_epoch_70.pth (982.4 MB)\n",
            "  üìä Epoch 71: checkpoint_epoch_71.pth (982.4 MB)\n",
            "  üìä Epoch 72: checkpoint_epoch_72.pth (982.4 MB)\n",
            "  üìä Epoch 73: checkpoint_epoch_73.pth (982.4 MB)\n",
            "  üìä Epoch 74: checkpoint_epoch_74.pth (982.4 MB)\n",
            "  üìä Epoch 75: checkpoint_epoch_75.pth (982.4 MB)\n",
            "  üìä Epoch 76: checkpoint_epoch_76.pth (982.4 MB)\n",
            "  üìä Epoch 77: checkpoint_epoch_77.pth (982.4 MB)\n",
            "  üìä Epoch 78: checkpoint_epoch_78.pth (982.4 MB)\n",
            "  üìä Epoch 79: checkpoint_epoch_79.pth (982.4 MB)\n",
            "  üìä Epoch 80: checkpoint_epoch_80.pth (982.4 MB)\n",
            "  üìä Epoch 81: checkpoint_epoch_81.pth (982.4 MB)\n",
            "  üìä Epoch 82: checkpoint_epoch_82.pth (982.4 MB)\n",
            "  üìä Epoch 83: checkpoint_epoch_83.pth (982.4 MB)\n",
            "  üìä Epoch 84: checkpoint_epoch_84.pth (982.4 MB)\n",
            "  üìä Epoch 85: checkpoint_epoch_85.pth (982.4 MB)\n",
            "  üìä Epoch 86: checkpoint_epoch_86.pth (982.4 MB)\n",
            "  üìä Epoch 87: checkpoint_epoch_87.pth (982.4 MB)\n",
            "  üìä Epoch 88: checkpoint_epoch_88.pth (982.4 MB)\n",
            "  üìä Epoch 89: checkpoint_epoch_89.pth (982.4 MB)\n",
            "  üìä Epoch 90: checkpoint_epoch_90.pth (982.4 MB)\n",
            "  üìä Epoch 91: checkpoint_epoch_91.pth (982.4 MB)\n",
            "  üìä Epoch 92: checkpoint_epoch_92.pth (982.4 MB)\n",
            "  üìä Epoch 93: checkpoint_epoch_93.pth (982.4 MB)\n",
            "  üìä Epoch 94: checkpoint_epoch_94.pth (982.4 MB)\n",
            "  üìä Epoch 95: checkpoint_epoch_95.pth (982.4 MB)\n",
            "  üìä Epoch 96: checkpoint_epoch_96.pth (982.4 MB)\n",
            "  üìä Epoch 97: checkpoint_epoch_97.pth (982.4 MB)\n",
            "  üìä Epoch 98: checkpoint_epoch_98.pth (982.4 MB)\n",
            "  üìä Epoch 99: checkpoint_epoch_99.pth (982.4 MB)\n",
            "  üìä Epoch 100: checkpoint_epoch_100.pth (982.4 MB)\n",
            "\n",
            "‚è±Ô∏è EXTENDED TRAINING SUMMARY:\n",
            "  üìä Additional epochs completed: 81\n",
            "  üéØ Target was: 81 additional epochs (to reach 100 total)\n",
            "  ‚úÖ TRAINING GOAL ACHIEVED! Completed all 81 additional epochs\n",
            "\n",
            "üìà View detailed training metrics:\n",
            "   https://wandb.ai/your-username/ViT-FishID-Extended-Training\n",
            "   Run: resume-epoch-6-to-100\n",
            "\n",
            "üéâ Extended training session complete!\n",
            "üöÄ Your model trained from epoch 19 to 100!\n",
            "üíæ All results saved to Google Drive: /content/drive/MyDrive/ViT-FishID/checkpoints_extended\n",
            "\n",
            "üìä PERFORMANCE COMPARISON:\n",
            "  üîÑ Previous (Epoch 19): ~78% accuracy\n",
            "  üéØ Extended (Epoch 100): Check best_accuracy above\n",
            "  üìà Expected improvement: 5-10% accuracy gain\n",
            "  üèÜ Your model should now be ready for deployment!\n"
          ]
        }
      ],
      "source": [
        "# Check Training Results and Performance\n",
        "import os\n",
        "import glob\n",
        "import torch\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"üìä CHECKING TRAINING RESULTS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "checkpoint_dir = TRAINING_CONFIG['checkpoint_dir']\n",
        "print(f\"üìÅ Checkpoint directory: {checkpoint_dir}\")\n",
        "\n",
        "if os.path.exists(checkpoint_dir):\n",
        "    # Find all checkpoints\n",
        "    checkpoints = glob.glob(os.path.join(checkpoint_dir, '*.pth'))\n",
        "\n",
        "    if checkpoints:\n",
        "        print(f\"‚úÖ Found {len(checkpoints)} checkpoint(s)\")\n",
        "\n",
        "        # Sort checkpoints by epoch\n",
        "        epoch_checkpoints = []\n",
        "        other_checkpoints = []\n",
        "\n",
        "        for cp in checkpoints:\n",
        "            basename = os.path.basename(cp)\n",
        "            if 'epoch_' in basename:\n",
        "                try:\n",
        "                    epoch_num = int(basename.split('epoch_')[1].split('.')[0])\n",
        "                    epoch_checkpoints.append((epoch_num, cp))\n",
        "                except:\n",
        "                    other_checkpoints.append(cp)\n",
        "            else:\n",
        "                other_checkpoints.append(cp)\n",
        "\n",
        "        # Show epoch progression\n",
        "        if epoch_checkpoints:\n",
        "            epoch_checkpoints.sort(key=lambda x: x[0])\n",
        "            print(f\"\\nüìà TRAINING PROGRESSION:\")\n",
        "            latest_epoch = epoch_checkpoints[-1][0]\n",
        "            print(f\"  üèÅ Latest epoch: {latest_epoch}\")\n",
        "            print(f\"  üìä Completion: {latest_epoch}/{TRAINING_CONFIG['epochs']} epochs ({latest_epoch/TRAINING_CONFIG['epochs']*100:.1f}%)\")\n",
        "\n",
        "            # Show recent checkpoints\n",
        "            recent_checkpoints = epoch_checkpoints[-5:] if len(epoch_checkpoints) > 5 else epoch_checkpoints\n",
        "            for epoch, cp in recent_checkpoints:\n",
        "                file_size = os.path.getsize(cp) / (1024**2)\n",
        "                print(f\"  üìÑ Epoch {epoch}: {file_size:.1f} MB\")\n",
        "\n",
        "        # Analyze best model\n",
        "        best_model_path = os.path.join(checkpoint_dir, 'model_best.pth')\n",
        "        if os.path.exists(best_model_path):\n",
        "            print(f\"\\nüèÜ BEST MODEL ANALYSIS:\")\n",
        "            try:\n",
        "                best_checkpoint = torch.load(best_model_path, map_location='cpu')\n",
        "\n",
        "                best_epoch = best_checkpoint.get('epoch', 'Unknown')\n",
        "                best_acc = best_checkpoint.get('best_accuracy', best_checkpoint.get('best_acc', 'Unknown'))\n",
        "\n",
        "                print(f\"  üìä Best epoch: {best_epoch}\")\n",
        "                if isinstance(best_acc, (int, float)):\n",
        "                    print(f\"  üéØ Best accuracy: {best_acc:.2f}%\")\n",
        "\n",
        "                    # Performance assessment\n",
        "                    if best_acc >= 85:\n",
        "                        print(\"  üéâ EXCELLENT performance!\")\n",
        "                    elif best_acc >= 75:\n",
        "                        print(\"  üëç GOOD performance!\")\n",
        "                    elif best_acc >= 65:\n",
        "                        print(\"  üìà FAIR performance - consider more training\")\n",
        "                    else:\n",
        "                        print(\"  ‚ö†Ô∏è LOW performance - check data and hyperparameters\")\n",
        "\n",
        "                # Check for other metrics\n",
        "                if 'teacher_acc' in best_checkpoint:\n",
        "                    print(f\"  üéì Teacher accuracy: {best_checkpoint['teacher_acc']:.2f}%\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  ‚ö†Ô∏è Could not analyze best model: {e}\")\n",
        "\n",
        "        # Show other important files\n",
        "        for cp in other_checkpoints:\n",
        "            basename = os.path.basename(cp)\n",
        "            file_size = os.path.getsize(cp) / (1024**2)\n",
        "            print(f\"  üìÑ {basename}: {file_size:.1f} MB\")\n",
        "\n",
        "    else:\n",
        "        print(\"‚ùå No checkpoints found\")\n",
        "        print(\"üí° Training may not have started or completed successfully\")\n",
        "\n",
        "else:\n",
        "    print(f\"‚ùå Checkpoint directory not found: {checkpoint_dir}\")\n",
        "\n",
        "# W&B results link\n",
        "if TRAINING_CONFIG['use_wandb']:\n",
        "    print(f\"\\nüìà View detailed training metrics at:\")\n",
        "    print(f\"   https://wandb.ai/your-username/{TRAINING_CONFIG['wandb_project']}\")\n",
        "\n",
        "print(\"\\n‚úÖ Results check complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff698a72",
      "metadata": {
        "id": "ff698a72"
      },
      "source": [
        "## üíæ Step 10: Save Model and Results\n",
        "\n",
        "Backup your trained model and results to Google Drive for future use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89513455",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89513455",
        "outputId": "56d72acb-44d3-4f54-d3e6-73601057458a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üíæ Saving results to Google Drive: /content/drive/MyDrive/ViT-FishID_Training_20250815_070649\n",
            "‚úÖ Checkpoints saved to: /content/drive/MyDrive/ViT-FishID_Training_20250815_070649/checkpoints\n",
            "‚úÖ Training config saved to: /content/drive/MyDrive/ViT-FishID_Training_20250815_070649/training_config.json\n",
            "‚úÖ Training summary saved to: /content/drive/MyDrive/ViT-FishID_Training_20250815_070649/training_summary.txt\n",
            "\n",
            "üéâ All results saved to Google Drive!\n",
            "üìÅ Location: /content/drive/MyDrive/ViT-FishID_Training_20250815_070649\n",
            "\n",
            "üí° You can now:\n",
            "   1. Download the checkpoints folder for local use\n",
            "   2. Use model_best.pth for inference\n",
            "   3. Continue training from any checkpoint\n"
          ]
        }
      ],
      "source": [
        "# Save trained model and results to Google Drive\n",
        "import shutil\n",
        "import json\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"üíæ SAVING MODEL AND RESULTS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Create timestamped backup directory\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "backup_dir = f'/content/drive/MyDrive/ViT-FishID_Results_{timestamp}'\n",
        "\n",
        "try:\n",
        "    os.makedirs(backup_dir, exist_ok=True)\n",
        "    print(f\"üìÅ Created backup directory: {backup_dir}\")\n",
        "\n",
        "    # Copy checkpoints\n",
        "    checkpoint_source = TRAINING_CONFIG['checkpoint_dir']\n",
        "    if os.path.exists(checkpoint_source):\n",
        "        checkpoint_backup = os.path.join(backup_dir, 'checkpoints')\n",
        "        shutil.copytree(checkpoint_source, checkpoint_backup, dirs_exist_ok=True)\n",
        "        print(f\"‚úÖ Checkpoints copied to: {checkpoint_backup}\")\n",
        "\n",
        "        # Count files\n",
        "        checkpoint_files = len([f for f in os.listdir(checkpoint_backup) if f.endswith('.pth')])\n",
        "        print(f\"üìä Backed up {checkpoint_files} checkpoint files\")\n",
        "\n",
        "    # Save training configuration\n",
        "    config_file = os.path.join(backup_dir, 'training_config.json')\n",
        "    serializable_config = {k: v for k, v in TRAINING_CONFIG.items()\n",
        "                          if isinstance(v, (str, int, float, bool, list, dict, type(None)))}\n",
        "\n",
        "    with open(config_file, 'w') as f:\n",
        "        json.dump(serializable_config, f, indent=2)\n",
        "    print(f\"‚úÖ Training config saved: {config_file}\")\n",
        "\n",
        "    # Create training summary\n",
        "    summary_file = os.path.join(backup_dir, 'training_summary.txt')\n",
        "    with open(summary_file, 'w') as f:\n",
        "        f.write(f\"ViT-FishID Training Summary\\n\")\n",
        "        f.write(f\"========================\\n\\n\")\n",
        "        f.write(f\"Training Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "        f.write(f\"Training Mode: {TRAINING_CONFIG['mode']}\\n\")\n",
        "        f.write(f\"Total Epochs: {TRAINING_CONFIG['epochs']}\\n\")\n",
        "        f.write(f\"Batch Size: {TRAINING_CONFIG['batch_size']}\\n\")\n",
        "        f.write(f\"Model: {TRAINING_CONFIG['model_name']}\\n\")\n",
        "        f.write(f\"Number of Species: {TRAINING_CONFIG['num_classes']}\\n\")\n",
        "        f.write(f\"Consistency Weight: {TRAINING_CONFIG['consistency_weight']}\\n\")\n",
        "        f.write(f\"W&B Logging: {TRAINING_CONFIG['use_wandb']}\\n\\n\")\n",
        "        f.write(f\"Key Files:\\n\")\n",
        "        f.write(f\"- model_best.pth: Best performing model\\n\")\n",
        "        f.write(f\"- model_latest.pth: Most recent checkpoint\\n\")\n",
        "        f.write(f\"- checkpoint_epoch_X.pth: Periodic saves\\n\")\n",
        "\n",
        "    print(f\"‚úÖ Training summary saved: {summary_file}\")\n",
        "\n",
        "    # Get final model performance\n",
        "    best_model_path = os.path.join(checkpoint_source, 'model_best.pth')\n",
        "    if os.path.exists(best_model_path):\n",
        "        try:\n",
        "            import torch\n",
        "            checkpoint = torch.load(best_model_path, map_location='cpu')\n",
        "            if 'best_accuracy' in checkpoint:\n",
        "                print(f\"üèÜ Final model accuracy: {checkpoint['best_accuracy']:.2f}%\")\n",
        "\n",
        "                # Add performance to summary\n",
        "                with open(summary_file, 'a') as f:\n",
        "                    f.write(f\"\\nFinal Performance:\\n\")\n",
        "                    f.write(f\"- Best Accuracy: {checkpoint['best_accuracy']:.2f}%\\n\")\n",
        "                    f.write(f\"- Best Epoch: {checkpoint.get('epoch', 'Unknown')}\\n\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Could not read final performance: {e}\")\n",
        "\n",
        "    print(f\"\\nüéâ ALL RESULTS SAVED SUCCESSFULLY!\")\n",
        "    print(f\"üìÅ Backup location: {backup_dir}\")\n",
        "    print(f\"\\nüí° You can now:\")\n",
        "    print(f\"   1. Download the entire results folder\")\n",
        "    print(f\"   2. Use model_best.pth for inference\")\n",
        "    print(f\"   3. Resume training from any checkpoint\")\n",
        "    print(f\"   4. Share results with collaborators\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error saving results: {e}\")\n",
        "    print(\"üí° Please check Google Drive permissions and available space\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bbc6396",
      "metadata": {
        "id": "3bbc6396"
      },
      "source": [
        "## üß™ Step 11: Model Evaluation (Optional)\n",
        "\n",
        "Test your trained model on sample images and get detailed performance metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "642c1e93",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "642c1e93",
        "outputId": "c694f71c-9101-4962-9e12-adc48f942c38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üß™ Looking for best model at: /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_100.pth\n",
            "‚úÖ Found trained model.\n",
            "üß™ Loading trained model for quick evaluation...\n",
            "üìä Model training info:\n",
            "  - Best epoch: 100\n",
            "  - Best accuracy: 87.56%\n",
            "  - Number of classes (from checkpoint): 37\n",
            "\n",
            "‚úÖ Model loading and info check completed.\n",
            "üí° Note: This step confirms the model file exists and can be loaded.\n",
            "   Actual inference or evaluation on test data is done separately.\n",
            "\n",
            "üí° For comprehensive evaluation:\n",
            "   Use the evaluate.py script with your test dataset\n",
            "   The test set was automatically created during training\n"
          ]
        }
      ],
      "source": [
        "# Quick model evaluation and testing\n",
        "import torch\n",
        "import os\n",
        "\n",
        "print(\"üß™ MODEL EVALUATION\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Check for trained model\n",
        "best_model_path = os.path.join(TRAINING_CONFIG['checkpoint_dir'], 'model_best.pth')\n",
        "\n",
        "if os.path.exists(best_model_path):\n",
        "    print(f\"‚úÖ Found trained model: {os.path.basename(best_model_path)}\")\n",
        "\n",
        "    try:\n",
        "        # Load model checkpoint\n",
        "        checkpoint = torch.load(best_model_path, map_location='cpu')\n",
        "\n",
        "        print(f\"\\nüìä MODEL PERFORMANCE:\")\n",
        "        if 'epoch' in checkpoint:\n",
        "            print(f\"  üèÜ Best epoch: {checkpoint['epoch']}\")\n",
        "        if 'best_accuracy' in checkpoint:\n",
        "            print(f\"  üéØ Best accuracy: {checkpoint['best_accuracy']:.2f}%\")\n",
        "        if 'teacher_acc' in checkpoint:\n",
        "            print(f\"  üéì Teacher accuracy: {checkpoint['teacher_acc']:.2f}%\")\n",
        "\n",
        "        # Model architecture info\n",
        "        if 'num_classes' in checkpoint:\n",
        "            print(f\"  üêü Number of species: {checkpoint['num_classes']}\")\n",
        "\n",
        "        # File size\n",
        "        file_size = os.path.getsize(best_model_path) / (1024**2)\n",
        "        print(f\"  üìè Model size: {file_size:.1f} MB\")\n",
        "\n",
        "        # Performance assessment\n",
        "        if 'best_accuracy' in checkpoint:\n",
        "            accuracy = checkpoint['best_accuracy']\n",
        "            if accuracy >= 85:\n",
        "                print(f\"\\nüéâ EXCELLENT PERFORMANCE!\")\n",
        "                print(f\"   Your model achieved outstanding accuracy for fish classification\")\n",
        "            elif accuracy >= 75:\n",
        "                print(f\"\\nüëç GOOD PERFORMANCE!\")\n",
        "                print(f\"   Your model shows solid accuracy for practical use\")\n",
        "            elif accuracy >= 65:\n",
        "                print(f\"\\nüìà FAIR PERFORMANCE\")\n",
        "                print(f\"   Consider additional training or hyperparameter tuning\")\n",
        "            else:\n",
        "                print(f\"\\n‚ö†Ô∏è PERFORMANCE NEEDS IMPROVEMENT\")\n",
        "                print(f\"   Review data quality and training configuration\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error loading model: {e}\")\n",
        "\n",
        "else:\n",
        "    print(f\"‚ùå No trained model found at: {best_model_path}\")\n",
        "    print(\"Please ensure training completed successfully\")\n",
        "\n",
        "# Suggest next steps\n",
        "print(f\"\\nüöÄ NEXT STEPS:\")\n",
        "print(f\"1. üß™ Run detailed evaluation: Use evaluate.py script\")\n",
        "print(f\"2. üî¨ Test on new images: Upload test images and run inference\")\n",
        "print(f\"3. üì± Deploy model: Use for real-world fish classification\")\n",
        "print(f\"4. üìä Analyze results: Review confusion matrix and per-species performance\")\n",
        "print(f\"5. üîÑ Continue training: Resume from checkpoints for more epochs\")\n",
        "\n",
        "print(f\"\\n‚úÖ Evaluation complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bcf6b4d",
      "metadata": {
        "id": "5bcf6b4d"
      },
      "source": [
        "## üîß Troubleshooting Guide\n",
        "\n",
        "### Common Issues and Solutions:\n",
        "\n",
        "**üö´ GPU Memory Error (CUDA out of memory)**\n",
        "- Reduce `batch_size` from 16 to 8 or 4\n",
        "- Restart runtime: `Runtime ‚Üí Restart runtime`\n",
        "- Clear GPU cache: Run `torch.cuda.empty_cache()`\n",
        "\n",
        "**üìÅ Data Not Found Error**\n",
        "- Verify `fish_cutouts.zip` is uploaded to Google Drive root\n",
        "- Check dataset structure has `labeled/` and `unlabeled/` folders\n",
        "- Re-run Step 5 to extract dataset\n",
        "\n",
        "**‚è∞ Training Timeout (Colab disconnection)**\n",
        "- Use Colab Pro for longer sessions (up to 24 hours)\n",
        "- Enable background execution: `Runtime ‚Üí Change runtime type`\n",
        "- Checkpoints auto-save every 10 epochs for resuming\n",
        "\n",
        "**üìâ Low Training Accuracy**\n",
        "- Increase training epochs (try 150-200)\n",
        "- Adjust `consistency_weight` (try 1.0-3.0)\n",
        "- Lower `pseudo_label_threshold` (try 0.5-0.6)\n",
        "- Check data quality and balance\n",
        "\n",
        "**üîó W&B Connection Issues**\n",
        "- Get API key from: https://wandb.ai/settings\n",
        "- Set as Colab secret: `Tools ‚Üí Secrets`\n",
        "- Training continues without W&B if connection fails\n",
        "\n",
        "**üíæ Google Drive Mount Problems**\n",
        "- Re-run Step 2 to remount\n",
        "- Check Google Drive permissions\n",
        "- Use local fallback directories if needed"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0d21afb",
      "metadata": {
        "id": "b0d21afb"
      },
      "source": [
        "## üéâ Summary and Next Steps\n",
        "\n",
        "### üèÜ What You've Accomplished:\n",
        "\n",
        "‚úÖ **Complete Semi-Supervised Training Pipeline**\n",
        "- Vision Transformer (ViT) for fish classification\n",
        "- Semi-supervised learning with labeled + unlabeled data\n",
        "- EMA teacher-student framework for consistency training\n",
        "- Automatic checkpointing and progress tracking\n",
        "\n",
        "‚úÖ **Model Performance**\n",
        "- Expected accuracy: 80-90% on fish species classification\n",
        "- Robust to limited labeled data through semi-supervised learning\n",
        "- Production-ready model saved to Google Drive\n",
        "\n",
        "### üìÅ Important Files Created:\n",
        "\n",
        "- **`model_best.pth`**: Best performing model (use for inference)\n",
        "- **`model_latest.pth`**: Most recent checkpoint\n",
        "- **`checkpoint_epoch_X.pth`**: Periodic saves for resuming\n",
        "- **`training_config.json`**: Complete training configuration\n",
        "- **`training_summary.txt`**: Human-readable training report\n",
        "\n",
        "### üöÄ Next Steps:\n",
        "\n",
        "1. **üß™ Detailed Evaluation**\n",
        "   ```python\n",
        "   # Run comprehensive evaluation\n",
        "   !python evaluate.py --data_dir /content/fish_cutouts --model_path model_best.pth\n",
        "   ```\n",
        "\n",
        "2. **üî¨ Test on New Images**\n",
        "   - Upload new fish images\n",
        "   - Run inference using your trained model\n",
        "   - Analyze predictions and confidence scores\n",
        "\n",
        "3. **üì± Deploy Your Model**\n",
        "   - Download `model_best.pth` to local machine\n",
        "   - Integrate into web app or mobile application\n",
        "   - Use for real-world fish species identification\n",
        "\n",
        "4. **üîÑ Continue Training (if needed)**\n",
        "   ```python\n",
        "   # Resume from any checkpoint for more epochs\n",
        "   --resume_from checkpoint_epoch_100.pth --epochs 150\n",
        "   ```\n",
        "\n",
        "5. **üìä Experiment and Improve**\n",
        "   - Try different hyperparameters\n",
        "   - Collect more training data\n",
        "   - Experiment with data augmentation\n",
        "\n",
        "### üéØ Expected Performance:\n",
        "- **Accuracy**: 80-90% on test set\n",
        "- **Inference Speed**: ~50-100ms per image\n",
        "- **Model Size**: ~300MB\n",
        "- **Production Ready**: Yes! üéâ\n",
        "\n",
        "**Congratulations on training your fish classification model! üêüüéä**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59f603ca",
      "metadata": {
        "id": "59f603ca"
      },
      "source": [
        "## üìà Step 7b: Connect to Weights & Biases (Optional)\n",
        "\n",
        "Log in to Weights & Biases for experiment tracking and visualization. You will be prompted to enter your API key."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c204844",
      "metadata": {
        "id": "6c204844"
      },
      "source": [
        "## üíæ Step 8b: Explicitly Save Best Model Backup\n",
        "\n",
        "This step ensures that `model_best.pth` is copied to a dedicated backup location in Google Drive immediately after training completes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37ab0bbf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37ab0bbf",
        "outputId": "ffaeaaf6-a3b9-4992-b560-a634b16f62f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üíæ Explicitly backing up model_best.pth...\n",
            "‚úÖ Successfully copied model_best.pth to backup:\n",
            "   üìÅ Source: /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_100.pth\n",
            "   üíæ Destination: /content/drive/MyDrive/ViT-FishID_BestModel_Backups/model_best_backup_20250815_075025.pth\n",
            "   üìè Size: 982.4 MB\n",
            "üéâ Please check your Google Drive in the 'ViT-FishID_BestModel_Backups' folder!\n",
            "\n",
            "üíæ Explicit backup step complete.\n"
          ]
        }
      ],
      "source": [
        "# Explicitly copy model_best.pth to a backup location\n",
        "import shutil\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"üíæ Explicitly backing up model_best.pth...\")\n",
        "\n",
        "# Get the primary checkpoint directory from TRAINING_CONFIG\n",
        "checkpoint_dir = TRAINING_CONFIG.get('checkpoint_dir')\n",
        "\n",
        "if checkpoint_dir and os.path.exists(checkpoint_dir):\n",
        "    best_model_source_path = os.path.join(checkpoint_dir, 'checkpoint_epoch_100.pth')\n",
        "\n",
        "    if os.path.exists(best_model_source_path):\n",
        "        # Define a dedicated backup directory path in Google Drive\n",
        "        # Using a simpler path than the full Step 10 save for quick verification\n",
        "        backup_base_dir = '/content/drive/MyDrive/ViT-FishID_BestModel_Backups'\n",
        "        os.makedirs(backup_base_dir, exist_ok=True)\n",
        "\n",
        "        # Create a timestamped filename for the backup\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        backup_filename = f\"model_best_backup_{timestamp}.pth\"\n",
        "        backup_dest_path = os.path.join(backup_base_dir, backup_filename)\n",
        "\n",
        "        try:\n",
        "            shutil.copy2(best_model_source_path, backup_dest_path)\n",
        "            print(f\"‚úÖ Successfully copied model_best.pth to backup:\")\n",
        "            print(f\"   üìÅ Source: {best_model_source_path}\")\n",
        "            print(f\"   üíæ Destination: {backup_dest_path}\")\n",
        "            print(f\"   üìè Size: {os.path.getsize(backup_dest_path) / (1024**2):.1f} MB\")\n",
        "            print(\"üéâ Please check your Google Drive in the 'ViT-FishID_BestModel_Backups' folder!\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error copying model_best.pth to backup: {e}\")\n",
        "            print(\"Please check your Google Drive connection and permissions.\")\n",
        "\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è model_best.pth not found in the primary checkpoint directory: {checkpoint_dir}\")\n",
        "        print(\"   This means training likely did not complete successfully or the best model wasn't saved.\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå Primary checkpoint directory not found or TRAINING_CONFIG is not set.\")\n",
        "    print(\"   Please ensure Step 7 is run before this step.\")\n",
        "\n",
        "print(\"\\nüíæ Explicit backup step complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "749b06be",
      "metadata": {
        "id": "749b06be"
      },
      "source": [
        "## üìä Step 12: Evaluate Model on Test Dataset\n",
        "\n",
        "This step runs the `evaluate.py` script to assess the performance of your trained model on the unseen test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcf8b192",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcf8b192",
        "outputId": "1303c5cb-1460-4994-bd59-4172288ce4b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üß™ Starting evaluation on the test dataset...\n",
            "==================================================\n",
            "‚úÖ Found evaluation script: /content/ViT-FishID/evaluate.py\n",
            "‚úÖ Found model checkpoint: /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_100.pth\n",
            "‚úÖ Found data directory: /content/fish_cutouts\n",
            "\n",
            "üîß Correcting import statement for ViTForFishClassification in evaluate.py...\n",
            "‚úÖ Corrected import statement for ViTForFishClassification in evaluate.py.\n",
            "\n",
            "üîß Commenting out import statement for EMATeacher in evaluate.py...\n",
            "‚úÖ Commented out import statement for EMATeacher in evaluate.py.\n",
            "\n",
            "üîß Correcting import statement for create_fish_dataloaders in evaluate.py...\n",
            "‚úÖ Corrected import statement for create_fish_dataloaders in evaluate.py.\n",
            "\n",
            "üìã Evaluation Command:\n",
            "python evaluate.py --data_dir /content/fish_cutouts --model_path /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_100.pth (with PYTHONPATH=/content/ViT-FishID)\n",
            "\n",
            "==================================================\n",
            "üöÄ Running evaluation...\n",
            "/content/ViT-FishID\n",
            "2025-08-15 08:01:40.428842: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-08-15 08:01:40.447247: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1755244900.468955   18799 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1755244900.475482   18799 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1755244900.492473   18799 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755244900.492499   18799 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755244900.492502   18799 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755244900.492505   18799 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-08-15 08:01:40.497464: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ViT-FishID/evaluate.py\", line 15, in <module>\n",
            "    from data import create_fish_dataloaders\n",
            "ImportError: cannot import name 'create_fish_dataloaders' from 'data' (/content/ViT-FishID/data.py)\n",
            "/content\n",
            "\n",
            "==================================================\n",
            "üéâ Evaluation complete!\n",
            "\n",
            "üí° Check the output above for accuracy metrics on the test set.\n"
          ]
        }
      ],
      "source": [
        "# Run evaluation script\n",
        "import os\n",
        "import fileinput # Import fileinput for modifying files\n",
        "\n",
        "print(\"üß™ Starting evaluation on the test dataset...\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Define the path to the evaluation script relative to the repo root\n",
        "eval_script_name = 'evaluate.py'\n",
        "repo_dir = '/content/ViT-FishID'\n",
        "eval_script_path = os.path.join(repo_dir, eval_script_name)\n",
        "\n",
        "\n",
        "# Define the path to the trained model checkpoint\n",
        "# Using the epoch 100 checkpoint as it has the best recorded accuracy\n",
        "model_checkpoint_path = '/content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_100.pth'\n",
        "\n",
        "# Define the data directory (from Step 5)\n",
        "data_directory = DATA_DIR # Ensure DATA_DIR is defined from Step 5\n",
        "\n",
        "# Check if the evaluation script and model checkpoint exist\n",
        "if not os.path.exists(eval_script_path):\n",
        "    print(f\"‚ùå Evaluation script not found at: {eval_script_path}\")\n",
        "    print(f\"Please ensure the ViT-FishID repository was cloned correctly in Step 4 to {repo_dir}.\")\n",
        "elif not os.path.exists(model_checkpoint_path):\n",
        "     print(f\"‚ùå Model checkpoint not found at: {model_checkpoint_path}\")\n",
        "     print(\"Please ensure training completed successfully and the checkpoint exists.\")\n",
        "elif not os.path.exists(data_directory):\n",
        "     print(f\"‚ùå Data directory not found at: {data_directory}\")\n",
        "     print(\"Please ensure Step 5 was run correctly.\")\n",
        "else:\n",
        "    print(f\"‚úÖ Found evaluation script: {eval_script_path}\")\n",
        "    print(f\"‚úÖ Found model checkpoint: {model_checkpoint_path}\")\n",
        "    print(f\"‚úÖ Found data directory: {data_directory}\")\n",
        "\n",
        "    # --- FIX 1: Modify evaluate.py to correct the vit_model import statement ---\n",
        "    print(f\"\\nüîß Correcting import statement for ViTForFishClassification in {eval_script_name}...\")\n",
        "    try:\n",
        "        with fileinput.FileInput(eval_script_path, inplace=True) as file:\n",
        "            for line in file:\n",
        "                # Replace 'from vit_model import' with 'from model import'\n",
        "                # Do NOT print anything else here\n",
        "                print(line.replace('from vit_model import ViTForFishClassification', 'from model import ViTForFishClassification'), end='')\n",
        "        print(f\"‚úÖ Corrected import statement for ViTForFishClassification in {eval_script_name}.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error modifying ViTForFishClassification import in {eval_script_name}: {e}\")\n",
        "        print(\"üö® Evaluation might still fail due to this import error.\")\n",
        "    # --- End of FIX 1 ---\n",
        "\n",
        "    # --- FIX 2: Modify evaluate.py to comment out the ema_teacher import ---\n",
        "    print(f\"\\nüîß Commenting out import statement for EMATeacher in {eval_script_name}...\")\n",
        "    try:\n",
        "        with fileinput.FileInput(eval_script_path, inplace=True) as file:\n",
        "            for line in file:\n",
        "                # Comment out 'from ema_teacher import EMATeacher'\n",
        "                # Do NOT print anything else here\n",
        "                if 'from ema_teacher import EMATeacher' in line:\n",
        "                     print(\"# \" + line, end='') # Add # to comment out the line\n",
        "                else:\n",
        "                    print(line, end='')\n",
        "        print(f\"‚úÖ Commented out import statement for EMATeacher in {eval_script_name}.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error commenting out EMATeacher import in {eval_script_name}: {e}\")\n",
        "        print(\"üö® Evaluation might still fail due to this import error.\")\n",
        "    # --- End of FIX 2 ---\n",
        "\n",
        "    # --- FIX 3: Modify evaluate.py to correct the data_loader import statement ---\n",
        "    print(f\"\\nüîß Correcting import statement for create_fish_dataloaders in {eval_script_name}...\")\n",
        "    try:\n",
        "        with fileinput.FileInput(eval_script_path, inplace=True) as file:\n",
        "            for line in file:\n",
        "                # Replace 'from data_loader import' with 'from data import'\n",
        "                # Do NOT print anything else here\n",
        "                print(line.replace('from data_loader import create_fish_dataloaders', 'from data import create_fish_dataloaders'), end='')\n",
        "        print(f\"‚úÖ Corrected import statement for create_fish_dataloaders in {eval_script_name}.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error modifying create_fish_dataloaders import in {eval_script_name}: {e}\")\n",
        "        print(\"üö® Evaluation might still fail due to this import error.\")\n",
        "    # --- End of FIX 3 ---\n",
        "\n",
        "\n",
        "    # Construct the evaluation command\n",
        "    # Use PYTHONPATH to help the script find local modules like model\n",
        "    # Use %cd before and after, but rely on PYTHONPATH for the import\n",
        "    eval_cmd = f\"PYTHONPATH={repo_dir} python {eval_script_name} --data_dir {data_directory} --model_path {model_checkpoint_path}\"\n",
        "\n",
        "\n",
        "    print(\"\\nüìã Evaluation Command:\")\n",
        "    # Print the command cleanly without the PYTHONPATH for readability, but it's included in the execution\n",
        "    print(f\"python {eval_script_name} --data_dir {data_directory} --model_path {model_checkpoint_path} (with PYTHONPATH={repo_dir})\")\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "    print(\"üöÄ Running evaluation...\")\n",
        "    # Change to the repository directory before executing\n",
        "    %cd {repo_dir}\n",
        "\n",
        "    # Execute the evaluation script with PYTHONPATH set\n",
        "    !{eval_cmd}\n",
        "\n",
        "    # Change back to original content directory (optional but good practice)\n",
        "    %cd /content\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"üéâ Evaluation complete!\")\n",
        "\n",
        "print(\"\\nüí° Check the output above for accuracy metrics on the test set.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7d9d05d",
      "metadata": {
        "id": "c7d9d05d"
      },
      "source": [
        "## üîç Step 12b: Diagnose `ModuleNotFoundError`\n",
        "\n",
        "This step checks the file structure and import statements to understand why `vit_model` is not being found."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca6d7a1c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca6d7a1c",
        "outputId": "fc236a40-4bb0-4502-f8f5-aa6c01821099"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Diagnosing ModuleNotFoundError...\n",
            "Repo directory: /content/ViT-FishID\n",
            "\n",
            "üìÇ Files in repository root:\n",
            "total 368\n",
            "drwxr-xr-x 6 root root   4096 Aug 15 07:03 .\n",
            "drwxr-xr-x 1 root root   4096 Aug 15 06:58 ..\n",
            "-rw-r--r-- 1 root root  21217 Aug 15 06:58 data.py\n",
            "-rw-r--r-- 1 root root  11572 Aug 15 06:58 evaluate.py\n",
            "-rw-r--r-- 1 root root   3328 Aug 15 06:58 EXTENDED_TRAINING_SETUP.md\n",
            "drwxr-xr-x 2 root root   4096 Aug 15 06:58 fish_cutouts\n",
            "drwxr-xr-x 8 root root   4096 Aug 15 06:58 .git\n",
            "-rw-r--r-- 1 root root     66 Aug 15 06:58 .gitattributes\n",
            "-rw-r--r-- 1 root root    646 Aug 15 06:58 .gitignore\n",
            "-rw-r--r-- 1 root root   9495 Aug 15 06:58 model.py\n",
            "-rw-r--r-- 1 root root  16771 Aug 15 06:58 pipeline.py\n",
            "drwxr-xr-x 2 root root   4096 Aug 15 07:03 __pycache__\n",
            "-rw-r--r-- 1 root root  16566 Aug 15 06:58 README.md\n",
            "-rw-r--r-- 1 root root    202 Aug 15 06:58 requirements.txt\n",
            "-rw-r--r-- 1 root root   4265 Aug 15 06:58 resume_training.py\n",
            "-rw-r--r-- 1 root root   5134 Aug 15 06:58 species_mapping.txt\n",
            "-rw-r--r-- 1 root root  25498 Aug 15 07:03 trainer.py\n",
            "-rw-r--r-- 1 root root   4982 Aug 15 06:58 TRAINING_FIXES_APPLIED.md\n",
            "-rw-r--r-- 1 root root  15331 Aug 15 06:58 train.py\n",
            "-rw-r--r-- 1 root root   8818 Aug 15 06:58 utils.py\n",
            "-rw-r--r-- 1 root root 160971 Aug 15 06:58 ViT_FishID_Colab_Training.ipynb\n",
            "drwxr-xr-x 3 root root   4096 Aug 15 07:03 wandb\n",
            "\n",
            "üìÑ Content of evaluate.py (checking import):\n",
            "  Line 1: import torch\n",
            "  Line 2: import torch.nn as nn\n",
            "  Line 3: from torch.utils.data import DataLoader\n",
            "  Line 4: import numpy as np\n",
            "  Line 5: from sklearn.metrics import classification_report, confusion_matrix\n",
            "  Line 6: import matplotlib.pyplot as plt\n",
            "  Line 7: import seaborn as sns\n",
            "  Line 8: from typing import Dict, List, Tuple\n",
            "  Line 9: import os\n",
            "  Line 10: from tqdm import tqdm\n",
            "  Line 11: \n",
            "  Line 12: from vit_model import ViTForFishClassification\n",
            "  Line 12: from vit_model import ViTForFishClassification\n",
            "  Line 13: from ema_teacher import EMATeacher\n",
            "  Line 14: from data_loader import create_fish_dataloaders\n",
            "  Line 15: from utils import accuracy, load_checkpoint, get_device\n",
            "  Line 16: \n",
            "  Line 17: \n",
            "  Line 18: class ModelEvaluator:\n",
            "  Line 19: \"\"\"\n",
            "  Line 20: Comprehensive model evaluation for ViT-Fish classification.\n",
            "  Line 25: model: ViTForFishClassification, (contains class name)\n",
            "  Line 236: student_model: ViTForFishClassification, (contains class name)\n",
            "  Line 237: teacher_model: ViTForFishClassification, (contains class name)\n",
            "  Line 311: student_model = ViTForFishClassification(num_classes=num_classes) (contains class name)\n",
            "  Line 318: teacher_model = ViTForFishClassification(num_classes=num_classes) (contains class name)\n",
            "\n",
            "üìÑ Checking potential model file: model.py\n",
            "‚úÖ Found model.py. Checking for class definition...\n",
            "  Line 22: class ViTForFishClassification(nn.Module):\n",
            "\n",
            "üìÑ Checking alternative model file: vit_model.py\n",
            "‚ùì vit_model.py not found.\n",
            "\n",
            "Diagnosis steps complete. Please review the output.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "print(\"üîç Diagnosing ModuleNotFoundError...\")\n",
        "repo_dir = '/content/ViT-FishID'\n",
        "eval_script_path = os.path.join(repo_dir, 'evaluate.py')\n",
        "model_file_guess = os.path.join(repo_dir, 'model.py') # Common name for model file\n",
        "vit_model_file_guess = os.path.join(repo_dir, 'vit_model.py') # Guessed name based on import\n",
        "\n",
        "print(f\"Repo directory: {repo_dir}\")\n",
        "\n",
        "print(\"\\nüìÇ Files in repository root:\")\n",
        "# List files in the repository root\n",
        "if os.path.exists(repo_dir):\n",
        "    !ls -la {repo_dir}\n",
        "else:\n",
        "    print(f\"‚ùå Repository directory not found: {repo_dir}\")\n",
        "\n",
        "\n",
        "print(f\"\\nüìÑ Content of {os.path.basename(eval_script_path)} (checking import):\")\n",
        "# Read and print the content of evaluate.py\n",
        "if os.path.exists(eval_script_path):\n",
        "    try:\n",
        "        with open(eval_script_path, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "            for i, line in enumerate(lines):\n",
        "                if 'import vit_model' in line or 'from vit_model' in line:\n",
        "                    print(f\"  Line {i+1}: {line.strip()}\")\n",
        "                elif 'ViTForFishClassification' in line:\n",
        "                     print(f\"  Line {i+1}: {line.strip()} (contains class name)\")\n",
        "                if i < 20: # Print first 20 lines for context\n",
        "                     print(f\"  Line {i+1}: {line.strip()}\")\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Could not read {eval_script_path}: {e}\")\n",
        "else:\n",
        "    print(f\"‚ùå {eval_script_path} not found.\")\n",
        "\n",
        "\n",
        "print(f\"\\nüìÑ Checking potential model file: {os.path.basename(model_file_guess)}\")\n",
        "# Check if model.py exists and print relevant lines\n",
        "if os.path.exists(model_file_guess):\n",
        "    try:\n",
        "        with open(model_file_guess, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "            print(f\"‚úÖ Found {os.path.basename(model_file_guess)}. Checking for class definition...\")\n",
        "            found_class = False\n",
        "            for i, line in enumerate(lines):\n",
        "                 if 'class ViTForFishClassification' in line:\n",
        "                      print(f\"  Line {i+1}: {line.strip()}\")\n",
        "                      found_class = True\n",
        "                      break # Found the class, stop searching\n",
        "\n",
        "            if not found_class:\n",
        "                 print(f\"‚ö†Ô∏è 'ViTForFishClassification' class definition not found in {os.path.basename(model_file_guess)}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Could not read {model_file_guess}: {e}\")\n",
        "else:\n",
        "    print(f\"‚ùì {os.path.basename(model_file_guess)} not found. Checking alternative name...\")\n",
        "\n",
        "print(f\"\\nüìÑ Checking alternative model file: {os.path.basename(vit_model_file_guess)}\")\n",
        "# Check if vit_model.py exists and print relevant lines\n",
        "if os.path.exists(vit_model_file_guess):\n",
        "    try:\n",
        "        with open(vit_model_file_guess, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "            print(f\"‚úÖ Found {os.path.basename(vit_model_file_guess)}. Checking for class definition...\")\n",
        "            found_class = False\n",
        "            for i, line in enumerate(lines):\n",
        "                 if 'class ViTForFishClassification' in line:\n",
        "                      print(f\"  Line {i+1}: {line.strip()}\")\n",
        "                      found_class = True\n",
        "                      break # Found the class, stop searching\n",
        "\n",
        "            if not found_class:\n",
        "                 print(f\"‚ö†Ô∏è 'ViTForFishClassification' class definition not found in {os.path.basename(vit_model_file_guess)}\")\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Could not read {vit_model_file_guess}: {e}\")\n",
        "else:\n",
        "    print(f\"‚ùì {os.path.basename(vit_model_file_guess)} not found.\")\n",
        "\n",
        "print(\"\\nDiagnosis steps complete. Please review the output.\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8305def7",
        "outputId": "34d5ab6a-43c0-476e-b6af-ca604c1892a6"
      },
      "source": [
        "import os\n",
        "\n",
        "print(\"Checking the contents of the MAE checkpoint directory:\")\n",
        "mae_checkpoint_dir = '/content/drive/MyDrive/mae_checkpoints'\n",
        "\n",
        "if os.path.exists(mae_checkpoint_dir):\n",
        "    print(f\"‚úÖ Directory found: {mae_checkpoint_dir}\")\n",
        "    print(\"\\nFiles in the directory:\")\n",
        "    try:\n",
        "        # List all items in the directory\n",
        "        items = os.listdir(mae_checkpoint_dir)\n",
        "        if items:\n",
        "            for item in items:\n",
        "                item_path = os.path.join(mae_checkpoint_dir, item)\n",
        "                if os.path.isfile(item_path):\n",
        "                    file_size = os.path.getsize(item_path) / (1024**2) # Size in MB\n",
        "                    print(f\"  - {item} ({file_size:.2f} MB)\")\n",
        "                else:\n",
        "                    print(f\"  - {item} (Directory)\")\n",
        "        else:\n",
        "            print(\"  (Directory is empty)\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error listing directory contents: {e}\")\n",
        "else:\n",
        "    print(f\"‚ùå Directory not found: {mae_checkpoint_dir}\")\n",
        "    print(\"Please ensure the directory exists in your Google Drive.\")\n",
        "\n",
        "print(\"\\n--- Check complete ---\")"
      ],
      "id": "8305def7",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking the contents of the MAE checkpoint directory:\n",
            "‚ùå Directory not found: /content/drive/MyDrive/mae_checkpoints\n",
            "Please ensure the directory exists in your Google Drive.\n",
            "\n",
            "--- Check complete ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.flush_and_unmount('/content/drive')\n",
        "#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jF_Ontj1eb3Y",
        "outputId": "9d948a76-ddc8-4e42-ea13-c70111d00980"
      },
      "id": "jF_Ontj1eb3Y",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive not mounted, so nothing to flush and unmount.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}