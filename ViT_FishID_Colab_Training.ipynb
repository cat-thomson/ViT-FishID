{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e0af9a0",
   "metadata": {
    "id": "0e0af9a0"
   },
   "source": [
    "# 🐟 ViT-FishID: Semi-Supervised Fish Classification\n",
    "\n",
    "**COMPLETE TRAINING PIPELINE WITH GOOGLE COLAB**\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/cat-thomson/ViT-FishID/blob/main/ViT_FishID_Colab_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "## 🎯 What This Notebook Does\n",
    "\n",
    "This notebook implements a **complete semi-supervised learning pipeline** for fish species classification using:\n",
    "\n",
    "**🤖 Vision Transformer (ViT)**: State-of-the-art transformer architecture for image classification\n",
    "**📊 Semi-Supervised Learning**: Leverages both labeled and unlabeled fish images\n",
    "**🎓 EMA Teacher-Student Framework**: Uses exponential moving averages for consistency training\n",
    "**☁️ Google Colab**: Cloud-based training with GPU acceleration\n",
    "\n",
    "## 📊 Expected Performance\n",
    "\n",
    "- **Training Time**: 4-6 hours for 100 epochs\n",
    "- **GPU Requirements**: T4/V100/A100 (Colab Pro recommended)\n",
    "- **Expected Accuracy**: 80-90% on fish species classification\n",
    "- **Data Efficiency**: Works well with limited labeled data\n",
    "\n",
    "## 🛠️ What You Need\n",
    "\n",
    "1. **Fish Dataset**: Labeled and unlabeled fish images (upload to Google Drive)\n",
    "2. **Google Colab Pro**: Recommended for longer training sessions\n",
    "3. **Weights & Biases Account**: Optional for experiment tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bcb2a3",
   "metadata": {
    "id": "26bcb2a3"
   },
   "source": [
    "## 🔧 Step 1: Environment Setup and GPU Check\n",
    "\n",
    "First, let's verify that we have GPU access and set up the optimal environment for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3540b19",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f3540b19",
    "outputId": "4859151f-eadc-4319-a3ac-b5f70e71df87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 SYSTEM INFORMATION\n",
      "==================================================\n",
      "Python version: 3.13.5 (main, Jun 11 2025, 15:36:57) [Clang 17.0.0 (clang-1700.0.13.3)]\n",
      "PyTorch version: 2.8.0\n",
      "CUDA available: False\n",
      "❌ No GPU detected!\n",
      "📝 To enable GPU in Colab:\n",
      "   Runtime → Change runtime type → Hardware accelerator → GPU\n",
      "   Then restart this notebook\n",
      "\n",
      "🎯 Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Check GPU availability and system information\n",
    "import torch\n",
    "import os\n",
    "import gc\n",
    "\n",
    "print(\"🔍 SYSTEM INFORMATION\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Python version: {os.sys.version}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device_name = torch.cuda.get_device_name(0)\n",
    "    device_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    print(f\"GPU Device: {device_name}\")\n",
    "    print(f\"GPU Memory: {device_memory:.1f} GB\")\n",
    "    print(\"✅ GPU is ready for training!\")\n",
    "    \n",
    "    # Set optimal GPU settings\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    \n",
    "    # Clear GPU cache\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    print(\"🚀 GPU optimized for training\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ No GPU detected!\")\n",
    "    print(\"📝 To enable GPU in Colab:\")\n",
    "    print(\"   Runtime → Change runtime type → Hardware accelerator → GPU\")\n",
    "    print(\"   Then restart this notebook\")\n",
    "\n",
    "# Set device for later use\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\n🎯 Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149f671b",
   "metadata": {
    "id": "149f671b"
   },
   "source": [
    "## 📁 Step 2: Mount Google Drive\n",
    "\n",
    "This will give us access to your fish dataset stored in Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4abb3ffd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4abb3ffd",
    "outputId": "29fb191e-611d-4f2d-a4d5-69fec2c1d936"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "\n",
      "📂 Google Drive contents:\n",
      "  - Mock Matric\n",
      "  - Photos\n",
      "  - Admin\n",
      "  - Uni\n",
      "  - Fish_Training_Output\n",
      "  - Colab Notebooks\n",
      "  - ViT-FishID\n",
      "  - fish_cutouts.zip\n",
      "  - ViT-FishID_Training_20250814_154652\n",
      "  - ViT-FishID_Training_20250814_202307\n",
      "  ... and 3 more items\n",
      "\n",
      "✅ Google Drive mounted successfully!\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# List contents to verify mount\n",
    "print(\"\\n📂 Google Drive contents:\")\n",
    "drive_path = '/content/drive/MyDrive'\n",
    "if os.path.exists(drive_path):\n",
    "    items = os.listdir(drive_path)[:10]  # Show first 10 items\n",
    "    for item in items:\n",
    "        print(f\"  - {item}\")\n",
    "    if len(os.listdir(drive_path)) > 10:\n",
    "        print(f\"  ... and {len(os.listdir(drive_path)) - 10} more items\")\n",
    "    print(\"\\n✅ Google Drive mounted successfully!\")\n",
    "else:\n",
    "    print(\"❌ Failed to mount Google Drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8b6273",
   "metadata": {
    "id": "be8b6273"
   },
   "source": [
    "## 📦 Step 3: Install Dependencies\n",
    "\n",
    "Installing all required packages for ViT-FishID training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c724abc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8c724abc",
    "outputId": "77da503f-48d7-49ca-dc48-111168649d45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Installing dependencies...\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m128.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m100.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m111.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h✅ All dependencies installed successfully!\n",
      "\n",
      "📋 Package versions:\n",
      "  - torch: 2.6.0+cu124\n",
      "  - torchvision: 0.21.0+cu124\n",
      "  - timm: 1.0.19\n",
      "  - albumentations: 2.0.8\n",
      "  - opencv: 4.12.0\n",
      "  - sklearn: 1.6.1\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "print(\"📦 Installing dependencies...\")\n",
    "\n",
    "!pip install -q torch torchvision torchaudio\n",
    "!pip install -q timm transformers\n",
    "!pip install -q albumentations\n",
    "!pip install -q wandb\n",
    "!pip install -q opencv-python-headless\n",
    "!pip install -q scikit-learn\n",
    "!pip install -q matplotlib seaborn\n",
    "!pip install -q tqdm\n",
    "\n",
    "print(\"✅ All dependencies installed successfully!\")\n",
    "\n",
    "# Verify installations\n",
    "import torch\n",
    "import torchvision\n",
    "import timm\n",
    "import albumentations\n",
    "import cv2\n",
    "import sklearn\n",
    "\n",
    "print(\"\\n📋 Package versions:\")\n",
    "print(f\"  - torch: {torch.__version__}\")\n",
    "print(f\"  - torchvision: {torchvision.__version__}\")\n",
    "print(f\"  - timm: {timm.__version__}\")\n",
    "print(f\"  - albumentations: {albumentations.__version__}\")\n",
    "print(f\"  - opencv: {cv2.__version__}\")\n",
    "print(f\"  - sklearn: {sklearn.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b795fc",
   "metadata": {
    "id": "12b795fc"
   },
   "source": [
    "## 🔄 Step 4: Clone ViT-FishID Repository\n",
    "\n",
    "Getting the latest code from your GitHub repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4e4cd45",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c4e4cd45",
    "outputId": "8efc760e-aea2-48bd-f684-8f9d338697e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Cloning ViT-FishID repository...\n",
      "Cloning into '/content/ViT-FishID'...\n",
      "remote: Enumerating objects: 119, done.\u001b[K\n",
      "remote: Counting objects: 100% (119/119), done.\u001b[K\n",
      "remote: Compressing objects: 100% (86/86), done.\u001b[K\n",
      "remote: Total 119 (delta 44), reused 98 (delta 27), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (119/119), 201.94 KiB | 20.19 MiB/s, done.\n",
      "Resolving deltas: 100% (44/44), done.\n",
      "/content/ViT-FishID\n",
      "\n",
      "📂 Project structure:\n",
      "total 360\n",
      "drwxr-xr-x 4 root root   4096 Aug 15 06:58 .\n",
      "drwxr-xr-x 1 root root   4096 Aug 15 06:58 ..\n",
      "-rw-r--r-- 1 root root  21217 Aug 15 06:58 data.py\n",
      "-rw-r--r-- 1 root root  11572 Aug 15 06:58 evaluate.py\n",
      "-rw-r--r-- 1 root root   3328 Aug 15 06:58 EXTENDED_TRAINING_SETUP.md\n",
      "drwxr-xr-x 2 root root   4096 Aug 15 06:58 fish_cutouts\n",
      "drwxr-xr-x 8 root root   4096 Aug 15 06:58 .git\n",
      "-rw-r--r-- 1 root root     66 Aug 15 06:58 .gitattributes\n",
      "-rw-r--r-- 1 root root    646 Aug 15 06:58 .gitignore\n",
      "-rw-r--r-- 1 root root   9495 Aug 15 06:58 model.py\n",
      "-rw-r--r-- 1 root root  16771 Aug 15 06:58 pipeline.py\n",
      "-rw-r--r-- 1 root root  16566 Aug 15 06:58 README.md\n",
      "-rw-r--r-- 1 root root    202 Aug 15 06:58 requirements.txt\n",
      "-rw-r--r-- 1 root root   4265 Aug 15 06:58 resume_training.py\n",
      "-rw-r--r-- 1 root root   5134 Aug 15 06:58 species_mapping.txt\n",
      "-rw-r--r-- 1 root root  25497 Aug 15 06:58 trainer.py\n",
      "-rw-r--r-- 1 root root   4982 Aug 15 06:58 TRAINING_FIXES_APPLIED.md\n",
      "-rw-r--r-- 1 root root  15331 Aug 15 06:58 train.py\n",
      "-rw-r--r-- 1 root root   8818 Aug 15 06:58 utils.py\n",
      "-rw-r--r-- 1 root root 160971 Aug 15 06:58 ViT_FishID_Colab_Training.ipynb\n",
      "\n",
      "✅ Repository cloned successfully!\n"
     ]
    }
   ],
   "source": [
    "# Clone the repository\n",
    "import os\n",
    "\n",
    "# Remove existing directory if it exists\n",
    "if os.path.exists('/content/ViT-FishID'):\n",
    "    !rm -rf /content/ViT-FishID\n",
    "\n",
    "# Clone the repository\n",
    "print(\"📥 Cloning ViT-FishID repository...\")\n",
    "!git clone https://github.com/cat-thomson/ViT-FishID.git /content/ViT-FishID\n",
    "\n",
    "# Change to project directory\n",
    "%cd /content/ViT-FishID\n",
    "\n",
    "# List project files\n",
    "print(\"\\n📂 Project structure:\")\n",
    "!ls -la\n",
    "\n",
    "print(\"\\n✅ Repository cloned successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8155c400",
   "metadata": {
    "id": "8155c400"
   },
   "source": [
    "## 🐠 Step 5: Setup Fish Dataset\n",
    "\n",
    "**Important**: Upload your `fish_cutouts.zip` file to Google Drive before running this step.\n",
    "\n",
    "Expected dataset structure:\n",
    "```\n",
    "fish_cutouts/\n",
    "├── labeled/\n",
    "│   ├── species_1/\n",
    "│   │   ├── fish_001.jpg\n",
    "│   │   └── fish_002.jpg\n",
    "│   └── species_2/\n",
    "│       └── ...\n",
    "└── unlabeled/\n",
    "    ├── fish_003.jpg\n",
    "    └── fish_004.jpg\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nre5_INaKDXl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nre5_INaKDXl",
    "outputId": "c9c02e13-e2c0-4c0b-802a-0f0111fd50b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🗂️ SETTING UP FISH DATASET - CORRECTED PATHS\n",
      "==================================================\n",
      "🎯 ZIP file location: /content/drive/MyDrive/fish_cutouts.zip\n",
      "🎯 Target data directory: /content/fish_cutouts\n",
      "📥 Data not found locally, extracting from Google Drive...\n",
      "✅ Found ZIP file at: /content/drive/MyDrive/fish_cutouts.zip\n",
      "📏 ZIP file size: 216.5 MB\n",
      "📦 Extracting fish_cutouts.zip...\n",
      "✅ ZIP extraction completed\n",
      "📁 Found in ZIP: ['dataset_info.json', '__MACOSX', 'labeled', 'unlabeled']\n",
      "📄 Found dataset info: dataset_info.json\n",
      "✅ Found labeled directory: labeled\n",
      "✅ Found unlabeled directory: unlabeled\n",
      "✅ Data organized at: /content/fish_cutouts\n",
      "📄 Copied dataset_info.json\n",
      "🐟 Verified: 37 species in labeled data\n",
      "📊 Verified: 24015 images in unlabeled data\n",
      "\n",
      "✅ DATASET READY\n",
      "📁 Location: /content/fish_cutouts\n",
      "  📂 labeled/: 37 species folders\n",
      "  📂 unlabeled/: 24015 images\n",
      "  📄 dataset_info.json: Available\n",
      "🚀 Ready to proceed with training!\n"
     ]
    }
   ],
   "source": [
    "# Setup fish dataset from Google Drive\n",
    "import zipfile\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "\n",
    "print(\"🐠 SETTING UP FISH DATASET\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Configuration\n",
    "ZIP_FILE_PATH = '/content/drive/MyDrive/fish_cutouts.zip'\n",
    "DATA_DIR = '/content/fish_cutouts'\n",
    "\n",
    "print(f\"📂 Looking for dataset: {ZIP_FILE_PATH}\")\n",
    "print(f\"🎯 Target directory: {DATA_DIR}\")\n",
    "\n",
    "# Check if data already exists locally\n",
    "if os.path.exists(DATA_DIR) and os.path.exists(os.path.join(DATA_DIR, 'labeled')):\n",
    "    print(\"✅ Dataset already available locally!\")\n",
    "    \n",
    "    # Quick validation\n",
    "    labeled_dir = os.path.join(DATA_DIR, 'labeled')\n",
    "    unlabeled_dir = os.path.join(DATA_DIR, 'unlabeled')\n",
    "    \n",
    "    if os.path.exists(labeled_dir):\n",
    "        species_count = len([d for d in os.listdir(labeled_dir) \n",
    "                           if os.path.isdir(os.path.join(labeled_dir, d)) and not d.startswith('.')])\n",
    "        print(f\"🐟 Found {species_count} labeled species\")\n",
    "    \n",
    "    if os.path.exists(unlabeled_dir):\n",
    "        unlabeled_count = len([f for f in os.listdir(unlabeled_dir) \n",
    "                             if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "        print(f\"📊 Found {unlabeled_count} unlabeled images\")\n",
    "\n",
    "else:\n",
    "    print(\"📥 Extracting dataset from Google Drive...\")\n",
    "    \n",
    "    # Check if ZIP file exists\n",
    "    if not os.path.exists(ZIP_FILE_PATH):\n",
    "        print(f\"❌ Dataset not found at: {ZIP_FILE_PATH}\")\n",
    "        print(\"📝 Please upload fish_cutouts.zip to Google Drive root directory\")\n",
    "    else:\n",
    "        print(f\"✅ Found dataset: {os.path.getsize(ZIP_FILE_PATH) / (1024**2):.1f} MB\")\n",
    "        \n",
    "        try:\n",
    "            # Extract to temporary directory\n",
    "            temp_dir = '/content/temp_extract'\n",
    "            if os.path.exists(temp_dir):\n",
    "                shutil.rmtree(temp_dir)\n",
    "            \n",
    "            with zipfile.ZipFile(ZIP_FILE_PATH, 'r') as zip_ref:\n",
    "                zip_ref.extractall(temp_dir)\n",
    "            \n",
    "            # Find and organize data\n",
    "            extracted_items = os.listdir(temp_dir)\n",
    "            print(f\"📁 Extracted: {extracted_items}\")\n",
    "            \n",
    "            # Look for labeled and unlabeled directories\n",
    "            labeled_source = None\n",
    "            unlabeled_source = None\n",
    "            \n",
    "            for item in extracted_items:\n",
    "                item_path = os.path.join(temp_dir, item)\n",
    "                if item == 'labeled' and os.path.isdir(item_path):\n",
    "                    labeled_source = item_path\n",
    "                elif item == 'unlabeled' and os.path.isdir(item_path):\n",
    "                    unlabeled_source = item_path\n",
    "            \n",
    "            if labeled_source and unlabeled_source:\n",
    "                # Create target directory\n",
    "                if os.path.exists(DATA_DIR):\n",
    "                    shutil.rmtree(DATA_DIR)\n",
    "                os.makedirs(DATA_DIR)\n",
    "                \n",
    "                # Move directories\n",
    "                shutil.move(labeled_source, os.path.join(DATA_DIR, 'labeled'))\n",
    "                shutil.move(unlabeled_source, os.path.join(DATA_DIR, 'unlabeled'))\n",
    "                \n",
    "                print(\"✅ Dataset organized successfully!\")\n",
    "                \n",
    "                # Verify structure\n",
    "                labeled_dir = os.path.join(DATA_DIR, 'labeled')\n",
    "                species_count = len([d for d in os.listdir(labeled_dir) \n",
    "                                   if os.path.isdir(os.path.join(labeled_dir, d)) and not d.startswith('.')])\n",
    "                \n",
    "                unlabeled_dir = os.path.join(DATA_DIR, 'unlabeled')\n",
    "                unlabeled_count = len([f for f in os.listdir(unlabeled_dir) \n",
    "                                     if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "                \n",
    "                print(f\"🐟 Verified: {species_count} species\")\n",
    "                print(f\"📊 Verified: {unlabeled_count} unlabeled images\")\n",
    "                \n",
    "            else:\n",
    "                print(\"❌ Could not find labeled and unlabeled directories\")\n",
    "            \n",
    "            # Cleanup\n",
    "            if os.path.exists(temp_dir):\n",
    "                shutil.rmtree(temp_dir)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error extracting dataset: {e}\")\n",
    "\n",
    "# Final verification\n",
    "if os.path.exists(DATA_DIR):\n",
    "    print(f\"\\n✅ DATASET READY\")\n",
    "    print(f\"📁 Location: {DATA_DIR}\")\n",
    "    print(\"🚀 Ready for training!\")\n",
    "else:\n",
    "    print(f\"\\n❌ DATASET SETUP FAILED\")\n",
    "    print(\"Please check that fish_cutouts.zip is uploaded to Google Drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f0fe32",
   "metadata": {
    "id": "31f0fe32"
   },
   "source": [
    "## 📈 Step 6: Setup Weights & Biases (Optional)\n",
    "\n",
    "Weights & Biases provides excellent training visualization and experiment tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab343772",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "ab343772",
    "outputId": "b6d9c2df-bbb0-46ae-ca3b-537ed8e98191"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 Connecting to Weights & Biases...\n",
      "🔑 Please enter your W&B API key when prompted.\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "wandb: Paste an API key from your profile and hit enter:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ··········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcativthomson\u001b[0m (\u001b[33mcativthomson-university-of-cape-town\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully logged in to W&B.\n",
      "❌ W&B connection not established. Logging may be disabled.\n"
     ]
    }
   ],
   "source": [
    "# Login to Weights & Biases for experiment tracking\n",
    "import wandb\n",
    "import os\n",
    "\n",
    "print(\"📈 SETTING UP WEIGHTS & BIASES\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Check if API key is available\n",
    "if os.environ.get(\"WANDB_API_KEY\"):\n",
    "    print(\"✅ W&B API key found in environment\")\n",
    "    try:\n",
    "        wandb.login(relogin=True)\n",
    "        print(\"✅ Successfully logged in to W&B\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ W&B relogin failed: {e}\")\n",
    "        print(\"Trying manual login...\")\n",
    "        wandb.login()\n",
    "else:\n",
    "    print(\"🔑 Please enter your W&B API key when prompted\")\n",
    "    print(\"💡 Get your API key from: https://wandb.ai/settings\")\n",
    "    try:\n",
    "        wandb.login()\n",
    "        print(\"✅ Successfully logged in to W&B\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ W&B login failed: {e}\")\n",
    "        print(\"Continuing without W&B logging...\")\n",
    "\n",
    "# Check connection status\n",
    "if wandb.run:\n",
    "    print(f\"🚀 W&B Run URL: {wandb.run.url}\")\n",
    "    USE_WANDB = True\n",
    "else:\n",
    "    print(\"📊 W&B not connected - training will continue without logging\")\n",
    "    USE_WANDB = False\n",
    "\n",
    "print(f\"✅ W&B setup complete (Enabled: {USE_WANDB})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5190f01",
   "metadata": {
    "id": "b5190f01"
   },
   "source": [
    "## 🔄 Step 6: Locate Checkpoint from Epoch 19\n",
    "\n",
    "Finding your saved checkpoint to resume training from where you left off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61b35ced",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "61b35ced",
    "outputId": "80d1b4e8-edbd-4fe9-c8a5-ffc25514190a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Looking for checkpoint from epoch 100...\n",
      "📁 Checking: /content/drive/MyDrive/ViT-FishID/checkpoints_extended\n",
      "🎯 Found candidate: checkpoint_epoch_100.pth\n",
      "✅ FOUND EPOCH 100 CHECKPOINT!\n",
      "📁 Location: /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_100.pth\n",
      "📊 Epoch: 100\n",
      "📊 Best accuracy so far: 87.56%\n",
      "📁 Checking: /content/drive/MyDrive/ViT-FishID/checkpoints_backup\n",
      "🎯 Found candidate: checkpoint_epoch_100.pth\n",
      "✅ FOUND EPOCH 100 CHECKPOINT!\n",
      "📁 Location: /content/drive/MyDrive/ViT-FishID/checkpoints_backup/checkpoint_epoch_100.pth\n",
      "📊 Epoch: 100\n",
      "📊 Best accuracy so far: 87.56%\n",
      "\n",
      "🎉 Checkpoint ready for resuming training!\n",
      "📄 File: checkpoint_epoch_100.pth\n",
      "📏 Size: 982.4 MB\n",
      "💾 New checkpoints will be saved to: /content/drive/MyDrive/ViT-FishID/checkpoints_extended\n"
     ]
    }
   ],
   "source": [
    "# Locate checkpoint from epoch 19\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "\n",
    "print(\"🔍 Looking for checkpoint from epoch 100...\")\n",
    "\n",
    "# Possible checkpoint locations\n",
    "checkpoint_locations = [\n",
    "    '/content/drive/MyDrive/ViT-FishID/checkpoints_extended', '/content/drive/MyDrive/ViT-FishID/checkpoints_backup'\n",
    "]\n",
    "\n",
    "checkpoint_path = None\n",
    "checkpoint_info = None\n",
    "\n",
    "# Search for epoch 19 checkpoint\n",
    "for location_pattern in checkpoint_locations:\n",
    "    for location in glob.glob(location_pattern):\n",
    "        if os.path.exists(location):\n",
    "            print(f\"📁 Checking: {location}\")\n",
    "\n",
    "            # Look for epoch 19 specifically\n",
    "            epoch_100_files = glob.glob(os.path.join(location, '*epoch_100*'))\n",
    "            manual_files = glob.glob(os.path.join(location, '*manual*epoch*100*'))\n",
    "            emergency_files = glob.glob(os.path.join(location, '*emergency*epoch*100*'))\n",
    "\n",
    "            all_candidates = epoch_100_files + manual_files + emergency_files\n",
    "\n",
    "            for candidate in all_candidates:\n",
    "                if candidate.endswith('.pth'):\n",
    "                    print(f\"🎯 Found candidate: {os.path.basename(candidate)}\")\n",
    "                    try:\n",
    "                        # Verify checkpoint can be loaded\n",
    "                        test_checkpoint = torch.load(candidate, map_location='cpu')\n",
    "                        epoch = test_checkpoint.get('epoch', 'unknown')\n",
    "\n",
    "                        if epoch == 100 or '100' in os.path.basename(candidate):\n",
    "                            checkpoint_path = candidate\n",
    "                            checkpoint_info = test_checkpoint\n",
    "                            print(f\"✅ FOUND EPOCH 100 CHECKPOINT!\")\n",
    "                            print(f\"📁 Location: {checkpoint_path}\")\n",
    "                            print(f\"📊 Epoch: {epoch}\")\n",
    "\n",
    "                            if 'best_accuracy' in test_checkpoint:\n",
    "                                print(f\"📊 Best accuracy so far: {test_checkpoint['best_accuracy']:.2f}%\")\n",
    "                            elif 'best_acc' in test_checkpoint:\n",
    "                                print(f\"📊 Best accuracy so far: {test_checkpoint['best_acc']:.2f}%\")\n",
    "\n",
    "                            break\n",
    "                    except Exception as e:\n",
    "                        print(f\"⚠️ Could not load {candidate}: {e}\")\n",
    "\n",
    "            if checkpoint_path:\n",
    "                break\n",
    "\n",
    "        if checkpoint_path:\n",
    "            break\n",
    "\n",
    "if checkpoint_path:\n",
    "    print(f\"\\n🎉 Checkpoint ready for resuming training!\")\n",
    "    print(f\"📄 File: {os.path.basename(checkpoint_path)}\")\n",
    "    print(f\"📏 Size: {os.path.getsize(checkpoint_path) / (1024*1024):.1f} MB\")\n",
    "\n",
    "    # Set up checkpoint directory for new saves\n",
    "    checkpoint_save_dir = '/content/drive/MyDrive/ViT-FishID/checkpoints_extended'\n",
    "    os.makedirs(checkpoint_save_dir, exist_ok=True)\n",
    "    print(f\"💾 New checkpoints will be saved to: {checkpoint_save_dir}\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ No checkpoint found for epoch 19!\")\n",
    "    print(\"\\n🔧 Troubleshooting:\")\n",
    "    print(\"1. Check that you have a checkpoint saved from previous training\")\n",
    "    print(\"2. Ensure the checkpoint is uploaded to Google Drive\")\n",
    "    print(\"3. Look for files named like: checkpoint_epoch_19.pth, emergency_checkpoint_epoch_19.pth\")\n",
    "    print(\"\\n📁 Checked locations:\")\n",
    "    for location in checkpoint_locations:\n",
    "        print(f\"  - {location}\")\n",
    "\n",
    "    # Fallback: look for any checkpoints\n",
    "    print(\"\\n🔍 All available checkpoints:\")\n",
    "    for location_pattern in checkpoint_locations:\n",
    "        for location in glob.glob(location_pattern):\n",
    "            if os.path.exists(location):\n",
    "                all_checkpoints = glob.glob(os.path.join(location, '*.pth'))\n",
    "                for cp in all_checkpoints:\n",
    "                    print(f\"  - {os.path.basename(cp)}\")\n",
    "\n",
    "# Store checkpoint path for later use\n",
    "RESUME_CHECKPOINT = checkpoint_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe6af6d",
   "metadata": {
    "id": "0fe6af6d"
   },
   "source": [
    "## ⚙️ Step 7: Configure Training Parameters\n",
    "\n",
    "Configure the training settings for your semi-supervised fish classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hSokV6NDjgYa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hSokV6NDjgYa",
    "outputId": "8c7b1c32-b0db-4c59-fea7-411ce6f2574d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 EXTENDED TRAINING CONFIGURATION - WITH W&B\n",
      "==================================================\n",
      "📊 Detected 37 fish species\n",
      "\n",
      "EXTENDED TRAINING CONFIGURATION SUMMARY\n",
      "==================================================\n",
      "📊 Resume from: Epoch 100\n",
      "📊 Target epochs: 100\n",
      "📊 Remaining epochs: 1\n",
      "⏱️ Estimated time: 5-7 minutes\n",
      "📊 Batch size: 16 (optimized for Colab Pro)\n",
      "💾 Checkpoint saves: EVERY 1 epoch(s)\n",
      "📊 Mode: semi_supervised with consistency weight 2.0\n",
      "📊 Logging: W&B Enabled (Project: ViT-FishID-Extended-Training, Run: resume-epoch-6-to-100)\n",
      "📊 Num Classes: 37\n",
      "\n",
      "SETTING UP CHECKPOINT DIRECTORIES\n",
      "==================================================\n",
      "📁 Primary saves: /content/drive/MyDrive/ViT-FishID/checkpoints_extended (Created/Exists)\n",
      "💾 Backup saves: /content/drive/MyDrive/ViT-FishID/checkpoints_backup (Created/Exists)\n",
      "\n",
      "✅ Will resume training from: checkpoint_epoch_100.pth\n",
      "\n",
      "🚀 Configuration complete. Ready to resume/start training!\n"
     ]
    }
   ],
   "source": [
    "# Training Configuration for Semi-Supervised Fish Classification\n",
    "import os\n",
    "\n",
    "print(\"⚙️ TRAINING CONFIGURATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Auto-detect number of species from dataset\n",
    "NUM_CLASSES = 37  # Default\n",
    "if 'DATA_DIR' in globals() and os.path.exists(DATA_DIR):\n",
    "    labeled_dir = os.path.join(DATA_DIR, 'labeled')\n",
    "    if os.path.exists(labeled_dir):\n",
    "        species_count = len([d for d in os.listdir(labeled_dir) \n",
    "                           if os.path.isdir(os.path.join(labeled_dir, d)) and not d.startswith('.')])\n",
    "        NUM_CLASSES = species_count\n",
    "        print(f\"📊 Auto-detected {species_count} fish species\")\n",
    "\n",
    "# Create checkpoint directories\n",
    "CHECKPOINT_DIR = '/content/drive/MyDrive/ViT-FishID/checkpoints'\n",
    "BACKUP_DIR = '/content/drive/MyDrive/ViT-FishID/checkpoints_backup'\n",
    "\n",
    "try:\n",
    "    os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "    os.makedirs(BACKUP_DIR, exist_ok=True)\n",
    "    print(f\"📁 Checkpoints: {CHECKPOINT_DIR}\")\n",
    "    print(f\"💾 Backups: {BACKUP_DIR}\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Could not create Google Drive directories: {e}\")\n",
    "    CHECKPOINT_DIR = '/content/checkpoints'\n",
    "    BACKUP_DIR = '/content/checkpoints_backup'\n",
    "    os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "    os.makedirs(BACKUP_DIR, exist_ok=True)\n",
    "    print(f\"📁 Using local checkpoints: {CHECKPOINT_DIR}\")\n",
    "\n",
    "# Training Configuration\n",
    "TRAINING_CONFIG = {\n",
    "    # BASIC SETTINGS\n",
    "    'mode': 'semi_supervised',\n",
    "    'data_dir': DATA_DIR if 'DATA_DIR' in globals() else '/content/fish_cutouts',\n",
    "    'epochs': 100,\n",
    "    'batch_size': 16,\n",
    "    'learning_rate': 1e-4,\n",
    "    'weight_decay': 0.05,\n",
    "    \n",
    "    # MODEL SETTINGS\n",
    "    'model_name': 'vit_base_patch16_224',\n",
    "    'num_classes': NUM_CLASSES,\n",
    "    'pretrained': True,\n",
    "    \n",
    "    # SEMI-SUPERVISED SETTINGS\n",
    "    'consistency_weight': 2.0,\n",
    "    'pseudo_label_threshold': 0.7,\n",
    "    'temperature': 4.0,\n",
    "    'warmup_epochs': 10,\n",
    "    'ramp_up_epochs': 30,\n",
    "    \n",
    "    # CHECKPOINT SETTINGS\n",
    "    'save_frequency': 10,  # Save every 10 epochs\n",
    "    'checkpoint_dir': CHECKPOINT_DIR,\n",
    "    'backup_dir': BACKUP_DIR,\n",
    "    \n",
    "    # LOGGING SETTINGS\n",
    "    'use_wandb': USE_WANDB if 'USE_WANDB' in globals() else False,\n",
    "    'wandb_project': 'ViT-FishID-Training',\n",
    "    'wandb_run_name': f'fish-classification-{NUM_CLASSES}-classes',\n",
    "}\n",
    "\n",
    "print(\"\\n📋 TRAINING CONFIGURATION\")\n",
    "print(\"=\"*50)\n",
    "print(f\"🎯 Training mode: {TRAINING_CONFIG['mode']}\")\n",
    "print(f\"📊 Total epochs: {TRAINING_CONFIG['epochs']}\")\n",
    "print(f\"📦 Batch size: {TRAINING_CONFIG['batch_size']}\")\n",
    "print(f\"🧠 Model: {TRAINING_CONFIG['model_name']}\")\n",
    "print(f\"🐟 Number of species: {TRAINING_CONFIG['num_classes']}\")\n",
    "print(f\"⚖️ Consistency weight: {TRAINING_CONFIG['consistency_weight']}\")\n",
    "print(f\"🎯 Pseudo-label threshold: {TRAINING_CONFIG['pseudo_label_threshold']}\")\n",
    "print(f\"💾 Save frequency: Every {TRAINING_CONFIG['save_frequency']} epochs\")\n",
    "print(f\"📈 W&B logging: {TRAINING_CONFIG['use_wandb']}\")\n",
    "\n",
    "# Time estimation\n",
    "estimated_time_hours = TRAINING_CONFIG['epochs'] * 3 / 60  # ~3 minutes per epoch\n",
    "print(f\"\\n⏱️ Estimated training time: {estimated_time_hours:.1f} hours\")\n",
    "print(f\"💡 Recommendation: Use Colab Pro for longer training sessions\")\n",
    "\n",
    "print(\"\\n✅ Configuration complete - ready to start training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34762fd6",
   "metadata": {},
   "source": [
    "## 🤖 Step 7a: Load MAE Pre-trained Model (Optional)\n",
    "\n",
    "**This step loads your pre-trained MAE model to initialize the ViT encoder with better features.**\n",
    "\n",
    "The MAE (Masked Autoencoder) model you trained provides much better initial weights for the Vision Transformer compared to ImageNet pretraining, especially for fish images since it was trained specifically on your fish dataset.\n",
    "\n",
    "Benefits of using MAE initialization:\n",
    "- **Better Feature Representations**: Learned specifically on fish images\n",
    "- **Faster Convergence**: Model starts with relevant features\n",
    "- **Improved Performance**: Often leads to 2-5% accuracy improvement\n",
    "\n",
    "### 📁 MAE Model Locations\n",
    "\n",
    "Your MAE models should be in one of these locations:\n",
    "- **Local**: `/Users/catalinathomson/Desktop/Fish/ViT-FishID/mae_checkpoints/mae_final_model.pth`\n",
    "- **Google Drive**: `/content/drive/MyDrive/mae_checkpoints/mae_final_model.pth` (after upload)\n",
    "\n",
    "### 🔧 Setup Instructions\n",
    "\n",
    "1. **Upload MAE Model**: Upload your `mae_final_model.pth` or `mae_best_model.pth` to Google Drive\n",
    "2. **Update Path**: Modify `MAE_MODEL_PATH` in the next cell if needed\n",
    "3. **Enable/Disable**: Set `LOAD_MAE_PRETRAINED = True/False` to control MAE loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ef2d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MAE Pre-trained Model and Create Custom ViT Model\n",
    "import torch\n",
    "import os\n",
    "import shutil\n",
    "from model import ViTForFishClassification\n",
    "\n",
    "print(\"🤖 SETTING UP MAE-INITIALIZED ViT MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Configuration for MAE loading\n",
    "MAE_MODEL_PATH = '/content/drive/MyDrive/mae_checkpoints/mae_final_model.pth'  # Update this path if needed\n",
    "LOAD_MAE_PRETRAINED = True  # Set to False to skip MAE loading\n",
    "\n",
    "# Global variable to store MAE state for later use\n",
    "MAE_ENCODER_WEIGHTS = None\n",
    "\n",
    "def load_mae_encoder_weights(mae_checkpoint_path):\n",
    "    \"\"\"\n",
    "    Load and extract encoder weights from MAE checkpoint.\n",
    "    \n",
    "    Args:\n",
    "        mae_checkpoint_path: Path to MAE checkpoint file\n",
    "        \n",
    "    Returns:\n",
    "        dict: Filtered encoder weights compatible with ViT backbone\n",
    "    \"\"\"\n",
    "    print(f\"📥 Loading MAE checkpoint from: {mae_checkpoint_path}\")\n",
    "    \n",
    "    # Load MAE checkpoint\n",
    "    checkpoint = torch.load(mae_checkpoint_path, map_location='cpu')\n",
    "    \n",
    "    # Print checkpoint info\n",
    "    if 'epoch' in checkpoint:\n",
    "        print(f\"📊 MAE trained for {checkpoint['epoch']} epochs\")\n",
    "    if 'train_loss' in checkpoint:\n",
    "        print(f\"📉 Final MAE loss: {checkpoint['train_loss']:.4f}\")\n",
    "    \n",
    "    # Get model state dict\n",
    "    mae_state_dict = checkpoint.get('model_state_dict', checkpoint.get('state_dict', checkpoint))\n",
    "    \n",
    "    # Filter encoder weights (remove decoder, mask token, and other non-encoder components)\n",
    "    encoder_weights = {}\n",
    "    for key, value in mae_state_dict.items():\n",
    "        # Keep only encoder-related weights\n",
    "        if any(prefix in key for prefix in [\n",
    "            'patch_embed',\n",
    "            'pos_embed', \n",
    "            'cls_token',\n",
    "            'blocks',\n",
    "            'norm'\n",
    "        ]) and not any(exclude in key for exclude in [\n",
    "            'decoder',\n",
    "            'mask_token',\n",
    "            'head'\n",
    "        ]):\n",
    "            encoder_weights[key] = value\n",
    "    \n",
    "    print(f\"📊 Extracted {len(encoder_weights)} encoder parameters from MAE\")\n",
    "    \n",
    "    return encoder_weights\n",
    "\n",
    "def create_mae_initialized_model(num_classes, model_name='vit_base_patch16_224', mae_weights=None):\n",
    "    \"\"\"\n",
    "    Create ViT model and optionally initialize with MAE weights.\n",
    "    \n",
    "    Args:\n",
    "        num_classes: Number of classification classes\n",
    "        model_name: ViT model architecture name\n",
    "        mae_weights: Optional MAE encoder weights dictionary\n",
    "        \n",
    "    Returns:\n",
    "        ViTForFishClassification: Initialized model\n",
    "    \"\"\"\n",
    "    print(f\"🏗️ Creating ViT model: {model_name}\")\n",
    "    \n",
    "    # Create ViT model (without ImageNet pretraining if we have MAE weights)\n",
    "    use_imagenet_pretrained = mae_weights is None\n",
    "    model = ViTForFishClassification(\n",
    "        num_classes=num_classes,\n",
    "        model_name=model_name,\n",
    "        pretrained=use_imagenet_pretrained,\n",
    "        dropout_rate=0.1\n",
    "    )\n",
    "    \n",
    "    if mae_weights is not None:\n",
    "        print(\"⚡ Initializing ViT backbone with MAE encoder weights...\")\n",
    "        \n",
    "        # Get current backbone state dict\n",
    "        backbone_state = model.backbone.state_dict()\n",
    "        \n",
    "        # Update with MAE weights (only for matching keys and shapes)\n",
    "        updated_keys = []\n",
    "        shape_mismatches = []\n",
    "        \n",
    "        for mae_key, mae_weight in mae_weights.items():\n",
    "            if mae_key in backbone_state:\n",
    "                if mae_weight.shape == backbone_state[mae_key].shape:\n",
    "                    backbone_state[mae_key] = mae_weight.clone()\n",
    "                    updated_keys.append(mae_key)\n",
    "                else:\n",
    "                    shape_mismatches.append(f\"{mae_key}: MAE{mae_weight.shape} != ViT{backbone_state[mae_key].shape}\")\n",
    "        \n",
    "        # Load updated weights\n",
    "        model.backbone.load_state_dict(backbone_state)\n",
    "        \n",
    "        print(f\"✅ Successfully transferred {len(updated_keys)} MAE encoder weights\")\n",
    "        \n",
    "        if shape_mismatches:\n",
    "            print(f\"⚠️ Found {len(shape_mismatches)} shape mismatches (using original weights):\")\n",
    "            for mismatch in shape_mismatches[:5]:  # Show first 5 mismatches\n",
    "                print(f\"   {mismatch}\")\n",
    "        \n",
    "        print(\"🎯 ViT model initialized with MAE-learned features!\")\n",
    "        \n",
    "    else:\n",
    "        print(\"🌐 Using ImageNet pretrained weights\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Main execution\n",
    "if LOAD_MAE_PRETRAINED:\n",
    "    # Check if MAE model exists in Google Drive\n",
    "    if os.path.exists(MAE_MODEL_PATH):\n",
    "        print(f\"✅ Found MAE model: {os.path.basename(MAE_MODEL_PATH)}\")\n",
    "        print(f\"📏 Size: {os.path.getsize(MAE_MODEL_PATH) / (1024**2):.1f} MB\")\n",
    "        \n",
    "        try:\n",
    "            # Load MAE encoder weights\n",
    "            MAE_ENCODER_WEIGHTS = load_mae_encoder_weights(MAE_MODEL_PATH)\n",
    "            print(\"🎉 MAE encoder weights loaded successfully!\")\n",
    "            \n",
    "            # Update training config\n",
    "            TRAINING_CONFIG['mae_pretrained'] = True\n",
    "            TRAINING_CONFIG['mae_model_path'] = MAE_MODEL_PATH\n",
    "            TRAINING_CONFIG['pretrained'] = False  # Don't use ImageNet since we have MAE\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error loading MAE model: {e}\")\n",
    "            print(\"🔄 Falling back to ImageNet pretrained weights...\")\n",
    "            MAE_ENCODER_WEIGHTS = None\n",
    "            TRAINING_CONFIG['mae_pretrained'] = False\n",
    "            TRAINING_CONFIG['pretrained'] = True\n",
    "    \n",
    "    else:\n",
    "        # MAE model not found, check alternative locations\n",
    "        print(f\"❌ MAE model not found at: {MAE_MODEL_PATH}\")\n",
    "        \n",
    "        # Try to copy from local mae_checkpoints if exists\n",
    "        local_mae_path = f'/content/ViT-FishID/mae_checkpoints/{os.path.basename(MAE_MODEL_PATH)}'\n",
    "        if os.path.exists(local_mae_path):\n",
    "            print(f\"\udd0d Found MAE model in local repository: {local_mae_path}\")\n",
    "            try:\n",
    "                # Create directory and copy\n",
    "                os.makedirs(os.path.dirname(MAE_MODEL_PATH), exist_ok=True)\n",
    "                shutil.copy2(local_mae_path, MAE_MODEL_PATH)\n",
    "                print(f\"✅ Copied MAE model to Google Drive: {MAE_MODEL_PATH}\")\n",
    "                \n",
    "                # Now load it\n",
    "                MAE_ENCODER_WEIGHTS = load_mae_encoder_weights(MAE_MODEL_PATH)\n",
    "                TRAINING_CONFIG['mae_pretrained'] = True\n",
    "                TRAINING_CONFIG['mae_model_path'] = MAE_MODEL_PATH\n",
    "                TRAINING_CONFIG['pretrained'] = False\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error copying/loading MAE model: {e}\")\n",
    "                MAE_ENCODER_WEIGHTS = None\n",
    "                TRAINING_CONFIG['mae_pretrained'] = False\n",
    "                TRAINING_CONFIG['pretrained'] = True\n",
    "        else:\n",
    "            print(\"\ud83d📝 Available options:\")\n",
    "            print(\"1. Upload mae_final_model.pth or mae_best_model.pth to /content/drive/MyDrive/mae_checkpoints/\")\n",
    "            print(\"2. Update MAE_MODEL_PATH variable to correct location\")\n",
    "            print(\"3. Set LOAD_MAE_PRETRAINED = False to use ImageNet weights\")\n",
    "            print(\"🔄 Continuing with ImageNet pretrained weights...\")\n",
    "            MAE_ENCODER_WEIGHTS = None\n",
    "            TRAINING_CONFIG['mae_pretrained'] = False\n",
    "            TRAINING_CONFIG['pretrained'] = True\n",
    "\n",
    "else:\n",
    "    print(\"⏭️ Skipping MAE loading - will use ImageNet pretrained weights\")\n",
    "    MAE_ENCODER_WEIGHTS = None\n",
    "    TRAINING_CONFIG['mae_pretrained'] = False\n",
    "    TRAINING_CONFIG['pretrained'] = True\n",
    "\n",
    "# Test model creation (optional - this creates a model to verify everything works)\n",
    "print(f\"\\n🧪 Testing model creation...\")\n",
    "try:\n",
    "    test_model = create_mae_initialized_model(\n",
    "        num_classes=NUM_CLASSES,\n",
    "        model_name=TRAINING_CONFIG['model_name'],\n",
    "        mae_weights=MAE_ENCODER_WEIGHTS\n",
    "    )\n",
    "    \n",
    "    # Test forward pass\n",
    "    test_input = torch.randn(1, 3, 224, 224)\n",
    "    with torch.no_grad():\n",
    "        test_output = test_model(test_input)\n",
    "    \n",
    "    print(f\"✅ Model test successful!\")\n",
    "    print(f\"📊 Input shape: {test_input.shape}\")\n",
    "    print(f\"📊 Output shape: {test_output.shape}\")\n",
    "    print(f\"🎯 Model ready for training!\")\n",
    "    \n",
    "    # Clean up test model\n",
    "    del test_model, test_input, test_output\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Model test failed: {e}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(f\"✅ MAE INITIALIZATION SETUP COMPLETE!\")\n",
    "print(f\"🤖 MAE pretrained: {TRAINING_CONFIG.get('mae_pretrained', False)}\")\n",
    "print(f\"🌐 ImageNet pretrained: {TRAINING_CONFIG.get('pretrained', True)}\")\n",
    "print(f\"📊 Model: {TRAINING_CONFIG['model_name']} with {NUM_CLASSES} classes\")\n",
    "\n",
    "if TRAINING_CONFIG.get('mae_pretrained', False):\n",
    "    print(\"🎉 Your model will start with MAE-learned features specific to fish images!\")\n",
    "    print(\"🚀 This should lead to faster training and better performance!\")\n",
    "else:\n",
    "    print(\"🌐 Your model will use standard ImageNet pretrained features.\")\n",
    "\n",
    "print(\"🎯 Ready to proceed to training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a481fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: Copy MAE Model to Google Drive (if needed)\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "print(\"🔍 CHECKING MAE MODEL AVAILABILITY\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Define possible local locations (in cloned repo)\n",
    "local_mae_locations = [\n",
    "    '/content/ViT-FishID/mae_checkpoints/mae_final_model.pth',\n",
    "    '/content/ViT-FishID/mae_checkpoints/mae_best_model.pth',\n",
    "]\n",
    "\n",
    "# Define Google Drive location\n",
    "gdrive_mae_dir = '/content/drive/MyDrive/mae_checkpoints'\n",
    "os.makedirs(gdrive_mae_dir, exist_ok=True)\n",
    "\n",
    "# Check and copy MAE models if they exist locally but not in Google Drive\n",
    "for local_path in local_mae_locations:\n",
    "    model_name = os.path.basename(local_path)\n",
    "    gdrive_path = os.path.join(gdrive_mae_dir, model_name)\n",
    "    \n",
    "    if os.path.exists(local_path):\n",
    "        file_size = os.path.getsize(local_path) / (1024**2)\n",
    "        print(f\"✅ Found local MAE model: {model_name} ({file_size:.1f} MB)\")\n",
    "        \n",
    "        if not os.path.exists(gdrive_path):\n",
    "            print(f\"📥 Copying to Google Drive...\")\n",
    "            try:\n",
    "                shutil.copy2(local_path, gdrive_path)\n",
    "                print(f\"✅ Copied {model_name} to Google Drive\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error copying {model_name}: {e}\")\n",
    "        else:\n",
    "            print(f\"✅ {model_name} already exists in Google Drive\")\n",
    "    else:\n",
    "        print(f\"❌ Local MAE model not found: {model_name}\")\n",
    "\n",
    "# List available MAE models in Google Drive\n",
    "print(f\"\\n📁 Available MAE models in Google Drive:\")\n",
    "if os.path.exists(gdrive_mae_dir):\n",
    "    mae_files = [f for f in os.listdir(gdrive_mae_dir) if f.endswith('.pth')]\n",
    "    if mae_files:\n",
    "        for mae_file in mae_files:\n",
    "            file_path = os.path.join(gdrive_mae_dir, mae_file)\n",
    "            file_size = os.path.getsize(file_path) / (1024**2)\n",
    "            print(f\"  📄 {mae_file} ({file_size:.1f} MB)\")\n",
    "    else:\n",
    "        print(\"  ❌ No MAE models found in Google Drive\")\n",
    "        print(\"  📝 Please upload your MAE model manually to /content/drive/MyDrive/mae_checkpoints/\")\n",
    "else:\n",
    "    print(\"  ❌ Mae checkpoints directory not found in Google Drive\")\n",
    "\n",
    "print(\"\\n✅ MAE model check complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9cbd50",
   "metadata": {
    "id": "aa9cbd50"
   },
   "source": [
    "## 🚀 Step 8: Start Semi-Supervised Training\n",
    "\n",
    "This cell will start the complete training process. Expected time: 4-6 hours for 100 epochs.\n",
    "\n",
    "**Training Process:**\n",
    "1. **Supervised Learning**: Uses labeled fish images with ground truth\n",
    "2. **Semi-Supervised Learning**: Leverages unlabeled images with pseudo-labels\n",
    "3. **EMA Teacher-Student**: Uses exponential moving average for consistency\n",
    "4. **Automatic Checkpointing**: Saves progress every 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fffcae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a39f349",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c873987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bd6a6ca",
   "metadata": {},
   "source": [
    "## 🔄 Step 7b: Resume Training (If Interrupted)\n",
    "\n",
    "**Use this section if your training was interrupted and you want to continue from where you left off.**\n",
    "\n",
    "This will automatically find your latest checkpoint and resume training from that point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "njLKb7xaepxo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "njLKb7xaepxo",
    "outputId": "2404e35d-a058-4349-bafa-18e98981bb07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 STARTING EXTENDED TRAINING SESSION\n",
      "============================================================\n",
      "📂 Resuming from: checkpoint_epoch_99.pth\n",
      "🚀 Starting training from epoch: 100\n",
      "📊 Training for 1 more epochs...\n",
      "🎯 Target: 100 total epochs\n",
      "⏱️ Estimated time: 4-6 minutes\n",
      "💾 Checkpoints saved to: /content/drive/MyDrive/ViT-FishID/checkpoints_extended\n",
      "\n",
      "📋 Extended Training Command:\n",
      "python train.py \n",
      "    --mode semi_supervised \n",
      "    --data_dir /content/fish_cutouts \n",
      "    --epochs 100 \n",
      "    --batch_size 16 \n",
      "    --learning_rate 0.0001 \n",
      "    --weight_decay 0.05 \n",
      "    --model_name vit_base_patch16_224 \n",
      "    --consistency_weight 2.0 \n",
      "    --pseudo_label_threshold 0.7 \n",
      "    --temperature 4.0 \n",
      "    --warmup_epochs 5 \n",
      "    --ramp_up_epochs 15 \n",
      "    --save_dir /content/drive/MyDrive/ViT-FishID/checkpoints_extended \n",
      "    --save_frequency 1 \n",
      "    --resume_from /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_99.pth \n",
      "    --use_wandb \n",
      "    --pretrained\n",
      "\n",
      "============================================================\n",
      "🎬 TRAINING STARTED - EPOCH 100 TO 100\n",
      "⏰ Started at: 2025-08-15 07:03:08\n",
      "✅ Commented out line saving ema_teacher state_dict: 'ema_teacher_state_dict': trainer.ema_teacher.teacher.state_dict(),  # Fixed key name\n",
      "✅ Modified /content/ViT-FishID/trainer.py to skip saving EMA teacher state_dict.\n",
      "2025-08-15 07:03:16.032238: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-15 07:03:16.049070: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1755241396.070136    2955 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1755241396.076517    2955 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1755241396.092669    2955 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755241396.092697    2955 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755241396.092700    2955 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755241396.092703    2955 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-15 07:03:16.097419: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Random seed set to 42\n",
      "Using GPU: NVIDIA A100-SXM4-40GB\n",
      "🐟 ViT-FishID Training\n",
      "📊 Mode: semi_supervised\n",
      "🖥️  Device: cuda\n",
      "📁 Data directory: /content/fish_cutouts\n",
      "\n",
      "📦 Creating data loaders...\n",
      "⚠️  Warning: Some classes have only 1 sample(s). Using random splitting instead of stratified.\n",
      "   Classes with 1 sample: ['Carangidae_Caranx_heberi', 'Serranidae_Lipropoma_spp1', 'Sparidae_Sparodon_durbanesis']\n",
      "/content/ViT-FishID/data.py:229: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
      "📊 Dataset initialized:\n",
      "  - Labeled samples: 3,084\n",
      "  - Unlabeled samples: 6,168\n",
      "  - Total samples per epoch: 9,252\n",
      "📊 Semi-supervised data loaders created:\n",
      "  - Train labeled: 3,084\n",
      "  - Train unlabeled: 6,168\n",
      "  - Val samples: 1,029\n",
      "  - Test samples: 1,029\n",
      "  - Classes: 37\n",
      "  - Split ratios: Train=60.0%, Val=20.0%, Test=20.0%\n",
      "🏷️  Classes (37): ['Carangidae_Caranx_heberi', 'Carangidae_Pseudocaranx_dentex', 'Carangidae_Seriola_dumerili', 'Carangidae_Seriola_lalandi', 'Carangidae_Seriola_rivoliana', 'Carangidae_Trachurus_delagoa', 'Serranidae_Aulacocephalus_temminckii', 'Serranidae_Epinephelus_andersoni', 'Serranidae_Epinephelus_marginatus', 'Serranidae_Epinephelus_rivulatus', 'Serranidae_Epinephelus_tukula', 'Serranidae_Lipropoma_spp1', 'Serranidae_Serranus_knysnaensis', 'Sparidae_Argyrops_spinifer', 'Sparidae_Boopsoidea_inornata', 'Sparidae_Cheimerius_nufar', 'Sparidae_Chrysoblephus_anglicus', 'Sparidae_Chrysoblephus_cristiceps', 'Sparidae_Chrysoblephus_lophus', 'Sparidae_Chrysoblephus_puniceus', 'Sparidae_Cymatoceps_nasutus', 'Sparidae_Diplodus_capensis', 'Sparidae_Diplodus_hottentotus', 'Sparidae_Pachymetopon_aeneum', 'Sparidae_Pachymetopon_grande', 'Sparidae_Pagellus_bellottii_natalensis', 'Sparidae_Petrus_rupestris', 'Sparidae_Polyamblydon_germanum', 'Sparidae_Polysteganus_praeorbitalis', 'Sparidae_Polysteganus_undulosus', 'Sparidae_Porcostoma_dentata', 'Sparidae_Rhabdosargus_holubi', 'Sparidae_Rhabdosargus_sarba', 'Sparidae_Rhabdosargus_thorpei', 'Sparidae_Sarpa_salpa', 'Sparidae_Sparodon_durbanesis', 'Sparidae_Spondyliosoma_emarginatum']\n",
      "📊 Test set available with 1,029 samples for final evaluation\n",
      "\n",
      "🧠 Creating ViT model: vit_base_patch16_224\n",
      "model.safetensors: 100% 346M/346M [00:00<00:00, 479MB/s]\n",
      "✅ EMA Teacher initialized with momentum: 0.999\n",
      "📊 Model parameters: 85,828,645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcativthomson\u001b[0m (\u001b[33mcativthomson-university-of-cape-town\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.21.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/ViT-FishID/wandb/run-20250815_070324-ogt296e8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msemi_supervised_vit_base_patch16_224_20250815_070323\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/cativthomson-university-of-cape-town/vit-fish-id\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/cativthomson-university-of-cape-town/vit-fish-id/runs/ogt296e8\u001b[0m\n",
      "✅ W&B initialized: vit-fish-id/semi_supervised_vit_base_patch16_224_20250815_070323\n",
      "\n",
      "🚀 Creating trainer...\n",
      "✅ Semi-Supervised Trainer initialized\n",
      "  - Consistency weight: 2.0\n",
      "  - Pseudo-label threshold: 0.7\n",
      "  - Learning rate: 0.0001\n",
      "  - Warmup epochs: 5\n",
      "  - Ramp-up epochs: 15\n",
      "📥 Resuming from checkpoint: /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_99.pth\n",
      "✅ Successfully loaded checkpoint from epoch 99\n",
      "📊 Previous best accuracy: 87.56073858114675\n",
      "🚀 Resuming training from epoch 100\n",
      "\n",
      "🎯 Starting semi_supervised training...\n",
      "💡 Note: Test set is reserved for final evaluation and not used during training\n",
      "🔄 Resuming training from epoch 100\n",
      "⏰ Remaining epochs: 1\n",
      "📁 Checkpoints will be saved to: /content/drive/MyDrive/ViT-FishID/checkpoints_extended\n",
      "Epoch 100: 100% 578/578 [01:37<00:00,  5.93it/s, Total=0.1759, Sup=0.1095, Cons=0.0332, L-Acc=97.0%, P-Acc=88.2%]\n",
      "                                               \n",
      "📊 Epoch 101/100\n",
      "Train - Total Loss: 0.1759\n",
      "Train - Labeled Acc: 97.0%, Pseudo Acc: 88.2%\n",
      "Train - High-conf Pseudo: 1212/6165 (19.7%)\n",
      "Student Val - Acc: 77.9%\n",
      "Teacher Val - Acc: 75.7%\n",
      "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_100.pth\n",
      "💾 Backup saved to: /content/drive/MyDrive/ViT-FishID/checkpoints_backup/checkpoint_epoch_100.pth\n",
      "📊 Epoch 100 checkpoint saved (Size: 982.4 MB)\n",
      "\n",
      "🎉 Training completed! Best validation accuracy: 87.56%\n",
      "\n",
      "✅ Training completed!\n",
      "💡 Use evaluate.py with the test set for final unbiased performance metrics\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading history steps 12-12, summary, console lines 19-35 (0.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading history steps 12-12, summary, console lines 19-35 (0.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading history steps 12-12, summary, console lines 19-35 (0.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading history steps 12-12, summary, console lines 19-35 (0.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading history steps 12-12, summary, console lines 19-35 (0.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading history steps 12-12, summary, console lines 19-35 (0.1s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               epoch ▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                       learning_rate ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              train/consistency_loss █▃▇▄▅▃▂▂▂▂▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train/consistency_weight ▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               train/high_conf_ratio ▁▁▁▁▁▂▃▄▅▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              train/labeled_accuracy █▂▁▂▃▄▄▃▃▃▃▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 train/learning_rate ▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               train/pseudo_accuracy ▁▁▁█████▇▇▇▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               train/supervised_loss ▁▁▁▁▁▁▁█▃▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/total_loss ▃▁▂▂▂▁▁█▃▁▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        train_epoch/consistency_loss ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_epoch/high_conf_pseudo_labels ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        train_epoch/labeled_accuracy ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train_epoch/labeled_samples ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train_epoch/pseudo_accuracy ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train_epoch/supervised_loss ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              train_epoch/total_loss ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train_epoch/unlabeled_samples ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                val/student_top1_acc ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                val/student_top5_acc ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                val/teacher_top1_acc ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                val/teacher_top5_acc ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               epoch 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                       learning_rate 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              train/consistency_loss 0.02646\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train/consistency_weight 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               train/high_conf_ratio 18.24359\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              train/labeled_accuracy 97.0297\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 train/learning_rate 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               train/pseudo_accuracy 88.6406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               train/supervised_loss 0.03465\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/total_loss 0.08756\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        train_epoch/consistency_loss 0.03318\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_epoch/high_conf_pseudo_labels 1212\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        train_epoch/labeled_accuracy 97.04833\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train_epoch/labeled_samples 3083\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train_epoch/pseudo_accuracy 88.20132\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train_epoch/supervised_loss 0.10952\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              train_epoch/total_loss 0.17589\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train_epoch/unlabeled_samples 6165\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                val/student_top1_acc 77.93975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                val/student_top5_acc 92.80855\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                val/teacher_top1_acc 75.70457\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                val/teacher_top5_acc 94.94655\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33msemi_supervised_vit_base_patch16_224_20250815_070323\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/cativthomson-university-of-cape-town/vit-fish-id/runs/ogt296e8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/cativthomson-university-of-cape-town/vit-fish-id\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250815_070324-ogt296e8/logs\u001b[0m\n",
      "\n",
      "🎉 Training completed successfully!\n",
      "💾 Checkpoints saved to: /content/drive/MyDrive/ViT-FishID/checkpoints_extended\n",
      "🏆 Best accuracy: 87.56%\n",
      "\n",
      "============================================================\n",
      "🎉 EXTENDED TRAINING COMPLETED!\n",
      "⏰ Finished at: 2025-08-15 07:05:32\n",
      "🏆 Total epochs completed: 100\n",
      "💾 All checkpoints saved to Google Drive\n",
      "\n",
      "✅ Your model is ready for evaluation and deployment!\n"
     ]
    }
   ],
   "source": [
    "# Start Semi-Supervised Training with Optional MAE Initialization\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"🚀 STARTING SEMI-SUPERVISED FISH CLASSIFICATION TRAINING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Change to repository directory\n",
    "%cd /content/ViT-FishID\n",
    "\n",
    "# Check for existing checkpoints to resume from\n",
    "RESUME_FROM = None\n",
    "if os.path.exists(TRAINING_CONFIG['checkpoint_dir']):\n",
    "    checkpoints = glob.glob(os.path.join(TRAINING_CONFIG['checkpoint_dir'], 'checkpoint_epoch_*.pth'))\n",
    "    if checkpoints:\n",
    "        # Find the latest checkpoint\n",
    "        epoch_numbers = []\n",
    "        for cp in checkpoints:\n",
    "            try:\n",
    "                epoch_num = int(cp.split('epoch_')[1].split('.')[0])\n",
    "                epoch_numbers.append((epoch_num, cp))\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        if epoch_numbers:\n",
    "            epoch_numbers.sort(key=lambda x: x[0], reverse=True)  # Latest first\n",
    "            latest_epoch, latest_checkpoint = epoch_numbers[0]\n",
    "            print(f\"🔍 Found existing checkpoints. Latest: Epoch {latest_epoch}\")\n",
    "            \n",
    "            # Ask user if they want to resume (auto-skip in Colab for now)\n",
    "            # resume_choice = input(\"Do you want to resume from the latest checkpoint? (y/n): \").lower().strip()\n",
    "            resume_choice = 'n'  # Set to 'y' if you want to auto-resume\n",
    "            \n",
    "            if resume_choice in ['y', 'yes']:\n",
    "                RESUME_FROM = latest_checkpoint\n",
    "                print(f\"✅ Will resume from: {os.path.basename(latest_checkpoint)}\")\n",
    "            else:\n",
    "                print(\"🆕 Starting fresh training from epoch 1\")\n",
    "\n",
    "# Create a modified training script if we have MAE weights\n",
    "if TRAINING_CONFIG.get('mae_pretrained', False) and 'MAE_ENCODER_WEIGHTS' in globals() and MAE_ENCODER_WEIGHTS is not None:\n",
    "    print(\"🤖 Creating MAE-enhanced training script...\")\n",
    "    \n",
    "    # Create custom train script that initializes with MAE weights\n",
    "    mae_train_script = \"\"\"#!/usr/bin/env python3\n",
    "import sys\n",
    "sys.path.append('/content/ViT-FishID')\n",
    "\n",
    "import torch\n",
    "import argparse\n",
    "from model import ViTForFishClassification\n",
    "\n",
    "# Function to create MAE-initialized model\n",
    "def create_mae_initialized_model(num_classes, model_name, mae_weights):\n",
    "    model = ViTForFishClassification(\n",
    "        num_classes=num_classes,\n",
    "        model_name=model_name,\n",
    "        pretrained=False,  # Don't use ImageNet\n",
    "        dropout_rate=0.1\n",
    "    )\n",
    "    \n",
    "    if mae_weights is not None:\n",
    "        backbone_state = model.backbone.state_dict()\n",
    "        updated_keys = []\n",
    "        \n",
    "        for mae_key, mae_weight in mae_weights.items():\n",
    "            if mae_key in backbone_state:\n",
    "                if mae_weight.shape == backbone_state[mae_key].shape:\n",
    "                    backbone_state[mae_key] = mae_weight.clone()\n",
    "                    updated_keys.append(mae_key)\n",
    "        \n",
    "        model.backbone.load_state_dict(backbone_state)\n",
    "        print(f\"✅ Loaded {len(updated_keys)} MAE encoder weights into model\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Load MAE weights\n",
    "mae_checkpoint = torch.load('{}', map_location='cpu')\n",
    "mae_state_dict = mae_checkpoint.get('model_state_dict', mae_checkpoint.get('state_dict', mae_checkpoint))\n",
    "\n",
    "mae_weights = {{}}\n",
    "for key, value in mae_state_dict.items():\n",
    "    if any(prefix in key for prefix in ['patch_embed', 'pos_embed', 'cls_token', 'blocks', 'norm']) and not any(exclude in key for exclude in ['decoder', 'mask_token', 'head']):\n",
    "        mae_weights[key] = value\n",
    "\n",
    "print(f\"🤖 Loaded {{len(mae_weights)}} MAE encoder weights\")\n",
    "\n",
    "# Now run the original training with MAE initialization\n",
    "\"\"\".format(TRAINING_CONFIG.get('mae_model_path', ''))\n",
    "    \n",
    "    # Write the custom script\n",
    "    with open('/content/mae_init_prefix.py', 'w') as f:\n",
    "        f.write(mae_train_script)\n",
    "    \n",
    "    # Build training command with MAE initialization\n",
    "    training_cmd = f\"\"\"python -c \"\n",
    "import sys\n",
    "sys.path.append('/content/ViT-FishID')\n",
    "exec(open('/content/mae_init_prefix.py').read())\n",
    "\n",
    "# Now import and run training\n",
    "from train import *\n",
    "import torch\n",
    "\n",
    "# Override model creation in train.py\n",
    "original_args = parse_arguments()\n",
    "\n",
    "# Parse our arguments\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.mode = '{TRAINING_CONFIG['mode']}'\n",
    "        self.data_dir = '{TRAINING_CONFIG['data_dir']}'\n",
    "        self.epochs = {TRAINING_CONFIG['epochs']}\n",
    "        self.batch_size = {TRAINING_CONFIG['batch_size']}\n",
    "        self.learning_rate = {TRAINING_CONFIG['learning_rate']}\n",
    "        self.weight_decay = {TRAINING_CONFIG['weight_decay']}\n",
    "        self.model_name = '{TRAINING_CONFIG['model_name']}'\n",
    "        self.consistency_weight = {TRAINING_CONFIG['consistency_weight']}\n",
    "        self.pseudo_label_threshold = {TRAINING_CONFIG['pseudo_label_threshold']}\n",
    "        self.temperature = {TRAINING_CONFIG['temperature']}\n",
    "        self.warmup_epochs = {TRAINING_CONFIG['warmup_epochs']}\n",
    "        self.ramp_up_epochs = {TRAINING_CONFIG['ramp_up_epochs']}\n",
    "        self.save_dir = '{TRAINING_CONFIG['checkpoint_dir']}'\n",
    "        self.save_frequency = {TRAINING_CONFIG['save_frequency']}\n",
    "        self.pretrained = False\n",
    "        self.use_wandb = {str(TRAINING_CONFIG['use_wandb']).lower()}\n",
    "        self.resume_from = {'None' if not RESUME_FROM else f'\\\\'{RESUME_FROM}\\\\''}\n",
    "        self.num_workers = 4\n",
    "        self.image_size = 224\n",
    "        self.dropout_rate = 0.1\n",
    "        self.num_classes = {NUM_CLASSES}\n",
    "        \n",
    "args = Args()\n",
    "\n",
    "# Set up device and seed\n",
    "device = get_device()\n",
    "set_seed(42)\n",
    "\n",
    "# Create MAE-initialized model\n",
    "print('🤖 Creating MAE-initialized model for training...')\n",
    "student_model = create_mae_initialized_model(\n",
    "    num_classes=args.num_classes,\n",
    "    model_name=args.model_name,\n",
    "    mae_weights=mae_weights\n",
    ").to(device)\n",
    "\n",
    "# Continue with regular training process\n",
    "from trainer import EMATrainer, SemiSupervisedTrainer\n",
    "from data import create_dataloaders, create_semi_supervised_dataloaders\n",
    "\n",
    "# Create data loaders\n",
    "if args.mode == 'supervised':\n",
    "    train_loader, val_loader, num_classes = create_dataloaders(\n",
    "        args.data_dir,\n",
    "        batch_size=args.batch_size,\n",
    "        image_size=args.image_size,\n",
    "        num_workers=args.num_workers\n",
    "    )\n",
    "    unlabeled_loader = None\n",
    "else:\n",
    "    train_loader, val_loader, unlabeled_loader, num_classes = create_semi_supervised_dataloaders(\n",
    "        args.data_dir,\n",
    "        batch_size=args.batch_size,\n",
    "        image_size=args.image_size,\n",
    "        num_workers=args.num_workers\n",
    "    )\n",
    "\n",
    "print(f'📊 Number of classes: {{num_classes}}')\n",
    "print(f'🎯 Training mode: {{args.mode}}')\n",
    "\n",
    "# Create trainer\n",
    "if args.mode == 'semi_supervised' and unlabeled_loader is not None:\n",
    "    trainer = SemiSupervisedTrainer(\n",
    "        student_model=student_model,\n",
    "        device=device,\n",
    "        learning_rate=args.learning_rate,\n",
    "        weight_decay=args.weight_decay,\n",
    "        consistency_weight=args.consistency_weight,\n",
    "        pseudo_label_threshold=args.pseudo_label_threshold,\n",
    "        temperature=args.temperature,\n",
    "        warmup_epochs=args.warmup_epochs,\n",
    "        ramp_up_epochs=args.ramp_up_epochs\n",
    "    )\n",
    "else:\n",
    "    trainer = EMATrainer(\n",
    "        student_model=student_model,\n",
    "        device=device,\n",
    "        learning_rate=args.learning_rate,\n",
    "        weight_decay=args.weight_decay\n",
    "    )\n",
    "\n",
    "# Initialize W&B\n",
    "if args.use_wandb:\n",
    "    import wandb\n",
    "    wandb.init(\n",
    "        project='ViT-FishID-MAE-Training',\n",
    "        config=vars(args),\n",
    "        tags=['mae-initialized', 'fish-classification']\n",
    "    )\n",
    "\n",
    "# Resume from checkpoint if specified\n",
    "if args.resume_from and args.resume_from != 'None':\n",
    "    print(f'📥 Resuming from checkpoint: {{args.resume_from}}')\n",
    "    try:\n",
    "        checkpoint = torch.load(args.resume_from, map_location=device)\n",
    "        trainer.student_model.load_state_dict(checkpoint['student_state_dict'])\n",
    "        if hasattr(trainer, 'teacher_model') and 'teacher_state_dict' in checkpoint:\n",
    "            trainer.teacher_model.teacher_model.load_state_dict(checkpoint['teacher_state_dict'])\n",
    "        trainer.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint.get('epoch', 0) + 1\n",
    "        print(f'✅ Resumed from epoch {{start_epoch}}')\n",
    "    except Exception as e:\n",
    "        print(f'❌ Error loading checkpoint: {{e}}')\n",
    "        start_epoch = 1\n",
    "else:\n",
    "    start_epoch = 1\n",
    "\n",
    "print(f'🚀 Starting training from epoch {{start_epoch}}')\n",
    "\n",
    "# Training loop\n",
    "best_accuracy = 0.0\n",
    "for epoch in range(start_epoch, args.epochs + 1):\n",
    "    print(f'\\\\n📅 Epoch {{epoch}}/{{args.epochs}}')\n",
    "    \n",
    "    # Training\n",
    "    if args.mode == 'semi_supervised' and unlabeled_loader is not None:\n",
    "        train_loss = trainer.train_epoch(train_loader, unlabeled_loader, epoch)\n",
    "    else:\n",
    "        train_loss = trainer.train_epoch(train_loader, epoch)\n",
    "    \n",
    "    # Validation\n",
    "    val_accuracy = trainer.validate(val_loader)\n",
    "    \n",
    "    # Update best accuracy\n",
    "    is_best = val_accuracy > best_accuracy\n",
    "    if is_best:\n",
    "        best_accuracy = val_accuracy\n",
    "    \n",
    "    print(f'📊 Epoch {{epoch}} - Train Loss: {{train_loss:.4f}}, Val Acc: {{val_accuracy:.2f}}% (Best: {{best_accuracy:.2f}}%)')\n",
    "    \n",
    "    # Save checkpoint\n",
    "    if epoch % args.save_frequency == 0 or is_best:\n",
    "        checkpoint_data = {{\n",
    "            'epoch': epoch,\n",
    "            'student_state_dict': trainer.student_model.state_dict(),\n",
    "            'optimizer_state_dict': trainer.optimizer.state_dict(),\n",
    "            'best_accuracy': best_accuracy,\n",
    "            'train_loss': train_loss,\n",
    "            'val_accuracy': val_accuracy\n",
    "        }}\n",
    "        \n",
    "        if hasattr(trainer, 'teacher_model'):\n",
    "            checkpoint_data['teacher_state_dict'] = trainer.teacher_model.teacher_model.state_dict()\n",
    "            checkpoint_data['teacher_acc'] = getattr(trainer, 'teacher_accuracy', val_accuracy)\n",
    "        \n",
    "        # Save regular checkpoint\n",
    "        if epoch % args.save_frequency == 0:\n",
    "            checkpoint_path = os.path.join(args.save_dir, f'checkpoint_epoch_{{epoch}}.pth')\n",
    "            torch.save(checkpoint_data, checkpoint_path)\n",
    "            print(f'💾 Saved checkpoint: {{checkpoint_path}}')\n",
    "        \n",
    "        # Save best model\n",
    "        if is_best:\n",
    "            best_path = os.path.join(args.save_dir, 'model_best.pth')\n",
    "            torch.save(checkpoint_data, best_path)\n",
    "            print(f'🏆 New best model saved: {{best_path}}')\n",
    "    \n",
    "    # W&B logging\n",
    "    if args.use_wandb:\n",
    "        wandb.log({{\n",
    "            'epoch': epoch,\n",
    "            'train_loss': train_loss,\n",
    "            'val_accuracy': val_accuracy,\n",
    "            'best_accuracy': best_accuracy\n",
    "        }})\n",
    "\n",
    "print(f'\\\\n🎉 Training completed!')\n",
    "print(f'🏆 Best accuracy: {{best_accuracy:.2f}}%')\n",
    "\n",
    "if args.use_wandb:\n",
    "    wandb.finish()\n",
    "\" \"\"\"\n",
    "\n",
    "else:\n",
    "    # Build standard training command without MAE\n",
    "    training_cmd = f\"\"\"python train.py \\\\\n",
    "    --mode {TRAINING_CONFIG['mode']} \\\\\n",
    "    --data_dir {TRAINING_CONFIG['data_dir']} \\\\\n",
    "    --epochs {TRAINING_CONFIG['epochs']} \\\\\n",
    "    --batch_size {TRAINING_CONFIG['batch_size']} \\\\\n",
    "    --learning_rate {TRAINING_CONFIG['learning_rate']} \\\\\n",
    "    --weight_decay {TRAINING_CONFIG['weight_decay']} \\\\\n",
    "    --model_name {TRAINING_CONFIG['model_name']} \\\\\n",
    "    --consistency_weight {TRAINING_CONFIG['consistency_weight']} \\\\\n",
    "    --pseudo_label_threshold {TRAINING_CONFIG['pseudo_label_threshold']} \\\\\n",
    "    --temperature {TRAINING_CONFIG['temperature']} \\\\\n",
    "    --warmup_epochs {TRAINING_CONFIG['warmup_epochs']} \\\\\n",
    "    --ramp_up_epochs {TRAINING_CONFIG['ramp_up_epochs']} \\\\\n",
    "    --save_dir {TRAINING_CONFIG['checkpoint_dir']} \\\\\n",
    "    --save_frequency {TRAINING_CONFIG['save_frequency']}\"\"\"\n",
    "\n",
    "    # Add resume checkpoint if found\n",
    "    if RESUME_FROM:\n",
    "        training_cmd += f\" \\\\\\n    --resume_from {RESUME_FROM}\"\n",
    "\n",
    "    # Add pretrained flag\n",
    "    if TRAINING_CONFIG['pretrained']:\n",
    "        training_cmd += \" \\\\\\n    --pretrained\"\n",
    "\n",
    "    # Add W&B logging\n",
    "    if TRAINING_CONFIG['use_wandb']:\n",
    "        training_cmd += \" \\\\\\n    --use_wandb\"\n",
    "\n",
    "print(\"📋 TRAINING CONFIGURATION:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"🎯 Training {TRAINING_CONFIG['num_classes']} fish species\")\n",
    "print(f\"📊 Mode: {TRAINING_CONFIG['mode']}\")\n",
    "print(f\"🤖 MAE pretrained: {TRAINING_CONFIG.get('mae_pretrained', False)}\")\n",
    "print(f\"🌐 ImageNet pretrained: {TRAINING_CONFIG.get('pretrained', True)}\")\n",
    "\n",
    "if RESUME_FROM:\n",
    "    print(f\"🔄 Resuming from: {os.path.basename(RESUME_FROM)}\")\n",
    "else:\n",
    "    print(f\"🆕 Starting fresh training\")\n",
    "\n",
    "print(f\"⏱️ Estimated time: {TRAINING_CONFIG['epochs'] * 3 / 60:.1f} hours\")\n",
    "print(f\"💾 Checkpoints: {TRAINING_CONFIG['checkpoint_dir']}\")\n",
    "print(f\"📈 W&B logging: {TRAINING_CONFIG['use_wandb']}\")\n",
    "\n",
    "if TRAINING_CONFIG.get('mae_pretrained', False):\n",
    "    print(f\"🎉 Using MAE-learned features from: {os.path.basename(TRAINING_CONFIG.get('mae_model_path', ''))}\")\n",
    "    print(f\"🚀 This should significantly improve training performance!\")\n",
    "\n",
    "print(f\"\\n🎬 TRAINING STARTED\")\n",
    "print(\"⏰ Started at:\", datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "# Execute training\n",
    "!{training_cmd}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🎉 TRAINING COMPLETED!\")\n",
    "print(\"⏰ Finished at:\", datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "# Check for results\n",
    "best_model_path = os.path.join(TRAINING_CONFIG['checkpoint_dir'], 'model_best.pth')\n",
    "if os.path.exists(best_model_path):\n",
    "    try:\n",
    "        import torch\n",
    "        checkpoint = torch.load(best_model_path, map_location='cpu')\n",
    "        if 'best_accuracy' in checkpoint:\n",
    "            print(f\"🏆 Best accuracy achieved: {checkpoint['best_accuracy']:.2f}%\")\n",
    "        if 'epoch' in checkpoint:\n",
    "            print(f\"📊 Best model from epoch: {checkpoint['epoch']}\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(\"✅ Your MAE-enhanced model is ready for evaluation and deployment!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5af5177",
   "metadata": {
    "id": "b5af5177"
   },
   "source": [
    "## 📊 Step 9: Check Training Results\n",
    "\n",
    "Review the training progress and model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ea96e8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "87ea96e8",
    "outputId": "2054291d-a4ae-48d9-d5ed-2529032142bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 Checking results in: /content/drive/MyDrive/ViT-FishID/checkpoints_extended\n",
      "\n",
      "✅ Found 100 checkpoint(s) from extended training:\n",
      "  📊 Epoch 1: checkpoint_epoch_1.pth (982.4 MB)\n",
      "  📊 Epoch 2: checkpoint_epoch_2.pth (982.4 MB)\n",
      "  📊 Epoch 3: checkpoint_epoch_3.pth (982.4 MB)\n",
      "  📊 Epoch 4: checkpoint_epoch_4.pth (982.4 MB)\n",
      "  📊 Epoch 5: checkpoint_epoch_5.pth (982.4 MB)\n",
      "  📊 Epoch 6: checkpoint_epoch_6.pth (982.4 MB)\n",
      "  📊 Epoch 7: checkpoint_epoch_7.pth (982.4 MB)\n",
      "  📊 Epoch 8: checkpoint_epoch_8.pth (982.4 MB)\n",
      "  📊 Epoch 9: checkpoint_epoch_9.pth (982.4 MB)\n",
      "  📊 Epoch 10: checkpoint_epoch_10.pth (982.4 MB)\n",
      "  📊 Epoch 11: checkpoint_epoch_11.pth (982.4 MB)\n",
      "  📊 Epoch 12: checkpoint_epoch_12.pth (982.4 MB)\n",
      "  📊 Epoch 13: checkpoint_epoch_13.pth (982.4 MB)\n",
      "  📊 Epoch 14: checkpoint_epoch_14.pth (982.4 MB)\n",
      "  📊 Epoch 15: checkpoint_epoch_15.pth (982.4 MB)\n",
      "  📊 Epoch 16: checkpoint_epoch_16.pth (982.4 MB)\n",
      "  📊 Epoch 17: checkpoint_epoch_17.pth (982.4 MB)\n",
      "  📊 Epoch 18: checkpoint_epoch_18.pth (982.4 MB)\n",
      "  📊 Epoch 19: checkpoint_epoch_19.pth (982.4 MB)\n",
      "  📊 Epoch 20: checkpoint_epoch_20.pth (982.4 MB)\n",
      "  📊 Epoch 21: checkpoint_epoch_21.pth (982.4 MB)\n",
      "  📊 Epoch 22: checkpoint_epoch_22.pth (982.4 MB)\n",
      "  📊 Epoch 23: checkpoint_epoch_23.pth (982.4 MB)\n",
      "  📊 Epoch 24: checkpoint_epoch_24.pth (982.4 MB)\n",
      "  📊 Epoch 25: checkpoint_epoch_25.pth (982.4 MB)\n",
      "  📊 Epoch 26: checkpoint_epoch_26.pth (982.4 MB)\n",
      "  📊 Epoch 27: checkpoint_epoch_27.pth (982.4 MB)\n",
      "  📊 Epoch 28: checkpoint_epoch_28.pth (982.4 MB)\n",
      "  📊 Epoch 29: checkpoint_epoch_29.pth (982.4 MB)\n",
      "  📊 Epoch 30: checkpoint_epoch_30.pth (982.4 MB)\n",
      "  📊 Epoch 31: checkpoint_epoch_31.pth (982.4 MB)\n",
      "  📊 Epoch 32: checkpoint_epoch_32.pth (982.4 MB)\n",
      "  📊 Epoch 33: checkpoint_epoch_33.pth (982.4 MB)\n",
      "  📊 Epoch 34: checkpoint_epoch_34.pth (982.4 MB)\n",
      "  📊 Epoch 35: checkpoint_epoch_35.pth (982.4 MB)\n",
      "  📊 Epoch 36: checkpoint_epoch_36.pth (982.4 MB)\n",
      "  📊 Epoch 37: checkpoint_epoch_37.pth (982.4 MB)\n",
      "  📊 Epoch 38: checkpoint_epoch_38.pth (982.4 MB)\n",
      "  📊 Epoch 39: checkpoint_epoch_39.pth (982.4 MB)\n",
      "  📊 Epoch 40: checkpoint_epoch_40.pth (982.4 MB)\n",
      "  📊 Epoch 41: checkpoint_epoch_41.pth (982.4 MB)\n",
      "  📊 Epoch 42: checkpoint_epoch_42.pth (982.4 MB)\n",
      "  📊 Epoch 43: checkpoint_epoch_43.pth (982.4 MB)\n",
      "  📊 Epoch 44: checkpoint_epoch_44.pth (982.4 MB)\n",
      "  📊 Epoch 45: checkpoint_epoch_45.pth (982.4 MB)\n",
      "  📊 Epoch 46: checkpoint_epoch_46.pth (982.4 MB)\n",
      "  📊 Epoch 47: checkpoint_epoch_47.pth (982.4 MB)\n",
      "  📊 Epoch 48: checkpoint_epoch_48.pth (982.4 MB)\n",
      "  📊 Epoch 49: checkpoint_epoch_49.pth (982.4 MB)\n",
      "  📊 Epoch 50: checkpoint_epoch_50.pth (982.4 MB)\n",
      "  📊 Epoch 51: checkpoint_epoch_51.pth (982.4 MB)\n",
      "  📊 Epoch 52: checkpoint_epoch_52.pth (982.4 MB)\n",
      "  📊 Epoch 53: checkpoint_epoch_53.pth (982.4 MB)\n",
      "  📊 Epoch 54: checkpoint_epoch_54.pth (982.4 MB)\n",
      "  📊 Epoch 55: checkpoint_epoch_55.pth (982.4 MB)\n",
      "  📊 Epoch 56: checkpoint_epoch_56.pth (982.4 MB)\n",
      "  📊 Epoch 57: checkpoint_epoch_57.pth (982.4 MB)\n",
      "  📊 Epoch 58: checkpoint_epoch_58.pth (982.4 MB)\n",
      "  📊 Epoch 59: checkpoint_epoch_59.pth (982.4 MB)\n",
      "  📊 Epoch 60: checkpoint_epoch_60.pth (982.4 MB)\n",
      "  📊 Epoch 61: checkpoint_epoch_61.pth (982.4 MB)\n",
      "  📊 Epoch 62: checkpoint_epoch_62.pth (982.4 MB)\n",
      "  📊 Epoch 63: checkpoint_epoch_63.pth (982.4 MB)\n",
      "  📊 Epoch 64: checkpoint_epoch_64.pth (982.4 MB)\n",
      "  📊 Epoch 65: checkpoint_epoch_65.pth (982.4 MB)\n",
      "  📊 Epoch 66: checkpoint_epoch_66.pth (982.4 MB)\n",
      "  📊 Epoch 67: checkpoint_epoch_67.pth (982.4 MB)\n",
      "  📊 Epoch 68: checkpoint_epoch_68.pth (982.4 MB)\n",
      "  📊 Epoch 69: checkpoint_epoch_69.pth (982.4 MB)\n",
      "  📊 Epoch 70: checkpoint_epoch_70.pth (982.4 MB)\n",
      "  📊 Epoch 71: checkpoint_epoch_71.pth (982.4 MB)\n",
      "  📊 Epoch 72: checkpoint_epoch_72.pth (982.4 MB)\n",
      "  📊 Epoch 73: checkpoint_epoch_73.pth (982.4 MB)\n",
      "  📊 Epoch 74: checkpoint_epoch_74.pth (982.4 MB)\n",
      "  📊 Epoch 75: checkpoint_epoch_75.pth (982.4 MB)\n",
      "  📊 Epoch 76: checkpoint_epoch_76.pth (982.4 MB)\n",
      "  📊 Epoch 77: checkpoint_epoch_77.pth (982.4 MB)\n",
      "  📊 Epoch 78: checkpoint_epoch_78.pth (982.4 MB)\n",
      "  📊 Epoch 79: checkpoint_epoch_79.pth (982.4 MB)\n",
      "  📊 Epoch 80: checkpoint_epoch_80.pth (982.4 MB)\n",
      "  📊 Epoch 81: checkpoint_epoch_81.pth (982.4 MB)\n",
      "  📊 Epoch 82: checkpoint_epoch_82.pth (982.4 MB)\n",
      "  📊 Epoch 83: checkpoint_epoch_83.pth (982.4 MB)\n",
      "  📊 Epoch 84: checkpoint_epoch_84.pth (982.4 MB)\n",
      "  📊 Epoch 85: checkpoint_epoch_85.pth (982.4 MB)\n",
      "  📊 Epoch 86: checkpoint_epoch_86.pth (982.4 MB)\n",
      "  📊 Epoch 87: checkpoint_epoch_87.pth (982.4 MB)\n",
      "  📊 Epoch 88: checkpoint_epoch_88.pth (982.4 MB)\n",
      "  📊 Epoch 89: checkpoint_epoch_89.pth (982.4 MB)\n",
      "  📊 Epoch 90: checkpoint_epoch_90.pth (982.4 MB)\n",
      "  📊 Epoch 91: checkpoint_epoch_91.pth (982.4 MB)\n",
      "  📊 Epoch 92: checkpoint_epoch_92.pth (982.4 MB)\n",
      "  📊 Epoch 93: checkpoint_epoch_93.pth (982.4 MB)\n",
      "  📊 Epoch 94: checkpoint_epoch_94.pth (982.4 MB)\n",
      "  📊 Epoch 95: checkpoint_epoch_95.pth (982.4 MB)\n",
      "  📊 Epoch 96: checkpoint_epoch_96.pth (982.4 MB)\n",
      "  📊 Epoch 97: checkpoint_epoch_97.pth (982.4 MB)\n",
      "  📊 Epoch 98: checkpoint_epoch_98.pth (982.4 MB)\n",
      "  📊 Epoch 99: checkpoint_epoch_99.pth (982.4 MB)\n",
      "  📊 Epoch 100: checkpoint_epoch_100.pth (982.4 MB)\n",
      "\n",
      "⏱️ EXTENDED TRAINING SUMMARY:\n",
      "  📊 Additional epochs completed: 81\n",
      "  🎯 Target was: 81 additional epochs (to reach 100 total)\n",
      "  ✅ TRAINING GOAL ACHIEVED! Completed all 81 additional epochs\n",
      "\n",
      "📈 View detailed training metrics:\n",
      "   https://wandb.ai/your-username/ViT-FishID-Extended-Training\n",
      "   Run: resume-epoch-6-to-100\n",
      "\n",
      "🎉 Extended training session complete!\n",
      "🚀 Your model trained from epoch 19 to 100!\n",
      "💾 All results saved to Google Drive: /content/drive/MyDrive/ViT-FishID/checkpoints_extended\n",
      "\n",
      "📊 PERFORMANCE COMPARISON:\n",
      "  🔄 Previous (Epoch 19): ~78% accuracy\n",
      "  🎯 Extended (Epoch 100): Check best_accuracy above\n",
      "  📈 Expected improvement: 5-10% accuracy gain\n",
      "  🏆 Your model should now be ready for deployment!\n"
     ]
    }
   ],
   "source": [
    "# Check Training Results and Performance\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"📊 CHECKING TRAINING RESULTS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "checkpoint_dir = TRAINING_CONFIG['checkpoint_dir']\n",
    "print(f\"📁 Checkpoint directory: {checkpoint_dir}\")\n",
    "\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    # Find all checkpoints\n",
    "    checkpoints = glob.glob(os.path.join(checkpoint_dir, '*.pth'))\n",
    "    \n",
    "    if checkpoints:\n",
    "        print(f\"✅ Found {len(checkpoints)} checkpoint(s)\")\n",
    "        \n",
    "        # Sort checkpoints by epoch\n",
    "        epoch_checkpoints = []\n",
    "        other_checkpoints = []\n",
    "        \n",
    "        for cp in checkpoints:\n",
    "            basename = os.path.basename(cp)\n",
    "            if 'epoch_' in basename:\n",
    "                try:\n",
    "                    epoch_num = int(basename.split('epoch_')[1].split('.')[0])\n",
    "                    epoch_checkpoints.append((epoch_num, cp))\n",
    "                except:\n",
    "                    other_checkpoints.append(cp)\n",
    "            else:\n",
    "                other_checkpoints.append(cp)\n",
    "        \n",
    "        # Show epoch progression\n",
    "        if epoch_checkpoints:\n",
    "            epoch_checkpoints.sort(key=lambda x: x[0])\n",
    "            print(f\"\\n📈 TRAINING PROGRESSION:\")\n",
    "            latest_epoch = epoch_checkpoints[-1][0]\n",
    "            print(f\"  🏁 Latest epoch: {latest_epoch}\")\n",
    "            print(f\"  📊 Completion: {latest_epoch}/{TRAINING_CONFIG['epochs']} epochs ({latest_epoch/TRAINING_CONFIG['epochs']*100:.1f}%)\")\n",
    "            \n",
    "            # Show recent checkpoints\n",
    "            recent_checkpoints = epoch_checkpoints[-5:] if len(epoch_checkpoints) > 5 else epoch_checkpoints\n",
    "            for epoch, cp in recent_checkpoints:\n",
    "                file_size = os.path.getsize(cp) / (1024**2)\n",
    "                print(f\"  📄 Epoch {epoch}: {file_size:.1f} MB\")\n",
    "        \n",
    "        # Analyze best model\n",
    "        best_model_path = os.path.join(checkpoint_dir, 'model_best.pth')\n",
    "        if os.path.exists(best_model_path):\n",
    "            print(f\"\\n🏆 BEST MODEL ANALYSIS:\")\n",
    "            try:\n",
    "                best_checkpoint = torch.load(best_model_path, map_location='cpu')\n",
    "                \n",
    "                best_epoch = best_checkpoint.get('epoch', 'Unknown')\n",
    "                best_acc = best_checkpoint.get('best_accuracy', best_checkpoint.get('best_acc', 'Unknown'))\n",
    "                \n",
    "                print(f\"  📊 Best epoch: {best_epoch}\")\n",
    "                if isinstance(best_acc, (int, float)):\n",
    "                    print(f\"  🎯 Best accuracy: {best_acc:.2f}%\")\n",
    "                    \n",
    "                    # Performance assessment\n",
    "                    if best_acc >= 85:\n",
    "                        print(\"  🎉 EXCELLENT performance!\")\n",
    "                    elif best_acc >= 75:\n",
    "                        print(\"  👍 GOOD performance!\")\n",
    "                    elif best_acc >= 65:\n",
    "                        print(\"  📈 FAIR performance - consider more training\")\n",
    "                    else:\n",
    "                        print(\"  ⚠️ LOW performance - check data and hyperparameters\")\n",
    "                \n",
    "                # Check for other metrics\n",
    "                if 'teacher_acc' in best_checkpoint:\n",
    "                    print(f\"  🎓 Teacher accuracy: {best_checkpoint['teacher_acc']:.2f}%\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  ⚠️ Could not analyze best model: {e}\")\n",
    "        \n",
    "        # Show other important files\n",
    "        for cp in other_checkpoints:\n",
    "            basename = os.path.basename(cp)\n",
    "            file_size = os.path.getsize(cp) / (1024**2)\n",
    "            print(f\"  📄 {basename}: {file_size:.1f} MB\")\n",
    "    \n",
    "    else:\n",
    "        print(\"❌ No checkpoints found\")\n",
    "        print(\"💡 Training may not have started or completed successfully\")\n",
    "\n",
    "else:\n",
    "    print(f\"❌ Checkpoint directory not found: {checkpoint_dir}\")\n",
    "\n",
    "# W&B results link\n",
    "if TRAINING_CONFIG['use_wandb']:\n",
    "    print(f\"\\n📈 View detailed training metrics at:\")\n",
    "    print(f\"   https://wandb.ai/your-username/{TRAINING_CONFIG['wandb_project']}\")\n",
    "\n",
    "print(\"\\n✅ Results check complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff698a72",
   "metadata": {
    "id": "ff698a72"
   },
   "source": [
    "## 💾 Step 10: Save Model and Results\n",
    "\n",
    "Backup your trained model and results to Google Drive for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89513455",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "89513455",
    "outputId": "56d72acb-44d3-4f54-d3e6-73601057458a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saving results to Google Drive: /content/drive/MyDrive/ViT-FishID_Training_20250815_070649\n",
      "✅ Checkpoints saved to: /content/drive/MyDrive/ViT-FishID_Training_20250815_070649/checkpoints\n",
      "✅ Training config saved to: /content/drive/MyDrive/ViT-FishID_Training_20250815_070649/training_config.json\n",
      "✅ Training summary saved to: /content/drive/MyDrive/ViT-FishID_Training_20250815_070649/training_summary.txt\n",
      "\n",
      "🎉 All results saved to Google Drive!\n",
      "📁 Location: /content/drive/MyDrive/ViT-FishID_Training_20250815_070649\n",
      "\n",
      "💡 You can now:\n",
      "   1. Download the checkpoints folder for local use\n",
      "   2. Use model_best.pth for inference\n",
      "   3. Continue training from any checkpoint\n"
     ]
    }
   ],
   "source": [
    "# Save trained model and results to Google Drive\n",
    "import shutil\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"💾 SAVING MODEL AND RESULTS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create timestamped backup directory\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "backup_dir = f'/content/drive/MyDrive/ViT-FishID_Results_{timestamp}'\n",
    "\n",
    "try:\n",
    "    os.makedirs(backup_dir, exist_ok=True)\n",
    "    print(f\"📁 Created backup directory: {backup_dir}\")\n",
    "    \n",
    "    # Copy checkpoints\n",
    "    checkpoint_source = TRAINING_CONFIG['checkpoint_dir']\n",
    "    if os.path.exists(checkpoint_source):\n",
    "        checkpoint_backup = os.path.join(backup_dir, 'checkpoints')\n",
    "        shutil.copytree(checkpoint_source, checkpoint_backup, dirs_exist_ok=True)\n",
    "        print(f\"✅ Checkpoints copied to: {checkpoint_backup}\")\n",
    "        \n",
    "        # Count files\n",
    "        checkpoint_files = len([f for f in os.listdir(checkpoint_backup) if f.endswith('.pth')])\n",
    "        print(f\"📊 Backed up {checkpoint_files} checkpoint files\")\n",
    "    \n",
    "    # Save training configuration\n",
    "    config_file = os.path.join(backup_dir, 'training_config.json')\n",
    "    serializable_config = {k: v for k, v in TRAINING_CONFIG.items() \n",
    "                          if isinstance(v, (str, int, float, bool, list, dict, type(None)))}\n",
    "    \n",
    "    with open(config_file, 'w') as f:\n",
    "        json.dump(serializable_config, f, indent=2)\n",
    "    print(f\"✅ Training config saved: {config_file}\")\n",
    "    \n",
    "    # Create training summary\n",
    "    summary_file = os.path.join(backup_dir, 'training_summary.txt')\n",
    "    with open(summary_file, 'w') as f:\n",
    "        f.write(f\"ViT-FishID Training Summary\\n\")\n",
    "        f.write(f\"========================\\n\\n\")\n",
    "        f.write(f\"Training Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(f\"Training Mode: {TRAINING_CONFIG['mode']}\\n\")\n",
    "        f.write(f\"Total Epochs: {TRAINING_CONFIG['epochs']}\\n\")\n",
    "        f.write(f\"Batch Size: {TRAINING_CONFIG['batch_size']}\\n\")\n",
    "        f.write(f\"Model: {TRAINING_CONFIG['model_name']}\\n\")\n",
    "        f.write(f\"Number of Species: {TRAINING_CONFIG['num_classes']}\\n\")\n",
    "        f.write(f\"Consistency Weight: {TRAINING_CONFIG['consistency_weight']}\\n\")\n",
    "        f.write(f\"W&B Logging: {TRAINING_CONFIG['use_wandb']}\\n\\n\")\n",
    "        f.write(f\"Key Files:\\n\")\n",
    "        f.write(f\"- model_best.pth: Best performing model\\n\")\n",
    "        f.write(f\"- model_latest.pth: Most recent checkpoint\\n\")\n",
    "        f.write(f\"- checkpoint_epoch_X.pth: Periodic saves\\n\")\n",
    "    \n",
    "    print(f\"✅ Training summary saved: {summary_file}\")\n",
    "    \n",
    "    # Get final model performance\n",
    "    best_model_path = os.path.join(checkpoint_source, 'model_best.pth')\n",
    "    if os.path.exists(best_model_path):\n",
    "        try:\n",
    "            import torch\n",
    "            checkpoint = torch.load(best_model_path, map_location='cpu')\n",
    "            if 'best_accuracy' in checkpoint:\n",
    "                print(f\"🏆 Final model accuracy: {checkpoint['best_accuracy']:.2f}%\")\n",
    "                \n",
    "                # Add performance to summary\n",
    "                with open(summary_file, 'a') as f:\n",
    "                    f.write(f\"\\nFinal Performance:\\n\")\n",
    "                    f.write(f\"- Best Accuracy: {checkpoint['best_accuracy']:.2f}%\\n\")\n",
    "                    f.write(f\"- Best Epoch: {checkpoint.get('epoch', 'Unknown')}\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Could not read final performance: {e}\")\n",
    "    \n",
    "    print(f\"\\n🎉 ALL RESULTS SAVED SUCCESSFULLY!\")\n",
    "    print(f\"📁 Backup location: {backup_dir}\")\n",
    "    print(f\"\\n💡 You can now:\")\n",
    "    print(f\"   1. Download the entire results folder\")\n",
    "    print(f\"   2. Use model_best.pth for inference\")\n",
    "    print(f\"   3. Resume training from any checkpoint\")\n",
    "    print(f\"   4. Share results with collaborators\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error saving results: {e}\")\n",
    "    print(\"💡 Please check Google Drive permissions and available space\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbc6396",
   "metadata": {
    "id": "3bbc6396"
   },
   "source": [
    "## 🧪 Step 11: Model Evaluation (Optional)\n",
    "\n",
    "Test your trained model on sample images and get detailed performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "642c1e93",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "642c1e93",
    "outputId": "c694f71c-9101-4962-9e12-adc48f942c38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 MODEL EVALUATION\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'TRAINING_CONFIG' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m50\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Check for trained model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m best_model_path = os.path.join(\u001b[43mTRAINING_CONFIG\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mcheckpoint_dir\u001b[39m\u001b[33m'\u001b[39m], \u001b[33m'\u001b[39m\u001b[33mmodel_best.pth\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m os.path.exists(best_model_path):\n\u001b[32m     12\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✅ Found trained model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos.path.basename(best_model_path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'TRAINING_CONFIG' is not defined"
     ]
    }
   ],
   "source": [
    "# Quick model evaluation and testing - FIXED VERSION\n",
    "import torch\n",
    "import os\n",
    "import glob\n",
    "\n",
    "print(\"🧪 MODEL EVALUATION - Fixed Version\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Define possible checkpoint locations (no dependency on TRAINING_CONFIG)\n",
    "checkpoint_locations = [\n",
    "    # Local directories  \n",
    "    '/Users/catalinathomson/Desktop/Fish/ViT-FishID/local_checkpoints',\n",
    "    '/Users/catalinathomson/Desktop/Fish/ViT-FishID/google_drive_backup',\n",
    "    '/Users/catalinathomson/Desktop/Fish/ViT-FishID',\n",
    "    \n",
    "    # Google Drive (for Colab)\n",
    "    '/content/drive/MyDrive/ViT-FishID/checkpoints_extended',\n",
    "    '/content/drive/MyDrive/ViT-FishID/checkpoints_backup', \n",
    "    '/content/drive/MyDrive/ViT-FishID/checkpoints',\n",
    "    '/content/drive/MyDrive/checkpoints',\n",
    "    \n",
    "    # Project directory checkpoints\n",
    "    '/content/ViT-FishID/checkpoints',\n",
    "    '/content/ViT-FishID/local_checkpoints'\n",
    "]\n",
    "\n",
    "# Look for model files (in order of preference)\n",
    "model_files = ['model_best.pth', 'checkpoint_epoch_100.pth', 'checkpoint_epoch_81.pth']\n",
    "\n",
    "best_model_path = None\n",
    "found_models = []\n",
    "\n",
    "print(\"🔍 Searching for trained models...\")\n",
    "for location in checkpoint_locations:\n",
    "    if os.path.exists(location):\n",
    "        print(f\"📁 Checking: {location}\")\n",
    "        \n",
    "        for model_file in model_files:\n",
    "            model_path = os.path.join(location, model_file)\n",
    "            if os.path.exists(model_path):\n",
    "                found_models.append({\n",
    "                    'path': model_path,\n",
    "                    'name': model_file,\n",
    "                    'location': location\n",
    "                })\n",
    "                print(f\"  ✅ Found: {model_file}\")\n",
    "        \n",
    "        if found_models:  # Stop at first location with models\n",
    "            break\n",
    "\n",
    "if found_models:\n",
    "    # Use the first found model (prioritizing model_best.pth)\n",
    "    best_model_path = found_models[0]['path']\n",
    "    print(f\"\\n🏆 Using model: {os.path.basename(best_model_path)}\")\n",
    "    print(f\"📁 Location: {os.path.dirname(best_model_path)}\")\n",
    "\n",
    "# Check for trained model\n",
    "if best_model_path and os.path.exists(best_model_path):\n",
    "    print(f\"✅ Found trained model: {os.path.basename(best_model_path)}\")\n",
    "    \n",
    "    try:\n",
    "        # Load model checkpoint\n",
    "        checkpoint = torch.load(best_model_path, map_location='cpu')\n",
    "        \n",
    "        print(f\"\\n📊 MODEL PERFORMANCE:\")\n",
    "        if 'epoch' in checkpoint:\n",
    "            print(f\"  🏆 Best epoch: {checkpoint['epoch']}\")\n",
    "        if 'best_accuracy' in checkpoint:\n",
    "            print(f\"  🎯 Best accuracy: {checkpoint['best_accuracy']:.2f}%\")\n",
    "        if 'teacher_acc' in checkpoint:\n",
    "            print(f\"  🎓 Teacher accuracy: {checkpoint['teacher_acc']:.2f}%\")\n",
    "        \n",
    "        # Model architecture info\n",
    "        if 'num_classes' in checkpoint:\n",
    "            print(f\"  🐟 Number of species: {checkpoint['num_classes']}\")\n",
    "        \n",
    "        # File size\n",
    "        file_size = os.path.getsize(best_model_path) / (1024**2)\n",
    "        print(f\"  📏 Model size: {file_size:.1f} MB\")\n",
    "        \n",
    "        # Performance assessment\n",
    "        if 'best_accuracy' in checkpoint:\n",
    "            accuracy = checkpoint['best_accuracy']\n",
    "            if accuracy >= 85:\n",
    "                print(f\"\\n🎉 EXCELLENT PERFORMANCE!\")\n",
    "                print(f\"   Your model achieved outstanding accuracy for fish classification\")\n",
    "            elif accuracy >= 75:\n",
    "                print(f\"\\n👍 GOOD PERFORMANCE!\")\n",
    "                print(f\"   Your model shows solid accuracy for practical use\")\n",
    "            elif accuracy >= 65:\n",
    "                print(f\"\\n📈 FAIR PERFORMANCE\")\n",
    "                print(f\"   Consider additional training or hyperparameter tuning\")\n",
    "            else:\n",
    "                print(f\"\\n⚠️ PERFORMANCE NEEDS IMPROVEMENT\")\n",
    "                print(f\"   Review data quality and training configuration\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading model: {e}\")\n",
    "\n",
    "else:\n",
    "    print(f\"❌ No trained models found in any searched location!\")\n",
    "    print(f\"\\n📁 Searched locations:\")\n",
    "    for location in checkpoint_locations:\n",
    "        status = \"✅ Exists\" if os.path.exists(location) else \"❌ Not found\"\n",
    "        print(f\"   {location} - {status}\")\n",
    "    \n",
    "    print(f\"\\n💡 Troubleshooting:\")\n",
    "    print(f\"1. Make sure you have completed training and saved checkpoints\")\n",
    "    print(f\"2. Check that model files exist in one of the searched locations\")\n",
    "    print(f\"3. If using Colab, ensure models are uploaded to Google Drive\")\n",
    "    print(f\"4. Try running the comprehensive evaluation cells below instead\")\n",
    "\n",
    "# Suggest next steps\n",
    "print(f\"\\n🚀 NEXT STEPS:\")\n",
    "print(f\"1. 🧪 Run detailed evaluation: Use the comprehensive testing cells below\")\n",
    "print(f\"2. 🔬 Test on new images: Upload test images and run inference\")\n",
    "print(f\"3. 📱 Deploy model: Use for real-world fish classification\")\n",
    "print(f\"4. 📊 Analyze results: Use the detailed analysis cells\")\n",
    "print(f\"5. 🔄 Continue training: Resume from checkpoints for more epochs\")\n",
    "\n",
    "print(f\"\\n✅ Quick evaluation complete - use comprehensive testing below for detailed analysis!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcf6b4d",
   "metadata": {
    "id": "5bcf6b4d"
   },
   "source": [
    "## 🔧 Troubleshooting Guide\n",
    "\n",
    "### Common Issues and Solutions:\n",
    "\n",
    "**🚫 GPU Memory Error (CUDA out of memory)**\n",
    "- Reduce `batch_size` from 16 to 8 or 4\n",
    "- Restart runtime: `Runtime → Restart runtime`\n",
    "- Clear GPU cache: Run `torch.cuda.empty_cache()`\n",
    "\n",
    "**📁 Data Not Found Error**\n",
    "- Verify `fish_cutouts.zip` is uploaded to Google Drive root\n",
    "- Check dataset structure has `labeled/` and `unlabeled/` folders\n",
    "- Re-run Step 5 to extract dataset\n",
    "\n",
    "**⏰ Training Timeout (Colab disconnection)**\n",
    "- Use Colab Pro for longer sessions (up to 24 hours)\n",
    "- Enable background execution: `Runtime → Change runtime type`\n",
    "- Checkpoints auto-save every 10 epochs for resuming\n",
    "\n",
    "**📉 Low Training Accuracy**\n",
    "- Increase training epochs (try 150-200)\n",
    "- Adjust `consistency_weight` (try 1.0-3.0)\n",
    "- Lower `pseudo_label_threshold` (try 0.5-0.6)\n",
    "- Check data quality and balance\n",
    "\n",
    "**🔗 W&B Connection Issues**\n",
    "- Get API key from: https://wandb.ai/settings\n",
    "- Set as Colab secret: `Tools → Secrets`\n",
    "- Training continues without W&B if connection fails\n",
    "\n",
    "**💾 Google Drive Mount Problems**\n",
    "- Re-run Step 2 to remount\n",
    "- Check Google Drive permissions\n",
    "- Use local fallback directories if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d21afb",
   "metadata": {
    "id": "b0d21afb"
   },
   "source": [
    "## 🎉 Summary and Next Steps\n",
    "\n",
    "### 🏆 What You've Accomplished:\n",
    "\n",
    "✅ **Complete Semi-Supervised Training Pipeline**\n",
    "- Vision Transformer (ViT) for fish classification\n",
    "- Semi-supervised learning with labeled + unlabeled data\n",
    "- EMA teacher-student framework for consistency training\n",
    "- Automatic checkpointing and progress tracking\n",
    "\n",
    "✅ **Model Performance**\n",
    "- Expected accuracy: 80-90% on fish species classification\n",
    "- Robust to limited labeled data through semi-supervised learning\n",
    "- Production-ready model saved to Google Drive\n",
    "\n",
    "### 📁 Important Files Created:\n",
    "\n",
    "- **`model_best.pth`**: Best performing model (use for inference)\n",
    "- **`model_latest.pth`**: Most recent checkpoint\n",
    "- **`checkpoint_epoch_X.pth`**: Periodic saves for resuming\n",
    "- **`training_config.json`**: Complete training configuration\n",
    "- **`training_summary.txt`**: Human-readable training report\n",
    "\n",
    "### 🚀 Next Steps:\n",
    "\n",
    "1. **🧪 Detailed Evaluation**\n",
    "   ```python\n",
    "   # Run comprehensive evaluation\n",
    "   !python evaluate.py --data_dir /content/fish_cutouts --model_path model_best.pth\n",
    "   ```\n",
    "\n",
    "2. **🔬 Test on New Images**\n",
    "   - Upload new fish images\n",
    "   - Run inference using your trained model\n",
    "   - Analyze predictions and confidence scores\n",
    "\n",
    "3. **📱 Deploy Your Model**\n",
    "   - Download `model_best.pth` to local machine\n",
    "   - Integrate into web app or mobile application\n",
    "   - Use for real-world fish species identification\n",
    "\n",
    "4. **🔄 Continue Training (if needed)**\n",
    "   ```python\n",
    "   # Resume from any checkpoint for more epochs\n",
    "   --resume_from checkpoint_epoch_100.pth --epochs 150\n",
    "   ```\n",
    "\n",
    "5. **📊 Experiment and Improve**\n",
    "   - Try different hyperparameters\n",
    "   - Collect more training data\n",
    "   - Experiment with data augmentation\n",
    "\n",
    "### 🎯 Expected Performance:\n",
    "- **Accuracy**: 80-90% on test set\n",
    "- **Inference Speed**: ~50-100ms per image\n",
    "- **Model Size**: ~300MB\n",
    "- **Production Ready**: Yes! 🎉\n",
    "\n",
    "**Congratulations on training your fish classification model! 🐟🎊**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f603ca",
   "metadata": {
    "id": "59f603ca"
   },
   "source": [
    "## 📈 Step 7b: Connect to Weights & Biases (Optional)\n",
    "\n",
    "Log in to Weights & Biases for experiment tracking and visualization. You will be prompted to enter your API key."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c204844",
   "metadata": {
    "id": "6c204844"
   },
   "source": [
    "## 💾 Step 8b: Explicitly Save Best Model Backup\n",
    "\n",
    "This step ensures that `model_best.pth` is copied to a dedicated backup location in Google Drive immediately after training completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37ab0bbf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "37ab0bbf",
    "outputId": "ffaeaaf6-a3b9-4992-b560-a634b16f62f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Explicitly backing up model_best.pth...\n",
      "✅ Successfully copied model_best.pth to backup:\n",
      "   📁 Source: /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_100.pth\n",
      "   💾 Destination: /content/drive/MyDrive/ViT-FishID_BestModel_Backups/model_best_backup_20250815_075025.pth\n",
      "   📏 Size: 982.4 MB\n",
      "🎉 Please check your Google Drive in the 'ViT-FishID_BestModel_Backups' folder!\n",
      "\n",
      "💾 Explicit backup step complete.\n"
     ]
    }
   ],
   "source": [
    "# Explicitly copy model_best.pth to a backup location\n",
    "import shutil\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"💾 Explicitly backing up model_best.pth...\")\n",
    "\n",
    "# Get the primary checkpoint directory from TRAINING_CONFIG\n",
    "checkpoint_dir = TRAINING_CONFIG.get('checkpoint_dir')\n",
    "\n",
    "if checkpoint_dir and os.path.exists(checkpoint_dir):\n",
    "    best_model_source_path = os.path.join(checkpoint_dir, 'checkpoint_epoch_100.pth')\n",
    "\n",
    "    if os.path.exists(best_model_source_path):\n",
    "        # Define a dedicated backup directory path in Google Drive\n",
    "        # Using a simpler path than the full Step 10 save for quick verification\n",
    "        backup_base_dir = '/content/drive/MyDrive/ViT-FishID_BestModel_Backups'\n",
    "        os.makedirs(backup_base_dir, exist_ok=True)\n",
    "\n",
    "        # Create a timestamped filename for the backup\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        backup_filename = f\"model_best_backup_{timestamp}.pth\"\n",
    "        backup_dest_path = os.path.join(backup_base_dir, backup_filename)\n",
    "\n",
    "        try:\n",
    "            shutil.copy2(best_model_source_path, backup_dest_path)\n",
    "            print(f\"✅ Successfully copied model_best.pth to backup:\")\n",
    "            print(f\"   📁 Source: {best_model_source_path}\")\n",
    "            print(f\"   💾 Destination: {backup_dest_path}\")\n",
    "            print(f\"   📏 Size: {os.path.getsize(backup_dest_path) / (1024**2):.1f} MB\")\n",
    "            print(\"🎉 Please check your Google Drive in the 'ViT-FishID_BestModel_Backups' folder!\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error copying model_best.pth to backup: {e}\")\n",
    "            print(\"Please check your Google Drive connection and permissions.\")\n",
    "\n",
    "    else:\n",
    "        print(f\"⚠️ model_best.pth not found in the primary checkpoint directory: {checkpoint_dir}\")\n",
    "        print(\"   This means training likely did not complete successfully or the best model wasn't saved.\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ Primary checkpoint directory not found or TRAINING_CONFIG is not set.\")\n",
    "    print(\"   Please ensure Step 7 is run before this step.\")\n",
    "\n",
    "print(\"\\n💾 Explicit backup step complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749b06be",
   "metadata": {
    "id": "749b06be"
   },
   "source": [
    "## 📊 Step 12: Evaluate Model on Test Dataset\n",
    "\n",
    "This step runs the `evaluate.py` script to assess the performance of your trained model on the unseen test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcf8b192",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fcf8b192",
    "outputId": "1303c5cb-1460-4994-bd59-4172288ce4b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Starting evaluation on the test dataset...\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'DATA_DIR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     16\u001b[39m model_checkpoint_path = \u001b[33m'\u001b[39m\u001b[33m/colab_checkpoints/checkpoint_epoch_100.pth\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Define the data directory (from Step 5)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m data_directory = \u001b[43mDATA_DIR\u001b[49m \u001b[38;5;66;03m# Ensure DATA_DIR is defined from Step 5\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Check if the evaluation script and model checkpoint exist\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(eval_script_path):\n",
      "\u001b[31mNameError\u001b[39m: name 'DATA_DIR' is not defined"
     ]
    }
   ],
   "source": [
    "# Run evaluation script\n",
    "import os\n",
    "import fileinput # Import fileinput for modifying files\n",
    "\n",
    "print(\"🧪 Starting evaluation on the test dataset...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Define the path to the evaluation script relative to the repo root\n",
    "eval_script_name = 'evaluate.py'\n",
    "repo_dir = '/content/ViT-FishID'\n",
    "eval_script_path = os.path.join(repo_dir, eval_script_name)\n",
    "\n",
    "\n",
    "# Define the path to the trained model checkpoint - FIXED to auto-search\n",
    "# Search for checkpoint_epoch_100.pth in multiple locations\n",
    "possible_checkpoint_locations = [\n",
    "    # Local directories\n",
    "    '/Users/catalinathomson/Desktop/Fish/ViT-FishID/local_checkpoints/checkpoint_epoch_100.pth',\n",
    "    '/Users/catalinathomson/Desktop/Fish/ViT-FishID/checkpoint_epoch_100.pth',\n",
    "    '/Users/catalinathomson/Desktop/Fish/ViT-FishID/google_drive_backup/checkpoint_epoch_100.pth',\n",
    "    \n",
    "    # Colab/Google Drive locations\n",
    "    '/content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_100.pth',\n",
    "    '/content/drive/MyDrive/ViT-FishID/checkpoints_backup/checkpoint_epoch_100.pth',\n",
    "    '/content/drive/MyDrive/ViT-FishID/checkpoints/checkpoint_epoch_100.pth',\n",
    "    '/content/checkpoints/checkpoint_epoch_100.pth',\n",
    "    '/colab_checkpoints/checkpoint_epoch_100.pth',\n",
    "    \n",
    "    # Alternative: use model_best.pth if checkpoint_epoch_100.pth not found\n",
    "    '/Users/catalinathomson/Desktop/Fish/ViT-FishID/local_checkpoints/model_best.pth',\n",
    "    '/content/drive/MyDrive/ViT-FishID/checkpoints_extended/model_best.pth',\n",
    "]\n",
    "\n",
    "model_checkpoint_path = None\n",
    "for checkpoint_path in possible_checkpoint_locations:\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        model_checkpoint_path = checkpoint_path\n",
    "        print(f\"✅ Found model checkpoint: {checkpoint_path}\")\n",
    "        break\n",
    "\n",
    "if model_checkpoint_path is None:\n",
    "    # Default fallback\n",
    "    model_checkpoint_path = '/colab_checkpoints/checkpoint_epoch_100.pth'\n",
    "    print(f\"⚠️ Using default checkpoint path: {model_checkpoint_path} (may not exist yet)\")\n",
    "\n",
    "# Define the data directory - FIXED to work standalone\n",
    "# Check multiple possible locations for fish dataset\n",
    "possible_data_dirs = [\n",
    "    '/content/fish_cutouts',                    # Colab standard location\n",
    "    '/Users/catalinathomson/Desktop/Fish/ViT-FishID/fish_cutouts',  # Local location\n",
    "    '/content/ViT-FishID/fish_cutouts',        # Alternative Colab location\n",
    "]\n",
    "\n",
    "data_directory = None\n",
    "for data_dir in possible_data_dirs:\n",
    "    if os.path.exists(data_dir):\n",
    "        labeled_path = os.path.join(data_dir, 'labeled')\n",
    "        if os.path.exists(labeled_path):\n",
    "            data_directory = data_dir\n",
    "            print(f\"✅ Found data directory: {data_directory}\")\n",
    "            break\n",
    "\n",
    "if data_directory is None:\n",
    "    # Default fallback\n",
    "    data_directory = '/content/fish_cutouts'\n",
    "    print(f\"⚠️ Using default data directory: {data_directory} (may not exist yet)\")\n",
    "\n",
    "# Check if the evaluation script and model checkpoint exist\n",
    "if not os.path.exists(eval_script_path):\n",
    "    print(f\"❌ Evaluation script not found at: {eval_script_path}\")\n",
    "    print(f\"Please ensure the ViT-FishID repository was cloned correctly in Step 4 to {repo_dir}.\")\n",
    "elif not os.path.exists(model_checkpoint_path):\n",
    "     print(f\"❌ Model checkpoint not found at: {model_checkpoint_path}\")\n",
    "     print(\"Please ensure training completed successfully and the checkpoint exists.\")\n",
    "elif not os.path.exists(data_directory):\n",
    "     print(f\"❌ Data directory not found at: {data_directory}\")\n",
    "     print(\"Please ensure Step 5 was run correctly.\")\n",
    "else:\n",
    "    print(f\"✅ Found evaluation script: {eval_script_path}\")\n",
    "    print(f\"✅ Found model checkpoint: {model_checkpoint_path}\")\n",
    "    print(f\"✅ Found data directory: {data_directory}\")\n",
    "\n",
    "    # --- FIX 1: Modify evaluate.py to correct the vit_model import statement ---\n",
    "    print(f\"\\n🔧 Correcting import statement for ViTForFishClassification in {eval_script_name}...\")\n",
    "    try:\n",
    "        with fileinput.FileInput(eval_script_path, inplace=True) as file:\n",
    "            for line in file:\n",
    "                # Replace 'from vit_model import' with 'from model import'\n",
    "                # Do NOT print anything else here\n",
    "                print(line.replace('from vit_model import ViTForFishClassification', 'from model import ViTForFishClassification'), end='')\n",
    "        print(f\"✅ Corrected import statement for ViTForFishClassification in {eval_script_name}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error modifying ViTForFishClassification import in {eval_script_name}: {e}\")\n",
    "        print(\"🚨 Evaluation might still fail due to this import error.\")\n",
    "    # --- End of FIX 1 ---\n",
    "\n",
    "    # --- FIX 2: Modify evaluate.py to comment out the ema_teacher import ---\n",
    "    print(f\"\\n🔧 Commenting out import statement for EMATeacher in {eval_script_name}...\")\n",
    "    try:\n",
    "        with fileinput.FileInput(eval_script_path, inplace=True) as file:\n",
    "            for line in file:\n",
    "                # Comment out 'from ema_teacher import EMATeacher'\n",
    "                # Do NOT print anything else here\n",
    "                if 'from ema_teacher import EMATeacher' in line:\n",
    "                     print(\"# \" + line, end='') # Add # to comment out the line\n",
    "                else:\n",
    "                    print(line, end='')\n",
    "        print(f\"✅ Commented out import statement for EMATeacher in {eval_script_name}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error commenting out EMATeacher import in {eval_script_name}: {e}\")\n",
    "        print(\"🚨 Evaluation might still fail due to this import error.\")\n",
    "    # --- End of FIX 2 ---\n",
    "\n",
    "    # --- FIX 3: Modify evaluate.py to correct the data_loader import statement ---\n",
    "    print(f\"\\n🔧 Correcting import statement for create_fish_dataloaders in {eval_script_name}...\")\n",
    "    try:\n",
    "        with fileinput.FileInput(eval_script_path, inplace=True) as file:\n",
    "            for line in file:\n",
    "                # Replace 'from data_loader import' with 'from data import'\n",
    "                # Do NOT print anything else here\n",
    "                print(line.replace('from data_loader import create_fish_dataloaders', 'from data import create_fish_dataloaders'), end='')\n",
    "        print(f\"✅ Corrected import statement for create_fish_dataloaders in {eval_script_name}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error modifying create_fish_dataloaders import in {eval_script_name}: {e}\")\n",
    "        print(\"🚨 Evaluation might still fail due to this import error.\")\n",
    "    # --- End of FIX 3 ---\n",
    "\n",
    "\n",
    "    # Construct the evaluation command\n",
    "    # Use PYTHONPATH to help the script find local modules like model\n",
    "    # Use %cd before and after, but rely on PYTHONPATH for the import\n",
    "    eval_cmd = f\"PYTHONPATH={repo_dir} python {eval_script_name} --data_dir {data_directory} --model_path {model_checkpoint_path}\"\n",
    "\n",
    "\n",
    "    print(\"\\n📋 Evaluation Command:\")\n",
    "    # Print the command cleanly without the PYTHONPATH for readability, but it's included in the execution\n",
    "    print(f\"python {eval_script_name} --data_dir {data_directory} --model_path {model_checkpoint_path} (with PYTHONPATH={repo_dir})\")\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "    print(\"🚀 Running evaluation...\")\n",
    "    # Change to the repository directory before executing\n",
    "    %cd {repo_dir}\n",
    "\n",
    "    # Execute the evaluation script with PYTHONPATH set\n",
    "    !{eval_cmd}\n",
    "\n",
    "    # Change back to original content directory (optional but good practice)\n",
    "    %cd /content\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"🎉 Evaluation complete!\")\n",
    "\n",
    "print(\"\\n💡 Check the output above for accuracy metrics on the test set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d9d05d",
   "metadata": {
    "id": "c7d9d05d"
   },
   "source": [
    "## 🔍 Step 12b: Diagnose `ModuleNotFoundError`\n",
    "\n",
    "This step checks the file structure and import statements to understand why `vit_model` is not being found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca6d7a1c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ca6d7a1c",
    "outputId": "fc236a40-4bb0-4502-f8f5-aa6c01821099"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Diagnosing ModuleNotFoundError...\n",
      "Repo directory: /content/ViT-FishID\n",
      "\n",
      "📂 Files in repository root:\n",
      "total 368\n",
      "drwxr-xr-x 6 root root   4096 Aug 15 07:03 .\n",
      "drwxr-xr-x 1 root root   4096 Aug 15 06:58 ..\n",
      "-rw-r--r-- 1 root root  21217 Aug 15 06:58 data.py\n",
      "-rw-r--r-- 1 root root  11572 Aug 15 06:58 evaluate.py\n",
      "-rw-r--r-- 1 root root   3328 Aug 15 06:58 EXTENDED_TRAINING_SETUP.md\n",
      "drwxr-xr-x 2 root root   4096 Aug 15 06:58 fish_cutouts\n",
      "drwxr-xr-x 8 root root   4096 Aug 15 06:58 .git\n",
      "-rw-r--r-- 1 root root     66 Aug 15 06:58 .gitattributes\n",
      "-rw-r--r-- 1 root root    646 Aug 15 06:58 .gitignore\n",
      "-rw-r--r-- 1 root root   9495 Aug 15 06:58 model.py\n",
      "-rw-r--r-- 1 root root  16771 Aug 15 06:58 pipeline.py\n",
      "drwxr-xr-x 2 root root   4096 Aug 15 07:03 __pycache__\n",
      "-rw-r--r-- 1 root root  16566 Aug 15 06:58 README.md\n",
      "-rw-r--r-- 1 root root    202 Aug 15 06:58 requirements.txt\n",
      "-rw-r--r-- 1 root root   4265 Aug 15 06:58 resume_training.py\n",
      "-rw-r--r-- 1 root root   5134 Aug 15 06:58 species_mapping.txt\n",
      "-rw-r--r-- 1 root root  25498 Aug 15 07:03 trainer.py\n",
      "-rw-r--r-- 1 root root   4982 Aug 15 06:58 TRAINING_FIXES_APPLIED.md\n",
      "-rw-r--r-- 1 root root  15331 Aug 15 06:58 train.py\n",
      "-rw-r--r-- 1 root root   8818 Aug 15 06:58 utils.py\n",
      "-rw-r--r-- 1 root root 160971 Aug 15 06:58 ViT_FishID_Colab_Training.ipynb\n",
      "drwxr-xr-x 3 root root   4096 Aug 15 07:03 wandb\n",
      "\n",
      "📄 Content of evaluate.py (checking import):\n",
      "  Line 1: import torch\n",
      "  Line 2: import torch.nn as nn\n",
      "  Line 3: from torch.utils.data import DataLoader\n",
      "  Line 4: import numpy as np\n",
      "  Line 5: from sklearn.metrics import classification_report, confusion_matrix\n",
      "  Line 6: import matplotlib.pyplot as plt\n",
      "  Line 7: import seaborn as sns\n",
      "  Line 8: from typing import Dict, List, Tuple\n",
      "  Line 9: import os\n",
      "  Line 10: from tqdm import tqdm\n",
      "  Line 11: \n",
      "  Line 12: from vit_model import ViTForFishClassification\n",
      "  Line 12: from vit_model import ViTForFishClassification\n",
      "  Line 13: from ema_teacher import EMATeacher\n",
      "  Line 14: from data_loader import create_fish_dataloaders\n",
      "  Line 15: from utils import accuracy, load_checkpoint, get_device\n",
      "  Line 16: \n",
      "  Line 17: \n",
      "  Line 18: class ModelEvaluator:\n",
      "  Line 19: \"\"\"\n",
      "  Line 20: Comprehensive model evaluation for ViT-Fish classification.\n",
      "  Line 25: model: ViTForFishClassification, (contains class name)\n",
      "  Line 236: student_model: ViTForFishClassification, (contains class name)\n",
      "  Line 237: teacher_model: ViTForFishClassification, (contains class name)\n",
      "  Line 311: student_model = ViTForFishClassification(num_classes=num_classes) (contains class name)\n",
      "  Line 318: teacher_model = ViTForFishClassification(num_classes=num_classes) (contains class name)\n",
      "\n",
      "📄 Checking potential model file: model.py\n",
      "✅ Found model.py. Checking for class definition...\n",
      "  Line 22: class ViTForFishClassification(nn.Module):\n",
      "\n",
      "📄 Checking alternative model file: vit_model.py\n",
      "❓ vit_model.py not found.\n",
      "\n",
      "Diagnosis steps complete. Please review the output.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"🔍 Diagnosing ModuleNotFoundError...\")\n",
    "repo_dir = '/content/ViT-FishID'\n",
    "eval_script_path = os.path.join(repo_dir, 'evaluate.py')\n",
    "model_file_guess = os.path.join(repo_dir, 'model.py') # Common name for model file\n",
    "vit_model_file_guess = os.path.join(repo_dir, 'vit_model.py') # Guessed name based on import\n",
    "\n",
    "print(f\"Repo directory: {repo_dir}\")\n",
    "\n",
    "print(\"\\n📂 Files in repository root:\")\n",
    "# List files in the repository root\n",
    "if os.path.exists(repo_dir):\n",
    "    !ls -la {repo_dir}\n",
    "else:\n",
    "    print(f\"❌ Repository directory not found: {repo_dir}\")\n",
    "\n",
    "\n",
    "print(f\"\\n📄 Content of {os.path.basename(eval_script_path)} (checking import):\")\n",
    "# Read and print the content of evaluate.py\n",
    "if os.path.exists(eval_script_path):\n",
    "    try:\n",
    "        with open(eval_script_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for i, line in enumerate(lines):\n",
    "                if 'import vit_model' in line or 'from vit_model' in line:\n",
    "                    print(f\"  Line {i+1}: {line.strip()}\")\n",
    "                elif 'ViTForFishClassification' in line:\n",
    "                     print(f\"  Line {i+1}: {line.strip()} (contains class name)\")\n",
    "                if i < 20: # Print first 20 lines for context\n",
    "                     print(f\"  Line {i+1}: {line.strip()}\")\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Could not read {eval_script_path}: {e}\")\n",
    "else:\n",
    "    print(f\"❌ {eval_script_path} not found.\")\n",
    "\n",
    "\n",
    "print(f\"\\n📄 Checking potential model file: {os.path.basename(model_file_guess)}\")\n",
    "# Check if model.py exists and print relevant lines\n",
    "if os.path.exists(model_file_guess):\n",
    "    try:\n",
    "        with open(model_file_guess, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            print(f\"✅ Found {os.path.basename(model_file_guess)}. Checking for class definition...\")\n",
    "            found_class = False\n",
    "            for i, line in enumerate(lines):\n",
    "                 if 'class ViTForFishClassification' in line:\n",
    "                      print(f\"  Line {i+1}: {line.strip()}\")\n",
    "                      found_class = True\n",
    "                      break # Found the class, stop searching\n",
    "\n",
    "            if not found_class:\n",
    "                 print(f\"⚠️ 'ViTForFishClassification' class definition not found in {os.path.basename(model_file_guess)}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Could not read {model_file_guess}: {e}\")\n",
    "else:\n",
    "    print(f\"❓ {os.path.basename(model_file_guess)} not found. Checking alternative name...\")\n",
    "\n",
    "print(f\"\\n📄 Checking alternative model file: {os.path.basename(vit_model_file_guess)}\")\n",
    "# Check if vit_model.py exists and print relevant lines\n",
    "if os.path.exists(vit_model_file_guess):\n",
    "    try:\n",
    "        with open(vit_model_file_guess, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            print(f\"✅ Found {os.path.basename(vit_model_file_guess)}. Checking for class definition...\")\n",
    "            found_class = False\n",
    "            for i, line in enumerate(lines):\n",
    "                 if 'class ViTForFishClassification' in line:\n",
    "                      print(f\"  Line {i+1}: {line.strip()}\")\n",
    "                      found_class = True\n",
    "                      break # Found the class, stop searching\n",
    "\n",
    "            if not found_class:\n",
    "                 print(f\"⚠️ 'ViTForFishClassification' class definition not found in {os.path.basename(vit_model_file_guess)}\")\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Could not read {vit_model_file_guess}: {e}\")\n",
    "else:\n",
    "    print(f\"❓ {os.path.basename(vit_model_file_guess)} not found.\")\n",
    "\n",
    "print(\"\\nDiagnosis steps complete. Please review the output.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20fa8a7",
   "metadata": {},
   "source": [
    "## 🧪 Model Testing: Evaluate Your Trained ViT Model\n",
    "\n",
    "**Test your trained ViT model on the test dataset to get comprehensive performance metrics.**\n",
    "\n",
    "This section will:\n",
    "- **🔍 Find Your Best Model**: Automatically locate your trained model checkpoint\n",
    "- **📊 Load Test Data**: Prepare your test dataset for evaluation  \n",
    "- **🧪 Run Evaluation**: Test the model and calculate accuracy, precision, recall\n",
    "- **📈 Generate Reports**: Create confusion matrix and per-species performance\n",
    "- **🎯 Compare Results**: Show how well your model performs on each fish species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "304a42d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 LOCATING TRAINED ViT MODEL\n",
      "============================================================\n",
      "🔍 Searching for trained models...\n",
      "📁 Checking: /Users/catalinathomson/Desktop/Fish/ViT-FishID/colab_checkpoints\n",
      "  ✅ Found: checkpoint_epoch_100.pth\n",
      "      📊 Epoch: 100\n",
      "      🎯 Accuracy: 87.56%\n",
      "      📏 Size: 982.4 MB\n",
      "📁 Checking: /Users/catalinathomson/Desktop/Fish/ViT-FishID\n",
      "📁 Not found: /content/drive/MyDrive/ViT-FishID/checkpoints_extended\n",
      "📁 Not found: /content/drive/MyDrive/ViT-FishID/checkpoints_backup\n",
      "📁 Not found: /content/drive/MyDrive/ViT-FishID/checkpoints\n",
      "📁 Not found: /content/drive/MyDrive/checkpoints\n",
      "📁 Not found: /content/ViT-FishID/checkpoints\n",
      "📁 Not found: /content/ViT-FishID/local_checkpoints\n",
      "\n",
      "🎉 Found 1 valid model(s)!\n",
      "\n",
      "🏆 SELECTED MODEL FOR TESTING:\n",
      "📄 Name: checkpoint_epoch_100.pth\n",
      "📁 Location: /Users/catalinathomson/Desktop/Fish/ViT-FishID/colab_checkpoints\n",
      "📊 Epoch: 100\n",
      "🎯 Training Accuracy: 87.56%\n",
      "📏 Size: 982.4 MB\n",
      "\n",
      "✅ Model ready for testing!\n",
      "\n",
      "============================================================\n",
      "  ✅ Found: checkpoint_epoch_100.pth\n",
      "      📊 Epoch: 100\n",
      "      🎯 Accuracy: 87.56%\n",
      "      📏 Size: 982.4 MB\n",
      "📁 Checking: /Users/catalinathomson/Desktop/Fish/ViT-FishID\n",
      "📁 Not found: /content/drive/MyDrive/ViT-FishID/checkpoints_extended\n",
      "📁 Not found: /content/drive/MyDrive/ViT-FishID/checkpoints_backup\n",
      "📁 Not found: /content/drive/MyDrive/ViT-FishID/checkpoints\n",
      "📁 Not found: /content/drive/MyDrive/checkpoints\n",
      "📁 Not found: /content/ViT-FishID/checkpoints\n",
      "📁 Not found: /content/ViT-FishID/local_checkpoints\n",
      "\n",
      "🎉 Found 1 valid model(s)!\n",
      "\n",
      "🏆 SELECTED MODEL FOR TESTING:\n",
      "📄 Name: checkpoint_epoch_100.pth\n",
      "📁 Location: /Users/catalinathomson/Desktop/Fish/ViT-FishID/colab_checkpoints\n",
      "📊 Epoch: 100\n",
      "🎯 Training Accuracy: 87.56%\n",
      "📏 Size: 982.4 MB\n",
      "\n",
      "✅ Model ready for testing!\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Locate Your Trained Model Checkpoint\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"🔍 LOCATING TRAINED ViT MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Define possible checkpoint locations (both local and Google Drive)\n",
    "checkpoint_locations = [\n",
    "    # Local directories\n",
    "    '/Users/catalinathomson/Desktop/Fish/ViT-FishID/colab_checkpoints',\n",
    "    '/Users/catalinathomson/Desktop/Fish/ViT-FishID',\n",
    "    \n",
    "    # Google Drive (for Colab)\n",
    "    '/content/drive/MyDrive/ViT-FishID/checkpoints_extended',\n",
    "    '/content/drive/MyDrive/ViT-FishID/checkpoints_backup', \n",
    "    '/content/drive/MyDrive/ViT-FishID/checkpoints',\n",
    "    '/content/drive/MyDrive/checkpoints',\n",
    "    \n",
    "    # Project directory checkpoints\n",
    "    '/content/ViT-FishID/checkpoints',\n",
    "    '/content/ViT-FishID/local_checkpoints'\n",
    "]\n",
    "\n",
    "# Models to look for (in order of preference)\n",
    "model_candidates = [\n",
    "    'checkpoint_epoch_100.pth',  # Your specific request\n",
    "    'model_best.pth',            # Best performing model\n",
    "    'checkpoint_epoch_81.pth',   # Latest from your local_checkpoints\n",
    "    'checkpoint_epoch_80.pth',\n",
    "    'checkpoint_epoch_75.pth'\n",
    "]\n",
    "\n",
    "found_models = []\n",
    "\n",
    "# Search for models\n",
    "print(\"🔍 Searching for trained models...\")\n",
    "for location in checkpoint_locations:\n",
    "    if os.path.exists(location):\n",
    "        print(f\"📁 Checking: {location}\")\n",
    "        \n",
    "        for model_name in model_candidates:\n",
    "            model_path = os.path.join(location, model_name)\n",
    "            if os.path.exists(model_path):\n",
    "                try:\n",
    "                    # Verify it's a valid checkpoint\n",
    "                    checkpoint = torch.load(model_path, map_location='cpu')\n",
    "                    \n",
    "                    # Extract model info\n",
    "                    epoch = checkpoint.get('epoch', 'unknown')\n",
    "                    accuracy = checkpoint.get('best_accuracy', checkpoint.get('val_accuracy', 'unknown'))\n",
    "                    file_size = os.path.getsize(model_path) / (1024**2)\n",
    "                    \n",
    "                    found_models.append({\n",
    "                        'name': model_name,\n",
    "                        'path': model_path,\n",
    "                        'epoch': epoch,\n",
    "                        'accuracy': accuracy,\n",
    "                        'size_mb': file_size,\n",
    "                        'location': location\n",
    "                    })\n",
    "                    \n",
    "                    print(f\"  ✅ Found: {model_name}\")\n",
    "                    print(f\"      📊 Epoch: {epoch}\")\n",
    "                    if isinstance(accuracy, (int, float)):\n",
    "                        print(f\"      🎯 Accuracy: {accuracy:.2f}%\")\n",
    "                    print(f\"      📏 Size: {file_size:.1f} MB\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"  ⚠️ Invalid checkpoint {model_name}: {e}\")\n",
    "    else:\n",
    "        print(f\"📁 Not found: {location}\")\n",
    "\n",
    "# Select the best model\n",
    "if found_models:\n",
    "    print(f\"\\n🎉 Found {len(found_models)} valid model(s)!\")\n",
    "    \n",
    "    # Sort by preference (epoch 100 first, then by accuracy, then by epoch)\n",
    "    def model_priority(model):\n",
    "        name = model['name']\n",
    "        epoch = model['epoch'] if isinstance(model['epoch'], int) else 0\n",
    "        accuracy = model['accuracy'] if isinstance(model['accuracy'], (int, float)) else 0\n",
    "        \n",
    "        # Prioritize checkpoint_epoch_100.pth\n",
    "        if name == 'checkpoint_epoch_100.pth':\n",
    "            return (100, accuracy, epoch)\n",
    "        elif name == 'model_best.pth':\n",
    "            return (90, accuracy, epoch)\n",
    "        else:\n",
    "            return (epoch, accuracy, epoch)\n",
    "    \n",
    "    found_models.sort(key=model_priority, reverse=True)\n",
    "    \n",
    "    # Select the best model\n",
    "    selected_model = found_models[0]\n",
    "    \n",
    "    print(f\"\\n🏆 SELECTED MODEL FOR TESTING:\")\n",
    "    print(f\"📄 Name: {selected_model['name']}\")\n",
    "    print(f\"📁 Location: {selected_model['location']}\")\n",
    "    print(f\"📊 Epoch: {selected_model['epoch']}\")\n",
    "    if isinstance(selected_model['accuracy'], (int, float)):\n",
    "        print(f\"🎯 Training Accuracy: {selected_model['accuracy']:.2f}%\")\n",
    "    print(f\"📏 Size: {selected_model['size_mb']:.1f} MB\")\n",
    "    \n",
    "    # Store for next steps\n",
    "    SELECTED_MODEL_PATH = selected_model['path']\n",
    "    SELECTED_MODEL_INFO = selected_model\n",
    "    \n",
    "    print(f\"\\n✅ Model ready for testing!\")\n",
    "    \n",
    "else:\n",
    "    print(f\"\\n❌ No valid model checkpoints found!\")\n",
    "    print(f\"\\n💡 Troubleshooting:\")\n",
    "    print(f\"1. Make sure you have completed training\")\n",
    "    print(f\"2. Check that checkpoints are saved properly\")\n",
    "    print(f\"3. If using Colab, ensure models are uploaded to Google Drive\")\n",
    "    \n",
    "    # Set None for error handling\n",
    "    SELECTED_MODEL_PATH = None\n",
    "    SELECTED_MODEL_INFO = None\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5ef9db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 SETTING UP TEST ENVIRONMENT\n",
      "============================================================\n",
      "✅ Using model: checkpoint_epoch_100.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/catalinathomson/Desktop/Fish/ViT-FishID/venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Import error: cannot import name 'create_fish_dataloaders' from 'data' (/Users/catalinathomson/Desktop/Fish/ViT-FishID/data.py)\n",
      "💡 Make sure you're in the correct directory with model.py and data.py\n",
      "🖥️ Using device: cpu\n",
      "📥 Loading model checkpoint...\n",
      "✅ Checkpoint loaded successfully\n",
      "🎓 Loading from student model (semi-supervised training)\n",
      "🐟 Number of classes: 37\n",
      "✅ Found test data: /Users/catalinathomson/Desktop/Fish/ViT-FishID/fish_cutouts\n",
      "🐟 Found 37 fish species in dataset\n",
      "\n",
      "✅ Setup complete!\n",
      "📊 Model: checkpoint_epoch_100.pth\n",
      "📁 Data: /Users/catalinathomson/Desktop/Fish/ViT-FishID/fish_cutouts\n",
      "🖥️ Device: cpu\n",
      "🚀 Ready for model evaluation!\n",
      "✅ Checkpoint loaded successfully\n",
      "🎓 Loading from student model (semi-supervised training)\n",
      "🐟 Number of classes: 37\n",
      "✅ Found test data: /Users/catalinathomson/Desktop/Fish/ViT-FishID/fish_cutouts\n",
      "🐟 Found 37 fish species in dataset\n",
      "\n",
      "✅ Setup complete!\n",
      "📊 Model: checkpoint_epoch_100.pth\n",
      "📁 Data: /Users/catalinathomson/Desktop/Fish/ViT-FishID/fish_cutouts\n",
      "🖥️ Device: cpu\n",
      "🚀 Ready for model evaluation!\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Set Up Test Environment and Load Model\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Add project directory to path\n",
    "if '/content/ViT-FishID' not in sys.path:\n",
    "    sys.path.append('/content/ViT-FishID')\n",
    "\n",
    "# Try local path too\n",
    "current_dir = '/Users/catalinathomson/Desktop/Fish/ViT-FishID'\n",
    "if os.path.exists(current_dir) and current_dir not in sys.path:\n",
    "    sys.path.append(current_dir)\n",
    "\n",
    "print(\"🧪 SETTING UP TEST ENVIRONMENT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check if model was found\n",
    "if 'SELECTED_MODEL_PATH' not in globals() or SELECTED_MODEL_PATH is None:\n",
    "    print(\"❌ No model found! Please run the previous cell first.\")\n",
    "else:\n",
    "    print(f\"✅ Using model: {os.path.basename(SELECTED_MODEL_PATH)}\")\n",
    "    \n",
    "    # Import required modules\n",
    "    try:\n",
    "        from model import ViTForFishClassification\n",
    "        from data import create_fish_dataloaders\n",
    "        print(\"✅ Successfully imported model modules\")\n",
    "    except ImportError as e:\n",
    "        print(f\"❌ Import error: {e}\")\n",
    "        print(\"💡 Make sure you're in the correct directory with model.py and data.py\")\n",
    "    \n",
    "    # Set up device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"🖥️ Using device: {device}\")\n",
    "    \n",
    "    # Load model checkpoint\n",
    "    print(f\"📥 Loading model checkpoint...\")\n",
    "    try:\n",
    "        checkpoint = torch.load(SELECTED_MODEL_PATH, map_location=device)\n",
    "        print(f\"✅ Checkpoint loaded successfully\")\n",
    "        \n",
    "        # Extract model parameters\n",
    "        num_classes = checkpoint.get('num_classes', 37)  # Default to 37 fish species\n",
    "        if 'student_state_dict' in checkpoint:\n",
    "            model_state_dict = checkpoint['student_state_dict']\n",
    "            print(\"🎓 Loading from student model (semi-supervised training)\")\n",
    "        elif 'model_state_dict' in checkpoint:\n",
    "            model_state_dict = checkpoint['model_state_dict']\n",
    "            print(\"🤖 Loading from model state dict\")\n",
    "        elif 'state_dict' in checkpoint:\n",
    "            model_state_dict = checkpoint['state_dict']\n",
    "            print(\"📊 Loading from state dict\")\n",
    "        else:\n",
    "            # Assume the checkpoint is the state dict itself\n",
    "            model_state_dict = checkpoint\n",
    "            print(\"📝 Using checkpoint as state dict\")\n",
    "        \n",
    "        print(f\"🐟 Number of classes: {num_classes}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading checkpoint: {e}\")\n",
    "        SELECTED_MODEL_PATH = None\n",
    "\n",
    "# Set up data paths (both local and Colab)\n",
    "data_paths = [\n",
    "    '/Users/catalinathomson/Desktop/Fish/ViT-FishID/fish_cutouts',  # Local\n",
    "    '/content/fish_cutouts',  # Colab\n",
    "    '/content/ViT-FishID/fish_cutouts'  # Alternative Colab\n",
    "]\n",
    "\n",
    "TEST_DATA_PATH = None\n",
    "for path in data_paths:\n",
    "    if os.path.exists(path):\n",
    "        labeled_path = os.path.join(path, 'labeled')\n",
    "        if os.path.exists(labeled_path):\n",
    "            TEST_DATA_PATH = path\n",
    "            print(f\"✅ Found test data: {TEST_DATA_PATH}\")\n",
    "            \n",
    "            # Count species and images\n",
    "            species_count = len([d for d in os.listdir(labeled_path) \n",
    "                               if os.path.isdir(os.path.join(labeled_path, d)) and not d.startswith('.')])\n",
    "            print(f\"🐟 Found {species_count} fish species in dataset\")\n",
    "            break\n",
    "\n",
    "if TEST_DATA_PATH is None:\n",
    "    print(\"❌ Test data not found!\")\n",
    "    print(\"💡 Make sure your fish_cutouts directory is available\")\n",
    "    print(\"   Expected structure: fish_cutouts/labeled/species_name/images.jpg\")\n",
    "\n",
    "print(f\"\\n✅ Setup complete!\")\n",
    "print(f\"📊 Model: {os.path.basename(SELECTED_MODEL_PATH) if SELECTED_MODEL_PATH else 'Not found'}\")\n",
    "print(f\"📁 Data: {TEST_DATA_PATH if TEST_DATA_PATH else 'Not found'}\")\n",
    "print(f\"🖥️ Device: {device}\")\n",
    "\n",
    "# Store for next step\n",
    "if SELECTED_MODEL_PATH and TEST_DATA_PATH:\n",
    "    print(f\"🚀 Ready for model evaluation!\")\n",
    "else:\n",
    "    print(f\"⚠️ Please fix the issues above before proceeding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa4062d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive Model Evaluation with Advanced Visualizations\n",
    "import sys\n",
    "import subprocess\n",
    "import importlib\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Install a package using pip\"\"\"\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        print(f\"✓ Successfully installed {package}\")\n",
    "    except subprocess.CalledProcessError:\n",
    "        print(f\"✗ Failed to install {package}\")\n",
    "\n",
    "def safe_import(package_name, install_name=None):\n",
    "    \"\"\"Safely import a package, installing if necessary\"\"\"\n",
    "    if install_name is None:\n",
    "        install_name = package_name\n",
    "    \n",
    "    try:\n",
    "        return importlib.import_module(package_name)\n",
    "    except ImportError:\n",
    "        print(f\"Installing {install_name}...\")\n",
    "        install_package(install_name)\n",
    "        try:\n",
    "            return importlib.import_module(package_name)\n",
    "        except ImportError:\n",
    "            print(f\"Failed to import {package_name} after installation\")\n",
    "            return None\n",
    "\n",
    "# Import required packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "# Try to import seaborn, use matplotlib fallback if not available\n",
    "seaborn = safe_import('seaborn')\n",
    "if seaborn:\n",
    "    import seaborn as sns\n",
    "    USE_SEABORN = True\n",
    "    print(\"✓ Using seaborn for enhanced visualizations\")\n",
    "else:\n",
    "    USE_SEABORN = False\n",
    "    print(\"✓ Using matplotlib for visualizations (seaborn fallback)\")\n",
    "\n",
    "def create_heatmap(data, labels, title, figsize=(12, 10), cmap='Blues'):\n",
    "    \"\"\"Create heatmap using seaborn or matplotlib\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    if USE_SEABORN and seaborn:\n",
    "        sns.heatmap(data, annot=True, fmt='d', cmap=cmap, \n",
    "                   xticklabels=labels, yticklabels=labels, ax=ax)\n",
    "    else:\n",
    "        # Matplotlib fallback\n",
    "        im = ax.imshow(data, interpolation='nearest', cmap=plt.cm.get_cmap(cmap))\n",
    "        ax.figure.colorbar(im, ax=ax)\n",
    "        \n",
    "        # Add text annotations\n",
    "        thresh = data.max() / 2.\n",
    "        for i in range(data.shape[0]):\n",
    "            for j in range(data.shape[1]):\n",
    "                ax.text(j, i, format(data[i, j], 'd'),\n",
    "                       ha=\"center\", va=\"center\",\n",
    "                       color=\"white\" if data[i, j] > thresh else \"black\")\n",
    "        \n",
    "        ax.set_xticks(np.arange(len(labels)))\n",
    "        ax.set_yticks(np.arange(len(labels)))\n",
    "        ax.set_xticklabels(labels, rotation=45, ha=\"right\")\n",
    "        ax.set_yticklabels(labels)\n",
    "    \n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('Actual')\n",
    "    plt.tight_layout()\n",
    "    return fig, ax\n",
    "\n",
    "def comprehensive_model_evaluation(model_path, test_data_path, device='cuda'):\n",
    "    \"\"\"\n",
    "    Perform comprehensive evaluation of the trained model\n",
    "    \"\"\"\n",
    "    # Auto-detect paths if not provided\n",
    "    if not model_path:\n",
    "        # Search for latest checkpoint\n",
    "        import glob\n",
    "        checkpoint_patterns = [\n",
    "            'local_checkpoints/checkpoint_epoch_*.pth',\n",
    "            'checkpoint_epoch_*.pth',\n",
    "            'mae_checkpoints/*.pth'\n",
    "        ]\n",
    "        \n",
    "        found_checkpoints = []\n",
    "        for pattern in checkpoint_patterns:\n",
    "            found_checkpoints.extend(glob.glob(pattern))\n",
    "        \n",
    "        if found_checkpoints:\n",
    "            # Get latest checkpoint by epoch number or modification time\n",
    "            latest_checkpoint = max(found_checkpoints, key=lambda x: \n",
    "                int(x.split('epoch_')[1].split('.')[0]) if 'epoch_' in x else 0)\n",
    "            model_path = latest_checkpoint\n",
    "            print(f\"Using latest checkpoint: {model_path}\")\n",
    "        else:\n",
    "            print(\"No checkpoints found!\")\n",
    "            return\n",
    "    \n",
    "    # Load test dataset\n",
    "    from data import FishDataset\n",
    "    from torch.utils.data import DataLoader\n",
    "    from torchvision import transforms\n",
    "    \n",
    "    # Test transforms (same as validation)\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                           std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    try:\n",
    "        test_dataset = FishDataset(test_data_path, transform=test_transform, is_test=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "        print(f\"✓ Loaded test dataset: {len(test_dataset)} images\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Failed to load test dataset: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Load model\n",
    "    from model import ViTForFishClassification\n",
    "    \n",
    "    try:\n",
    "        # Determine number of classes\n",
    "        with open('species_mapping.txt', 'r') as f:\n",
    "            species_lines = f.readlines()\n",
    "        num_classes = len([line.strip() for line in species_lines if line.strip()])\n",
    "        \n",
    "        # Initialize model\n",
    "        model = ViTForFishClassification(num_classes=num_classes)\n",
    "        \n",
    "        # Load checkpoint\n",
    "        checkpoint = torch.load(model_path, map_location=device)\n",
    "        \n",
    "        # Handle different checkpoint formats\n",
    "        if 'model_state_dict' in checkpoint:\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            epoch = checkpoint.get('epoch', 'Unknown')\n",
    "            accuracy = checkpoint.get('accuracy', 'Unknown')\n",
    "            print(f\"✓ Loaded model from epoch {epoch} with accuracy {accuracy}\")\n",
    "        else:\n",
    "            model.load_state_dict(checkpoint)\n",
    "            print(f\"✓ Loaded model state dict from {model_path}\")\n",
    "        \n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Failed to load model: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Load species mapping\n",
    "    try:\n",
    "        species_mapping = {}\n",
    "        with open('species_mapping.txt', 'r') as f:\n",
    "            for line in f:\n",
    "                if line.strip():\n",
    "                    idx, species = line.strip().split(': ', 1)\n",
    "                    species_mapping[int(idx)] = species\n",
    "        print(f\"✓ Loaded {len(species_mapping)} species classes\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Failed to load species mapping: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Evaluation\n",
    "    print(\"\\n🔄 Starting comprehensive evaluation...\")\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_probabilities = []\n",
    "    class_correct = defaultdict(int)\n",
    "    class_total = defaultdict(int)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels) in enumerate(test_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            probabilities = torch.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probabilities.extend(probabilities.cpu().numpy())\n",
    "            \n",
    "            # Per-class accuracy tracking\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(labels.size(0)):\n",
    "                label = labels[i].item()\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "            \n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f\"Processed {batch_idx * len(images)}/{len(test_dataset)} images\", end='\\r')\n",
    "    \n",
    "    print(f\"\\n✓ Evaluation complete!\")\n",
    "    \n",
    "    # Calculate metrics\n",
    "    overall_accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    cm = confusion_matrix(all_labels, all_predictions)\n",
    "    \n",
    "    print(f\"\\n📊 EVALUATION RESULTS\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Overall Accuracy: {overall_accuracy:.4f} ({overall_accuracy*100:.2f}%)\")\n",
    "    print(f\"Total Test Images: {len(all_labels)}\")\n",
    "    \n",
    "    # Classification report\n",
    "    print(f\"\\n📋 Detailed Classification Report:\")\n",
    "    class_names = [species_mapping[i] for i in sorted(species_mapping.keys())]\n",
    "    report = classification_report(all_labels, all_predictions, \n",
    "                                 target_names=class_names, \n",
    "                                 output_dict=True)\n",
    "    \n",
    "    print(classification_report(all_labels, all_predictions, target_names=class_names))\n",
    "    \n",
    "    # Per-class accuracy\n",
    "    print(f\"\\n🎯 Per-Class Accuracy:\")\n",
    "    for class_idx in sorted(class_total.keys()):\n",
    "        if class_total[class_idx] > 0:\n",
    "            acc = class_correct[class_idx] / class_total[class_idx]\n",
    "            species_name = species_mapping.get(class_idx, f\"Class_{class_idx}\")\n",
    "            print(f\"{species_name:30s}: {acc:.4f} ({acc*100:5.1f}%) [{class_correct[class_idx]}/{class_total[class_idx]}]\")\n",
    "    \n",
    "    # Visualizations\n",
    "    print(f\"\\n\udcc8 Generating visualizations...\")\n",
    "    \n",
    "    # Set color palette\n",
    "    if USE_SEABORN:\n",
    "        sns.set_palette(\"husl\")\n",
    "    \n",
    "    # 1. Confusion Matrix\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    \n",
    "    # Filter for classes that appear in test set\n",
    "    unique_labels = sorted(list(set(all_labels)))\n",
    "    cm_filtered = cm[np.ix_(unique_labels, unique_labels)]\n",
    "    filtered_class_names = [class_names[i] for i in unique_labels]\n",
    "    \n",
    "    if len(unique_labels) > 20:  # If too many classes, show full matrix\n",
    "        fig, ax = create_heatmap(cm, class_names, \n",
    "                               f'Confusion Matrix - All Classes (Accuracy: {overall_accuracy:.3f})',\n",
    "                               figsize=(20, 16), cmap='Blues')\n",
    "    else:\n",
    "        fig, ax = create_heatmap(cm_filtered, filtered_class_names, \n",
    "                               f'Confusion Matrix - Test Classes (Accuracy: {overall_accuracy:.3f})',\n",
    "                               figsize=(12, 10), cmap='Blues')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # 2. Per-class accuracy bar chart\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    class_accuracies = []\n",
    "    class_labels = []\n",
    "    \n",
    "    for class_idx in sorted(class_total.keys()):\n",
    "        if class_total[class_idx] > 0:\n",
    "            acc = class_correct[class_idx] / class_total[class_idx]\n",
    "            class_accuracies.append(acc)\n",
    "            species_name = species_mapping.get(class_idx, f\"Class_{class_idx}\")\n",
    "            class_labels.append(species_name)\n",
    "    \n",
    "    bars = plt.bar(range(len(class_accuracies)), class_accuracies)\n",
    "    plt.xlabel('Species')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(f'Per-Class Accuracy (Overall: {overall_accuracy:.3f})')\n",
    "    plt.xticks(range(len(class_labels)), class_labels, rotation=45, ha='right')\n",
    "    plt.ylim(0, 1.0)\n",
    "    \n",
    "    # Color bars based on accuracy\n",
    "    for i, bar in enumerate(bars):\n",
    "        if class_accuracies[i] >= 0.8:\n",
    "            bar.set_color('green')\n",
    "        elif class_accuracies[i] >= 0.6:\n",
    "            bar.set_color('orange')\n",
    "        else:\n",
    "            bar.set_color('red')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 3. Confidence distribution\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    all_probabilities = np.array(all_probabilities)\n",
    "    max_confidences = np.max(all_probabilities, axis=1)\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(max_confidences, bins=50, alpha=0.7, edgecolor='black')\n",
    "    plt.xlabel('Maximum Confidence')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Prediction Confidence Distribution')\n",
    "    plt.axvline(np.mean(max_confidences), color='red', linestyle='--', \n",
    "                label=f'Mean: {np.mean(max_confidences):.3f}')\n",
    "    plt.legend()\n",
    "    \n",
    "    # 4. Correct vs Incorrect predictions confidence\n",
    "    plt.subplot(1, 2, 2)\n",
    "    correct_mask = np.array(all_predictions) == np.array(all_labels)\n",
    "    correct_conf = max_confidences[correct_mask]\n",
    "    incorrect_conf = max_confidences[~correct_mask]\n",
    "    \n",
    "    plt.hist(correct_conf, bins=30, alpha=0.7, label=f'Correct ({len(correct_conf)})', \n",
    "             color='green', edgecolor='black')\n",
    "    plt.hist(incorrect_conf, bins=30, alpha=0.7, label=f'Incorrect ({len(incorrect_conf)})', \n",
    "             color='red', edgecolor='black')\n",
    "    plt.xlabel('Confidence')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Confidence by Prediction Correctness')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 5. Summary statistics\n",
    "    print(f\"\\n📊 SUMMARY STATISTICS\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Mean Confidence: {np.mean(max_confidences):.4f}\")\n",
    "    print(f\"Std Confidence: {np.std(max_confidences):.4f}\")\n",
    "    print(f\"Mean Correct Confidence: {np.mean(correct_conf):.4f}\")\n",
    "    print(f\"Mean Incorrect Confidence: {np.mean(incorrect_conf):.4f}\")\n",
    "    print(f\"High Confidence (>0.9) Predictions: {np.sum(max_confidences > 0.9)} ({np.sum(max_confidences > 0.9)/len(max_confidences)*100:.1f}%)\")\n",
    "    print(f\"Low Confidence (<0.5) Predictions: {np.sum(max_confidences < 0.5)} ({np.sum(max_confidences < 0.5)/len(max_confidences)*100:.1f}%)\")\n",
    "    \n",
    "    return {\n",
    "        'accuracy': overall_accuracy,\n",
    "        'predictions': all_predictions,\n",
    "        'labels': all_labels,\n",
    "        'probabilities': all_probabilities,\n",
    "        'confusion_matrix': cm,\n",
    "        'classification_report': report,\n",
    "        'per_class_accuracy': {species_mapping[i]: class_correct[i]/class_total[i] \n",
    "                              for i in class_total.keys() if class_total[i] > 0}\n",
    "    }\n",
    "\n",
    "# Run comprehensive evaluation\n",
    "if 'SELECTED_MODEL_PATH' in globals() and 'TEST_DATA_PATH' in globals():\n",
    "    print(f\"\ude80 Starting evaluation with:\")\n",
    "    print(f\"Model: {SELECTED_MODEL_PATH}\")\n",
    "    print(f\"Test Data: {TEST_DATA_PATH}\")\n",
    "    \n",
    "    results = comprehensive_model_evaluation(\n",
    "        model_path=SELECTED_MODEL_PATH,\n",
    "        test_data_path=TEST_DATA_PATH,\n",
    "        device=DEVICE\n",
    "    )\n",
    "else:\n",
    "    print(\"⚠️ Please run the previous cells to select a model and test dataset path.\")\n",
    "    print(\"Variables needed: SELECTED_MODEL_PATH, TEST_DATA_PATH, DEVICE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780518b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Generate Visualization and Detailed Analysis\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"📊 GENERATING VISUALIZATIONS AND DETAILED ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if 'EVALUATION_RESULTS' not in globals():\n",
    "    print(\"❌ No evaluation results found! Please run the evaluation cell first.\")\n",
    "else:\n",
    "    \n",
    "    # Extract results\n",
    "    overall_accuracy = EVALUATION_RESULTS['overall_accuracy']\n",
    "    class_accuracies = EVALUATION_RESULTS['class_accuracies']\n",
    "    class_names = EVALUATION_RESULTS['class_names']\n",
    "    predictions = EVALUATION_RESULTS['predictions']\n",
    "    labels = EVALUATION_RESULTS['labels']\n",
    "    probabilities = EVALUATION_RESULTS['probabilities']\n",
    "    \n",
    "    print(\"🎨 Creating visualizations...\")\n",
    "    \n",
    "    # Set up plotting style\n",
    "    plt.style.use('default')\n",
    "    sns.set_palette(\"husl\")\n",
    "    \n",
    "    # Figure 1: Confusion Matrix\n",
    "    print(\"📊 1. Creating Confusion Matrix...\")\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(labels, predictions)\n",
    "    \n",
    "    # For better visualization, limit to top species if too many classes\n",
    "    n_classes = len(class_names)\n",
    "    if n_classes > 20:\n",
    "        print(f\"⚠️ Too many classes ({n_classes}) for clear visualization. Showing top 20 species.\")\n",
    "        \n",
    "        # Find top 20 classes by frequency\n",
    "        unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "        top_indices = unique_labels[np.argsort(counts)[-20:]]\n",
    "        \n",
    "        # Filter confusion matrix and names\n",
    "        cm_filtered = cm[np.ix_(top_indices, top_indices)]\n",
    "        class_names_filtered = [class_names[i] if i < len(class_names) else f'Species_{i}' for i in top_indices]\n",
    "        \n",
    "        # Plot filtered confusion matrix\n",
    "        sns.heatmap(cm_filtered, \n",
    "                   annot=False, \n",
    "                   cmap='Blues',\n",
    "                   xticklabels=[name[:10] for name in class_names_filtered],\n",
    "                   yticklabels=[name[:10] for name in class_names_filtered])\n",
    "        plt.title(f'Confusion Matrix - Top 20 Species\\\\nOverall Accuracy: {overall_accuracy:.2f}%', fontsize=14)\n",
    "        \n",
    "    else:\n",
    "        # Plot full confusion matrix\n",
    "        sns.heatmap(cm, \n",
    "                   annot=False, \n",
    "                   cmap='Blues',\n",
    "                   xticklabels=[name[:10] for name in class_names],\n",
    "                   yticklabels=[name[:10] for name in class_names])\n",
    "        plt.title(f'Confusion Matrix - All Species\\\\nOverall Accuracy: {overall_accuracy:.2f}%', fontsize=14)\n",
    "    \n",
    "    plt.xlabel('Predicted Species', fontsize=12)\n",
    "    plt.ylabel('True Species', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Figure 2: Per-Species Accuracy Bar Chart\n",
    "    print(\"📊 2. Creating Per-Species Accuracy Chart...\")\n",
    "    \n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    # Sort species by accuracy for better visualization\n",
    "    sorted_indices = np.argsort(class_accuracies)[::-1]\n",
    "    sorted_accuracies = [class_accuracies[i] for i in sorted_indices]\n",
    "    sorted_names = [class_names[i] if i < len(class_names) else f'Species_{i}' for i in sorted_indices]\n",
    "    \n",
    "    # Color code by performance\n",
    "    colors = []\n",
    "    for acc in sorted_accuracies:\n",
    "        if acc >= 90:\n",
    "            colors.append('green')\n",
    "        elif acc >= 80:\n",
    "            colors.append('blue')\n",
    "        elif acc >= 70:\n",
    "            colors.append('orange')\n",
    "        else:\n",
    "            colors.append('red')\n",
    "    \n",
    "    # Create bar chart\n",
    "    bars = plt.bar(range(len(sorted_accuracies)), sorted_accuracies, color=colors, alpha=0.7)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, (bar, acc) in enumerate(zip(bars, sorted_accuracies)):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, \n",
    "                f'{acc:.1f}%', ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    plt.title(f'Per-Species Classification Accuracy\\\\nOverall: {overall_accuracy:.2f}%', fontsize=14)\n",
    "    plt.xlabel('Fish Species', fontsize=12)\n",
    "    plt.ylabel('Accuracy (%)', fontsize=12)\n",
    "    plt.xticks(range(len(sorted_names)), [name[:15] for name in sorted_names], rotation=45, ha='right')\n",
    "    plt.ylim(0, 105)\n",
    "    \n",
    "    # Add legend\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [\n",
    "        Patch(facecolor='green', alpha=0.7, label='Excellent (≥90%)'),\n",
    "        Patch(facecolor='blue', alpha=0.7, label='Good (80-89%)'),\n",
    "        Patch(facecolor='orange', alpha=0.7, label='Fair (70-79%)'),\n",
    "        Patch(facecolor='red', alpha=0.7, label='Poor (<70%)')\n",
    "    ]\n",
    "    plt.legend(handles=legend_elements, loc='upper right')\n",
    "    \n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Figure 3: Prediction Confidence Distribution\n",
    "    print(\"📊 3. Creating Prediction Confidence Distribution...\")\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Calculate max probabilities (confidence scores)\n",
    "    max_probs = np.max(probabilities, axis=1)\n",
    "    correct_mask = predictions == labels\n",
    "    \n",
    "    # Split by correct/incorrect predictions\n",
    "    correct_probs = max_probs[correct_mask]\n",
    "    incorrect_probs = max_probs[~correct_mask]\n",
    "    \n",
    "    # Create histogram\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(correct_probs, bins=30, alpha=0.7, color='green', label=f'Correct ({len(correct_probs)})')\n",
    "    plt.hist(incorrect_probs, bins=30, alpha=0.7, color='red', label=f'Incorrect ({len(incorrect_probs)})')\n",
    "    plt.xlabel('Prediction Confidence')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Prediction Confidence Distribution')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Box plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    box_data = [correct_probs, incorrect_probs]\n",
    "    plt.boxplot(box_data, labels=['Correct', 'Incorrect'], patch_artist=True)\n",
    "    plt.ylabel('Prediction Confidence')\n",
    "    plt.title('Confidence: Correct vs Incorrect')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detailed classification report\n",
    "    print(\"📋 DETAILED CLASSIFICATION REPORT:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Limit report to existing classes\n",
    "    existing_classes = sorted(list(set(labels)))\n",
    "    target_names = [class_names[i] if i < len(class_names) else f'Species_{i}' for i in existing_classes]\n",
    "    \n",
    "    report = classification_report(\n",
    "        labels, predictions, \n",
    "        labels=existing_classes,\n",
    "        target_names=target_names,\n",
    "        digits=3\n",
    "    )\n",
    "    print(report)\n",
    "    \n",
    "    # Additional insights\n",
    "    print(\"🔍 ADDITIONAL INSIGHTS:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Confidence statistics\n",
    "    print(f\"📊 Confidence Statistics:\")\n",
    "    print(f\"   Average confidence (correct): {np.mean(correct_probs):.3f}\")\n",
    "    print(f\"   Average confidence (incorrect): {np.mean(incorrect_probs):.3f}\")\n",
    "    print(f\"   Overall average confidence: {np.mean(max_probs):.3f}\")\n",
    "    \n",
    "    # Most/least confident predictions\n",
    "    most_confident_idx = np.argmax(max_probs)\n",
    "    least_confident_idx = np.argmin(max_probs)\n",
    "    \n",
    "    print(f\"\\n🎯 Confidence Extremes:\")\n",
    "    print(f\"   Most confident: {max_probs[most_confident_idx]:.3f} \"\n",
    "          f\"(Predicted: {class_names[predictions[most_confident_idx]] if predictions[most_confident_idx] < len(class_names) else f'Species_{predictions[most_confident_idx]}'}, \"\n",
    "          f\"Actual: {class_names[labels[most_confident_idx]] if labels[most_confident_idx] < len(class_names) else f'Species_{labels[most_confident_idx]}'})\")\n",
    "    \n",
    "    print(f\"   Least confident: {max_probs[least_confident_idx]:.3f} \"\n",
    "          f\"(Predicted: {class_names[predictions[least_confident_idx]] if predictions[least_confident_idx] < len(class_names) else f'Species_{predictions[least_confident_idx]}'}, \"\n",
    "          f\"Actual: {class_names[labels[least_confident_idx]] if labels[least_confident_idx] < len(class_names) else f'Species_{labels[least_confident_idx]}'})\")\n",
    "    \n",
    "    # Model performance assessment\n",
    "    print(f\"\\n🎯 MODEL PERFORMANCE ASSESSMENT:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if overall_accuracy >= 90:\n",
    "        print(\"🌟 OUTSTANDING! Your model shows exceptional performance.\")\n",
    "        print(\"   → Ready for production deployment\")\n",
    "        print(\"   → Excellent generalization to test data\")\n",
    "    elif overall_accuracy >= 80:\n",
    "        print(\"🎉 EXCELLENT! Your model performs very well.\")\n",
    "        print(\"   → Suitable for most practical applications\")\n",
    "        print(\"   → Consider fine-tuning for critical use cases\")\n",
    "    elif overall_accuracy >= 70:\n",
    "        print(\"👍 GOOD! Your model shows solid performance.\")\n",
    "        print(\"   → Good foundation for fish classification\")\n",
    "        print(\"   → Additional training data might boost performance\")\n",
    "    elif overall_accuracy >= 60:\n",
    "        print(\"📈 FAIR. Your model has decent performance.\")\n",
    "        print(\"   → Consider more training epochs or data augmentation\")\n",
    "        print(\"   → Review difficult species for targeted improvements\")\n",
    "    else:\n",
    "        print(\"⚠️ NEEDS IMPROVEMENT. Consider the following:\")\n",
    "        print(\"   → More training data, especially for poor-performing species\")\n",
    "        print(\"   → Different model architecture or hyperparameters\")\n",
    "        print(\"   → Data quality review and preprocessing improvements\")\n",
    "    \n",
    "    # Save results summary\n",
    "    try:\n",
    "        results_summary = {\n",
    "            'model_name': os.path.basename(SELECTED_MODEL_PATH),\n",
    "            'overall_accuracy': overall_accuracy,\n",
    "            'total_samples': len(labels),\n",
    "            'correct_predictions': int(sum(predictions == labels)),\n",
    "            'num_species': len(class_names),\n",
    "            'per_species_accuracy': {\n",
    "                class_names[i] if i < len(class_names) else f'Species_{i}': acc \n",
    "                for i, acc in enumerate(class_accuracies)\n",
    "            },\n",
    "            'confidence_stats': {\n",
    "                'avg_confidence_correct': float(np.mean(correct_probs)),\n",
    "                'avg_confidence_incorrect': float(np.mean(incorrect_probs)),\n",
    "                'overall_avg_confidence': float(np.mean(max_probs))\n",
    "            },\n",
    "            'evaluation_timestamp': str(pd.Timestamp.now())\n",
    "        }\n",
    "        \n",
    "        # Try to save to file\n",
    "        import json\n",
    "        results_file = 'model_evaluation_results.json'\n",
    "        with open(results_file, 'w') as f:\n",
    "            json.dump(results_summary, f, indent=2)\n",
    "        print(f\"\\n💾 Results saved to: {results_file}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n⚠️ Could not save results file: {e}\")\n",
    "    \n",
    "    print(f\"\\n🎉 EVALUATION AND ANALYSIS COMPLETE!\")\n",
    "    print(f\"✅ Your ViT model evaluation is finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c29b2fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 SYSTEM STATUS CHECK\n",
      "==================================================\n",
      "Using CPU\n",
      "CPU Usage: 19.1%\n",
      "RAM Usage: 80.2% (5.8GB / 18.0GB)\n",
      "✓ Test dataset path: /Users/catalinathomson/Desktop/Fish/ViT-FishID/fish_cutouts\n",
      "✓ Model path: /Users/catalinathomson/Desktop/Fish/ViT-FishID/colab_checkpoints/checkpoint_epoch_100.pth\n",
      "\n",
      "💡 If evaluation has been running for >5 minutes:\n",
      "1. Check if GPU/CPU usage is high (indicates it's working)\n",
      "2. Large datasets may take 10-20 minutes to evaluate\n",
      "3. Try interrupting the kernel and running the faster version below\n",
      "\n",
      "Current time: 11:00:02\n",
      "CPU Usage: 19.1%\n",
      "RAM Usage: 80.2% (5.8GB / 18.0GB)\n",
      "✓ Test dataset path: /Users/catalinathomson/Desktop/Fish/ViT-FishID/fish_cutouts\n",
      "✓ Model path: /Users/catalinathomson/Desktop/Fish/ViT-FishID/colab_checkpoints/checkpoint_epoch_100.pth\n",
      "\n",
      "💡 If evaluation has been running for >5 minutes:\n",
      "1. Check if GPU/CPU usage is high (indicates it's working)\n",
      "2. Large datasets may take 10-20 minutes to evaluate\n",
      "3. Try interrupting the kernel and running the faster version below\n",
      "\n",
      "Current time: 11:00:02\n"
     ]
    }
   ],
   "source": [
    "# Quick Progress Check - Run this to see if evaluation is working\n",
    "import time\n",
    "import torch\n",
    "import psutil\n",
    "import gc\n",
    "\n",
    "print(\"🔍 SYSTEM STATUS CHECK\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check GPU/CPU usage\n",
    "try:\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU Memory: {torch.cuda.memory_allocated() / 1024**3:.2f}GB / {torch.cuda.max_memory_allocated() / 1024**3:.2f}GB\")\n",
    "        print(f\"GPU Utilization: {torch.cuda.utilization()}%\")\n",
    "    else:\n",
    "        print(\"Using CPU\")\n",
    "    \n",
    "    # Check CPU and RAM\n",
    "    cpu_percent = psutil.cpu_percent(interval=1)\n",
    "    memory = psutil.virtual_memory()\n",
    "    print(f\"CPU Usage: {cpu_percent}%\")\n",
    "    print(f\"RAM Usage: {memory.percent}% ({memory.used / 1024**3:.1f}GB / {memory.total / 1024**3:.1f}GB)\")\n",
    "    \n",
    "    # Check if variables are still in memory\n",
    "    if 'TEST_DATA_PATH' in globals():\n",
    "        print(f\"✓ Test dataset path: {TEST_DATA_PATH}\")\n",
    "    if 'SELECTED_MODEL_PATH' in globals():\n",
    "        print(f\"✓ Model path: {SELECTED_MODEL_PATH}\")\n",
    "    \n",
    "    print(\"\\n💡 If evaluation has been running for >5 minutes:\")\n",
    "    print(\"1. Check if GPU/CPU usage is high (indicates it's working)\")\n",
    "    print(\"2. Large datasets may take 10-20 minutes to evaluate\")\n",
    "    print(\"3. Try interrupting the kernel and running the faster version below\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error checking status: {e}\")\n",
    "\n",
    "print(f\"\\nCurrent time: {time.strftime('%H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5811ea40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FASTER Model Evaluation with Real-time Progress\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "def fast_model_evaluation(model_path, test_data_path, device='cuda', max_batches=None):\n",
    "    \"\"\"\n",
    "    Fast evaluation with progress bars and real-time feedback\n",
    "    \"\"\"\n",
    "    print(f\"🚀 FAST EVALUATION STARTING...\")\n",
    "    print(f\"Time: {time.strftime('%H:%M:%S')}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Load test dataset with progress\n",
    "    print(\"📁 Loading test dataset...\")\n",
    "    try:\n",
    "        from data import FishDataset\n",
    "        from torch.utils.data import DataLoader\n",
    "        from torchvision import transforms\n",
    "        \n",
    "        test_transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        test_dataset = FishDataset(test_data_path, transform=test_transform, is_test=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "        \n",
    "        dataset_load_time = time.time() - start_time\n",
    "        print(f\"✅ Dataset loaded: {len(test_dataset)} images in {dataset_load_time:.1f}s\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Dataset loading failed: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Load model with progress\n",
    "    print(\"\\n🧠 Loading model...\")\n",
    "    model_start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        from model import ViTForFishClassification\n",
    "        \n",
    "        # Get number of classes\n",
    "        with open('species_mapping.txt', 'r') as f:\n",
    "            species_lines = f.readlines()\n",
    "        num_classes = len([line.strip() for line in species_lines if line.strip()])\n",
    "        \n",
    "        model = ViTForFishClassification(num_classes=num_classes)\n",
    "        checkpoint = torch.load(model_path, map_location=device)\n",
    "        \n",
    "        if 'model_state_dict' in checkpoint:\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            epoch = checkpoint.get('epoch', 'Unknown')\n",
    "            print(f\"✅ Model loaded from epoch {epoch}\")\n",
    "        else:\n",
    "            model.load_state_dict(checkpoint)\n",
    "            print(f\"✅ Model loaded from checkpoint\")\n",
    "        \n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        \n",
    "        model_load_time = time.time() - model_start_time\n",
    "        print(f\"   Model loading took: {model_load_time:.1f}s\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Model loading failed: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Load species mapping\n",
    "    print(\"\\n📋 Loading species mapping...\")\n",
    "    try:\n",
    "        species_mapping = {}\n",
    "        with open('species_mapping.txt', 'r') as f:\n",
    "            for line in f:\n",
    "                if line.strip():\n",
    "                    idx, species = line.strip().split(': ', 1)\n",
    "                    species_mapping[int(idx)] = species\n",
    "        print(f\"✅ Loaded {len(species_mapping)} species classes\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Species mapping failed: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Evaluation with progress bar\n",
    "    print(f\"\\n🔬 Starting evaluation...\")\n",
    "    eval_start_time = time.time()\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_probabilities = []\n",
    "    \n",
    "    total_batches = len(test_loader)\n",
    "    if max_batches:\n",
    "        total_batches = min(total_batches, max_batches)\n",
    "    \n",
    "    # Create progress bar\n",
    "    pbar = tqdm(total=total_batches, desc=\"Evaluating\", \n",
    "                bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels) in enumerate(test_loader):\n",
    "            if max_batches and batch_idx >= max_batches:\n",
    "                break\n",
    "                \n",
    "            batch_start = time.time()\n",
    "            \n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            probabilities = torch.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probabilities.extend(probabilities.cpu().numpy())\n",
    "            \n",
    "            batch_time = time.time() - batch_start\n",
    "            \n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({\n",
    "                'Batch_Time': f'{batch_time:.2f}s',\n",
    "                'Images/s': f'{len(images)/batch_time:.1f}',\n",
    "                'Processed': f'{len(all_predictions)}'\n",
    "            })\n",
    "            pbar.update(1)\n",
    "            \n",
    "            # Print progress every 20 batches\n",
    "            if batch_idx % 20 == 0 and batch_idx > 0:\n",
    "                elapsed = time.time() - eval_start_time\n",
    "                imgs_per_sec = len(all_predictions) / elapsed\n",
    "                print(f\"\\n   Progress: {batch_idx}/{total_batches} batches, \"\n",
    "                      f\"{len(all_predictions)} images, {imgs_per_sec:.1f} imgs/s\")\n",
    "    \n",
    "    pbar.close()\n",
    "    eval_time = time.time() - eval_start_time\n",
    "    \n",
    "    print(f\"\\n✅ Evaluation complete!\")\n",
    "    print(f\"   Total time: {eval_time:.1f}s\")\n",
    "    print(f\"   Speed: {len(all_predictions)/eval_time:.1f} images/second\")\n",
    "    \n",
    "    # Quick results\n",
    "    overall_accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    \n",
    "    print(f\"\\n📊 QUICK RESULTS\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Overall Accuracy: {overall_accuracy:.4f} ({overall_accuracy*100:.2f}%)\")\n",
    "    print(f\"Total Images Processed: {len(all_labels)}\")\n",
    "    print(f\"Total Evaluation Time: {time.time() - start_time:.1f}s\")\n",
    "    \n",
    "    # Simple confusion matrix preview\n",
    "    cm = confusion_matrix(all_labels, all_predictions)\n",
    "    print(f\"Confusion Matrix Shape: {cm.shape}\")\n",
    "    \n",
    "    # Top and bottom performing classes\n",
    "    unique_labels = sorted(list(set(all_labels)))\n",
    "    class_accuracies = []\n",
    "    \n",
    "    for class_idx in unique_labels:\n",
    "        mask = np.array(all_labels) == class_idx\n",
    "        if np.sum(mask) > 0:\n",
    "            class_acc = np.sum(np.array(all_predictions)[mask] == class_idx) / np.sum(mask)\n",
    "            class_accuracies.append((class_idx, class_acc, np.sum(mask)))\n",
    "    \n",
    "    # Sort by accuracy\n",
    "    class_accuracies.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(f\"\\n🏆 TOP 5 PERFORMING CLASSES:\")\n",
    "    for i, (class_idx, acc, count) in enumerate(class_accuracies[:5]):\n",
    "        species_name = species_mapping.get(class_idx, f\"Class_{class_idx}\")\n",
    "        print(f\"  {i+1}. {species_name[:25]:25s}: {acc:.3f} ({count} samples)\")\n",
    "    \n",
    "    print(f\"\\n⚠️  BOTTOM 5 PERFORMING CLASSES:\")\n",
    "    for i, (class_idx, acc, count) in enumerate(class_accuracies[-5:]):\n",
    "        species_name = species_mapping.get(class_idx, f\"Class_{class_idx}\")\n",
    "        print(f\"  {i+1}. {species_name[:25]:25s}: {acc:.3f} ({count} samples)\")\n",
    "    \n",
    "    # Quick visualization\n",
    "    print(f\"\\n📈 Generating quick accuracy chart...\")\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Overall accuracy bar\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.bar(['Overall Accuracy'], [overall_accuracy], color='skyblue')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.title(f'Model Accuracy: {overall_accuracy:.3f}')\n",
    "    plt.ylabel('Accuracy')\n",
    "    \n",
    "    # Class accuracy distribution\n",
    "    plt.subplot(1, 2, 2)\n",
    "    accuracies = [acc for _, acc, _ in class_accuracies]\n",
    "    plt.hist(accuracies, bins=20, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "    plt.xlabel('Class Accuracy')\n",
    "    plt.ylabel('Number of Classes')\n",
    "    plt.title('Distribution of Per-Class Accuracies')\n",
    "    plt.axvline(overall_accuracy, color='red', linestyle='--', label=f'Overall: {overall_accuracy:.3f}')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'accuracy': overall_accuracy,\n",
    "        'predictions': all_predictions,\n",
    "        'labels': all_labels,\n",
    "        'evaluation_time': eval_time,\n",
    "        'class_accuracies': class_accuracies\n",
    "    }\n",
    "\n",
    "# Run fast evaluation\n",
    "if 'SELECTED_MODEL_PATH' in globals() and 'TEST_DATA_PATH' in globals():\n",
    "    print(f\"🎯 Starting FAST evaluation...\")\n",
    "    print(f\"Model: {SELECTED_MODEL_PATH}\")\n",
    "    print(f\"Test Data: {TEST_DATA_PATH}\")\n",
    "    print(f\"Device: {DEVICE}\")\n",
    "    \n",
    "    # Run with progress feedback (limit to first 100 batches for speed test)\n",
    "    results = fast_model_evaluation(\n",
    "        model_path=SELECTED_MODEL_PATH,\n",
    "        test_data_path=TEST_DATA_PATH,\n",
    "        device=DEVICE,\n",
    "        max_batches=50  # Remove this line to process all data\n",
    "    )\n",
    "    \n",
    "    if results:\n",
    "        print(f\"\\n🎉 FAST EVALUATION COMPLETED!\")\n",
    "        print(f\"Final Accuracy: {results['accuracy']:.4f}\")\n",
    "else:\n",
    "    print(\"⚠️ Please run the model selection cell first to set SELECTED_MODEL_PATH and TEST_DATA_PATH\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
