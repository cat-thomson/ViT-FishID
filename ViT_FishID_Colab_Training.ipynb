{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e0af9a0",
   "metadata": {
    "id": "0e0af9a0"
   },
   "source": [
    "# üêü ViT-FishID: Semi-Supervised Fish Classification\n",
    "\n",
    "**COMPLETE TRAINING PIPELINE WITH GOOGLE COLAB**\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/cat-thomson/ViT-FishID/blob/main/ViT_FishID_Colab_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "## üéØ What This Notebook Does\n",
    "\n",
    "This notebook implements a **complete semi-supervised learning pipeline** for fish species classification using:\n",
    "\n",
    "**ü§ñ Vision Transformer (ViT)**: State-of-the-art transformer architecture for image classification\n",
    "**üìä Semi-Supervised Learning**: Leverages both labeled and unlabeled fish images\n",
    "**üéì EMA Teacher-Student Framework**: Uses exponential moving averages for consistency training\n",
    "**‚òÅÔ∏è Google Colab**: Cloud-based training with GPU acceleration\n",
    "\n",
    "## üìä Expected Performance\n",
    "\n",
    "- **Training Time**: 4-6 hours for 100 epochs\n",
    "- **GPU Requirements**: T4/V100/A100 (Colab Pro recommended)\n",
    "- **Expected Accuracy**: 80-90% on fish species classification\n",
    "- **Data Efficiency**: Works well with limited labeled data\n",
    "\n",
    "## üõ†Ô∏è What You Need\n",
    "\n",
    "1. **Fish Dataset**: Labeled and unlabeled fish images (upload to Google Drive)\n",
    "2. **Google Colab Pro**: Recommended for longer training sessions\n",
    "3. **Weights & Biases Account**: Optional for experiment tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bcb2a3",
   "metadata": {
    "id": "26bcb2a3"
   },
   "source": [
    "## üîß Step 1: Environment Setup and GPU Check\n",
    "\n",
    "First, let's verify that we have GPU access and set up the optimal environment for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3540b19",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f3540b19",
    "outputId": "23cef4f3-72a1-4e63-de50-2c68d478e6b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç SYSTEM INFORMATION\n",
      "==================================================\n",
      "Python version: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
      "PyTorch version: 2.6.0+cu124\n",
      "CUDA available: True\n",
      "GPU Device: Tesla T4\n",
      "GPU Memory: 14.7 GB\n",
      "‚úÖ GPU is ready for training!\n",
      "üöÄ GPU optimized for training\n",
      "\n",
      "üéØ Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check GPU availability and system information\n",
    "import torch\n",
    "import os\n",
    "import gc\n",
    "\n",
    "print(\"üîç SYSTEM INFORMATION\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Python version: {os.sys.version}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device_name = torch.cuda.get_device_name(0)\n",
    "    device_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    print(f\"GPU Device: {device_name}\")\n",
    "    print(f\"GPU Memory: {device_memory:.1f} GB\")\n",
    "    print(\"‚úÖ GPU is ready for training!\")\n",
    "\n",
    "    # Set optimal GPU settings\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "\n",
    "    # Clear GPU cache\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    print(\"üöÄ GPU optimized for training\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå No GPU detected!\")\n",
    "    print(\"üìù To enable GPU in Colab:\")\n",
    "    print(\"   Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator ‚Üí GPU\")\n",
    "    print(\"   Then restart this notebook\")\n",
    "\n",
    "# Set device for later use\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\nüéØ Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149f671b",
   "metadata": {
    "id": "149f671b"
   },
   "source": [
    "## üìÅ Step 2: Mount Google Drive\n",
    "\n",
    "This will give us access to your fish dataset stored in Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4abb3ffd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4abb3ffd",
    "outputId": "8788f96b-035e-431d-85cf-aac9ad80ffad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to mount Google Drive...\n",
      "Clearing contents of mount point: /content/drive\n",
      "‚úÖ Mount point cleared.\n",
      "Mounted at /content/drive\n",
      "\n",
      "üìÇ Google Drive contents:\n",
      "  - Mock Matric\n",
      "  - Photos\n",
      "  - Admin\n",
      "  - Uni\n",
      "  - Fish_Training_Output\n",
      "  - Colab Notebooks\n",
      "  - ViT-FishID\n",
      "  - ViT-FishID_Training_20250814_154652\n",
      "  - ViT-FishID_Training_20250814_202307\n",
      "  - ViT-FishID_Training_20250814_205442\n",
      "  ... and 6 more items\n",
      "\n",
      "‚úÖ Google Drive mounted successfully!\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Mount Google Drive\n",
    "print(\"Attempting to mount Google Drive...\")\n",
    "\n",
    "# Ensure the mount point is clean before mounting\n",
    "mount_point = '/content/drive'\n",
    "if os.path.exists(mount_point) and os.path.isdir(mount_point):\n",
    "    print(f\"Clearing contents of mount point: {mount_point}\")\n",
    "    try:\n",
    "        # Use `rm -rf` via shell command for robustness in Colab environment\n",
    "        !rm -rf {mount_point}/*\n",
    "        # Recreate the directory structure if it was completely removed\n",
    "        if not os.path.exists(mount_point):\n",
    "             os.makedirs(mount_point)\n",
    "        print(\"‚úÖ Mount point cleared.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error clearing mount point: {e}\")\n",
    "        print(\"Attempting to proceed with mount anyway...\")\n",
    "\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# List contents to verify mount\n",
    "print(\"\\nüìÇ Google Drive contents:\")\n",
    "drive_path = '/content/drive/MyDrive'\n",
    "if os.path.exists(drive_path):\n",
    "    items = os.listdir(drive_path)[:10]  # Show first 10 items\n",
    "    for item in items:\n",
    "        print(f\"  - {item}\")\n",
    "    if len(os.listdir(drive_path)) > 10:\n",
    "        print(f\"  ... and {len(os.listdir(drive_path)) - 10} more items\")\n",
    "    print(\"\\n‚úÖ Google Drive mounted successfully!\")\n",
    "else:\n",
    "    print(\"‚ùå Failed to mount Google Drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8b6273",
   "metadata": {
    "id": "be8b6273"
   },
   "source": [
    "## üì¶ Step 3: Install Dependencies\n",
    "\n",
    "Installing all required packages for ViT-FishID training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c724abc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8c724abc",
    "outputId": "ee0d1d80-c1a2-43a0-97e5-f8bd530daaf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Installing dependencies...\n",
      "‚úÖ All dependencies installed successfully!\n",
      "\n",
      "üìã Package versions:\n",
      "  - torch: 2.6.0+cu124\n",
      "  - torchvision: 0.21.0+cu124\n",
      "  - timm: 1.0.19\n",
      "  - albumentations: 2.0.8\n",
      "  - opencv: 4.12.0\n",
      "  - sklearn: 1.6.1\n"
     ]
    }
   ],
   "source": [
    "# Configuration for Semi-Supervised Fish Classification Training\n",
    "import os\n",
    "\n",
    "print(\"‚öôÔ∏è TRAINING CONFIGURATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Auto-detect number of species from dataset\n",
    "NUM_CLASSES = 37  # Default\n",
    "if 'DATA_DIR' in globals() and os.path.exists(DATA_DIR):\n",
    "    labeled_dir = os.path.join(DATA_DIR, 'labeled')\n",
    "    if os.path.exists(labeled_dir):\n",
    "        species_count = len([d for d in os.listdir(labeled_dir)\n",
    "                           if os.path.isdir(os.path.join(labeled_dir, d)) and not d.startswith('.')])\n",
    "        NUM_CLASSES = species_count\n",
    "        print(f\"üìä Auto-detected {species_count} fish species\")\n",
    "\n",
    "# Create checkpoint directories\n",
    "CHECKPOINT_DIR = '/content/drive/MyDrive/ViT-FishID/pretrained_checkpoints'\n",
    "BACKUP_DIR = '/content/drive/MyDrive/ViT-FishID/pretrained_checkpoints_backup'\n",
    "\n",
    "try:\n",
    "    os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "    os.makedirs(BACKUP_DIR, exist_ok=True)\n",
    "    print(f\"üìÅ Checkpoints: {CHECKPOINT_DIR}\")\n",
    "    print(f\"üíæ Backups: {BACKUP_DIR}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Could not create Google Drive directories: {e}\")\n",
    "    CHECKPOINT_DIR = '/content/pretrained_checkpoints'\n",
    "    BACKUP_DIR = '/content/pretrained_checkpoints_backup'\n",
    "    os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "    os.makedirs(BACKUP_DIR, exist_ok=True)\n",
    "    print(f\"üìÅ Using local checkpoints: {CHECKPOINT_DIR}\")\n",
    "\n",
    "# Training Configuration\n",
    "TRAINING_CONFIG = {\n",
    "    # BASIC SETTINGS\n",
    "    'mode': 'semi_supervised',\n",
    "    'data_dir': DATA_DIR if 'DATA_DIR' in globals() else '/content/fish_cutouts',\n",
    "    'epochs': 100,\n",
    "    'batch_size': 16,\n",
    "    'learning_rate': 1e-4,\n",
    "    'weight_decay': 0.05,\n",
    "\n",
    "    # MODEL SETTINGS - FIXED to match MAE architecture (384 dimensions)\n",
    "    'model_name': 'vit_small_patch16_224',  # Changed from vit_base to vit_small to match MAE\n",
    "    'num_classes': NUM_CLASSES,\n",
    "    'pretrained': True,\n",
    "\n",
    "    # SEMI-SUPERVISED SETTINGS\n",
    "    'consistency_weight': 2.0,\n",
    "    'pseudo_label_threshold': 0.7,\n",
    "    'temperature': 4.0,\n",
    "    'warmup_epochs': 10,\n",
    "    'ramp_up_epochs': 30,\n",
    "\n",
    "    # SAVE SETTINGS\n",
    "    'checkpoint_dir': CHECKPOINT_DIR,\n",
    "    'save_frequency': 10,\n",
    "\n",
    "    # LOGGING SETTINGS\n",
    "    'use_wandb': False,\n",
    "    'wandb_project': 'ViT-FishID-Training',\n",
    "    'wandb_run_name': f'mae-fish-classification-{NUM_CLASSES}-classes',\n",
    "\n",
    "    # HARDWARE SETTINGS\n",
    "    'num_workers': 4,\n",
    "    'image_size': 224,\n",
    "    'dropout_rate': 0.1,\n",
    "\n",
    "    # MAE SETTINGS (will be updated by Step 7)\n",
    "    'mae_pretrained': False,  # Will be set to True if MAE loading succeeds\n",
    "    'mae_model_path': None,   # Will be set to path if MAE loading succeeds\n",
    "}\n",
    "\n",
    "print(f\"\\nüìã CONFIGURATION SUMMARY:\")\n",
    "print(f\"üêü Fish species: {NUM_CLASSES}\")\n",
    "print(f\"üß† Model: {TRAINING_CONFIG['model_name']} (ViT-Small 384-dim - matches MAE)\")\n",
    "print(f\"üìä Mode: {TRAINING_CONFIG['mode']}\")\n",
    "print(f\"‚è±Ô∏è Epochs: {TRAINING_CONFIG['epochs']}\")\n",
    "print(f\"üì¶ Batch size: {TRAINING_CONFIG['batch_size']}\")\n",
    "print(f\"üéØ Learning rate: {TRAINING_CONFIG['learning_rate']}\")\n",
    "print(f\"‚öñÔ∏è Consistency weight: {TRAINING_CONFIG['consistency_weight']}\")\n",
    "print(f\"üéì Pseudo-label threshold: {TRAINING_CONFIG['pseudo_label_threshold']}\")\n",
    "print(f\"üíæ Checkpoints: {TRAINING_CONFIG['checkpoint_dir']}\")\n",
    "print(f\"üìà W&B logging: {TRAINING_CONFIG['use_wandb']}\")\n",
    "\n",
    "print(f\"\\nüîß ARCHITECTURE COMPATIBILITY:\")\n",
    "print(f\"   ‚úÖ MAE: ViT with 384 embedding dimensions\")\n",
    "print(f\"   ‚úÖ Training Model: {TRAINING_CONFIG['model_name']} with 384 embedding dimensions\")\n",
    "print(f\"   üéØ PERFECT MATCH! MAE weights should load successfully!\")\n",
    "\n",
    "print(f\"\\n‚öôÔ∏è Configuration complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b795fc",
   "metadata": {
    "id": "12b795fc"
   },
   "source": [
    "## üîÑ Step 4: Clone ViT-FishID Repository\n",
    "\n",
    "Getting the latest code from your GitHub repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4e4cd45",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c4e4cd45",
    "outputId": "86085e4c-db2e-498e-8baa-f7c49ef7021b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Cloning ViT-FishID repository...\n",
      "Cloning into '/content/ViT-FishID'...\n",
      "remote: Enumerating objects: 164, done.\u001b[K\n",
      "remote: Counting objects: 100% (164/164), done.\u001b[K\n",
      "remote: Compressing objects: 100% (122/122), done.\u001b[K\n",
      "remote: Total 164 (delta 69), reused 124 (delta 35), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (164/164), 322.97 KiB | 1.32 MiB/s, done.\n",
      "Resolving deltas: 100% (69/69), done.\n",
      "/content/ViT-FishID\n",
      "\n",
      "üìÇ Project structure:\n",
      "total 612\n",
      "drwxr-xr-x 5 root root   4096 Aug 18 09:21 .\n",
      "drwxr-xr-x 1 root root   4096 Aug 18 09:21 ..\n",
      "-rw-r--r-- 1 root root   4182 Aug 18 09:21 COLAB_CRASH_FIXES.md\n",
      "-rw-r--r-- 1 root root  21217 Aug 18 09:21 data.py\n",
      "-rw-r--r-- 1 root root  11572 Aug 18 09:21 evaluate.py\n",
      "-rw-r--r-- 1 root root   3328 Aug 18 09:21 EXTENDED_TRAINING_SETUP.md\n",
      "drwxr-xr-x 3 root root   4096 Aug 18 09:21 fish_cutouts\n",
      "drwxr-xr-x 8 root root   4096 Aug 18 09:21 .git\n",
      "-rw-r--r-- 1 root root     66 Aug 18 09:21 .gitattributes\n",
      "-rw-r--r-- 1 root root    646 Aug 18 09:21 .gitignore\n",
      "drwxr-xr-x 2 root root   4096 Aug 18 09:21 local_checkpoints\n",
      "-rw-r--r-- 1 root root  13100 Aug 18 09:21 local_resume_training.py\n",
      "-rw-r--r-- 1 root root      0 Aug 18 09:21 MAE_INTEGRATION_GUIDE.md\n",
      "-rw-r--r-- 1 root root   9495 Aug 18 09:21 model.py\n",
      "-rw-r--r-- 1 root root  16771 Aug 18 09:21 pipeline.py\n",
      "-rw-r--r-- 1 root root  16566 Aug 18 09:21 README.md\n",
      "-rw-r--r-- 1 root root    202 Aug 18 09:21 requirements.txt\n",
      "-rw-r--r-- 1 root root   4271 Aug 18 09:21 resume_training.py\n",
      "-rw-r--r-- 1 root root   5134 Aug 18 09:21 species_mapping.txt\n",
      "-rw-r--r-- 1 root root  25503 Aug 18 09:21 trainer.py\n",
      "-rw-r--r-- 1 root root   4982 Aug 18 09:21 TRAINING_FIXES_APPLIED.md\n",
      "-rw-r--r-- 1 root root  15343 Aug 18 09:21 train.py\n",
      "-rw-r--r-- 1 root root   8818 Aug 18 09:21 utils.py\n",
      "-rw-r--r-- 1 root root 153962 Aug 18 09:21 ViT_FishID_Colab_Training.ipynb\n",
      "-rw-r--r-- 1 root root 234973 Aug 18 09:21 ViT_FishID_MAE_EMA_Training.ipynb\n",
      "\n",
      "‚úÖ Repository cloned successfully!\n"
     ]
    }
   ],
   "source": [
    "# Clone the repository\n",
    "import os\n",
    "\n",
    "# Remove existing directory if it exists\n",
    "if os.path.exists('/content/ViT-FishID'):\n",
    "    !rm -rf /content/ViT-FishID\n",
    "\n",
    "# Clone the repository\n",
    "print(\"üì• Cloning ViT-FishID repository...\")\n",
    "!git clone https://github.com/cat-thomson/ViT-FishID.git /content/ViT-FishID\n",
    "\n",
    "# Change to project directory\n",
    "%cd /content/ViT-FishID\n",
    "\n",
    "# List project files\n",
    "print(\"\\nüìÇ Project structure:\")\n",
    "!ls -la\n",
    "\n",
    "print(\"\\n‚úÖ Repository cloned successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8155c400",
   "metadata": {
    "id": "8155c400"
   },
   "source": [
    "## üê† Step 5: Setup Fish Dataset\n",
    "\n",
    "**Important**: Upload your `fish_cutouts.zip` file to Google Drive before running this step.\n",
    "\n",
    "Expected dataset structure:\n",
    "```\n",
    "fish_cutouts/\n",
    "‚îú‚îÄ‚îÄ labeled/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ species_1/\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fish_001.jpg\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ fish_002.jpg\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ species_2/\n",
    "‚îÇ       ‚îî‚îÄ‚îÄ ...\n",
    "‚îî‚îÄ‚îÄ unlabeled/\n",
    "    ‚îú‚îÄ‚îÄ fish_003.jpg\n",
    "    ‚îî‚îÄ‚îÄ fish_004.jpg\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "nre5_INaKDXl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nre5_INaKDXl",
    "outputId": "f9e30750-e5ec-4cbe-8048-1cf712706717"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üê† SETTING UP FISH DATASET\n",
      "==================================================\n",
      "üìÇ Looking for dataset: /content/drive/MyDrive/fish_cutouts.zip\n",
      "üéØ Target directory: /content/fish_cutouts\n",
      "üì• Extracting dataset from Google Drive...\n",
      "‚úÖ Found dataset: 216.5 MB\n",
      "üìÅ Extracted: ['dataset_info.json', 'unlabeled', '__MACOSX', 'labeled']\n",
      "‚úÖ Dataset organized successfully!\n",
      "üêü Verified: 37 species\n",
      "üìä Verified: 24015 unlabeled images\n",
      "\n",
      "‚úÖ DATASET READY\n",
      "üìÅ Location: /content/fish_cutouts\n",
      "üöÄ Ready for training!\n"
     ]
    }
   ],
   "source": [
    "# Setup fish dataset from Google Drive\n",
    "import zipfile\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "\n",
    "print(\"üê† SETTING UP FISH DATASET\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Configuration\n",
    "ZIP_FILE_PATH = '/content/drive/MyDrive/fish_cutouts.zip'\n",
    "DATA_DIR = '/content/fish_cutouts'\n",
    "\n",
    "print(f\"üìÇ Looking for dataset: {ZIP_FILE_PATH}\")\n",
    "print(f\"üéØ Target directory: {DATA_DIR}\")\n",
    "\n",
    "# Check if data already exists locally\n",
    "if os.path.exists(DATA_DIR) and os.path.exists(os.path.join(DATA_DIR, 'labeled')):\n",
    "    print(\"‚úÖ Dataset already available locally!\")\n",
    "\n",
    "    # Quick validation\n",
    "    labeled_dir = os.path.join(DATA_DIR, 'labeled')\n",
    "    unlabeled_dir = os.path.join(DATA_DIR, 'unlabeled')\n",
    "\n",
    "    if os.path.exists(labeled_dir):\n",
    "        species_count = len([d for d in os.listdir(labeled_dir)\n",
    "                           if os.path.isdir(os.path.join(labeled_dir, d)) and not d.startswith('.')])\n",
    "        print(f\"üêü Found {species_count} labeled species\")\n",
    "\n",
    "    if os.path.exists(unlabeled_dir):\n",
    "        unlabeled_count = len([f for f in os.listdir(unlabeled_dir)\n",
    "                             if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "        print(f\"üìä Found {unlabeled_count} unlabeled images\")\n",
    "\n",
    "else:\n",
    "    print(\"üì• Extracting dataset from Google Drive...\")\n",
    "\n",
    "    # Check if ZIP file exists\n",
    "    if not os.path.exists(ZIP_FILE_PATH):\n",
    "        print(f\"‚ùå Dataset not found at: {ZIP_FILE_PATH}\")\n",
    "        print(\"üìù Please upload fish_cutouts.zip to Google Drive root directory\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Found dataset: {os.path.getsize(ZIP_FILE_PATH) / (1024**2):.1f} MB\")\n",
    "\n",
    "        try:\n",
    "            # Extract to temporary directory\n",
    "            temp_dir = '/content/temp_extract'\n",
    "            if os.path.exists(temp_dir):\n",
    "                shutil.rmtree(temp_dir)\n",
    "\n",
    "            with zipfile.ZipFile(ZIP_FILE_PATH, 'r') as zip_ref:\n",
    "                zip_ref.extractall(temp_dir)\n",
    "\n",
    "            # Find and organize data\n",
    "            extracted_items = os.listdir(temp_dir)\n",
    "            print(f\"üìÅ Extracted: {extracted_items}\")\n",
    "\n",
    "            # Look for labeled and unlabeled directories\n",
    "            labeled_source = None\n",
    "            unlabeled_source = None\n",
    "\n",
    "            for item in extracted_items:\n",
    "                item_path = os.path.join(temp_dir, item)\n",
    "                if item == 'labeled' and os.path.isdir(item_path):\n",
    "                    labeled_source = item_path\n",
    "                elif item == 'unlabeled' and os.path.isdir(item_path):\n",
    "                    unlabeled_source = item_path\n",
    "\n",
    "            if labeled_source and unlabeled_source:\n",
    "                # Create target directory\n",
    "                if os.path.exists(DATA_DIR):\n",
    "                    shutil.rmtree(DATA_DIR)\n",
    "                os.makedirs(DATA_DIR)\n",
    "\n",
    "                # Move directories\n",
    "                shutil.move(labeled_source, os.path.join(DATA_DIR, 'labeled'))\n",
    "                shutil.move(unlabeled_source, os.path.join(DATA_DIR, 'unlabeled'))\n",
    "\n",
    "                print(\"‚úÖ Dataset organized successfully!\")\n",
    "\n",
    "                # Verify structure\n",
    "                labeled_dir = os.path.join(DATA_DIR, 'labeled')\n",
    "                species_count = len([d for d in os.listdir(labeled_dir)\n",
    "                                   if os.path.isdir(os.path.join(labeled_dir, d)) and not d.startswith('.')])\n",
    "\n",
    "                unlabeled_dir = os.path.join(DATA_DIR, 'unlabeled')\n",
    "                unlabeled_count = len([f for f in os.listdir(unlabeled_dir)\n",
    "                                     if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "\n",
    "                print(f\"üêü Verified: {species_count} species\")\n",
    "                print(f\"üìä Verified: {unlabeled_count} unlabeled images\")\n",
    "\n",
    "            else:\n",
    "                print(\"‚ùå Could not find labeled and unlabeled directories\")\n",
    "\n",
    "            # Cleanup\n",
    "            if os.path.exists(temp_dir):\n",
    "                shutil.rmtree(temp_dir)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error extracting dataset: {e}\")\n",
    "\n",
    "# Final verification\n",
    "if os.path.exists(DATA_DIR):\n",
    "    print(f\"\\n‚úÖ DATASET READY\")\n",
    "    print(f\"üìÅ Location: {DATA_DIR}\")\n",
    "    print(\"üöÄ Ready for training!\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå DATASET SETUP FAILED\")\n",
    "    print(\"Please check that fish_cutouts.zip is uploaded to Google Drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f0fe32",
   "metadata": {
    "id": "31f0fe32"
   },
   "source": [
    "## üìà Step 6: Setup Weights & Biases (Optional)\n",
    "\n",
    "Weights & Biases provides excellent training visualization and experiment tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab343772",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ab343772",
    "outputId": "5ecc5316-eef3-4af2-e01e-01987bf9c2a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà SETTING UP WEIGHTS & BIASES\n",
      "========================================\n",
      "üîë Please enter your W&B API key when prompted\n",
      "üí° Get your API key from: https://wandb.ai/settings\n",
      "‚úÖ Successfully logged in to W&B\n",
      "üìä W&B not connected - training will continue without logging\n",
      "‚úÖ W&B setup complete (Enabled: False)\n"
     ]
    }
   ],
   "source": [
    "# Login to Weights & Biases for experiment tracking\n",
    "import wandb\n",
    "import os\n",
    "\n",
    "print(\"üìà SETTING UP WEIGHTS & BIASES\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Check if API key is available\n",
    "if os.environ.get(\"WANDB_API_KEY\"):\n",
    "    print(\"‚úÖ W&B API key found in environment\")\n",
    "    try:\n",
    "        wandb.login(relogin=True)\n",
    "        print(\"‚úÖ Successfully logged in to W&B\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è W&B relogin failed: {e}\")\n",
    "        print(\"Trying manual login...\")\n",
    "        wandb.login()\n",
    "else:\n",
    "    print(\"üîë Please enter your W&B API key when prompted\")\n",
    "    print(\"üí° Get your API key from: https://wandb.ai/settings\")\n",
    "    try:\n",
    "        wandb.login()\n",
    "        print(\"‚úÖ Successfully logged in to W&B\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå W&B login failed: {e}\")\n",
    "        print(\"Continuing without W&B logging...\")\n",
    "\n",
    "# Check connection status\n",
    "if wandb.run:\n",
    "    print(f\"üöÄ W&B Run URL: {wandb.run.url}\")\n",
    "    USE_WANDB = False  # Disable wandb to avoid logging issues\n",
    "else:\n",
    "    print(\"üìä W&B not connected - training will continue without logging\")\n",
    "    USE_WANDB = False\n",
    "\n",
    "print(f\"‚úÖ W&B setup complete (Enabled: {USE_WANDB})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5190f01",
   "metadata": {
    "id": "b5190f01"
   },
   "source": [
    "## üîÑ Step 6: Locate Checkpoint from Epoch 19\n",
    "\n",
    "Finding your saved checkpoint to resume training from where you left off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61b35ced",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "61b35ced",
    "outputId": "d584f10c-807c-4a0f-a05e-ac739c6b0bdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Looking for checkpoint from epoch 100...\n",
      "üíæ New checkpoints will be saved to: /content/drive/MyDrive/ViT-FishID/pretrained_checkpoints\n",
      "‚ùå No checkpoint found for epoch 19!\n",
      "üöÄ Starting fresh training from epoch 1\n"
     ]
    }
   ],
   "source": [
    "# Locate checkpoint from epoch 19\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "\n",
    "print(\"üîç Looking for checkpoint from epoch 100...\")\n",
    "\n",
    "# Configuration\n",
    "# Always start from the beginning\n",
    "checkpoint_path = None\n",
    "checkpoint_info = None\n",
    "RESUME_CHECKPOINT = None # Ensure this is explicitly set to None\n",
    "\n",
    "# Set up checkpoint directory for new saves\n",
    "checkpoint_save_dir = '/content/drive/MyDrive/ViT-FishID/pretrained_checkpoints'\n",
    "os.makedirs(checkpoint_save_dir, exist_ok=True)\n",
    "print(f\"üíæ New checkpoints will be saved to: {checkpoint_save_dir}\")\n",
    "\n",
    "\n",
    "if checkpoint_path:\n",
    "    print(f\"\\nüéâ Checkpoint ready for resuming training!\")\n",
    "    print(f\"üìÑ File: {os.path.basename(checkpoint_path)}\")\n",
    "    print(f\"üìè Size: {os.path.getsize(checkpoint_path) / (1024*1024):.1f} MB\")\n",
    "    print(f\"üíæ New checkpoints will be saved to: {checkpoint_save_dir}\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå No checkpoint found for epoch 19!\")\n",
    "    print(\"üöÄ Starting fresh training from epoch 1\")\n",
    "\n",
    "# Store checkpoint path for later use\n",
    "RESUME_CHECKPOINT = checkpoint_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe6af6d",
   "metadata": {
    "id": "0fe6af6d"
   },
   "source": [
    "## ‚öôÔ∏è Step 7: Configure Training Parameters\n",
    "\n",
    "Configure the training settings for your semi-supervised fish classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hSokV6NDjgYa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hSokV6NDjgYa",
    "outputId": "0c7b9d0c-3766-426c-8eb8-d80ae70f741d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è TRAINING CONFIGURATION\n",
      "==================================================\n",
      "üìÅ Checkpoints: /content/drive/MyDrive/ViT-FishID/pretrained_checkpoints\n",
      "üíæ Backups: /content/drive/MyDrive/ViT-FishID/pretrained_checkpoints_backup\n",
      "\n",
      "üìã TRAINING CONFIGURATION\n",
      "==================================================\n",
      "üéØ Training mode: semi_supervised\n",
      "üìä Total epochs: 100\n",
      "üì¶ Batch size: 16\n",
      "üß† Model: vit_base_patch16_224\n",
      "üêü Number of species: 37\n",
      "‚öñÔ∏è Consistency weight: 2.0\n",
      "üéØ Pseudo-label threshold: 0.7\n",
      "üíæ Save frequency: Every 10 epochs\n",
      "üìà W&B logging: False\n",
      "\n",
      "‚è±Ô∏è Estimated training time: 5.0 hours\n",
      "üí° Recommendation: Use Colab Pro for longer training sessions\n",
      "\n",
      "‚úÖ Configuration complete - ready to start training!\n"
     ]
    }
   ],
   "source": [
    "# Training Configuration for Semi-Supervised Fish Classification\n",
    "import os\n",
    "\n",
    "print(\"‚öôÔ∏è TRAINING CONFIGURATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Auto-detect number of species from dataset\n",
    "NUM_CLASSES = 37  # Default\n",
    "if 'DATA_DIR' in globals() and os.path.exists(DATA_DIR):\n",
    "    labeled_dir = os.path.join(DATA_DIR, 'labeled')\n",
    "    if os.path.exists(labeled_dir):\n",
    "        species_count = len([d for d in os.listdir(labeled_dir)\n",
    "                           if os.path.isdir(os.path.join(labeled_dir, d)) and not d.startswith('.')])\n",
    "        NUM_CLASSES = species_count\n",
    "        print(f\"üìä Auto-detected {species_count} fish species\")\n",
    "\n",
    "# Create checkpoint directories\n",
    "CHECKPOINT_DIR = '/content/drive/MyDrive/ViT-FishID/pretrained_checkpoints'\n",
    "BACKUP_DIR = '/content/drive/MyDrive/ViT-FishID/pretrained_checkpoints_backup'\n",
    "\n",
    "try:\n",
    "    os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "    os.makedirs(BACKUP_DIR, exist_ok=True)\n",
    "    print(f\"üìÅ Checkpoints: {CHECKPOINT_DIR}\")\n",
    "    print(f\"üíæ Backups: {BACKUP_DIR}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Could not create Google Drive directories: {e}\")\n",
    "    CHECKPOINT_DIR = '/content/pretraine_checkpoints'\n",
    "    BACKUP_DIR = '/content/pretrained_checkpoints_backup'\n",
    "    os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "    os.makedirs(BACKUP_DIR, exist_ok=True)\n",
    "    print(f\"üìÅ Using local checkpoints: {CHECKPOINT_DIR}\")\n",
    "\n",
    "# Training Configuration\n",
    "TRAINING_CONFIG = {\n",
    "    # BASIC SETTINGS\n",
    "    'mode': 'semi_supervised',\n",
    "    'data_dir': DATA_DIR if 'DATA_DIR' in globals() else '/content/fish_cutouts',\n",
    "    'epochs': 100,\n",
    "    'batch_size': 16,\n",
    "    'learning_rate': 1e-4,\n",
    "    'weight_decay': 0.05,\n",
    "\n",
    "    # MODEL SETTINGS - FIXED to match MAE architecture (384 dimensions)\n",
    "    'model_name': 'vit_small_patch16_224',  # Changed from vit_base to vit_small to match MAE\n",
    "    'num_classes': NUM_CLASSES,\n",
    "    'pretrained': True,\n",
    "\n",
    "    # SEMI-SUPERVISED SETTINGS\n",
    "    'consistency_weight': 2.0,\n",
    "    'pseudo_label_threshold': 0.7,\n",
    "    'temperature': 4.0,\n",
    "    'warmup_epochs': 10,\n",
    "    'ramp_up_epochs': 30,\n",
    "\n",
    "    # CHECKPOINT SETTINGS\n",
    "    'save_frequency': 10,  # Save every 10 epochs\n",
    "    'checkpoint_dir': CHECKPOINT_DIR,\n",
    "    'backup_dir': BACKUP_DIR,\n",
    "\n",
    "    # LOGGING SETTINGS\n",
    "    'use_wandb': USE_WANDB if 'USE_WANDB' in globals() else False,\n",
    "    'wandb_project': 'ViT-FishID-Training',\n",
    "    'wandb_run_name': f'fish-classification-{NUM_CLASSES}-classes',\n",
    "}\n",
    "\n",
    "print(\"\\nüìã TRAINING CONFIGURATION\")\n",
    "print(\"=\"*50)\n",
    "print(f\"üéØ Training mode: {TRAINING_CONFIG['mode']}\")\n",
    "print(f\"üìä Total epochs: {TRAINING_CONFIG['epochs']}\")\n",
    "print(f\"üì¶ Batch size: {TRAINING_CONFIG['batch_size']}\")\n",
    "print(f\"üß† Model: {TRAINING_CONFIG['model_name']} (ViT-Small 384-dim - matches MAE)\")\n",
    "print(f\"üêü Number of species: {TRAINING_CONFIG['num_classes']}\")\n",
    "print(f\"‚öñÔ∏è Consistency weight: {TRAINING_CONFIG['consistency_weight']}\")\n",
    "print(f\"üéØ Pseudo-label threshold: {TRAINING_CONFIG['pseudo_label_threshold']}\")\n",
    "print(f\"üíæ Save frequency: Every {TRAINING_CONFIG['save_frequency']} epochs\")\n",
    "print(f\"üìà W&B logging: {TRAINING_CONFIG['use_wandb']}\")\n",
    "\n",
    "# Time estimation\n",
    "estimated_time_hours = TRAINING_CONFIG['epochs'] * 3 / 60  # ~3 minutes per epoch\n",
    "print(f\"\\n‚è±Ô∏è Estimated training time: {estimated_time_hours:.1f} hours\")\n",
    "print(f\"üí° Recommendation: Use Colab Pro for longer training sessions\")\n",
    "\n",
    "print(f\"\\nüîß ARCHITECTURE COMPATIBILITY:\")\n",
    "print(f\"   ‚úÖ MAE: ViT with 384 embedding dimensions\")\n",
    "print(f\"   ‚úÖ Training Model: {TRAINING_CONFIG['model_name']} with 384 embedding dimensions\")\n",
    "print(f\"   üéØ PERFECT MATCH! MAE weights should load successfully!\")\n",
    "\n",
    "print(\"\\n‚úÖ Configuration complete - ready to start training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34762fd6",
   "metadata": {
    "id": "34762fd6"
   },
   "source": [
    "## ü§ñ Step 7a: Load MAE Pre-trained Model (Optional)\n",
    "\n",
    "**This step loads your pre-trained MAE model to initialize the ViT encoder with better features.**\n",
    "\n",
    "The MAE (Masked Autoencoder) model you trained provides much better initial weights for the Vision Transformer compared to ImageNet pretraining, especially for fish images since it was trained specifically on your fish dataset.\n",
    "\n",
    "Benefits of using MAE initialization:\n",
    "- **Better Feature Representations**: Learned specifically on fish images\n",
    "- **Faster Convergence**: Model starts with relevant features\n",
    "- **Improved Performance**: Often leads to 2-5% accuracy improvement\n",
    "\n",
    "### üìÅ MAE Model Locations\n",
    "\n",
    "Your MAE models should be in one of these locations:\n",
    "- **Local**: `/Users/catalinathomson/Desktop/Fish/ViT-FishID/mae_checkpoints/mae_final_model.pth`\n",
    "- **Google Drive**: `/content/drive/MyDrive/mae_checkpoints/mae_final_model.pth` (after upload)\n",
    "\n",
    "### üîß Setup Instructions\n",
    "\n",
    "1. **Upload MAE Model**: Upload your `mae_final_model.pth` or `mae_best_model.pth` to Google Drive\n",
    "2. **Update Path**: Modify `MAE_MODEL_PATH` in the next cell if needed\n",
    "3. **Enable/Disable**: Set `LOAD_MAE_PRETRAINED = True/False` to control MAE loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ef2d40",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "02ef2d40",
    "outputId": "72342f81-6170-4362-dac4-7ad8f9b157b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ SETTING UP MAE-INITIALIZED ViT MODEL\n",
      "============================================================\n",
      "Configured MAE_MODEL_PATH: /content/drive/MyDrive/mae_checkpoints/mae_final_model.pth\n",
      "Configured LOAD_MAE_PRETRAINED: True\n",
      "Attempting to load MAE pretrained model from: /content/drive/MyDrive/mae_checkpoints/mae_final_model.pth\n",
      "‚úÖ Found MAE model: mae_final_model.pth\n",
      "üìè Size: 149.6 MB\n",
      "üì• Loading MAE checkpoint from: /content/drive/MyDrive/mae_checkpoints/mae_final_model.pth\n",
      "‚úÖ MAE checkpoint loaded in 0.27 seconds.\n",
      "üìä MAE trained for 50 epochs\n",
      "‚úÖ Found model state dictionary in checkpoint.\n",
      "Filtering MAE state dictionary for encoder weights...\n",
      "üìä Extracted 78 encoder parameters from MAE in 0.00 seconds.\n",
      "üéâ MAE encoder weights loaded successfully!\n",
      "‚úÖ TRAINING_CONFIG updated for MAE pretraining.\n",
      "\n",
      "üß™ Testing model creation...\n",
      "Using model_name: vit_base_patch16_224\n",
      "Using MAE weights for test model: True\n",
      "Using ImageNet pretrained for test model: False\n",
      "üèóÔ∏è Creating ViT model: vit_base_patch16_224\n",
      "Using ImageNet pretrained weights: False\n",
      "‚úÖ ViT model created in 1.43 seconds.\n",
      "‚ö° Initializing ViT backbone with MAE encoder weights...\n",
      "‚úÖ Successfully transferred 0 MAE encoder weights in 0.00 seconds.\n",
      "üéØ ViT model initialized with MAE-learned features!\n",
      "Moving test model to device: cuda\n",
      "‚úÖ Model test successful!\n",
      "üìä Input shape: torch.Size([1, 3, 224, 224])\n",
      "üìä Output shape: torch.Size([1, 37])\n",
      "üéØ Model ready for training!\n",
      "\n",
      "============================================================\n",
      "‚úÖ MAE INITIALIZATION SETUP COMPLETE!\n",
      "ü§ñ MAE pretrained: True\n",
      "üåê ImageNet pretrained: False\n",
      "üìä Model: vit_base_patch16_224 with 37 classes\n",
      "üéâ Your model will start with MAE-learned features specific to fish images!\n",
      "üöÄ This should lead to faster training and better performance!\n",
      "üéØ Ready to proceed to training!\n"
     ]
    }
   ],
   "source": [
    "# Load MAE Pre-trained Model and Create Custom ViT Model\n",
    "import torch\n",
    "import os\n",
    "import shutil\n",
    "from model import ViTForFishClassification\n",
    "import time # Import time for basic profiling\n",
    "\n",
    "print(\"ü§ñ SETTING UP MAE-INITIALIZED ViT MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Configuration for MAE loading\n",
    "MAE_MODEL_PATH = '/content/drive/MyDrive/mae_checkpoints/mae_final_model.pth'  # Update this path if needed\n",
    "LOAD_MAE_PRETRAINED = True  # Set to False to skip MAE loading\n",
    "\n",
    "# Global variable to store MAE state for later use\n",
    "MAE_ENCODER_WEIGHTS = None\n",
    "print(f\"Configured MAE_MODEL_PATH: {MAE_MODEL_PATH}\")\n",
    "print(f\"Configured LOAD_MAE_PRETRAINED: {LOAD_MAE_PRETRAINED}\")\n",
    "\n",
    "\n",
    "def load_mae_encoder_weights(mae_checkpoint_path):\n",
    "    \"\"\"\n",
    "    Load and extract encoder weights from MAE checkpoint.\n",
    "\n",
    "    Args:\n",
    "        mae_checkpoint_path: Path to MAE checkpoint file\n",
    "\n",
    "    Returns:\n",
    "        dict: Filtered encoder weights compatible with ViT backbone\n",
    "    \"\"\"\n",
    "    print(f\"üì• Loading MAE checkpoint from: {mae_checkpoint_path}\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    try:\n",
    "        # Load MAE checkpoint\n",
    "        # Use map_location='cpu' first, then move to GPU if needed later\n",
    "        # Added weights_only=False based on error message\n",
    "        checkpoint = torch.load(mae_checkpoint_path, map_location='cpu', weights_only=False)\n",
    "        print(f\"‚úÖ MAE checkpoint loaded in {time.time() - start_time:.2f} seconds.\")\n",
    "\n",
    "        # Print checkpoint info\n",
    "        if 'epoch' in checkpoint:\n",
    "            print(f\"üìä MAE trained for {checkpoint['epoch']} epochs\")\n",
    "        if 'train_loss' in checkpoint:\n",
    "            print(f\"üìâ Final MAE loss: {checkpoint['train_loss']:.4f}\")\n",
    "        if 'model_state_dict' in checkpoint or 'state_dict' in checkpoint:\n",
    "             print(\"‚úÖ Found model state dictionary in checkpoint.\")\n",
    "        else:\n",
    "             print(\"‚ö†Ô∏è Could not find 'model_state_dict' or 'state_dict' in checkpoint.\")\n",
    "\n",
    "\n",
    "        # Get model state dict\n",
    "        mae_state_dict = checkpoint.get('model_state_dict', checkpoint.get('state_dict', None))\n",
    "\n",
    "        if mae_state_dict is None:\n",
    "             print(\"‚ùå MAE state dictionary not found in checkpoint.\")\n",
    "             return None\n",
    "\n",
    "        # Filter encoder weights (remove decoder, mask token, and other non-encoder components)\n",
    "        encoder_weights = {}\n",
    "        filter_prefixes = ['patch_embed', 'pos_embed', 'cls_token', 'blocks', 'norm']\n",
    "        exclude_substrings = ['decoder', 'mask_token', 'head']\n",
    "\n",
    "        print(\"Filtering MAE state dictionary for encoder weights...\")\n",
    "        start_time = time.time()\n",
    "        for key, value in mae_state_dict.items():\n",
    "            # Keep only encoder-related weights\n",
    "            if any(prefix in key for prefix in filter_prefixes) and not any(exclude in key for exclude in exclude_substrings):\n",
    "                encoder_weights[key] = value\n",
    "\n",
    "        print(f\"üìä Extracted {len(encoder_weights)} encoder parameters from MAE in {time.time() - start_time:.2f} seconds.\")\n",
    "\n",
    "        if not encoder_weights:\n",
    "             print(\"‚ö†Ô∏è No encoder weights were extracted. Check filter logic or checkpoint structure.\")\n",
    "\n",
    "\n",
    "        return encoder_weights\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading or processing MAE checkpoint: {e}\")\n",
    "        return None\n",
    "\n",
    "def create_mae_initialized_model(num_classes, model_name='vit_small_patch16_224', mae_weights=None):\n",
    "    \"\"\"\n",
    "    Create ViT model and optionally initialize with MAE weights.\n",
    "\n",
    "    Args:\n",
    "        num_classes: Number of classification classes\n",
    "        model_name: ViT model architecture name (default: vit_small to match MAE)\n",
    "        mae_weights: Optional MAE encoder weights dictionary\n",
    "\n",
    "    Returns:\n",
    "        ViTForFishClassification: Initialized model\n",
    "    \"\"\"\n",
    "    print(f\"üèóÔ∏è Creating ViT model: {model_name}\")\n",
    "\n",
    "    # Create ViT model (without ImageNet pretraining if we have MAE weights)\n",
    "    use_imagenet_pretrained = mae_weights is None\n",
    "    print(f\"Using ImageNet pretrained weights: {use_imagenet_pretrained}\")\n",
    "    start_time = time.time()\n",
    "    model = ViTForFishClassification(\n",
    "        num_classes=num_classes,\n",
    "        model_name=model_name,\n",
    "        pretrained=use_imagenet_pretrained,\n",
    "        dropout_rate=0.1\n",
    "    )\n",
    "    print(f\"‚úÖ ViT model created in {time.time() - start_time:.2f} seconds.\")\n",
    "\n",
    "    if mae_weights is not None:\n",
    "        print(\"‚ö° Initializing ViT backbone with MAE encoder weights...\")\n",
    "        start_time = time.time()\n",
    "        # Get current backbone state dict\n",
    "        backbone_state = model.backbone.state_dict()\n",
    "\n",
    "        # Update with MAE weights (only for matching keys and shapes)\n",
    "        updated_keys = []\n",
    "        shape_mismatches = []\n",
    "\n",
    "        for mae_key, mae_weight in mae_weights.items():\n",
    "            if mae_key in backbone_state:\n",
    "                if mae_weight.shape == backbone_state[mae_key].shape:\n",
    "                    backbone_state[mae_key] = mae_weight.clone()\n",
    "                    updated_keys.append(mae_key)\n",
    "                else:\n",
    "                    shape_mismatches.append(f\"{mae_key}: MAE{mae_weight.shape} != ViT{backbone_state[mae_key].shape}\")\n",
    "\n",
    "        # Load updated weights\n",
    "        try:\n",
    "            model.backbone.load_state_dict(backbone_state)\n",
    "            print(f\"‚úÖ Successfully transferred {len(updated_keys)} MAE encoder weights in {time.time() - start_time:.2f} seconds.\")\n",
    "\n",
    "            if shape_mismatches:\n",
    "                print(f\"‚ö†Ô∏è Found {len(shape_mismatches)} shape mismatches (using original weights for these):\")\n",
    "                for mismatch in shape_mismatches[:5]:  # Show first 5 mismatches\n",
    "                    print(f\"   {mismatch}\")\n",
    "\n",
    "            print(\"üéØ ViT model initialized with MAE-learned features!\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading MAE weights into ViT backbone: {e}\")\n",
    "            print(\"Continuing with potentially partially loaded weights or default ImageNet (if applicable).\")\n",
    "\n",
    "\n",
    "    else:\n",
    "        print(\"üåê Using ImageNet pretrained weights\")\n",
    "\n",
    "    return model\n",
    "\n",
    "# Main execution\n",
    "if LOAD_MAE_PRETRAINED:\n",
    "    print(f\"Attempting to load MAE pretrained model from: {MAE_MODEL_PATH}\")\n",
    "    # Check if MAE model exists in Google Drive\n",
    "    if os.path.exists(MAE_MODEL_PATH):\n",
    "        print(f\"‚úÖ Found MAE model: {os.path.basename(MAE_MODEL_PATH)}\")\n",
    "        try:\n",
    "            file_size = os.path.getsize(MAE_MODEL_PATH) / (1024**2)\n",
    "            print(f\"üìè Size: {file_size:.1f} MB\")\n",
    "        except Exception as e:\n",
    "             print(f\"‚ö†Ô∏è Could not get file size: {e}\")\n",
    "\n",
    "\n",
    "        try:\n",
    "            # Load MAE encoder weights\n",
    "            MAE_ENCODER_WEIGHTS = load_mae_encoder_weights(MAE_MODEL_PATH)\n",
    "\n",
    "            if MAE_ENCODER_WEIGHTS is not None:\n",
    "                 print(\"üéâ MAE encoder weights loaded successfully!\")\n",
    "\n",
    "                 # Update training config\n",
    "                 if 'TRAINING_CONFIG' in globals():\n",
    "                    TRAINING_CONFIG['mae_pretrained'] = True\n",
    "                    TRAINING_CONFIG['mae_model_path'] = MAE_MODEL_PATH\n",
    "                    TRAINING_CONFIG['pretrained'] = False  # Don't use ImageNet since we have MAE\n",
    "                    print(\"‚úÖ TRAINING_CONFIG updated for MAE pretraining.\")\n",
    "                 else:\n",
    "                    print(\"‚ö†Ô∏è TRAINING_CONFIG not found. Cannot update config with MAE settings.\")\n",
    "\n",
    "            else:\n",
    "                 print(\"‚ùå Failed to load MAE encoder weights. MAE_ENCODER_WEIGHTS is None.\")\n",
    "                 print(\"üîÑ Falling back to ImageNet pretrained weights...\")\n",
    "                 MAE_ENCODER_WEIGHTS = None\n",
    "                 if 'TRAINING_CONFIG' in globals():\n",
    "                    TRAINING_CONFIG['mae_pretrained'] = False\n",
    "                    TRAINING_CONFIG['pretrained'] = True\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error during MAE loading process: {e}\")\n",
    "            print(\"üîÑ Falling back to ImageNet pretrained weights...\")\n",
    "            MAE_ENCODER_WEIGHTS = None\n",
    "            if 'TRAINING_CONFIG' in globals():\n",
    "                TRAINING_CONFIG['mae_pretrained'] = False\n",
    "                TRAINING_CONFIG['pretrained'] = True\n",
    "\n",
    "\n",
    "    else:\n",
    "        # MAE model not found, check alternative locations\n",
    "        print(f\"‚ùå MAE model not found at: {MAE_MODEL_PATH}\")\n",
    "\n",
    "        # Try to copy from local mae_checkpoints if exists\n",
    "        local_mae_path = f'/content/ViT-FishID/mae_checkpoints/{os.path.basename(MAE_MODEL_PATH)}'\n",
    "        print(f\"Checking local path: {local_mae_path}\")\n",
    "        if os.path.exists(local_mae_path):\n",
    "            print(f\"üìÅ Found MAE model in local repository: {local_mae_path}\")\n",
    "            try:\n",
    "                # Create directory and copy\n",
    "                print(f\"Attempting to create directory: {os.path.dirname(MAE_MODEL_PATH)}\")\n",
    "                os.makedirs(os.path.dirname(MAE_MODEL_PATH), exist_ok=True)\n",
    "                print(f\"Copying from {local_mae_path} to {MAE_MODEL_PATH}\")\n",
    "                shutil.copy2(local_mae_path, MAE_MODEL_PATH)\n",
    "                print(f\"‚úÖ Copied MAE model to Google Drive: {MAE_MODEL_PATH}\")\n",
    "\n",
    "                # Now load it\n",
    "                MAE_ENCODER_WEIGHTS = load_mae_encoder_weights(MAE_MODEL_PATH)\n",
    "                if MAE_ENCODER_WEIGHTS is not None:\n",
    "                    if 'TRAINING_CONFIG' in globals():\n",
    "                        TRAINING_CONFIG['mae_pretrained'] = True\n",
    "                        TRAINING_CONFIG['mae_model_path'] = MAE_MODEL_PATH\n",
    "                        TRAINING_CONFIG['pretrained'] = False\n",
    "                else:\n",
    "                     print(\"‚ùå Failed to load MAE encoder weights after copying.\")\n",
    "                     MAE_ENCODER_WEIGHTS = None\n",
    "                     if 'TRAINING_CONFIG' in globals():\n",
    "                        TRAINING_CONFIG['mae_pretrained'] = False\n",
    "                        TRAINING_CONFIG['pretrained'] = True\n",
    "\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error copying/loading MAE model from local path: {e}\")\n",
    "                MAE_ENCODER_WEIGHTS = None\n",
    "                if 'TRAINING_CONFIG' in globals():\n",
    "                    TRAINING_CONFIG['mae_pretrained'] = False\n",
    "                    TRAINING_CONFIG['pretrained'] = True\n",
    "        else:\n",
    "            print(\"üìù MAE model not found in local repository either.\")\n",
    "            print(\"üìù Available options:\")\n",
    "            print(\"1. Upload mae_final_model.pth or mae_best_model.pth to /content/drive/MyDrive/mae_checkpoints/\")\n",
    "            print(\"2. Update MAE_MODEL_PATH variable to correct location\")\n",
    "            print(\"3. Set LOAD_MAE_PRETRAINED = False to use ImageNet weights\")\n",
    "            print(\"üîÑ Continuing with ImageNet pretrained weights...\")\n",
    "            MAE_ENCODER_WEIGHTS = None\n",
    "            if 'TRAINING_CONFIG' in globals():\n",
    "                TRAINING_CONFIG['mae_pretrained'] = False\n",
    "                TRAINING_CONFIG['pretrained'] = True\n",
    "\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è LOAD_MAE_PRETRAINED is False. Skipping MAE loading - will use ImageNet pretrained weights\")\n",
    "    MAE_ENCODER_WEIGHTS = None\n",
    "    if 'TRAINING_CONFIG' in globals():\n",
    "        TRAINING_CONFIG['mae_pretrained'] = False\n",
    "        TRAINING_CONFIG['pretrained'] = True\n",
    "\n",
    "\n",
    "# Test model creation (optional - this creates a model to verify everything works)\n",
    "print(f\"\\nüß™ Testing model creation...\")\n",
    "if 'NUM_CLASSES' not in globals():\n",
    "    print(\"‚ö†Ô∏è NUM_CLASSES not defined. Skipping model creation test.\")\n",
    "else:\n",
    "    try:\n",
    "        # Ensure model name and pretrained flag are correctly picked up from TRAINING_CONFIG\n",
    "        model_name_for_test = TRAINING_CONFIG.get('model_name', 'vit_small_patch16_224')  # Fixed fallback to vit_small\n",
    "        use_imagenet_for_test = TRAINING_CONFIG.get('pretrained', True) # Use the updated flag\n",
    "\n",
    "        # If MAE weights were loaded, pass them, otherwise rely on TRAINING_CONFIG['pretrained']\n",
    "        weights_for_test = MAE_ENCODER_WEIGHTS if MAE_ENCODER_WEIGHTS is not None else None\n",
    "\n",
    "        print(f\"Using model_name: {model_name_for_test}\")\n",
    "        print(f\"Using MAE weights for test model: {weights_for_test is not None}\")\n",
    "        print(f\"Using ImageNet pretrained for test model: {use_imagenet_for_test}\")\n",
    "\n",
    "        test_model = create_mae_initialized_model(\n",
    "            num_classes=NUM_CLASSES,\n",
    "            model_name=model_name_for_test,\n",
    "            mae_weights=weights_for_test # Pass MAE weights if available\n",
    "        )\n",
    "\n",
    "        # Move model to device for testing (optional but good practice)\n",
    "        # Assuming DEVICE is defined globally from Step 1\n",
    "        if 'DEVICE' in globals():\n",
    "            print(f\"Moving test model to device: {DEVICE}\")\n",
    "            test_model.to(DEVICE)\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è DEVICE variable not found. Skipping moving test model to device.\")\n",
    "\n",
    "\n",
    "        # Test forward pass\n",
    "        test_input = torch.randn(1, 3, 224, 224)\n",
    "        # Move test input to the same device as the model\n",
    "        if 'DEVICE' in globals():\n",
    "            test_input = test_input.to(DEVICE)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            test_output = test_model(test_input)\n",
    "\n",
    "        print(f\"‚úÖ Model test successful!\")\n",
    "        print(f\"üìä Input shape: {test_input.shape}\")\n",
    "        print(f\"üìä Output shape: {test_output.shape}\")\n",
    "        print(f\"üéØ Model ready for training!\")\n",
    "\n",
    "        # Clean up test model\n",
    "        del test_model, test_input, test_output\n",
    "        if 'DEVICE' in globals():\n",
    "             torch.cuda.empty_cache() # Clear GPU cache after test if on GPU\n",
    "        import gc\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Model test failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc() # Print full traceback for debugging\n",
    "\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(f\"‚úÖ MAE INITIALIZATION SETUP COMPLETE!\")\n",
    "if 'TRAINING_CONFIG' in globals():\n",
    "    print(f\"ü§ñ MAE pretrained: {TRAINING_CONFIG.get('mae_pretrained', False)}\")\n",
    "    print(f\"üåê ImageNet pretrained: {TRAINING_CONFIG.get('pretrained', True)}\")\n",
    "    print(f\"üìä Model: {TRAINING_CONFIG.get('model_name', 'N/A')} with {TRAINING_CONFIG.get('num_classes', 'N/A')} classes\")\n",
    "\n",
    "    if TRAINING_CONFIG.get('mae_pretrained', False):\n",
    "        print(\"üéâ Your model will start with MAE-learned features specific to fish images!\")\n",
    "        print(\"üöÄ This should lead to faster training and better performance!\")\n",
    "    else:\n",
    "        print(\"üåê Your model will use standard ImageNet pretrained features.\")\n",
    "else:\n",
    "     print(\"‚ö†Ô∏è TRAINING_CONFIG was not found, cannot provide detailed summary.\")\n",
    "\n",
    "print(\"üéØ Ready to proceed to training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9cbd50",
   "metadata": {
    "id": "aa9cbd50"
   },
   "source": [
    "## üöÄ Step 8: Start Semi-Supervised Training\n",
    "\n",
    "This cell will start the complete training process. Expected time: 4-6 hours for 100 epochs.\n",
    "\n",
    "**Training Process:**\n",
    "1. **Supervised Learning**: Uses labeled fish images with ground truth\n",
    "2. **Semi-Supervised Learning**: Leverages unlabeled images with pseudo-labels\n",
    "3. **EMA Teacher-Student**: Uses exponential moving average for consistency\n",
    "4. **Automatic Checkpointing**: Saves progress every 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "njLKb7xaepxo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "id": "njLKb7xaepxo",
    "outputId": "f24b78bd-885a-4bf5-e2b7-7891f97f884c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ STARTING SEMI-SUPERVISED FISH CLASSIFICATION TRAINING\n",
      "============================================================\n",
      "/content/ViT-FishID\n",
      "ü§ñ Preparing MAE-enhanced training script...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2801431964.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnum_classes_data\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m      \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"‚ö†Ô∏è Warning: Configured num_classes ({args.num_classes}) does not match detected data classes ({num_classes_data})\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m      \u001b[0;31m# Use the detected number of classes if they differ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m      \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_classes_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "# Start Semi-Supervised Training with Optional MAE Initialization\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import json # Import json for passing config\n",
    "\n",
    "print(\"üöÄ STARTING SEMI-SUPERVISED FISH CLASSIFICATION TRAINING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Change to repository directory\n",
    "%cd /content/ViT-FishID\n",
    "\n",
    "# Check for existing checkpoints to resume from\n",
    "RESUME_FROM = None\n",
    "if os.path.exists(TRAINING_CONFIG['checkpoint_dir']):\n",
    "    checkpoints = glob.glob(os.path.join(TRAINING_CONFIG['checkpoint_dir'], 'checkpoint_epoch_*.pth'))\n",
    "    if checkpoints:\n",
    "        # Find the latest checkpoint\n",
    "        epoch_numbers = []\n",
    "        for cp in checkpoints:\n",
    "            try:\n",
    "                epoch_num = int(cp.split('epoch_')[1].split('.')[0])\n",
    "                epoch_numbers.append((epoch_num, cp))\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        if epoch_numbers:\n",
    "            epoch_numbers.sort(key=lambda x: x[0], reverse=True)  # Latest first\n",
    "            latest_epoch, latest_checkpoint = epoch_numbers[0]\n",
    "            print(f\"üîç Found existing checkpoints. Latest: Epoch {latest_epoch}\")\n",
    "\n",
    "            # Ask user if they want to resume (auto-skip in Colab for now)\n",
    "            # resume_choice = input(\"Do you want to resume from the latest checkpoint? (y/n): \").lower().strip()\n",
    "            resume_choice = 'n'  # Set to 'y' if you want to auto-resume\n",
    "\n",
    "            if resume_choice in ['y', 'yes']:\n",
    "                RESUME_FROM = latest_checkpoint\n",
    "                print(f\"‚úÖ Will resume from: {os.path.basename(latest_checkpoint)}\")\n",
    "            else:\n",
    "                print(\"üÜï Starting fresh training from epoch 1\")\n",
    "\n",
    "# Determine which training script to use\n",
    "use_mae_script = TRAINING_CONFIG.get('mae_pretrained', False) and 'MAE_ENCODER_WEIGHTS' in globals() and MAE_ENCODER_WEIGHTS is not None\n",
    "\n",
    "# Serialize TRAINING_CONFIG, NUM_CLASSES, and RESUME_FROM to pass to the script\n",
    "training_config_json = json.dumps(TRAINING_CONFIG)\n",
    "num_classes_str = str(NUM_CLASSES)\n",
    "resume_from_str = RESUME_FROM if RESUME_FROM is not None else 'None'\n",
    "\n",
    "if use_mae_script:\n",
    "    print(\"ü§ñ Preparing MAE-enhanced training script...\")\n",
    "\n",
    "    # Generate the full training script with MAE initialization logic\n",
    "    training_script_content = f\"\"\"#!/usr/bin/env python3\n",
    "import sys\n",
    "sys.path.append('/content/ViT-FishID')\n",
    "\n",
    "import torch\n",
    "import argparse\n",
    "import os\n",
    "import glob\n",
    "import wandb\n",
    "import json # Import json to load config\n",
    "from datetime import datetime\n",
    "\n",
    "from model import ViTForFishClassification\n",
    "from trainer import EMATrainer, SemiSupervisedTrainer # Ensure both trainers are imported here\n",
    "from data import create_dataloaders, create_semi_supervised_dataloaders\n",
    "from utils import get_device, set_seed\n",
    "\n",
    "# --- Argument Parsing for Config ---\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--config_json', type=str, required=True, help='JSON string of training configuration')\n",
    "parser.add_argument('--num_classes_arg', type=int, required=True, help='Number of classes')\n",
    "parser.add_argument('--resume_from_arg', type=str, default='None', help='Path to resume checkpoint')\n",
    "\n",
    "# Parse arguments passed from the launching script\n",
    "script_args = parser.parse_args()\n",
    "TRAINING_CONFIG = json.loads(script_args.config_json)\n",
    "NUM_CLASSES = script_args.num_classes_arg\n",
    "RESUME_FROM = script_args.resume_from_arg if script_args.resume_from_arg != 'None' else None\n",
    "\n",
    "print(\"‚úÖ Loaded configuration from arguments.\")\n",
    "print(f\"üìä Configured num_classes: \" + str(NUM_CLASSES))\n",
    "if RESUME_FROM:\n",
    "    print(f\"üîÑ Configured resume_from: \" + str(RESUME_FROM))\n",
    "else:\n",
    "    print(\"üÜï Training from scratch based on arguments.\")\n",
    "\n",
    "# --- MAE Loading Logic (moved into the script) ---\n",
    "def load_mae_encoder_weights(mae_checkpoint_path):\n",
    "    print(f\"üì• Loading MAE checkpoint from: \" + str(mae_checkpoint_path))\n",
    "    try:\n",
    "        # Use weights_only=False based on previous error resolution\n",
    "        checkpoint = torch.load(mae_checkpoint_path, map_location='cpu', weights_only=False)\n",
    "        print(\"‚úÖ MAE checkpoint loaded.\")\n",
    "\n",
    "        # Handle different potential state_dict keys\n",
    "        mae_state_dict = checkpoint.get('model_state_dict', checkpoint.get('state_dict', checkpoint.get('model', None)))\n",
    "        if mae_state_dict is None:\n",
    "             print(\"‚ùå MAE state dictionary not found in checkpoint (checked 'model_state_dict', 'state_dict', 'model').\")\n",
    "             return None\n",
    "\n",
    "        encoder_weights = {{}}\n",
    "        filter_prefixes = ['patch_embed', 'pos_embed', 'cls_token', 'blocks', 'norm']\n",
    "        exclude_substrings = ['decoder', 'mask_token', 'head']\n",
    "\n",
    "        print(\"Filtering MAE state dictionary for encoder weights...\")\n",
    "        loaded_keys_count = 0\n",
    "        for mae_key, mae_weight in mae_state_dict.items():\n",
    "            should_include_prefix = False\n",
    "            for prefix in filter_prefixes:\n",
    "                if prefix in mae_key:\n",
    "                    should_include_prefix = True\n",
    "                    break\n",
    "\n",
    "            should_exclude_substring = False\n",
    "            for exclude_str in exclude_substrings:\n",
    "                 if exclude_str in mae_key:\n",
    "                      should_exclude_substring = True\n",
    "                      break\n",
    "\n",
    "            if should_include_prefix and not should_exclude_substring:\n",
    "                encoder_weights[mae_key] = mae_weight\n",
    "                loaded_keys_count += 1\n",
    "\n",
    "        print(f\"üìä Extracted \" + str(len(encoder_weights)) + \" encoder parameters from MAE.\")\n",
    "        return encoder_weights\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading or processing MAE checkpoint: \" + str(e))\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# --- End MAE Loading Logic ---\n",
    "\n",
    "# Function to create MAE-initialized model\n",
    "def create_mae_initialized_model(num_classes, model_name, mae_weights):\n",
    "    model = ViTForFishClassification(\n",
    "        num_classes=num_classes,\n",
    "        model_name=model_name,\n",
    "        pretrained=False,  # Don't use ImageNet if using MAE\n",
    "        dropout_rate=0.1\n",
    "    )\n",
    "\n",
    "    # Initialize updated_keys here to ensure it's always defined\n",
    "    updated_keys = []\n",
    "\n",
    "    if mae_weights is not None:\n",
    "        backbone_state = model.backbone.state_dict()\n",
    "        loaded_count = 0\n",
    "        \n",
    "        print(\"Debug: Checking parameter name compatibility...\")\n",
    "        print(f\"First 5 MAE parameter names: \" + str(list(mae_weights.keys())[:5]))\n",
    "        print(f\"First 5 ViT backbone parameter names: \" + str(list(backbone_state.keys())[:5]))\n",
    "        \n",
    "        # Handle prefix mapping: MAE uses 'encoder.' prefix, ViT has no prefix\n",
    "        for mae_key, mae_weight in mae_weights.items():\n",
    "             # Create ViT key by removing 'encoder.' prefix from MAE key\n",
    "             if mae_key.startswith('encoder.'):\n",
    "                 vit_key = mae_key[8:]  # Remove 'encoder.' (8 characters)\n",
    "             else:\n",
    "                 vit_key = mae_key  # Use as-is if no encoder prefix\n",
    "             \n",
    "             # Check if the mapped key exists in the model's state dict and if shapes match\n",
    "             if vit_key in backbone_state:\n",
    "                 if mae_weight.shape == backbone_state[vit_key].shape:\n",
    "                      backbone_state[vit_key] = mae_weight.clone()\n",
    "                      updated_keys.append(f\"\" + str(mae_key) + \" -> \" + str(vit_key))\n",
    "                      loaded_count += 1\n",
    "                      print(f\"‚úÖ Mapped \" + str(mae_key) + \" -> \" + str(vit_key))\n",
    "                 else:\n",
    "                      print(f\"‚ùå Shape mismatch for \" + str(mae_key) + \" -> \" + str(vit_key) + \": MAE \" + str(mae_weight.shape) + \" vs ViT \" + str(backbone_state[vit_key].shape))\n",
    "             else:\n",
    "                  # Try direct key match (fallback)\n",
    "                  if mae_key in backbone_state:\n",
    "                      if mae_weight.shape == backbone_state[mae_key].shape:\n",
    "                           backbone_state[mae_key] = mae_weight.clone()\n",
    "                           updated_keys.append(mae_key)\n",
    "                           loaded_count += 1\n",
    "                           print(f\"‚úÖ Direct match: \" + str(mae_key))\n",
    "                      else:\n",
    "                           print(f\"‚ùå Shape mismatch for \" + str(mae_key) + \": MAE \" + str(mae_weight.shape) + \" vs ViT \" + str(backbone_state[mae_key].shape))\n",
    "                  else:\n",
    "                       print(f\"‚ö†Ô∏è No match found for \" + str(mae_key) + \" (tried \" + str(vit_key) + \")\")\n",
    "\n",
    "        try:\n",
    "            model.backbone.load_state_dict(backbone_state, strict=False) # strict=False allows skipping mismatched keys\n",
    "            print(f\"‚úÖ Loaded \" + str(len(updated_keys)) + \" MAE encoder weights into model backbone state dict.\")\n",
    "            if len(updated_keys) == 0:\n",
    "                print(\"‚ö†Ô∏è WARNING: No MAE weights were loaded! Check parameter name compatibility.\")\n",
    "                print(\"This means the model is NOT using MAE pretraining.\")\n",
    "            else:\n",
    "                print(\"üéâ MAE pretraining weights successfully loaded!\")\n",
    "                print(f\"üìä Weight mapping summary:\")\n",
    "                for i, mapping in enumerate(updated_keys[:5]):  # Show first 5 mappings\n",
    "                    print(f\"  \" + str(i+1) + \". \" + str(mapping))\n",
    "                if len(updated_keys) > 5:\n",
    "                    print(f\"  ... and \" + str(len(updated_keys) - 5) + \" more\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading MAE weights into ViT backbone: \" + str(e))\n",
    "            print(\"Continuing with potentially partially loaded weights.\")\n",
    "\n",
    "    return model\n",
    "\n",
    "# Define arguments directly (or parse if needed) - Now using values from parsed args\n",
    "class Args:\n",
    "    def __init__(self, config, resume_from, num_classes):\n",
    "        self.mode = config['mode']\n",
    "        self.data_dir = config['data_dir']\n",
    "        self.epochs = config['epochs']\n",
    "        self.batch_size = config['batch_size']\n",
    "        self.learning_rate = config['learning_rate']\n",
    "        self.weight_decay = config['weight_decay']\n",
    "        self.model_name = config['model_name']\n",
    "        self.consistency_weight = config.get('consistency_weight', 0.1)\n",
    "        self.pseudo_label_threshold = config.get('pseudo_label_threshold', 0.7)\n",
    "        self.temperature = config.get('temperature', 0.7)\n",
    "        self.warmup_epochs = config.get('warmup_epochs', 0)\n",
    "        self.ramp_up_epochs = config.get('ramp_up_epochs', 0)\n",
    "        self.save_dir = config['checkpoint_dir']\n",
    "        self.save_frequency = config['save_frequency']\n",
    "        self.pretrained = config.get('pretrained', True)\n",
    "        self.use_wandb = config.get('use_wandb', False)\n",
    "        self.resume_from = resume_from\n",
    "        self.num_workers = config.get('num_workers', 4)\n",
    "        self.image_size = config.get('image_size', 224)\n",
    "        self.dropout_rate = config.get('dropout_rate', 0.1)\n",
    "        self.num_classes = num_classes\n",
    "        # MAE specific args - get from config\n",
    "        self.mae_model_path = config.get('mae_model_path', None)\n",
    "        self.mae_pretrained = config.get('mae_pretrained', False)\n",
    "\n",
    "# Create args object using values loaded from parsed args\n",
    "args = Args(TRAINING_CONFIG, RESUME_FROM, NUM_CLASSES)\n",
    "\n",
    "# Set up device and seed\n",
    "device = get_device()\n",
    "set_seed(42)\n",
    "\n",
    "# --- Model Creation with MAE Loading within the script ---\n",
    "print('ü§ñ Creating model for training...')\n",
    "\n",
    "# Load MAE weights within this script's process based on args\n",
    "mae_weights_for_init = None\n",
    "if args.mae_pretrained and args.mae_model_path and os.path.exists(args.mae_model_path):\n",
    "    print(f\"Attempting to load MAE pretrained model from: \" + str(args.mae_model_path))\n",
    "    mae_weights_for_init = load_mae_encoder_weights(args.mae_model_path)\n",
    "    if mae_weights_for_init is not None:\n",
    "        print(\"üéâ MAE encoder weights loaded successfully within script!\")\n",
    "    else:\n",
    "        print(\"‚ùå Failed to load MAE encoder weights within script. Falling back to ImageNet.\")\n",
    "else:\n",
    "     print(\"‚è≠Ô∏è Skipping MAE loading (config disabled, path missing, or file not found).\")\n",
    "     print(f\"üåê Will use ImageNet pretrained weights if args.pretrained is True (config value: \" + str(args.pretrained) + \").\")\n",
    "\n",
    "# Create model, using MAE weights if successfully loaded, otherwise use original pretrained flag\n",
    "if mae_weights_for_init is not None:\n",
    "     student_model = create_mae_initialized_model(\n",
    "         num_classes=args.num_classes,\n",
    "         model_name=args.model_name,\n",
    "         mae_weights=mae_weights_for_init # Pass the loaded MAE weights\n",
    "     ).to(device)\n",
    "     # Ensure pretrained flag is False if MAE is used\n",
    "     args.pretrained = False\n",
    "     print(\"‚úÖ Student model created and initialized with MAE weights.\")\n",
    "\n",
    "else: # Fallback to original pretrained flag (likely ImageNet)\n",
    "     student_model = ViTForFishClassification(\n",
    "        num_classes=args.num_classes,\n",
    "        model_name=args.model_name,\n",
    "        pretrained=args.pretrained, # Use the original pretrained flag\n",
    "        dropout_rate=args.dropout_rate\n",
    "     ).to(device)\n",
    "     print(f\"‚úÖ Student model created. Using ImageNet pretrained: \" + str(args.pretrained))\n",
    "\n",
    "# Create teacher model for EMA (if needed)\n",
    "teacher_model = None\n",
    "if args.mode == 'semi_supervised':\n",
    "    try:\n",
    "        from trainer import EMATeacher # Import EMATeacher here if needed\n",
    "        teacher_model = EMATeacher(student_model) # Create EMATeacher instance\n",
    "        # Check if teacher_model has an internal teacher_model attribute before calling .to()\n",
    "        if hasattr(teacher_model, 'teacher_model') and isinstance(teacher_model.teacher_model, torch.nn.Module):\n",
    "             teacher_model.teacher_model.to(device) # Move the internal teacher_model to device\n",
    "             print('üéì EMA Teacher model created and its internal model moved to device.')\n",
    "        else:\n",
    "             print(\"‚ö†Ô∏è EMATeacher's internal model could not be moved to device.\")\n",
    "\n",
    "    except NameError:\n",
    "         print(\"‚ö†Ô∏è EMATeacher class not found. Semi-supervised training will not work correctly.\")\n",
    "         print(\"‚ùå Please ensure EMATeacher is defined or imported in trainer.py\")\n",
    "         sys.exit(1) # Exit if EMATeacher is needed but not found\n",
    "    except Exception as e:\n",
    "         print(f\"‚ö†Ô∏è Error creating or moving EMATeacher model: \" + str(e))\n",
    "         import traceback\n",
    "         traceback.print_exc()\n",
    "         sys.exit(1) # Exit on other errors\n",
    "elif args.mode == 'supervised':\n",
    "    # Create teacher model for supervised mode as well\n",
    "    try:\n",
    "        from trainer import EMATeacher\n",
    "        teacher_model = EMATeacher(student_model)\n",
    "        if hasattr(teacher_model, 'teacher_model') and isinstance(teacher_model.teacher_model, torch.nn.Module):\n",
    "             teacher_model.teacher_model.to(device)\n",
    "             print('üéì EMA Teacher model created for supervised mode.')\n",
    "        else:\n",
    "             print(\"‚ö†Ô∏è EMATeacher's internal model could not be moved to device.\")\n",
    "    except Exception as e:\n",
    "         print(f\"‚ö†Ô∏è Error creating EMATeacher for supervised mode: \" + str(e))\n",
    "         # Continue without teacher model for supervised mode\n",
    "         teacher_model = None\n",
    "\n",
    "# Create data loaders\n",
    "print('Loading data...')\n",
    "if args.mode == 'supervised':\n",
    "    train_loader, val_loader, num_classes_data = create_dataloaders(\n",
    "        args.data_dir,\n",
    "        batch_size=args.batch_size,\n",
    "        image_size=args.image_size,\n",
    "        num_workers=args.num_workers\n",
    "    )\n",
    "    unlabeled_loader = None\n",
    "    test_loader = None # Initialize test_loader for supervised mode\n",
    "else: # semi_supervised mode\n",
    "    # Fixed to unpack the correct 6 values from create_semi_supervised_dataloaders\n",
    "    train_loader, val_loader, test_loader, class_names, labeled_count, unlabeled_count = create_semi_supervised_dataloaders(\n",
    "        args.data_dir,\n",
    "        batch_size=args.batch_size,\n",
    "        image_size=args.image_size,\n",
    "        num_workers=args.num_workers\n",
    "    )\n",
    "    # For semi-supervised mode, unlabeled data is included in train_loader\n",
    "    unlabeled_loader = None  # Not needed - unlabeled data is in train_loader\n",
    "    num_classes_data = len(class_names)  # Calculate from class_names\n",
    "print('‚úÖ Data loaders created.')\n",
    "\n",
    "if num_classes_data != args.num_classes:\n",
    "     print(f\"‚ö†Ô∏è Warning: Configured num_classes (\" + str(args.num_classes) + \") does not match detected data classes (\" + str(num_classes_data) + \")\")\n",
    "     # Use the detected number of classes if they differ\n",
    "     args.num_classes = num_classes_data\n",
    "     print(f\"‚úÖ Using \" + str(args.num_classes) + \" detected classes for training.\")\n",
    "\n",
    "print(f'üìä Number of classes: ' + str(args.num_classes))\n",
    "print(f'üéØ Training mode: ' + str(args.mode))\n",
    "\n",
    "# Create trainer\n",
    "print('Setting up trainer...')\n",
    "# Updated trainer creation logic since unlabeled_loader is now None\n",
    "if args.mode == 'semi_supervised' and teacher_model is not None:\n",
    "    trainer = SemiSupervisedTrainer(\n",
    "        student_model=student_model,\n",
    "        ema_teacher=teacher_model,  # Fixed: use ema_teacher parameter name\n",
    "        num_classes=args.num_classes,\n",
    "        device=device,\n",
    "        learning_rate=args.learning_rate,\n",
    "        weight_decay=args.weight_decay,\n",
    "        consistency_weight=args.consistency_weight,\n",
    "        pseudo_label_threshold=args.pseudo_label_threshold,\n",
    "        temperature=args.temperature,\n",
    "        warmup_epochs=args.warmup_epochs,\n",
    "        ramp_up_epochs=args.ramp_up_epochs,\n",
    "        use_wandb=args.use_wandb  # Pass wandb setting to trainer\n",
    "    )\n",
    "    print('‚úÖ SemiSupervisedTrainer created.')\n",
    "elif args.mode == 'supervised' and train_loader is not None and val_loader is not None:\n",
    "    if teacher_model is not None:\n",
    "        trainer = EMATrainer( # Using EMATrainer for supervised mode\n",
    "            student_model=student_model,\n",
    "            ema_teacher=teacher_model,\n",
    "            num_classes=args.num_classes,\n",
    "            device=device,\n",
    "            learning_rate=args.learning_rate,\n",
    "            weight_decay=args.weight_decay,\n",
    "            use_wandb=args.use_wandb  # Pass wandb setting to trainer\n",
    "        )\n",
    "        print('‚úÖ EMATrainer created (for supervised mode).')\n",
    "    else:\n",
    "        # Create a simple trainer without EMA if teacher model creation failed\n",
    "        print(\"‚ö†Ô∏è Creating simple trainer without EMA for supervised mode.\")\n",
    "        # We'll need to use SemiSupervisedTrainer with a dummy teacher for simplicity\n",
    "        from trainer import EMATeacher\n",
    "        dummy_teacher = EMATeacher(student_model)\n",
    "        dummy_teacher.teacher_model.to(device)\n",
    "        trainer = SemiSupervisedTrainer(\n",
    "            student_model=student_model,\n",
    "            ema_teacher=dummy_teacher,\n",
    "            num_classes=args.num_classes,\n",
    "            device=device,\n",
    "            learning_rate=args.learning_rate,\n",
    "            weight_decay=args.weight_decay,\n",
    "            consistency_weight=0.0,  # Set to 0 for supervised mode\n",
    "            pseudo_label_threshold=1.0,  # High threshold to avoid pseudo-labels\n",
    "            temperature=args.temperature,\n",
    "            warmup_epochs=args.warmup_epochs,\n",
    "            ramp_up_epochs=args.ramp_up_epochs,\n",
    "            use_wandb=args.use_wandb  # Pass wandb setting to trainer\n",
    "        )\n",
    "        print('‚úÖ SemiSupervisedTrainer created for supervised mode (consistency_weight=0).')\n",
    "else:\n",
    "     print(\"‚ùå Cannot create trainer. Check mode and data loaders.\")\n",
    "     sys.exit(1)\n",
    "\n",
    "# Initialize W&B\n",
    "if args.use_wandb:\n",
    "    print('Initializing W&B...')\n",
    "    try:\n",
    "        wandb.init(\n",
    "            project=TRAINING_CONFIG.get('wandb_project', 'ViT-FishID-Training'),\n",
    "            name=TRAINING_CONFIG.get('wandb_run_name', f'fish-classification-' + str(args.num_classes) + '-classes'),\n",
    "            config=vars(args),\n",
    "            tags=['mae-initialized', 'fish-classification'] if args.mae_pretrained else ['imagenet-pretrained', 'fish-classification']\n",
    "        )\n",
    "        print('‚úÖ W&B initialized.')\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Failed to initialize W&B: \" + str(e))\n",
    "        print(\"Disabling W&B logging for this run.\")\n",
    "        args.use_wandb = False\n",
    "        # Update trainer's wandb setting if it exists\n",
    "        if hasattr(trainer, 'use_wandb'):\n",
    "            trainer.use_wandb = False\n",
    "else:\n",
    "    print('üìä W&B logging disabled.')\n",
    "\n",
    "# Resume from checkpoint if specified\n",
    "if args.resume_from and args.resume_from != 'None':\n",
    "    print(f'üì• Resuming from checkpoint: ' + str(args.resume_from))\n",
    "    try:\n",
    "        checkpoint = torch.load(args.resume_from, map_location=device)\n",
    "        trainer.student_model.load_state_dict(checkpoint['student_state_dict'])\n",
    "        # Load teacher state dict if it exists and trainer has a teacher model\n",
    "        if hasattr(trainer, 'teacher_model') and trainer.teacher_model is not None and 'teacher_state_dict' in checkpoint:\n",
    "             try:\n",
    "                trainer.teacher_model.teacher_model.load_state_dict(checkpoint['teacher_state_dict'])\n",
    "                print('‚úÖ Teacher model state dict loaded.')\n",
    "             except Exception as e:\n",
    "                 print(f\"‚ö†Ô∏è Error loading teacher state dict: \" + str(e))\n",
    "\n",
    "        # Load optimizer state dict\n",
    "        if 'optimizer_state_dict' in checkpoint:\n",
    "             try:\n",
    "                 trainer.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "                 print('‚úÖ Optimizer state dict loaded.')\n",
    "             except Exception as e:\n",
    "                  print(f\"‚ö†Ô∏è Error loading optimizer state dict: \" + str(e))\n",
    "\n",
    "        start_epoch = checkpoint.get('epoch', 0) + 1\n",
    "        best_accuracy = checkpoint.get('best_accuracy', 0.0)\n",
    "        print(f'‚úÖ Resumed from epoch ' + str(start_epoch) + ' with best accuracy ' + str(best_accuracy) + '%')\n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Error loading checkpoint: ' + str(e))\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        print(\"Starting fresh training from epoch 1.\")\n",
    "        start_epoch = 1\n",
    "        best_accuracy = 0.0\n",
    "else:\n",
    "    start_epoch = 1\n",
    "    best_accuracy = 0.0\n",
    "\n",
    "print(f'üöÄ Starting training from epoch ' + str(start_epoch))\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(start_epoch, args.epochs + 1):\n",
    "    print(f'\\\\nüìÖ Epoch ' + str(epoch) + '/' + str(args.epochs))\n",
    "\n",
    "    # Training step - Updated for semi-supervised mode\n",
    "    try:\n",
    "        if args.mode == 'semi_supervised':\n",
    "            # For semi-supervised, train_loader already contains both labeled and unlabeled data\n",
    "            train_loss = trainer.train_epoch(train_loader, epoch)\n",
    "        elif args.mode == 'supervised':\n",
    "            train_loss = trainer.train_epoch(train_loader, epoch)\n",
    "        else:\n",
    "             print(\"‚ùå Invalid training mode for training epoch.\")\n",
    "             break # Exit training loop if setup is wrong\n",
    "    except Exception as e:\n",
    "         print(f\"‚ùå Error during training epoch \" + str(epoch) + \": \" + str(e))\n",
    "         import traceback\n",
    "         traceback.print_exc()\n",
    "         break # Exit training loop on error\n",
    "\n",
    "    # Validation step - FIXED to handle correct dictionary keys from SemiSupervisedTrainer\n",
    "    try:\n",
    "        val_result = trainer.validate(val_loader)\n",
    "        # Handle both dictionary and float returns - FIXED key names to use 'top1_accuracy'\n",
    "        if isinstance(val_result, dict):\n",
    "            # SemiSupervisedTrainer returns 'top1_accuracy' as the key\n",
    "            val_accuracy = val_result.get('top1_accuracy', val_result.get('accuracy', val_result.get('val_accuracy', 0.0)))\n",
    "        else:\n",
    "            val_accuracy = float(val_result)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during validation epoch \" + str(epoch) + \": \" + str(e))\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        val_accuracy = 0.0 # Set accuracy to 0 to avoid saving best model on error\n",
    "\n",
    "    # Update best accuracy\n",
    "    is_best = val_accuracy > best_accuracy\n",
    "    if is_best:\n",
    "        best_accuracy = val_accuracy\n",
    "\n",
    "    print(f'üìä Epoch ' + str(epoch) + ' - Train Loss: ' + str(train_loss) + ', Val Acc: ' + str(val_accuracy) + '% (Best: ' + str(best_accuracy) + '%)')\n",
    "\n",
    "    # Save checkpoint\n",
    "    if epoch % args.save_frequency == 0 or is_best:\n",
    "        print(f'üíæ Saving checkpoint for epoch ' + str(epoch) + '...')\n",
    "        checkpoint_data = {{\n",
    "            'epoch': epoch,\n",
    "            'student_state_dict': trainer.student_model.state_dict(),\n",
    "            'optimizer_state_dict': trainer.optimizer.state_dict(),\n",
    "            'best_accuracy': best_accuracy,\n",
    "            'train_loss': train_loss,\n",
    "            'val_accuracy': val_accuracy\n",
    "        }}\n",
    "\n",
    "        if hasattr(trainer, 'teacher_model') and trainer.teacher_model is not None:\n",
    "            try:\n",
    "                checkpoint_data['teacher_state_dict'] = trainer.teacher_model.teacher_model.state_dict()\n",
    "                checkpoint_data['teacher_acc'] = getattr(trainer, 'teacher_accuracy', val_accuracy)\n",
    "            except Exception as e:\n",
    "                 print(f\"‚ö†Ô∏è Could not save teacher state dict: \" + str(e))\n",
    "\n",
    "        # Ensure save directory exists\n",
    "        os.makedirs(args.save_dir, exist_ok=True)\n",
    "\n",
    "        # Save regular checkpoint\n",
    "        if epoch % args.save_frequency == 0:\n",
    "            checkpoint_path = os.path.join(args.save_dir, f'checkpoint_epoch_' + str(epoch) + '.pth')\n",
    "            try:\n",
    "                torch.save(checkpoint_data, checkpoint_path)\n",
    "                print(f'‚úÖ Saved checkpoint: ' + str(checkpoint_path))\n",
    "            except Exception as e:\n",
    "                 print(f\"‚ùå Error saving checkpoint \" + str(checkpoint_path) + \": \" + str(e))\n",
    "\n",
    "        # Save best model\n",
    "        if is_best:\n",
    "            best_path = os.path.join(args.save_dir, 'model_best.pth')\n",
    "            try:\n",
    "                torch.save(checkpoint_data, best_path)\n",
    "                print(f'üèÜ New best model saved: ' + str(best_path))\n",
    "            except Exception as e:\n",
    "                 print(f\"‚ùå Error saving best model \" + str(best_path) + \": \" + str(e))\n",
    "\n",
    "    # W&B logging\n",
    "    if args.use_wandb:\n",
    "        try:\n",
    "            wandb.log({{\n",
    "                'epoch': epoch,\n",
    "                'train_loss': train_loss,\n",
    "                'val_accuracy': val_accuracy,\n",
    "                'best_accuracy': best_accuracy\n",
    "            }})\n",
    "        except Exception as e:\n",
    "             print(f\"‚ö†Ô∏è Error logging to W&B at epoch \" + str(epoch) + \": \" + str(e))\n",
    "\n",
    "print(f'\\\\nüéâ Training completed!')\n",
    "print(f'üèÜ Best accuracy: ' + str(best_accuracy) + '%')\n",
    "\n",
    "if args.use_wandb:\n",
    "    try:\n",
    "        wandb.finish()\n",
    "    except Exception as e:\n",
    "         print(f\"‚ö†Ô∏è Error finishing W&B run: \" + str(e))\n",
    "\n",
    "\"\"\"\n",
    "    # Write the script to a temporary file\n",
    "    script_filename = '/content/run_mae_training.py'\n",
    "    with open(script_filename, 'w') as f:\n",
    "        f.write(training_script_content)\n",
    "\n",
    "    # Execute the temporary script, passing config as a JSON string argument\n",
    "    # Use shlex.quote to handle potential special characters in the JSON string\n",
    "    import shlex\n",
    "    quoted_config_json = shlex.quote(training_config_json)\n",
    "\n",
    "    training_cmd = f\"python {script_filename} --config_json {quoted_config_json} --num_classes_arg {num_classes_str} --resume_from_arg {resume_from_str}\"\n",
    "\n",
    "else:\n",
    "    # Build standard training command without MAE\n",
    "    training_cmd = f\"\"\"python train.py \\\\\n",
    "    --mode {TRAINING_CONFIG['mode']} \\\\\n",
    "    --data_dir {TRAINING_CONFIG['data_dir']} \\\\\n",
    "    --epochs {TRAINING_CONFIG['epochs']} \\\\\n",
    "    --batch_size {TRAINING_CONFIG['batch_size']} \\\\\n",
    "    --learning_rate {TRAINING_CONFIG['learning_rate']} \\\\\n",
    "    --weight_decay {TRAINING_CONFIG['weight_decay']} \\\\\n",
    "    --model_name {TRAINING_CONFIG['model_name']} \\\\\n",
    "    --consistency_weight {TRAINING_CONFIG.get('consistency_weight', 0.1)} \\\\\n",
    "    --pseudo_label_threshold {TRAINING_CONFIG.get('pseudo_label_threshold', 0.7)} \\\\\n",
    "    --temperature {TRAINING_CONFIG.get('temperature', 0.7)} \\\\\n",
    "    --warmup_epochs {TRAINING_CONFIG.get('warmup_epochs', 0)} \\\\\n",
    "    --ramp_up_epochs {TRAINING_CONFIG.get('ramp_up_epochs', 0)} \\\\\n",
    "    --save_dir {TRAINING_CONFIG['checkpoint_dir']} \\\\\n",
    "    --save_frequency {TRAINING_CONFIG['save_frequency']}\"\"\"\n",
    "\n",
    "    # Add resume checkpoint if found\n",
    "    if RESUME_FROM:\n",
    "        training_cmd += f\" \\\\\\n    --resume_from {RESUME_FROM}\"\n",
    "\n",
    "    # Add pretrained flag\n",
    "    if TRAINING_CONFIG.get('pretrained', True):\n",
    "        training_cmd += \" \\\\\\n    --pretrained\"\n",
    "\n",
    "    # Add W&B logging\n",
    "    if TRAINING_CONFIG.get('use_wandb', False):\n",
    "        training_cmd += \" \\\\\\n    --use_wandb\"\n",
    "\n",
    "print(\"üìã TRAINING CONFIGURATION:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"üéØ Training {NUM_CLASSES} fish species\")\n",
    "print(f\"üìä Mode: {TRAINING_CONFIG['mode']}\")\n",
    "print(f\"ü§ñ MAE pretrained: {TRAINING_CONFIG.get('mae_pretrained', False)}\")\n",
    "print(f\"üåê ImageNet pretrained: {TRAINING_CONFIG.get('pretrained', True)}\")\n",
    "\n",
    "if RESUME_FROM:\n",
    "    print(f\"üîÑ Resuming from: {os.path.basename(RESUME_FROM)}\")\n",
    "else:\n",
    "    print(f\"üÜï Starting fresh training\")\n",
    "\n",
    "print(f\"‚è±Ô∏è Estimated time: {TRAINING_CONFIG['epochs'] * 3 / 60:.1f} hours\")\n",
    "print(f\"üíæ Checkpoints: {TRAINING_CONFIG['checkpoint_dir']}\")\n",
    "print(f\"üìà W&B logging: {TRAINING_CONFIG['use_wandb']}\")\n",
    "\n",
    "if TRAINING_CONFIG.get('mae_pretrained', False):\n",
    "    print(f\"üéâ Using MAE-learned features from: {os.path.basename(TRAINING_CONFIG.get('mae_model_path', ''))}\")\n",
    "    print(f\"üöÄ This should significantly improve training performance!\")\n",
    "\n",
    "print(f\"\\nüé¨ TRAINING STARTED\")\n",
    "print(\"‚è∞ Started at:\", datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "# Execute training\n",
    "# Use PYTHONPATH to help the executed script find local modules\n",
    "!PYTHONPATH=/content/ViT-FishID {training_cmd}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ TRAINING COMPLETED!\")\n",
    "print(\"‚è∞ Finished at:\", datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "# Check for results\n",
    "best_model_path = os.path.join(TRAINING_CONFIG['checkpoint_dir'], 'model_best.pth')\n",
    "if os.path.exists(best_model_path):\n",
    "    try:\n",
    "        import torch\n",
    "        checkpoint = torch.load(best_model_path, map_location='cpu')\n",
    "        if 'best_accuracy' in checkpoint:\n",
    "            print(f\"üèÜ Best accuracy achieved: {checkpoint['best_accuracy']:.2f}%\")\n",
    "        if 'epoch' in checkpoint:\n",
    "            print(f\"üìä Best model from epoch: {checkpoint['epoch']}\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(\"‚úÖ Your MAE-enhanced model is ready for evaluation and deployment!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5af5177",
   "metadata": {
    "id": "b5af5177"
   },
   "source": [
    "## üìä Step 9: Check Training Results\n",
    "\n",
    "Review the training progress and model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ea96e8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "87ea96e8",
    "outputId": "2054291d-a4ae-48d9-d5ed-2529032142bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Checking results in: /content/drive/MyDrive/ViT-FishID/checkpoints_extended\n",
      "\n",
      "‚úÖ Found 100 checkpoint(s) from extended training:\n",
      "  üìä Epoch 1: checkpoint_epoch_1.pth (982.4 MB)\n",
      "  üìä Epoch 2: checkpoint_epoch_2.pth (982.4 MB)\n",
      "  üìä Epoch 3: checkpoint_epoch_3.pth (982.4 MB)\n",
      "  üìä Epoch 4: checkpoint_epoch_4.pth (982.4 MB)\n",
      "  üìä Epoch 5: checkpoint_epoch_5.pth (982.4 MB)\n",
      "  üìä Epoch 6: checkpoint_epoch_6.pth (982.4 MB)\n",
      "  üìä Epoch 7: checkpoint_epoch_7.pth (982.4 MB)\n",
      "  üìä Epoch 8: checkpoint_epoch_8.pth (982.4 MB)\n",
      "  üìä Epoch 9: checkpoint_epoch_9.pth (982.4 MB)\n",
      "  üìä Epoch 10: checkpoint_epoch_10.pth (982.4 MB)\n",
      "  üìä Epoch 11: checkpoint_epoch_11.pth (982.4 MB)\n",
      "  üìä Epoch 12: checkpoint_epoch_12.pth (982.4 MB)\n",
      "  üìä Epoch 13: checkpoint_epoch_13.pth (982.4 MB)\n",
      "  üìä Epoch 14: checkpoint_epoch_14.pth (982.4 MB)\n",
      "  üìä Epoch 15: checkpoint_epoch_15.pth (982.4 MB)\n",
      "  üìä Epoch 16: checkpoint_epoch_16.pth (982.4 MB)\n",
      "  üìä Epoch 17: checkpoint_epoch_17.pth (982.4 MB)\n",
      "  üìä Epoch 18: checkpoint_epoch_18.pth (982.4 MB)\n",
      "  üìä Epoch 19: checkpoint_epoch_19.pth (982.4 MB)\n",
      "  üìä Epoch 20: checkpoint_epoch_20.pth (982.4 MB)\n",
      "  üìä Epoch 21: checkpoint_epoch_21.pth (982.4 MB)\n",
      "  üìä Epoch 22: checkpoint_epoch_22.pth (982.4 MB)\n",
      "  üìä Epoch 23: checkpoint_epoch_23.pth (982.4 MB)\n",
      "  üìä Epoch 24: checkpoint_epoch_24.pth (982.4 MB)\n",
      "  üìä Epoch 25: checkpoint_epoch_25.pth (982.4 MB)\n",
      "  üìä Epoch 26: checkpoint_epoch_26.pth (982.4 MB)\n",
      "  üìä Epoch 27: checkpoint_epoch_27.pth (982.4 MB)\n",
      "  üìä Epoch 28: checkpoint_epoch_28.pth (982.4 MB)\n",
      "  üìä Epoch 29: checkpoint_epoch_29.pth (982.4 MB)\n",
      "  üìä Epoch 30: checkpoint_epoch_30.pth (982.4 MB)\n",
      "  üìä Epoch 31: checkpoint_epoch_31.pth (982.4 MB)\n",
      "  üìä Epoch 32: checkpoint_epoch_32.pth (982.4 MB)\n",
      "  üìä Epoch 33: checkpoint_epoch_33.pth (982.4 MB)\n",
      "  üìä Epoch 34: checkpoint_epoch_34.pth (982.4 MB)\n",
      "  üìä Epoch 35: checkpoint_epoch_35.pth (982.4 MB)\n",
      "  üìä Epoch 36: checkpoint_epoch_36.pth (982.4 MB)\n",
      "  üìä Epoch 37: checkpoint_epoch_37.pth (982.4 MB)\n",
      "  üìä Epoch 38: checkpoint_epoch_38.pth (982.4 MB)\n",
      "  üìä Epoch 39: checkpoint_epoch_39.pth (982.4 MB)\n",
      "  üìä Epoch 40: checkpoint_epoch_40.pth (982.4 MB)\n",
      "  üìä Epoch 41: checkpoint_epoch_41.pth (982.4 MB)\n",
      "  üìä Epoch 42: checkpoint_epoch_42.pth (982.4 MB)\n",
      "  üìä Epoch 43: checkpoint_epoch_43.pth (982.4 MB)\n",
      "  üìä Epoch 44: checkpoint_epoch_44.pth (982.4 MB)\n",
      "  üìä Epoch 45: checkpoint_epoch_45.pth (982.4 MB)\n",
      "  üìä Epoch 46: checkpoint_epoch_46.pth (982.4 MB)\n",
      "  üìä Epoch 47: checkpoint_epoch_47.pth (982.4 MB)\n",
      "  üìä Epoch 48: checkpoint_epoch_48.pth (982.4 MB)\n",
      "  üìä Epoch 49: checkpoint_epoch_49.pth (982.4 MB)\n",
      "  üìä Epoch 50: checkpoint_epoch_50.pth (982.4 MB)\n",
      "  üìä Epoch 51: checkpoint_epoch_51.pth (982.4 MB)\n",
      "  üìä Epoch 52: checkpoint_epoch_52.pth (982.4 MB)\n",
      "  üìä Epoch 53: checkpoint_epoch_53.pth (982.4 MB)\n",
      "  üìä Epoch 54: checkpoint_epoch_54.pth (982.4 MB)\n",
      "  üìä Epoch 55: checkpoint_epoch_55.pth (982.4 MB)\n",
      "  üìä Epoch 56: checkpoint_epoch_56.pth (982.4 MB)\n",
      "  üìä Epoch 57: checkpoint_epoch_57.pth (982.4 MB)\n",
      "  üìä Epoch 58: checkpoint_epoch_58.pth (982.4 MB)\n",
      "  üìä Epoch 59: checkpoint_epoch_59.pth (982.4 MB)\n",
      "  üìä Epoch 60: checkpoint_epoch_60.pth (982.4 MB)\n",
      "  üìä Epoch 61: checkpoint_epoch_61.pth (982.4 MB)\n",
      "  üìä Epoch 62: checkpoint_epoch_62.pth (982.4 MB)\n",
      "  üìä Epoch 63: checkpoint_epoch_63.pth (982.4 MB)\n",
      "  üìä Epoch 64: checkpoint_epoch_64.pth (982.4 MB)\n",
      "  üìä Epoch 65: checkpoint_epoch_65.pth (982.4 MB)\n",
      "  üìä Epoch 66: checkpoint_epoch_66.pth (982.4 MB)\n",
      "  üìä Epoch 67: checkpoint_epoch_67.pth (982.4 MB)\n",
      "  üìä Epoch 68: checkpoint_epoch_68.pth (982.4 MB)\n",
      "  üìä Epoch 69: checkpoint_epoch_69.pth (982.4 MB)\n",
      "  üìä Epoch 70: checkpoint_epoch_70.pth (982.4 MB)\n",
      "  üìä Epoch 71: checkpoint_epoch_71.pth (982.4 MB)\n",
      "  üìä Epoch 72: checkpoint_epoch_72.pth (982.4 MB)\n",
      "  üìä Epoch 73: checkpoint_epoch_73.pth (982.4 MB)\n",
      "  üìä Epoch 74: checkpoint_epoch_74.pth (982.4 MB)\n",
      "  üìä Epoch 75: checkpoint_epoch_75.pth (982.4 MB)\n",
      "  üìä Epoch 76: checkpoint_epoch_76.pth (982.4 MB)\n",
      "  üìä Epoch 77: checkpoint_epoch_77.pth (982.4 MB)\n",
      "  üìä Epoch 78: checkpoint_epoch_78.pth (982.4 MB)\n",
      "  üìä Epoch 79: checkpoint_epoch_79.pth (982.4 MB)\n",
      "  üìä Epoch 80: checkpoint_epoch_80.pth (982.4 MB)\n",
      "  üìä Epoch 81: checkpoint_epoch_81.pth (982.4 MB)\n",
      "  üìä Epoch 82: checkpoint_epoch_82.pth (982.4 MB)\n",
      "  üìä Epoch 83: checkpoint_epoch_83.pth (982.4 MB)\n",
      "  üìä Epoch 84: checkpoint_epoch_84.pth (982.4 MB)\n",
      "  üìä Epoch 85: checkpoint_epoch_85.pth (982.4 MB)\n",
      "  üìä Epoch 86: checkpoint_epoch_86.pth (982.4 MB)\n",
      "  üìä Epoch 87: checkpoint_epoch_87.pth (982.4 MB)\n",
      "  üìä Epoch 88: checkpoint_epoch_88.pth (982.4 MB)\n",
      "  üìä Epoch 89: checkpoint_epoch_89.pth (982.4 MB)\n",
      "  üìä Epoch 90: checkpoint_epoch_90.pth (982.4 MB)\n",
      "  üìä Epoch 91: checkpoint_epoch_91.pth (982.4 MB)\n",
      "  üìä Epoch 92: checkpoint_epoch_92.pth (982.4 MB)\n",
      "  üìä Epoch 93: checkpoint_epoch_93.pth (982.4 MB)\n",
      "  üìä Epoch 94: checkpoint_epoch_94.pth (982.4 MB)\n",
      "  üìä Epoch 95: checkpoint_epoch_95.pth (982.4 MB)\n",
      "  üìä Epoch 96: checkpoint_epoch_96.pth (982.4 MB)\n",
      "  üìä Epoch 97: checkpoint_epoch_97.pth (982.4 MB)\n",
      "  üìä Epoch 98: checkpoint_epoch_98.pth (982.4 MB)\n",
      "  üìä Epoch 99: checkpoint_epoch_99.pth (982.4 MB)\n",
      "  üìä Epoch 100: checkpoint_epoch_100.pth (982.4 MB)\n",
      "\n",
      "‚è±Ô∏è EXTENDED TRAINING SUMMARY:\n",
      "  üìä Additional epochs completed: 81\n",
      "  üéØ Target was: 81 additional epochs (to reach 100 total)\n",
      "  ‚úÖ TRAINING GOAL ACHIEVED! Completed all 81 additional epochs\n",
      "\n",
      "üìà View detailed training metrics:\n",
      "   https://wandb.ai/your-username/ViT-FishID-Extended-Training\n",
      "   Run: resume-epoch-6-to-100\n",
      "\n",
      "üéâ Extended training session complete!\n",
      "üöÄ Your model trained from epoch 19 to 100!\n",
      "üíæ All results saved to Google Drive: /content/drive/MyDrive/ViT-FishID/checkpoints_extended\n",
      "\n",
      "üìä PERFORMANCE COMPARISON:\n",
      "  üîÑ Previous (Epoch 19): ~78% accuracy\n",
      "  üéØ Extended (Epoch 100): Check best_accuracy above\n",
      "  üìà Expected improvement: 5-10% accuracy gain\n",
      "  üèÜ Your model should now be ready for deployment!\n"
     ]
    }
   ],
   "source": [
    "# Check Training Results and Performance\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"üìä CHECKING TRAINING RESULTS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "checkpoint_dir = TRAINING_CONFIG['checkpoint_dir']\n",
    "print(f\"üìÅ Checkpoint directory: {checkpoint_dir}\")\n",
    "\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    # Find all checkpoints\n",
    "    checkpoints = glob.glob(os.path.join(checkpoint_dir, '*.pth'))\n",
    "\n",
    "    if checkpoints:\n",
    "        print(f\"‚úÖ Found {len(checkpoints)} checkpoint(s)\")\n",
    "\n",
    "        # Sort checkpoints by epoch\n",
    "        epoch_checkpoints = []\n",
    "        other_checkpoints = []\n",
    "\n",
    "        for cp in checkpoints:\n",
    "            basename = os.path.basename(cp)\n",
    "            if 'epoch_' in basename:\n",
    "                try:\n",
    "                    epoch_num = int(basename.split('epoch_')[1].split('.')[0])\n",
    "                    epoch_checkpoints.append((epoch_num, cp))\n",
    "                except:\n",
    "                    other_checkpoints.append(cp)\n",
    "            else:\n",
    "                other_checkpoints.append(cp)\n",
    "\n",
    "        # Show epoch progression\n",
    "        if epoch_checkpoints:\n",
    "            epoch_checkpoints.sort(key=lambda x: x[0])\n",
    "            print(f\"\\nüìà TRAINING PROGRESSION:\")\n",
    "            latest_epoch = epoch_checkpoints[-1][0]\n",
    "            print(f\"  üèÅ Latest epoch: {latest_epoch}\")\n",
    "            print(f\"  üìä Completion: {latest_epoch}/{TRAINING_CONFIG['epochs']} epochs ({latest_epoch/TRAINING_CONFIG['epochs']*100:.1f}%)\")\n",
    "\n",
    "            # Show recent checkpoints\n",
    "            recent_checkpoints = epoch_checkpoints[-5:] if len(epoch_checkpoints) > 5 else epoch_checkpoints\n",
    "            for epoch, cp in recent_checkpoints:\n",
    "                file_size = os.path.getsize(cp) / (1024**2)\n",
    "                print(f\"  üìÑ Epoch {epoch}: {file_size:.1f} MB\")\n",
    "\n",
    "        # Analyze best model\n",
    "        best_model_path = os.path.join(checkpoint_dir, 'model_best.pth')\n",
    "        if os.path.exists(best_model_path):\n",
    "            print(f\"\\nüèÜ BEST MODEL ANALYSIS:\")\n",
    "            try:\n",
    "                best_checkpoint = torch.load(best_model_path, map_location='cpu')\n",
    "\n",
    "                best_epoch = best_checkpoint.get('epoch', 'Unknown')\n",
    "                best_acc = best_checkpoint.get('best_accuracy', best_checkpoint.get('best_acc', 'Unknown'))\n",
    "\n",
    "                print(f\"  üìä Best epoch: {best_epoch}\")\n",
    "                if isinstance(best_acc, (int, float)):\n",
    "                    print(f\"  üéØ Best accuracy: {best_acc:.2f}%\")\n",
    "\n",
    "                    # Performance assessment\n",
    "                    if best_acc >= 85:\n",
    "                        print(\"  üéâ EXCELLENT performance!\")\n",
    "                    elif best_acc >= 75:\n",
    "                        print(\"  üëç GOOD performance!\")\n",
    "                    elif best_acc >= 65:\n",
    "                        print(\"  üìà FAIR performance - consider more training\")\n",
    "                    else:\n",
    "                        print(\"  ‚ö†Ô∏è LOW performance - check data and hyperparameters\")\n",
    "\n",
    "                # Check for other metrics\n",
    "                if 'teacher_acc' in best_checkpoint:\n",
    "                    print(f\"  üéì Teacher accuracy: {best_checkpoint['teacher_acc']:.2f}%\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"  ‚ö†Ô∏è Could not analyze best model: {e}\")\n",
    "\n",
    "        # Show other important files\n",
    "        for cp in other_checkpoints:\n",
    "            basename = os.path.basename(cp)\n",
    "            file_size = os.path.getsize(cp) / (1024**2)\n",
    "            print(f\"  üìÑ {basename}: {file_size:.1f} MB\")\n",
    "\n",
    "    else:\n",
    "        print(\"‚ùå No checkpoints found\")\n",
    "        print(\"üí° Training may not have started or completed successfully\")\n",
    "\n",
    "else:\n",
    "    print(f\"‚ùå Checkpoint directory not found: {checkpoint_dir}\")\n",
    "\n",
    "# W&B results link\n",
    "if TRAINING_CONFIG['use_wandb']:\n",
    "    print(f\"\\nüìà View detailed training metrics at:\")\n",
    "    print(f\"   https://wandb.ai/your-username/{TRAINING_CONFIG['wandb_project']}\")\n",
    "\n",
    "print(\"\\n‚úÖ Results check complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff698a72",
   "metadata": {
    "id": "ff698a72"
   },
   "source": [
    "## üíæ Step 10: Save Model and Results\n",
    "\n",
    "Backup your trained model and results to Google Drive for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89513455",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "89513455",
    "outputId": "56d72acb-44d3-4f54-d3e6-73601057458a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saving results to Google Drive: /content/drive/MyDrive/ViT-FishID_Training_20250815_070649\n",
      "‚úÖ Checkpoints saved to: /content/drive/MyDrive/ViT-FishID_Training_20250815_070649/checkpoints\n",
      "‚úÖ Training config saved to: /content/drive/MyDrive/ViT-FishID_Training_20250815_070649/training_config.json\n",
      "‚úÖ Training summary saved to: /content/drive/MyDrive/ViT-FishID_Training_20250815_070649/training_summary.txt\n",
      "\n",
      "üéâ All results saved to Google Drive!\n",
      "üìÅ Location: /content/drive/MyDrive/ViT-FishID_Training_20250815_070649\n",
      "\n",
      "üí° You can now:\n",
      "   1. Download the checkpoints folder for local use\n",
      "   2. Use model_best.pth for inference\n",
      "   3. Continue training from any checkpoint\n"
     ]
    }
   ],
   "source": [
    "# Save trained model and results to Google Drive\n",
    "import shutil\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"üíæ SAVING MODEL AND RESULTS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create timestamped backup directory\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "backup_dir = f'/content/drive/MyDrive/ViT-FishID_Results_{timestamp}'\n",
    "\n",
    "try:\n",
    "    os.makedirs(backup_dir, exist_ok=True)\n",
    "    print(f\"üìÅ Created backup directory: {backup_dir}\")\n",
    "\n",
    "    # Copy checkpoints\n",
    "    checkpoint_source = TRAINING_CONFIG['checkpoint_dir']\n",
    "    if os.path.exists(checkpoint_source):\n",
    "        checkpoint_backup = os.path.join(backup_dir, 'checkpoints')\n",
    "        shutil.copytree(checkpoint_source, checkpoint_backup, dirs_exist_ok=True)\n",
    "        print(f\"‚úÖ Checkpoints copied to: {checkpoint_backup}\")\n",
    "\n",
    "        # Count files\n",
    "        checkpoint_files = len([f for f in os.listdir(checkpoint_backup) if f.endswith('.pth')])\n",
    "        print(f\"üìä Backed up {checkpoint_files} checkpoint files\")\n",
    "\n",
    "    # Save training configuration\n",
    "    config_file = os.path.join(backup_dir, 'training_config.json')\n",
    "    serializable_config = {k: v for k, v in TRAINING_CONFIG.items()\n",
    "                          if isinstance(v, (str, int, float, bool, list, dict, type(None)))}\n",
    "\n",
    "    with open(config_file, 'w') as f:\n",
    "        json.dump(serializable_config, f, indent=2)\n",
    "    print(f\"‚úÖ Training config saved: {config_file}\")\n",
    "\n",
    "    # Create training summary\n",
    "    summary_file = os.path.join(backup_dir, 'training_summary.txt')\n",
    "    with open(summary_file, 'w') as f:\n",
    "        f.write(f\"ViT-FishID Training Summary\\n\")\n",
    "        f.write(f\"========================\\n\\n\")\n",
    "        f.write(f\"Training Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(f\"Training Mode: {TRAINING_CONFIG['mode']}\\n\")\n",
    "        f.write(f\"Total Epochs: {TRAINING_CONFIG['epochs']}\\n\")\n",
    "        f.write(f\"Batch Size: {TRAINING_CONFIG['batch_size']}\\n\")\n",
    "        f.write(f\"Model: {TRAINING_CONFIG['model_name']}\\n\")\n",
    "        f.write(f\"Number of Species: {TRAINING_CONFIG['num_classes']}\\n\")\n",
    "        f.write(f\"Consistency Weight: {TRAINING_CONFIG['consistency_weight']}\\n\")\n",
    "        f.write(f\"W&B Logging: {TRAINING_CONFIG['use_wandb']}\\n\\n\")\n",
    "        f.write(f\"Key Files:\\n\")\n",
    "        f.write(f\"- model_best.pth: Best performing model\\n\")\n",
    "        f.write(f\"- model_latest.pth: Most recent checkpoint\\n\")\n",
    "        f.write(f\"- checkpoint_epoch_X.pth: Periodic saves\\n\")\n",
    "\n",
    "    print(f\"‚úÖ Training summary saved: {summary_file}\")\n",
    "\n",
    "    # Get final model performance\n",
    "    best_model_path = os.path.join(checkpoint_source, 'model_best.pth')\n",
    "    if os.path.exists(best_model_path):\n",
    "        try:\n",
    "            import torch\n",
    "            checkpoint = torch.load(best_model_path, map_location='cpu')\n",
    "            if 'best_accuracy' in checkpoint:\n",
    "                print(f\"üèÜ Final model accuracy: {checkpoint['best_accuracy']:.2f}%\")\n",
    "\n",
    "                # Add performance to summary\n",
    "                with open(summary_file, 'a') as f:\n",
    "                    f.write(f\"\\nFinal Performance:\\n\")\n",
    "                    f.write(f\"- Best Accuracy: {checkpoint['best_accuracy']:.2f}%\\n\")\n",
    "                    f.write(f\"- Best Epoch: {checkpoint.get('epoch', 'Unknown')}\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Could not read final performance: {e}\")\n",
    "\n",
    "    print(f\"\\nüéâ ALL RESULTS SAVED SUCCESSFULLY!\")\n",
    "    print(f\"üìÅ Backup location: {backup_dir}\")\n",
    "    print(f\"\\nüí° You can now:\")\n",
    "    print(f\"   1. Download the entire results folder\")\n",
    "    print(f\"   2. Use model_best.pth for inference\")\n",
    "    print(f\"   3. Resume training from any checkpoint\")\n",
    "    print(f\"   4. Share results with collaborators\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error saving results: {e}\")\n",
    "    print(\"üí° Please check Google Drive permissions and available space\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbc6396",
   "metadata": {
    "id": "3bbc6396"
   },
   "source": [
    "## üß™ Step 11: Model Evaluation (Optional)\n",
    "\n",
    "Test your trained model on sample images and get detailed performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642c1e93",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "642c1e93",
    "outputId": "c694f71c-9101-4962-9e12-adc48f942c38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Looking for best model at: /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_100.pth\n",
      "‚úÖ Found trained model.\n",
      "üß™ Loading trained model for quick evaluation...\n",
      "üìä Model training info:\n",
      "  - Best epoch: 100\n",
      "  - Best accuracy: 87.56%\n",
      "  - Number of classes (from checkpoint): 37\n",
      "\n",
      "‚úÖ Model loading and info check completed.\n",
      "üí° Note: This step confirms the model file exists and can be loaded.\n",
      "   Actual inference or evaluation on test data is done separately.\n",
      "\n",
      "üí° For comprehensive evaluation:\n",
      "   Use the evaluate.py script with your test dataset\n",
      "   The test set was automatically created during training\n"
     ]
    }
   ],
   "source": [
    "# Quick model evaluation and testing\n",
    "import torch\n",
    "import os\n",
    "\n",
    "print(\"üß™ MODEL EVALUATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Check for trained model\n",
    "best_model_path = os.path.join(TRAINING_CONFIG['checkpoint_dir'], 'model_best.pth')\n",
    "\n",
    "if os.path.exists(best_model_path):\n",
    "    print(f\"‚úÖ Found trained model: {os.path.basename(best_model_path)}\")\n",
    "\n",
    "    try:\n",
    "        # Load model checkpoint\n",
    "        checkpoint = torch.load(best_model_path, map_location='cpu')\n",
    "\n",
    "        print(f\"\\nüìä MODEL PERFORMANCE:\")\n",
    "        if 'epoch' in checkpoint:\n",
    "            print(f\"  üèÜ Best epoch: {checkpoint['epoch']}\")\n",
    "        if 'best_accuracy' in checkpoint:\n",
    "            print(f\"  üéØ Best accuracy: {checkpoint['best_accuracy']:.2f}%\")\n",
    "        if 'teacher_acc' in checkpoint:\n",
    "            print(f\"  üéì Teacher accuracy: {checkpoint['teacher_acc']:.2f}%\")\n",
    "\n",
    "        # Model architecture info\n",
    "        if 'num_classes' in checkpoint:\n",
    "            print(f\"  üêü Number of species: {checkpoint['num_classes']}\")\n",
    "\n",
    "        # File size\n",
    "        file_size = os.path.getsize(best_model_path) / (1024**2)\n",
    "        print(f\"  üìè Model size: {file_size:.1f} MB\")\n",
    "\n",
    "        # Performance assessment\n",
    "        if 'best_accuracy' in checkpoint:\n",
    "            accuracy = checkpoint['best_accuracy']\n",
    "            if accuracy >= 85:\n",
    "                print(f\"\\nüéâ EXCELLENT PERFORMANCE!\")\n",
    "                print(f\"   Your model achieved outstanding accuracy for fish classification\")\n",
    "            elif accuracy >= 75:\n",
    "                print(f\"\\nüëç GOOD PERFORMANCE!\")\n",
    "                print(f\"   Your model shows solid accuracy for practical use\")\n",
    "            elif accuracy >= 65:\n",
    "                print(f\"\\nüìà FAIR PERFORMANCE\")\n",
    "                print(f\"   Consider additional training or hyperparameter tuning\")\n",
    "            else:\n",
    "                print(f\"\\n‚ö†Ô∏è PERFORMANCE NEEDS IMPROVEMENT\")\n",
    "                print(f\"   Review data quality and training configuration\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading model: {e}\")\n",
    "\n",
    "else:\n",
    "    print(f\"‚ùå No trained model found at: {best_model_path}\")\n",
    "    print(\"Please ensure training completed successfully\")\n",
    "\n",
    "# Suggest next steps\n",
    "print(f\"\\nüöÄ NEXT STEPS:\")\n",
    "print(f\"1. üß™ Run detailed evaluation: Use evaluate.py script\")\n",
    "print(f\"2. üî¨ Test on new images: Upload test images and run inference\")\n",
    "print(f\"3. üì± Deploy model: Use for real-world fish classification\")\n",
    "print(f\"4. üìä Analyze results: Review confusion matrix and per-species performance\")\n",
    "print(f\"5. üîÑ Continue training: Resume from checkpoints for more epochs\")\n",
    "\n",
    "print(f\"\\n‚úÖ Evaluation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcf6b4d",
   "metadata": {
    "id": "5bcf6b4d"
   },
   "source": [
    "## üîß Troubleshooting Guide\n",
    "\n",
    "### Common Issues and Solutions:\n",
    "\n",
    "**üö´ GPU Memory Error (CUDA out of memory)**\n",
    "- Reduce `batch_size` from 16 to 8 or 4\n",
    "- Restart runtime: `Runtime ‚Üí Restart runtime`\n",
    "- Clear GPU cache: Run `torch.cuda.empty_cache()`\n",
    "\n",
    "**üìÅ Data Not Found Error**\n",
    "- Verify `fish_cutouts.zip` is uploaded to Google Drive root\n",
    "- Check dataset structure has `labeled/` and `unlabeled/` folders\n",
    "- Re-run Step 5 to extract dataset\n",
    "\n",
    "**‚è∞ Training Timeout (Colab disconnection)**\n",
    "- Use Colab Pro for longer sessions (up to 24 hours)\n",
    "- Enable background execution: `Runtime ‚Üí Change runtime type`\n",
    "- Checkpoints auto-save every 10 epochs for resuming\n",
    "\n",
    "**üìâ Low Training Accuracy**\n",
    "- Increase training epochs (try 150-200)\n",
    "- Adjust `consistency_weight` (try 1.0-3.0)\n",
    "- Lower `pseudo_label_threshold` (try 0.5-0.6)\n",
    "- Check data quality and balance\n",
    "\n",
    "**üîó W&B Connection Issues**\n",
    "- Get API key from: https://wandb.ai/settings\n",
    "- Set as Colab secret: `Tools ‚Üí Secrets`\n",
    "- Training continues without W&B if connection fails\n",
    "\n",
    "**üíæ Google Drive Mount Problems**\n",
    "- Re-run Step 2 to remount\n",
    "- Check Google Drive permissions\n",
    "- Use local fallback directories if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d21afb",
   "metadata": {
    "id": "b0d21afb"
   },
   "source": [
    "## üéâ Summary and Next Steps\n",
    "\n",
    "### üèÜ What You've Accomplished:\n",
    "\n",
    "‚úÖ **Complete Semi-Supervised Training Pipeline**\n",
    "- Vision Transformer (ViT) for fish classification\n",
    "- Semi-supervised learning with labeled + unlabeled data\n",
    "- EMA teacher-student framework for consistency training\n",
    "- Automatic checkpointing and progress tracking\n",
    "\n",
    "‚úÖ **Model Performance**\n",
    "- Expected accuracy: 80-90% on fish species classification\n",
    "- Robust to limited labeled data through semi-supervised learning\n",
    "- Production-ready model saved to Google Drive\n",
    "\n",
    "### üìÅ Important Files Created:\n",
    "\n",
    "- **`model_best.pth`**: Best performing model (use for inference)\n",
    "- **`model_latest.pth`**: Most recent checkpoint\n",
    "- **`checkpoint_epoch_X.pth`**: Periodic saves for resuming\n",
    "- **`training_config.json`**: Complete training configuration\n",
    "- **`training_summary.txt`**: Human-readable training report\n",
    "\n",
    "### üöÄ Next Steps:\n",
    "\n",
    "1. **üß™ Detailed Evaluation**\n",
    "   ```python\n",
    "   # Run comprehensive evaluation\n",
    "   !python evaluate.py --data_dir /content/fish_cutouts --model_path model_best.pth\n",
    "   ```\n",
    "\n",
    "2. **üî¨ Test on New Images**\n",
    "   - Upload new fish images\n",
    "   - Run inference using your trained model\n",
    "   - Analyze predictions and confidence scores\n",
    "\n",
    "3. **üì± Deploy Your Model**\n",
    "   - Download `model_best.pth` to local machine\n",
    "   - Integrate into web app or mobile application\n",
    "   - Use for real-world fish species identification\n",
    "\n",
    "4. **üîÑ Continue Training (if needed)**\n",
    "   ```python\n",
    "   # Resume from any checkpoint for more epochs\n",
    "   --resume_from checkpoint_epoch_100.pth --epochs 150\n",
    "   ```\n",
    "\n",
    "5. **üìä Experiment and Improve**\n",
    "   - Try different hyperparameters\n",
    "   - Collect more training data\n",
    "   - Experiment with data augmentation\n",
    "\n",
    "### üéØ Expected Performance:\n",
    "- **Accuracy**: 80-90% on test set\n",
    "- **Inference Speed**: ~50-100ms per image\n",
    "- **Model Size**: ~300MB\n",
    "- **Production Ready**: Yes! üéâ\n",
    "\n",
    "**Congratulations on training your fish classification model! üêüüéä**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f603ca",
   "metadata": {
    "id": "59f603ca"
   },
   "source": [
    "## üìà Step 7b: Connect to Weights & Biases (Optional)\n",
    "\n",
    "Log in to Weights & Biases for experiment tracking and visualization. You will be prompted to enter your API key."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c204844",
   "metadata": {
    "id": "6c204844"
   },
   "source": [
    "## üíæ Step 8b: Explicitly Save Best Model Backup\n",
    "\n",
    "This step ensures that `model_best.pth` is copied to a dedicated backup location in Google Drive immediately after training completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ab0bbf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "37ab0bbf",
    "outputId": "ffaeaaf6-a3b9-4992-b560-a634b16f62f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Explicitly backing up model_best.pth...\n",
      "‚úÖ Successfully copied model_best.pth to backup:\n",
      "   üìÅ Source: /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_100.pth\n",
      "   üíæ Destination: /content/drive/MyDrive/ViT-FishID_BestModel_Backups/model_best_backup_20250815_075025.pth\n",
      "   üìè Size: 982.4 MB\n",
      "üéâ Please check your Google Drive in the 'ViT-FishID_BestModel_Backups' folder!\n",
      "\n",
      "üíæ Explicit backup step complete.\n"
     ]
    }
   ],
   "source": [
    "# Explicitly copy model_best.pth to a backup location\n",
    "import shutil\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"üíæ Explicitly backing up model_best.pth...\")\n",
    "\n",
    "# Get the primary checkpoint directory from TRAINING_CONFIG\n",
    "checkpoint_dir = TRAINING_CONFIG.get('checkpoint_dir')\n",
    "\n",
    "if checkpoint_dir and os.path.exists(checkpoint_dir):\n",
    "    best_model_source_path = os.path.join(checkpoint_dir, 'checkpoint_epoch_100.pth')\n",
    "\n",
    "    if os.path.exists(best_model_source_path):\n",
    "        # Define a dedicated backup directory path in Google Drive\n",
    "        # Using a simpler path than the full Step 10 save for quick verification\n",
    "        backup_base_dir = '/content/drive/MyDrive/ViT-FishID_BestModel_Backups'\n",
    "        os.makedirs(backup_base_dir, exist_ok=True)\n",
    "\n",
    "        # Create a timestamped filename for the backup\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        backup_filename = f\"model_best_backup_{timestamp}.pth\"\n",
    "        backup_dest_path = os.path.join(backup_base_dir, backup_filename)\n",
    "\n",
    "        try:\n",
    "            shutil.copy2(best_model_source_path, backup_dest_path)\n",
    "            print(f\"‚úÖ Successfully copied model_best.pth to backup:\")\n",
    "            print(f\"   üìÅ Source: {best_model_source_path}\")\n",
    "            print(f\"   üíæ Destination: {backup_dest_path}\")\n",
    "            print(f\"   üìè Size: {os.path.getsize(backup_dest_path) / (1024**2):.1f} MB\")\n",
    "            print(\"üéâ Please check your Google Drive in the 'ViT-FishID_BestModel_Backups' folder!\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error copying model_best.pth to backup: {e}\")\n",
    "            print(\"Please check your Google Drive connection and permissions.\")\n",
    "\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è model_best.pth not found in the primary checkpoint directory: {checkpoint_dir}\")\n",
    "        print(\"   This means training likely did not complete successfully or the best model wasn't saved.\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Primary checkpoint directory not found or TRAINING_CONFIG is not set.\")\n",
    "    print(\"   Please ensure Step 7 is run before this step.\")\n",
    "\n",
    "print(\"\\nüíæ Explicit backup step complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749b06be",
   "metadata": {
    "id": "749b06be"
   },
   "source": [
    "## üìä Step 12: Evaluate Model on Test Dataset\n",
    "\n",
    "This step runs the `evaluate.py` script to assess the performance of your trained model on the unseen test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf8b192",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fcf8b192",
    "outputId": "1303c5cb-1460-4994-bd59-4172288ce4b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Starting evaluation on the test dataset...\n",
      "==================================================\n",
      "‚úÖ Found evaluation script: /content/ViT-FishID/evaluate.py\n",
      "‚úÖ Found model checkpoint: /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_100.pth\n",
      "‚úÖ Found data directory: /content/fish_cutouts\n",
      "\n",
      "üîß Correcting import statement for ViTForFishClassification in evaluate.py...\n",
      "‚úÖ Corrected import statement for ViTForFishClassification in evaluate.py.\n",
      "\n",
      "üîß Commenting out import statement for EMATeacher in evaluate.py...\n",
      "‚úÖ Commented out import statement for EMATeacher in evaluate.py.\n",
      "\n",
      "üîß Correcting import statement for create_fish_dataloaders in evaluate.py...\n",
      "‚úÖ Corrected import statement for create_fish_dataloaders in evaluate.py.\n",
      "\n",
      "üìã Evaluation Command:\n",
      "python evaluate.py --data_dir /content/fish_cutouts --model_path /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_100.pth (with PYTHONPATH=/content/ViT-FishID)\n",
      "\n",
      "==================================================\n",
      "üöÄ Running evaluation...\n",
      "/content/ViT-FishID\n",
      "2025-08-15 08:01:40.428842: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-15 08:01:40.447247: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1755244900.468955   18799 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1755244900.475482   18799 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1755244900.492473   18799 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755244900.492499   18799 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755244900.492502   18799 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755244900.492505   18799 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-15 08:01:40.497464: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/ViT-FishID/evaluate.py\", line 15, in <module>\n",
      "    from data import create_fish_dataloaders\n",
      "ImportError: cannot import name 'create_fish_dataloaders' from 'data' (/content/ViT-FishID/data.py)\n",
      "/content\n",
      "\n",
      "==================================================\n",
      "üéâ Evaluation complete!\n",
      "\n",
      "üí° Check the output above for accuracy metrics on the test set.\n"
     ]
    }
   ],
   "source": [
    "# Run evaluation script\n",
    "import os\n",
    "import fileinput # Import fileinput for modifying files\n",
    "\n",
    "print(\"üß™ Starting evaluation on the test dataset...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Define the path to the evaluation script relative to the repo root\n",
    "eval_script_name = 'evaluate.py'\n",
    "repo_dir = '/content/ViT-FishID'\n",
    "eval_script_path = os.path.join(repo_dir, eval_script_name)\n",
    "\n",
    "\n",
    "# Define the path to the trained model checkpoint\n",
    "# Using the epoch 100 checkpoint as it has the best recorded accuracy\n",
    "model_checkpoint_path = '/content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_100.pth'\n",
    "\n",
    "# Define the data directory (from Step 5)\n",
    "data_directory = DATA_DIR # Ensure DATA_DIR is defined from Step 5\n",
    "\n",
    "# Check if the evaluation script and model checkpoint exist\n",
    "if not os.path.exists(eval_script_path):\n",
    "    print(f\"‚ùå Evaluation script not found at: {eval_script_path}\")\n",
    "    print(f\"Please ensure the ViT-FishID repository was cloned correctly in Step 4 to {repo_dir}.\")\n",
    "elif not os.path.exists(model_checkpoint_path):\n",
    "     print(f\"‚ùå Model checkpoint not found at: {model_checkpoint_path}\")\n",
    "     print(\"Please ensure training completed successfully and the checkpoint exists.\")\n",
    "elif not os.path.exists(data_directory):\n",
    "     print(f\"‚ùå Data directory not found at: {data_directory}\")\n",
    "     print(\"Please ensure Step 5 was run correctly.\")\n",
    "else:\n",
    "    print(f\"‚úÖ Found evaluation script: {eval_script_path}\")\n",
    "    print(f\"‚úÖ Found model checkpoint: {model_checkpoint_path}\")\n",
    "    print(f\"‚úÖ Found data directory: {data_directory}\")\n",
    "\n",
    "    # --- FIX 1: Modify evaluate.py to correct the vit_model import statement ---\n",
    "    print(f\"\\nüîß Correcting import statement for ViTForFishClassification in {eval_script_name}...\")\n",
    "    try:\n",
    "        with fileinput.FileInput(eval_script_path, inplace=True) as file:\n",
    "            for line in file:\n",
    "                # Replace 'from vit_model import' with 'from model import'\n",
    "                # Do NOT print anything else here\n",
    "                print(line.replace('from vit_model import ViTForFishClassification', 'from model import ViTForFishClassification'), end='')\n",
    "        print(f\"‚úÖ Corrected import statement for ViTForFishClassification in {eval_script_name}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error modifying ViTForFishClassification import in {eval_script_name}: {e}\")\n",
    "        print(\"üö® Evaluation might still fail due to this import error.\")\n",
    "    # --- End of FIX 1 ---\n",
    "\n",
    "    # --- FIX 2: Modify evaluate.py to comment out the ema_teacher import ---\n",
    "    print(f\"\\nüîß Commenting out import statement for EMATeacher in {eval_script_name}...\")\n",
    "    try:\n",
    "        with fileinput.FileInput(eval_script_path, inplace=True) as file:\n",
    "            for line in file:\n",
    "                # Comment out 'from ema_teacher import EMATeacher'\n",
    "                # Do NOT print anything else here\n",
    "                if 'from ema_teacher import EMATeacher' in line:\n",
    "                     print(\"# \" + line, end='') # Add # to comment out the line\n",
    "                else:\n",
    "                    print(line, end='')\n",
    "        print(f\"‚úÖ Commented out import statement for EMATeacher in {eval_script_name}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error commenting out EMATeacher import in {eval_script_name}: {e}\")\n",
    "        print(\"üö® Evaluation might still fail due to this import error.\")\n",
    "    # --- End of FIX 2 ---\n",
    "\n",
    "    # --- FIX 3: Modify evaluate.py to correct the data_loader import statement ---\n",
    "    print(f\"\\nüîß Correcting import statement for create_fish_dataloaders in {eval_script_name}...\")\n",
    "    try:\n",
    "        with fileinput.FileInput(eval_script_path, inplace=True) as file:\n",
    "            for line in file:\n",
    "                # Replace 'from data_loader import' with 'from data import'\n",
    "                # Do NOT print anything else here\n",
    "                print(line.replace('from data_loader import create_fish_dataloaders', 'from data import create_fish_dataloaders'), end='')\n",
    "        print(f\"‚úÖ Corrected import statement for create_fish_dataloaders in {eval_script_name}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error modifying create_fish_dataloaders import in {eval_script_name}: {e}\")\n",
    "        print(\"üö® Evaluation might still fail due to this import error.\")\n",
    "    # --- End of FIX 3 ---\n",
    "\n",
    "\n",
    "    # Construct the evaluation command\n",
    "    # Use PYTHONPATH to help the script find local modules like model\n",
    "    # Use %cd before and after, but rely on PYTHONPATH for the import\n",
    "    eval_cmd = f\"PYTHONPATH={repo_dir} python {eval_script_name} --data_dir {data_directory} --model_path {model_checkpoint_path}\"\n",
    "\n",
    "\n",
    "    print(\"\\nüìã Evaluation Command:\")\n",
    "    # Print the command cleanly without the PYTHONPATH for readability, but it's included in the execution\n",
    "    print(f\"python {eval_script_name} --data_dir {data_directory} --model_path {model_checkpoint_path} (with PYTHONPATH={repo_dir})\")\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "    print(\"üöÄ Running evaluation...\")\n",
    "    # Change to the repository directory before executing\n",
    "    %cd {repo_dir}\n",
    "\n",
    "    # Execute the evaluation script with PYTHONPATH set\n",
    "    !{eval_cmd}\n",
    "\n",
    "    # Change back to original content directory (optional but good practice)\n",
    "    %cd /content\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"üéâ Evaluation complete!\")\n",
    "\n",
    "print(\"\\nüí° Check the output above for accuracy metrics on the test set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d9d05d",
   "metadata": {
    "id": "c7d9d05d"
   },
   "source": [
    "## üîç Step 12b: Diagnose `ModuleNotFoundError`\n",
    "\n",
    "This step checks the file structure and import statements to understand why `vit_model` is not being found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6d7a1c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ca6d7a1c",
    "outputId": "fc236a40-4bb0-4502-f8f5-aa6c01821099"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Diagnosing ModuleNotFoundError...\n",
      "Repo directory: /content/ViT-FishID\n",
      "\n",
      "üìÇ Files in repository root:\n",
      "total 368\n",
      "drwxr-xr-x 6 root root   4096 Aug 15 07:03 .\n",
      "drwxr-xr-x 1 root root   4096 Aug 15 06:58 ..\n",
      "-rw-r--r-- 1 root root  21217 Aug 15 06:58 data.py\n",
      "-rw-r--r-- 1 root root  11572 Aug 15 06:58 evaluate.py\n",
      "-rw-r--r-- 1 root root   3328 Aug 15 06:58 EXTENDED_TRAINING_SETUP.md\n",
      "drwxr-xr-x 2 root root   4096 Aug 15 06:58 fish_cutouts\n",
      "drwxr-xr-x 8 root root   4096 Aug 15 06:58 .git\n",
      "-rw-r--r-- 1 root root     66 Aug 15 06:58 .gitattributes\n",
      "-rw-r--r-- 1 root root    646 Aug 15 06:58 .gitignore\n",
      "-rw-r--r-- 1 root root   9495 Aug 15 06:58 model.py\n",
      "-rw-r--r-- 1 root root  16771 Aug 15 06:58 pipeline.py\n",
      "drwxr-xr-x 2 root root   4096 Aug 15 07:03 __pycache__\n",
      "-rw-r--r-- 1 root root  16566 Aug 15 06:58 README.md\n",
      "-rw-r--r-- 1 root root    202 Aug 15 06:58 requirements.txt\n",
      "-rw-r--r-- 1 root root   4265 Aug 15 06:58 resume_training.py\n",
      "-rw-r--r-- 1 root root   5134 Aug 15 06:58 species_mapping.txt\n",
      "-rw-r--r-- 1 root root  25498 Aug 15 07:03 trainer.py\n",
      "-rw-r--r-- 1 root root   4982 Aug 15 06:58 TRAINING_FIXES_APPLIED.md\n",
      "-rw-r--r-- 1 root root  15331 Aug 15 06:58 train.py\n",
      "-rw-r--r-- 1 root root   8818 Aug 15 06:58 utils.py\n",
      "-rw-r--r-- 1 root root 160971 Aug 15 06:58 ViT_FishID_Colab_Training.ipynb\n",
      "drwxr-xr-x 3 root root   4096 Aug 15 07:03 wandb\n",
      "\n",
      "üìÑ Content of evaluate.py (checking import):\n",
      "  Line 1: import torch\n",
      "  Line 2: import torch.nn as nn\n",
      "  Line 3: from torch.utils.data import DataLoader\n",
      "  Line 4: import numpy as np\n",
      "  Line 5: from sklearn.metrics import classification_report, confusion_matrix\n",
      "  Line 6: import matplotlib.pyplot as plt\n",
      "  Line 7: import seaborn as sns\n",
      "  Line 8: from typing import Dict, List, Tuple\n",
      "  Line 9: import os\n",
      "  Line 10: from tqdm import tqdm\n",
      "  Line 11: \n",
      "  Line 12: from vit_model import ViTForFishClassification\n",
      "  Line 12: from vit_model import ViTForFishClassification\n",
      "  Line 13: from ema_teacher import EMATeacher\n",
      "  Line 14: from data_loader import create_fish_dataloaders\n",
      "  Line 15: from utils import accuracy, load_checkpoint, get_device\n",
      "  Line 16: \n",
      "  Line 17: \n",
      "  Line 18: class ModelEvaluator:\n",
      "  Line 19: \"\"\"\n",
      "  Line 20: Comprehensive model evaluation for ViT-Fish classification.\n",
      "  Line 25: model: ViTForFishClassification, (contains class name)\n",
      "  Line 236: student_model: ViTForFishClassification, (contains class name)\n",
      "  Line 237: teacher_model: ViTForFishClassification, (contains class name)\n",
      "  Line 311: student_model = ViTForFishClassification(num_classes=num_classes) (contains class name)\n",
      "  Line 318: teacher_model = ViTForFishClassification(num_classes=num_classes) (contains class name)\n",
      "\n",
      "üìÑ Checking potential model file: model.py\n",
      "‚úÖ Found model.py. Checking for class definition...\n",
      "  Line 22: class ViTForFishClassification(nn.Module):\n",
      "\n",
      "üìÑ Checking alternative model file: vit_model.py\n",
      "‚ùì vit_model.py not found.\n",
      "\n",
      "Diagnosis steps complete. Please review the output.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"üîç Diagnosing ModuleNotFoundError...\")\n",
    "repo_dir = '/content/ViT-FishID'\n",
    "eval_script_path = os.path.join(repo_dir, 'evaluate.py')\n",
    "model_file_guess = os.path.join(repo_dir, 'model.py') # Common name for model file\n",
    "vit_model_file_guess = os.path.join(repo_dir, 'vit_model.py') # Guessed name based on import\n",
    "\n",
    "print(f\"Repo directory: {repo_dir}\")\n",
    "\n",
    "print(\"\\nüìÇ Files in repository root:\")\n",
    "# List files in the repository root\n",
    "if os.path.exists(repo_dir):\n",
    "    !ls -la {repo_dir}\n",
    "else:\n",
    "    print(f\"‚ùå Repository directory not found: {repo_dir}\")\n",
    "\n",
    "\n",
    "print(f\"\\nüìÑ Content of {os.path.basename(eval_script_path)} (checking import):\")\n",
    "# Read and print the content of evaluate.py\n",
    "if os.path.exists(eval_script_path):\n",
    "    try:\n",
    "        with open(eval_script_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for i, line in enumerate(lines):\n",
    "                if 'import vit_model' in line or 'from vit_model' in line:\n",
    "                    print(f\"  Line {i+1}: {line.strip()}\")\n",
    "                elif 'ViTForFishClassification' in line:\n",
    "                     print(f\"  Line {i+1}: {line.strip()} (contains class name)\")\n",
    "                if i < 20: # Print first 20 lines for context\n",
    "                     print(f\"  Line {i+1}: {line.strip()}\")\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Could not read {eval_script_path}: {e}\")\n",
    "else:\n",
    "    print(f\"‚ùå {eval_script_path} not found.\")\n",
    "\n",
    "\n",
    "print(f\"\\nüìÑ Checking potential model file: {os.path.basename(model_file_guess)}\")\n",
    "# Check if model.py exists and print relevant lines\n",
    "if os.path.exists(model_file_guess):\n",
    "    try:\n",
    "        with open(model_file_guess, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            print(f\"‚úÖ Found {os.path.basename(model_file_guess)}. Checking for class definition...\")\n",
    "            found_class = False\n",
    "            for i, line in enumerate(lines):\n",
    "                 if 'class ViTForFishClassification' in line:\n",
    "                      print(f\"  Line {i+1}: {line.strip()}\")\n",
    "                      found_class = True\n",
    "                      break # Found the class, stop searching\n",
    "\n",
    "            if not found_class:\n",
    "                 print(f\"‚ö†Ô∏è 'ViTForFishClassification' class definition not found in {os.path.basename(model_file_guess)}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Could not read {model_file_guess}: {e}\")\n",
    "else:\n",
    "    print(f\"‚ùì {os.path.basename(model_file_guess)} not found. Checking alternative name...\")\n",
    "\n",
    "print(f\"\\nüìÑ Checking alternative model file: {os.path.basename(vit_model_file_guess)}\")\n",
    "# Check if vit_model.py exists and print relevant lines\n",
    "if os.path.exists(vit_model_file_guess):\n",
    "    try:\n",
    "        with open(vit_model_file_guess, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            print(f\"‚úÖ Found {os.path.basename(vit_model_file_guess)}. Checking for class definition...\")\n",
    "            found_class = False\n",
    "            for i, line in enumerate(lines):\n",
    "                 if 'class ViTForFishClassification' in line:\n",
    "                      print(f\"  Line {i+1}: {line.strip()}\")\n",
    "                      found_class = True\n",
    "                      break # Found the class, stop searching\n",
    "\n",
    "            if not found_class:\n",
    "                 print(f\"‚ö†Ô∏è 'ViTForFishClassification' class definition not found in {os.path.basename(vit_model_file_guess)}\")\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Could not read {vit_model_file_guess}: {e}\")\n",
    "else:\n",
    "    print(f\"‚ùì {os.path.basename(vit_model_file_guess)} not found.\")\n",
    "\n",
    "print(\"\\nDiagnosis steps complete. Please review the output.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8305def7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8305def7",
    "outputId": "34d5ab6a-43c0-476e-b6af-ca604c1892a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the contents of the MAE checkpoint directory:\n",
      "‚ùå Directory not found: /content/drive/MyDrive/mae_checkpoints\n",
      "Please ensure the directory exists in your Google Drive.\n",
      "\n",
      "--- Check complete ---\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"Checking the contents of the MAE checkpoint directory:\")\n",
    "mae_checkpoint_dir = '/content/drive/MyDrive/mae_checkpoints'\n",
    "\n",
    "if os.path.exists(mae_checkpoint_dir):\n",
    "    print(f\"‚úÖ Directory found: {mae_checkpoint_dir}\")\n",
    "    print(\"\\nFiles in the directory:\")\n",
    "    try:\n",
    "        # List all items in the directory\n",
    "        items = os.listdir(mae_checkpoint_dir)\n",
    "        if items:\n",
    "            for item in items:\n",
    "                item_path = os.path.join(mae_checkpoint_dir, item)\n",
    "                if os.path.isfile(item_path):\n",
    "                    file_size = os.path.getsize(item_path) / (1024**2) # Size in MB\n",
    "                    print(f\"  - {item} ({file_size:.2f} MB)\")\n",
    "                else:\n",
    "                    print(f\"  - {item} (Directory)\")\n",
    "        else:\n",
    "            print(\"  (Directory is empty)\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error listing directory contents: {e}\")\n",
    "else:\n",
    "    print(f\"‚ùå Directory not found: {mae_checkpoint_dir}\")\n",
    "    print(\"Please ensure the directory exists in your Google Drive.\")\n",
    "\n",
    "print(\"\\n--- Check complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "jF_Ontj1eb3Y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jF_Ontj1eb3Y",
    "outputId": "9d948a76-ddc8-4e42-ea13-c70111d00980"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive not mounted, so nothing to flush and unmount.\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.flush_and_unmount('/content/drive')\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cf19ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Fixed Evaluation Script\n",
    "print(\"üß™ Testing the fixed evaluation script...\")\n",
    "\n",
    "# Check if evaluate.py exists and has correct imports\n",
    "import os\n",
    "eval_script_path = '/content/ViT-FishID/evaluate.py'\n",
    "\n",
    "if os.path.exists(eval_script_path):\n",
    "    print(\"‚úÖ Found evaluate.py\")\n",
    "    \n",
    "    # Test the imports\n",
    "    try:\n",
    "        import sys\n",
    "        sys.path.append('/content/ViT-FishID')\n",
    "        \n",
    "        # Test import of the fixed evaluation module\n",
    "        from evaluate import ModelEvaluator\n",
    "        print(\"‚úÖ Successfully imported ModelEvaluator\")\n",
    "        \n",
    "        # Test import of data loading function\n",
    "        from data import create_dataloaders\n",
    "        print(\"‚úÖ Successfully imported create_dataloaders\")\n",
    "        \n",
    "        # Test model import\n",
    "        from model import ViTForFishClassification\n",
    "        print(\"‚úÖ Successfully imported ViTForFishClassification\")\n",
    "        \n",
    "        print(\"\\nüéâ All imports work correctly!\")\n",
    "        print(\"üìã The evaluation script is now ready to use with:\")\n",
    "        print(\"   python evaluate.py --data_dir /path/to/data --model_path /path/to/checkpoint\")\n",
    "        \n",
    "    except ImportError as e:\n",
    "        print(f\"‚ùå Import error: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå evaluate.py not found\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üîß EVALUATION SCRIPT FIXES APPLIED:\")\n",
    "print(\"=\"*50)\n",
    "print(\"1. ‚úÖ Fixed import: create_fish_dataloaders ‚Üí create_dataloaders\")\n",
    "print(\"2. ‚úÖ Fixed import: vit_model ‚Üí model\") \n",
    "print(\"3. ‚úÖ Fixed import: data_loader ‚Üí data\")\n",
    "print(\"4. ‚úÖ Added proper argument parsing\")\n",
    "print(\"5. ‚úÖ Added Top-5 accuracy calculation\")\n",
    "print(\"6. ‚úÖ Simplified evaluation logic (removed teacher/student comparison)\")\n",
    "print(\"7. ‚úÖ Added comprehensive result reporting\")\n",
    "print(\"\\nüöÄ Ready for evaluation on your trained model!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3171f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç FIXED EVALUATION EXAMPLE\n",
    "print(\"=\"*60)\n",
    "print(\"üéØ EVALUATION SCRIPT USAGE EXAMPLE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Example paths (update these to your actual paths)\n",
    "example_model_path = \"/content/drive/MyDrive/ViT-FishID/pretrained_checkpoints/model_best.pth\"\n",
    "example_data_path = \"/content/fish_cutouts\"\n",
    "\n",
    "print(f\"üìã To evaluate your trained model, run:\")\n",
    "print()\n",
    "print(f\"!cd /content/ViT-FishID && python evaluate.py \\\\\")\n",
    "print(f\"    --data_dir {example_data_path} \\\\\")\n",
    "print(f\"    --model_path {example_model_path} \\\\\")\n",
    "print(f\"    --batch_size 32 \\\\\")\n",
    "print(f\"    --image_size 224\")\n",
    "\n",
    "print(\"\\nüìä This will output:\")\n",
    "print(\"  üéØ Top-1 Accuracy (main metric)\")\n",
    "print(\"  üìà Top-5 Accuracy (secondary metric)\")\n",
    "print(\"  üìã Per-class precision, recall, F1-scores\")\n",
    "print(\"  üîç Validation set comparison\")\n",
    "print(\"  üìä Confusion matrix and class accuracy plots\")\n",
    "\n",
    "print(\"\\nüí° Key improvements in the fixed script:\")\n",
    "print(\"  ‚úÖ Correct function imports from your codebase\")\n",
    "print(\"  ‚úÖ Proper argument parsing for flexible usage\")\n",
    "print(\"  ‚úÖ Both Top-1 and Top-5 accuracy calculation\")\n",
    "print(\"  ‚úÖ Comprehensive evaluation metrics\")\n",
    "print(\"  ‚úÖ Handles different checkpoint formats\")\n",
    "print(\"  ‚úÖ Clear, informative output formatting\")\n",
    "\n",
    "print(f\"\\nüéâ Your evaluation script is now fully compatible!\")\n",
    "print(f\"üöÄ Ready to evaluate the ViT-FishID model performance!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a610089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß Replace evaluate.py with Fixed Version\n",
    "import os\n",
    "\n",
    "print(\"üîÑ Replacing evaluate.py with the fixed version...\")\n",
    "\n",
    "# Ensure we're in the right directory\n",
    "%cd /content/ViT-FishID\n",
    "\n",
    "# Create the corrected evaluate.py content\n",
    "evaluate_py_content = '''import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, List, Tuple\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model import ViTForFishClassification\n",
    "# from trainer import EMATeacher  # Not needed for evaluation\n",
    "from data import create_dataloaders\n",
    "from utils import accuracy, load_checkpoint, get_device\n",
    "\n",
    "\n",
    "class ModelEvaluator:\n",
    "    \"\"\"\n",
    "    Comprehensive model evaluation for ViT-Fish classification.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model: ViTForFishClassification,\n",
    "        class_names: List[str],\n",
    "        device: str = 'cuda'\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize evaluator.\n",
    "        \n",
    "        Args:\n",
    "            model: Trained ViT model\n",
    "            class_names: List of class names\n",
    "            device: Device to run evaluation on\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.class_names = class_names\n",
    "        self.device = device\n",
    "        self.model.eval()\n",
    "    \n",
    "    def evaluate_dataset(\n",
    "        self, \n",
    "        data_loader: DataLoader,\n",
    "        save_dir: str = './evaluation_results'\n",
    "    ) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Comprehensive evaluation on dataset.\n",
    "        \n",
    "        Args:\n",
    "            data_loader: DataLoader for evaluation\n",
    "            save_dir: Directory to save results\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary of evaluation metrics\n",
    "        \"\"\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        all_predictions = []\n",
    "        all_targets = []\n",
    "        all_probabilities = []\n",
    "        \n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        top5_correct = 0  # Add top-5 tracking\n",
    "        \n",
    "        print(\"Evaluating model...\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, targets in tqdm(data_loader, desc='Evaluating'):\n",
    "                images = images.to(self.device)\n",
    "                targets = targets.to(self.device)\n",
    "                \n",
    "                # Forward pass\n",
    "                logits = self.model(images)\n",
    "                probabilities = torch.softmax(logits, dim=1)\n",
    "                predictions = torch.argmax(logits, dim=1)\n",
    "                \n",
    "                # Calculate top-5 accuracy\n",
    "                _, top5_pred = logits.topk(5, 1, True, True)\n",
    "                top5_correct += (targets.view(-1, 1).expand_as(top5_pred) == top5_pred).sum().item()\n",
    "                \n",
    "                # Collect results\n",
    "                all_predictions.extend(predictions.cpu().numpy())\n",
    "                all_targets.extend(targets.cpu().numpy())\n",
    "                all_probabilities.extend(probabilities.cpu().numpy())\n",
    "                \n",
    "                # Update accuracy\n",
    "                total_correct += (predictions == targets).sum().item()\n",
    "                total_samples += targets.size(0)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy_score = total_correct / total_samples * 100\n",
    "        top5_accuracy_score = top5_correct / total_samples * 100\n",
    "        \n",
    "        # Generate classification report\n",
    "        class_report = classification_report(\n",
    "            all_targets, \n",
    "            all_predictions, \n",
    "            target_names=self.class_names,\n",
    "            output_dict=True\n",
    "        )\n",
    "        \n",
    "        # Generate confusion matrix\n",
    "        cm = confusion_matrix(all_targets, all_predictions)\n",
    "        \n",
    "        # Save results\n",
    "        self._save_classification_report(class_report, save_dir)\n",
    "        self._plot_confusion_matrix(cm, save_dir)\n",
    "        self._plot_class_accuracies(class_report, save_dir)\n",
    "        \n",
    "        # Calculate per-class metrics\n",
    "        results = {\n",
    "            'accuracy': accuracy_score,  # Changed from 'overall_accuracy' to match main function\n",
    "            'top5_accuracy': top5_accuracy_score,  # Add top-5 accuracy\n",
    "            'macro_avg_precision': class_report['macro avg']['precision'] * 100,\n",
    "            'macro_avg_recall': class_report['macro avg']['recall'] * 100,\n",
    "            'macro_avg_f1': class_report['macro avg']['f1-score'] * 100,\n",
    "            'weighted_avg_precision': class_report['weighted avg']['precision'] * 100,\n",
    "            'weighted_avg_recall': class_report['weighted avg']['recall'] * 100,\n",
    "            'weighted_avg_f1': class_report['weighted avg']['f1-score'] * 100,\n",
    "            'classification_report': class_report  # Add classification report to results\n",
    "        }\n",
    "        \n",
    "        print(f\"\\\\nEvaluation Results:\")\n",
    "        print(f\"Top-1 Accuracy: {accuracy_score:.2f}%\")\n",
    "        print(f\"Top-5 Accuracy: {top5_accuracy_score:.2f}%\")\n",
    "        print(f\"Macro Avg F1-Score: {results['macro_avg_f1']:.2f}%\")\n",
    "        print(f\"Weighted Avg F1-Score: {results['weighted_avg_f1']:.2f}%\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _save_classification_report(self, report_dict: Dict, save_dir: str):\n",
    "        \"\"\"Save classification report to file.\"\"\"\n",
    "        import json\n",
    "        report_path = os.path.join(save_dir, 'classification_report.json')\n",
    "        with open(report_path, 'w') as f:\n",
    "            json.dump(report_dict, f, indent=2)\n",
    "        print(f\"Classification report saved to: {report_path}\")\n",
    "    \n",
    "    def _plot_confusion_matrix(self, cm: np.ndarray, save_dir: str):\n",
    "        \"\"\"Plot and save confusion matrix.\"\"\"\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        sns.heatmap(\n",
    "            cm, \n",
    "            annot=True, \n",
    "            fmt='d', \n",
    "            cmap='Blues',\n",
    "            xticklabels=self.class_names,\n",
    "            yticklabels=self.class_names\n",
    "        )\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.yticks(rotation=0)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        cm_path = os.path.join(save_dir, 'confusion_matrix.png')\n",
    "        plt.savefig(cm_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"Confusion matrix saved to: {cm_path}\")\n",
    "    \n",
    "    def _plot_class_accuracies(self, report_dict: Dict, save_dir: str):\n",
    "        \"\"\"Plot per-class accuracies.\"\"\"\n",
    "        class_names = []\n",
    "        accuracies = []\n",
    "        \n",
    "        for class_name in self.class_names:\n",
    "            if class_name in report_dict:\n",
    "                class_names.append(class_name)\n",
    "                accuracies.append(report_dict[class_name]['f1-score'] * 100)\n",
    "        \n",
    "        plt.figure(figsize=(15, 8))\n",
    "        bars = plt.bar(range(len(class_names)), accuracies)\n",
    "        plt.xlabel('Fish Species')\n",
    "        plt.ylabel('F1-Score (%)')\n",
    "        plt.title('Per-Class F1-Scores')\n",
    "        plt.xticks(range(len(class_names)), class_names, rotation=45, ha='right')\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, acc in zip(bars, accuracies):\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "                    f'{acc:.1f}%', ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        acc_path = os.path.join(save_dir, 'class_accuracies.png')\n",
    "        plt.savefig(acc_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"Class accuracies plot saved to: {acc_path}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main evaluation script.\"\"\"\n",
    "    import argparse\n",
    "    \n",
    "    # Parse arguments\n",
    "    parser = argparse.ArgumentParser(description='Evaluate ViT-FishID model')\n",
    "    parser.add_argument('--data_dir', type=str, required=True,\n",
    "                        help='Path to fish dataset directory')\n",
    "    parser.add_argument('--model_path', type=str, required=True,\n",
    "                        help='Path to model checkpoint')\n",
    "    parser.add_argument('--batch_size', type=int, default=32,\n",
    "                        help='Batch size for evaluation')\n",
    "    parser.add_argument('--image_size', type=int, default=224,\n",
    "                        help='Input image size')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    print(f\"üîç Evaluating model: {args.model_path}\")\n",
    "    print(f\"üìä Data directory: {args.data_dir}\")\n",
    "    \n",
    "    device = get_device()\n",
    "    print(f\"üñ•Ô∏è  Using device: {device}\")\n",
    "    \n",
    "    # Load data - use test_loader for evaluation\n",
    "    train_loader, val_loader, test_loader, class_names = create_dataloaders(\n",
    "        data_dir=args.data_dir,\n",
    "        batch_size=args.batch_size,\n",
    "        image_size=args.image_size\n",
    "    )\n",
    "    \n",
    "    print(f\"üìä Found {len(class_names)} classes: {class_names[:5]}...\" if len(class_names) > 5 else f\"üìä Found {len(class_names)} classes: {class_names}\")\n",
    "    \n",
    "    # Create model\n",
    "    num_classes = len(class_names)\n",
    "    model = ViTForFishClassification(\n",
    "        num_classes=num_classes,\n",
    "        model_name='vit_small_patch16_224',  # Adjust based on your training config\n",
    "        pretrained=False,\n",
    "        dropout_rate=0.1\n",
    "    ).to(device)\n",
    "    \n",
    "    # Load checkpoint\n",
    "    if os.path.exists(args.model_path):\n",
    "        print(f\"üì• Loading checkpoint: {args.model_path}\")\n",
    "        checkpoint = torch.load(args.model_path, map_location=device)\n",
    "        \n",
    "        # Handle different checkpoint formats\n",
    "        if 'student_state_dict' in checkpoint:\n",
    "            model.load_state_dict(checkpoint['student_state_dict'])\n",
    "            print(f\"‚úÖ Loaded student model weights\")\n",
    "            if 'best_accuracy' in checkpoint:\n",
    "                print(f\"üìä Training best accuracy: {checkpoint['best_accuracy']:.2f}%\")\n",
    "        elif 'model_state_dict' in checkpoint:\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            print(f\"‚úÖ Loaded model weights\")\n",
    "        else:\n",
    "            model.load_state_dict(checkpoint)\n",
    "            print(f\"‚úÖ Loaded model weights\")\n",
    "    else:\n",
    "        print(f\"‚ùå Checkpoint not found: {args.model_path}\")\n",
    "        return\n",
    "    \n",
    "    # Create evaluator\n",
    "    evaluator = ModelEvaluator(model, class_names, device)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    print(f\"\\\\nüß™ Evaluating on test set...\")\n",
    "    test_results = evaluator.evaluate_dataset(test_loader, \"test\")\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\\\nüìä TEST RESULTS:\")\n",
    "    print(f\"üéØ Accuracy: {test_results['accuracy']:.2f}%\")\n",
    "    print(f\"üìà Top-5 Accuracy: {test_results.get('top5_accuracy', 'N/A')}\")\n",
    "    \n",
    "    # Print per-class results\n",
    "    if 'classification_report' in test_results:\n",
    "        print(f\"\\\\nüìã Per-class Performance:\")\n",
    "        class_report = test_results['classification_report']\n",
    "        for class_name in class_names[:10]:  # Show first 10 classes\n",
    "            if class_name in class_report:\n",
    "                precision = class_report[class_name]['precision']\n",
    "                recall = class_report[class_name]['recall']\n",
    "                f1 = class_report[class_name]['f1-score']\n",
    "                print(f\"  {class_name}: P={precision:.3f}, R={recall:.3f}, F1={f1:.3f}\")\n",
    "        \n",
    "        if len(class_names) > 10:\n",
    "            print(f\"  ... and {len(class_names) - 10} more classes\")\n",
    "    \n",
    "    # Also evaluate on validation set for comparison\n",
    "    print(f\"\\\\nüîç Evaluating on validation set...\")\n",
    "    val_results = evaluator.evaluate_dataset(val_loader, \"validation\")\n",
    "    print(f\"üìä VALIDATION RESULTS:\")\n",
    "    print(f\"üéØ Accuracy: {val_results['accuracy']:.2f}%\")\n",
    "    \n",
    "    print(f\"\\\\n‚úÖ Evaluation completed!\")\n",
    "    print(f\"üìä Final Test Accuracy: {test_results['accuracy']:.2f}%\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "'''\n",
    "\n",
    "# Write the fixed evaluate.py file\n",
    "with open('evaluate.py', 'w') as f:\n",
    "    f.write(evaluate_py_content)\n",
    "\n",
    "print(\"‚úÖ Fixed evaluate.py has been created!\")\n",
    "print(\"üîß Key fixes applied:\")\n",
    "print(\"  ‚úÖ Corrected all import statements\")\n",
    "print(\"  ‚úÖ Added proper argument parsing\") \n",
    "print(\"  ‚úÖ Added Top-5 accuracy calculation\")\n",
    "print(\"  ‚úÖ Fixed function calls and return values\")\n",
    "print(\"  ‚úÖ Simplified evaluation logic\")\n",
    "\n",
    "# Verify the file was created\n",
    "if os.path.exists('evaluate.py'):\n",
    "    file_size = os.path.getsize('evaluate.py')\n",
    "    print(f\"‚úÖ File created successfully ({file_size} bytes)\")\n",
    "    print(\"üöÄ Ready to run evaluation!\")\n",
    "else:\n",
    "    print(\"‚ùå File creation failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f3c49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß Fix Class Mismatch Error in evaluate.py\n",
    "import os\n",
    "\n",
    "print(\"üîÑ Fixing class mismatch error in evaluate.py...\")\n",
    "\n",
    "# Read the current evaluate.py file\n",
    "with open('/content/ViT-FishID/evaluate.py', 'r') as f:\n",
    "    content = f.read()\n",
    "\n",
    "# Find and replace the classification_report generation to handle class mismatch\n",
    "old_classification_report = \"\"\"        # Generate classification report\n",
    "        class_report = classification_report(\n",
    "            all_targets, \n",
    "            all_predictions, \n",
    "            target_names=self.class_names,\n",
    "            output_dict=True\n",
    "        )\"\"\"\n",
    "\n",
    "new_classification_report = \"\"\"        # Generate classification report - handle class mismatch\n",
    "        # Get unique classes that actually appear in the test data\n",
    "        unique_classes = sorted(list(set(all_targets + all_predictions)))\n",
    "        present_class_names = [self.class_names[i] for i in unique_classes if i < len(self.class_names)]\n",
    "        \n",
    "        # Generate classification report with only present classes\n",
    "        class_report = classification_report(\n",
    "            all_targets, \n",
    "            all_predictions,\n",
    "            labels=unique_classes,  # Specify which labels to include\n",
    "            target_names=present_class_names,  # Only names for present classes\n",
    "            output_dict=True,\n",
    "            zero_division=0  # Handle division by zero for missing classes\n",
    "        )\"\"\"\n",
    "\n",
    "# Replace in the content\n",
    "if old_classification_report in content:\n",
    "    content = content.replace(old_classification_report, new_classification_report)\n",
    "    print(\"‚úÖ Fixed classification_report generation\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Could not find exact match for classification_report. Applying alternative fix...\")\n",
    "    # Alternative fix - replace the specific line\n",
    "    content = content.replace(\n",
    "        'class_report = classification_report(',\n",
    "        '''# Get unique classes that actually appear in the test data\n",
    "        unique_classes = sorted(list(set(all_targets + all_predictions)))\n",
    "        present_class_names = [self.class_names[i] for i in unique_classes if i < len(self.class_names)]\n",
    "        \n",
    "        class_report = classification_report('''\n",
    "    )\n",
    "    content = content.replace(\n",
    "        'target_names=self.class_names,',\n",
    "        'labels=unique_classes,\\n            target_names=present_class_names,'\n",
    "    )\n",
    "    content = content.replace(\n",
    "        'output_dict=True',\n",
    "        'output_dict=True,\\n            zero_division=0'\n",
    "    )\n",
    "\n",
    "# Also fix the confusion matrix to handle missing classes\n",
    "old_cm = \"cm = confusion_matrix(all_targets, all_predictions)\"\n",
    "new_cm = \"\"\"cm = confusion_matrix(all_targets, all_predictions, labels=unique_classes)\"\"\"\n",
    "\n",
    "if old_cm in content:\n",
    "    content = content.replace(old_cm, new_cm)\n",
    "    print(\"‚úÖ Fixed confusion_matrix generation\")\n",
    "\n",
    "# Fix the plotting functions to handle subset of classes\n",
    "old_heatmap = \"\"\"sns.heatmap(\n",
    "            cm, \n",
    "            annot=True, \n",
    "            fmt='d', \n",
    "            cmap='Blues',\n",
    "            xticklabels=self.class_names,\n",
    "            yticklabels=self.class_names\n",
    "        )\"\"\"\n",
    "\n",
    "new_heatmap = \"\"\"sns.heatmap(\n",
    "            cm, \n",
    "            annot=True, \n",
    "            fmt='d', \n",
    "            cmap='Blues',\n",
    "            xticklabels=present_class_names,  # Use only present classes\n",
    "            yticklabels=present_class_names   # Use only present classes\n",
    "        )\"\"\"\n",
    "\n",
    "if old_heatmap in content:\n",
    "    content = content.replace(old_heatmap, new_heatmap)\n",
    "    print(\"‚úÖ Fixed confusion matrix heatmap\")\n",
    "\n",
    "# Fix class accuracies plot\n",
    "old_class_plot = \"\"\"for class_name in self.class_names:\n",
    "            if class_name in report_dict:\"\"\"\n",
    "\n",
    "new_class_plot = \"\"\"for class_name in present_class_names:  # Use only present classes\n",
    "            if class_name in report_dict:\"\"\"\n",
    "\n",
    "if old_class_plot in content:\n",
    "    content = content.replace(old_class_plot, new_class_plot)\n",
    "    print(\"‚úÖ Fixed class accuracies plot\")\n",
    "\n",
    "# Write the fixed content back to the file\n",
    "with open('/content/ViT-FishID/evaluate.py', 'w') as f:\n",
    "    f.write(content)\n",
    "\n",
    "print(\"‚úÖ Fixed evaluate.py to handle class mismatches!\")\n",
    "print(\"üîß Applied fixes:\")\n",
    "print(\"  ‚úÖ Only use classes that appear in test data\")\n",
    "print(\"  ‚úÖ Handle zero-division for missing classes\") \n",
    "print(\"  ‚úÖ Fix confusion matrix dimensions\")\n",
    "print(\"  ‚úÖ Fix plotting functions for subset of classes\")\n",
    "print(\"\\nüöÄ Try running evaluation again!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad4f1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üõ°Ô∏è Alternative Robust Evaluation Function (Backup)\n",
    "# If the fixed evaluate.py still has issues, run this cell for a simple evaluation\n",
    "\n",
    "def simple_evaluate_model(model_path, data_dir, batch_size=32, image_size=224):\n",
    "    \"\"\"Simple, robust model evaluation that handles class mismatches.\"\"\"\n",
    "    \n",
    "    import torch\n",
    "    import numpy as np\n",
    "    from tqdm import tqdm\n",
    "    from sklearn.metrics import accuracy_score, classification_report\n",
    "    \n",
    "    # Import your modules\n",
    "    import sys\n",
    "    sys.path.append('/content/ViT-FishID')\n",
    "    from model import ViTForFishClassification\n",
    "    from data import create_dataloaders\n",
    "    from utils import get_device\n",
    "    \n",
    "    print(f\"üîç Simple Evaluation\")\n",
    "    print(f\"üìä Model: {model_path}\")\n",
    "    print(f\"üìÅ Data: {data_dir}\")\n",
    "    \n",
    "    device = get_device()\n",
    "    print(f\"üñ•Ô∏è  Device: {device}\")\n",
    "    \n",
    "    # Load data\n",
    "    try:\n",
    "        train_loader, val_loader, test_loader, class_names = create_dataloaders(\n",
    "            data_dir=data_dir,\n",
    "            batch_size=batch_size,\n",
    "            image_size=image_size\n",
    "        )\n",
    "        print(f\"‚úÖ Loaded data: {len(class_names)} total classes\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Data loading error: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Create and load model\n",
    "    try:\n",
    "        num_classes = len(class_names)\n",
    "        model = ViTForFishClassification(\n",
    "            num_classes=num_classes,\n",
    "            model_name='vit_small_patch16_224',\n",
    "            pretrained=False,\n",
    "            dropout_rate=0.1\n",
    "        ).to(device)\n",
    "        \n",
    "        # Load checkpoint\n",
    "        checkpoint = torch.load(model_path, map_location=device)\n",
    "        if 'student_state_dict' in checkpoint:\n",
    "            model.load_state_dict(checkpoint['student_state_dict'])\n",
    "            print(f\"‚úÖ Loaded student model weights\")\n",
    "        elif 'model_state_dict' in checkpoint:\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            print(f\"‚úÖ Loaded model weights\")\n",
    "        else:\n",
    "            model.load_state_dict(checkpoint)\n",
    "            print(f\"‚úÖ Loaded model weights\")\n",
    "            \n",
    "        model.eval()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Model loading error: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    print(f\"\\\\nüß™ Evaluating on test set...\")\n",
    "    \n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(test_loader, desc='Evaluating'):\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    \n",
    "    # Convert to numpy\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_targets = np.array(all_targets)\n",
    "    all_probs = np.array(all_probs)\n",
    "    \n",
    "    # Calculate Top-1 accuracy\n",
    "    top1_acc = accuracy_score(all_targets, all_preds) * 100\n",
    "    \n",
    "    # Calculate Top-5 accuracy\n",
    "    top5_preds = np.argsort(all_probs, axis=1)[:, -5:]  # Top 5 predictions\n",
    "    top5_correct = 0\n",
    "    for i, target in enumerate(all_targets):\n",
    "        if target in top5_preds[i]:\n",
    "            top5_correct += 1\n",
    "    top5_acc = (top5_correct / len(all_targets)) * 100\n",
    "    \n",
    "    # Get unique classes in test set\n",
    "    unique_classes = sorted(list(set(all_targets)))\n",
    "    present_class_names = [class_names[i] for i in unique_classes]\n",
    "    \n",
    "    print(f\"\\\\nüìä EVALUATION RESULTS:\")\n",
    "    print(f\"üéØ Top-1 Accuracy: {top1_acc:.2f}%\")\n",
    "    print(f\"üìà Top-5 Accuracy: {top5_acc:.2f}%\")\n",
    "    print(f\"üìã Classes in test set: {len(unique_classes)}/{len(class_names)}\")\n",
    "    \n",
    "    # Safe classification report\n",
    "    try:\n",
    "        report = classification_report(\n",
    "            all_targets, \n",
    "            all_preds,\n",
    "            labels=unique_classes,\n",
    "            target_names=present_class_names,\n",
    "            output_dict=False,  # Get string format\n",
    "            zero_division=0\n",
    "        )\n",
    "        print(f\"\\\\nüìã Per-Class Results:\")\n",
    "        print(report)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not generate detailed report: {e}\")\n",
    "    \n",
    "    # Show some class-wise accuracies\n",
    "    print(f\"\\\\nüîç Sample Class Performance:\")\n",
    "    for i, class_idx in enumerate(unique_classes[:10]):  # Show first 10\n",
    "        class_mask = all_targets == class_idx\n",
    "        if class_mask.sum() > 0:\n",
    "            class_acc = (all_preds[class_mask] == class_idx).mean() * 100\n",
    "            print(f\"  {class_names[class_idx]}: {class_acc:.1f}% ({class_mask.sum()} samples)\")\n",
    "    \n",
    "    if len(unique_classes) > 10:\n",
    "        print(f\"  ... and {len(unique_classes) - 10} more classes\")\n",
    "    \n",
    "    return {\n",
    "        'top1_accuracy': top1_acc,\n",
    "        'top5_accuracy': top5_acc,\n",
    "        'num_classes_tested': len(unique_classes),\n",
    "        'total_classes': len(class_names)\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Robust evaluation function defined!\")\n",
    "print(\"üìã If the fixed evaluate.py still has issues, run:\")\n",
    "print(\"   results = simple_evaluate_model(\")\n",
    "print(\"       '/content/drive/MyDrive/ViT-FishID/pretrained_checkpoints/model_best.pth',\")  \n",
    "print(\"       '/content/fish_cutouts')\")\n",
    "print(\"üõ°Ô∏è This function handles class mismatches gracefully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35563f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß Fix present_class_names Scope Error\n",
    "import os\n",
    "\n",
    "print(\"üîÑ Fixing present_class_names scope error...\")\n",
    "\n",
    "# Read the current evaluate.py file\n",
    "with open('/content/ViT-FishID/evaluate.py', 'r') as f:\n",
    "    content = f.read()\n",
    "\n",
    "print(\"üìù Applying fixes...\")\n",
    "\n",
    "# Fix 1: Update the evaluate_dataset method to pass present_class_names to plotting functions\n",
    "old_save_results = \"\"\"        # Save results\n",
    "        self._save_classification_report(class_report, save_dir)\n",
    "        self._plot_confusion_matrix(cm, save_dir)\n",
    "        self._plot_class_accuracies(class_report, save_dir)\"\"\"\n",
    "\n",
    "new_save_results = \"\"\"        # Save results\n",
    "        self._save_classification_report(class_report, save_dir)\n",
    "        self._plot_confusion_matrix(cm, save_dir, present_class_names)\n",
    "        self._plot_class_accuracies(class_report, save_dir, present_class_names)\"\"\"\n",
    "\n",
    "if old_save_results in content:\n",
    "    content = content.replace(old_save_results, new_save_results)\n",
    "    print(\"‚úÖ Fixed plotting function calls\")\n",
    "\n",
    "# Fix 2: Update _plot_confusion_matrix method signature\n",
    "old_plot_cm_def = \"def _plot_confusion_matrix(self, cm: np.ndarray, save_dir: str):\"\n",
    "new_plot_cm_def = \"def _plot_confusion_matrix(self, cm: np.ndarray, save_dir: str, class_names_subset: List[str]):\"\n",
    "\n",
    "if old_plot_cm_def in content:\n",
    "    content = content.replace(old_plot_cm_def, new_plot_cm_def)\n",
    "    print(\"‚úÖ Fixed _plot_confusion_matrix signature\")\n",
    "\n",
    "# Fix 3: Update heatmap call in _plot_confusion_matrix\n",
    "old_heatmap = \"\"\"xticklabels=present_class_names,  # Use only present classes\n",
    "            yticklabels=present_class_names   # Use only present classes\"\"\"\n",
    "\n",
    "new_heatmap = \"\"\"xticklabels=class_names_subset,  # Use only present classes\n",
    "            yticklabels=class_names_subset   # Use only present classes\"\"\"\n",
    "\n",
    "if old_heatmap in content:\n",
    "    content = content.replace(old_heatmap, new_heatmap)\n",
    "    print(\"‚úÖ Fixed heatmap class names\")\n",
    "\n",
    "# Fix 4: Update _plot_class_accuracies method signature\n",
    "old_plot_acc_def = \"def _plot_class_accuracies(self, report_dict: Dict, save_dir: str):\"\n",
    "new_plot_acc_def = \"def _plot_class_accuracies(self, report_dict: Dict, save_dir: str, class_names_subset: List[str]):\"\n",
    "\n",
    "if old_plot_acc_def in content:\n",
    "    content = content.replace(old_plot_acc_def, new_plot_acc_def)\n",
    "    print(\"‚úÖ Fixed _plot_class_accuracies signature\")\n",
    "\n",
    "# Fix 5: Update the loop in _plot_class_accuracies\n",
    "old_class_loop = \"for class_name in present_class_names:  # Use only present classes\"\n",
    "new_class_loop = \"for class_name in class_names_subset:  # Use only present classes\"\n",
    "\n",
    "if old_class_loop in content:\n",
    "    content = content.replace(old_class_loop, new_class_loop)\n",
    "    print(\"‚úÖ Fixed class accuracies loop\")\n",
    "\n",
    "# Write the fixed content back\n",
    "with open('/content/ViT-FishID/evaluate.py', 'w') as f:\n",
    "    f.write(content)\n",
    "\n",
    "print(\"‚úÖ Fixed all scope errors!\")\n",
    "print(\"üîß Applied fixes:\")\n",
    "print(\"  ‚úÖ Pass class names to plotting functions\")\n",
    "print(\"  ‚úÖ Update function signatures\")  \n",
    "print(\"  ‚úÖ Fix variable references in plots\")\n",
    "print(\"\\nüöÄ Try running evaluation again!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f93714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üÜï Create Clean, Working evaluate.py (Complete Replacement)\n",
    "import os\n",
    "\n",
    "print(\"üîÑ Creating completely clean evaluate.py...\")\n",
    "\n",
    "# Ensure we're in the right directory\n",
    "%cd /content/ViT-FishID\n",
    "\n",
    "# Create the clean, working evaluate.py content\n",
    "clean_evaluate_py = '''import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, List, Tuple\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "from model import ViTForFishClassification\n",
    "from data import create_dataloaders\n",
    "from utils import get_device\n",
    "\n",
    "\n",
    "class ModelEvaluator:\n",
    "    \"\"\"Clean, robust model evaluation for ViT-Fish classification.\"\"\"\n",
    "    \n",
    "    def __init__(self, model: ViTForFishClassification, class_names: List[str], device: str = 'cuda'):\n",
    "        self.model = model\n",
    "        self.class_names = class_names\n",
    "        self.device = device\n",
    "        self.model.eval()\n",
    "    \n",
    "    def evaluate_dataset(self, data_loader: DataLoader, save_dir: str = './evaluation_results') -> Dict[str, float]:\n",
    "        \"\"\"Comprehensive evaluation on dataset.\"\"\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        all_predictions = []\n",
    "        all_targets = []\n",
    "        all_probabilities = []\n",
    "        \n",
    "        print(\"Evaluating model...\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, targets in tqdm(data_loader, desc='Evaluating'):\n",
    "                images = images.to(self.device)\n",
    "                targets = targets.to(self.device)\n",
    "                \n",
    "                # Forward pass\n",
    "                logits = self.model(images)\n",
    "                probabilities = torch.softmax(logits, dim=1)\n",
    "                predictions = torch.argmax(logits, dim=1)\n",
    "                \n",
    "                # Collect results\n",
    "                all_predictions.extend(predictions.cpu().numpy())\n",
    "                all_targets.extend(targets.cpu().numpy())\n",
    "                all_probabilities.extend(probabilities.cpu().numpy())\n",
    "        \n",
    "        # Convert to numpy arrays\n",
    "        all_predictions = np.array(all_predictions)\n",
    "        all_targets = np.array(all_targets)\n",
    "        all_probabilities = np.array(all_probabilities)\n",
    "        \n",
    "        # Calculate Top-1 accuracy\n",
    "        top1_accuracy = accuracy_score(all_targets, all_predictions) * 100\n",
    "        \n",
    "        # Calculate Top-5 accuracy\n",
    "        top5_correct = 0\n",
    "        for i, target in enumerate(all_targets):\n",
    "            top5_preds = np.argsort(all_probabilities[i])[-5:]  # Top 5 predictions\n",
    "            if target in top5_preds:\n",
    "                top5_correct += 1\n",
    "        top5_accuracy = (top5_correct / len(all_targets)) * 100\n",
    "        \n",
    "        # Get unique classes that appear in the data\n",
    "        unique_classes = sorted(list(set(all_targets.tolist() + all_predictions.tolist())))\n",
    "        present_class_names = [self.class_names[i] for i in unique_classes if i < len(self.class_names)]\n",
    "        \n",
    "        print(f\"\\\\nFound {len(unique_classes)} classes in test data (out of {len(self.class_names)} total)\")\n",
    "        \n",
    "        # Generate classification report with proper handling\n",
    "        try:\n",
    "            class_report = classification_report(\n",
    "                all_targets, \n",
    "                all_predictions,\n",
    "                labels=unique_classes,\n",
    "                target_names=present_class_names,\n",
    "                output_dict=True,\n",
    "                zero_division=0\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not generate full classification report: {e}\")\n",
    "            class_report = {}\n",
    "        \n",
    "        # Generate confusion matrix\n",
    "        cm = confusion_matrix(all_targets, all_predictions, labels=unique_classes)\n",
    "        \n",
    "        # Save results\n",
    "        self._save_results(class_report, save_dir)\n",
    "        self._save_confusion_matrix(cm, present_class_names, save_dir)\n",
    "        self._save_class_accuracies(class_report, save_dir)\n",
    "        \n",
    "        # Prepare results dictionary\n",
    "        results = {\n",
    "            'accuracy': top1_accuracy,\n",
    "            'top5_accuracy': top5_accuracy,\n",
    "            'num_test_classes': len(unique_classes),\n",
    "            'total_classes': len(self.class_names),\n",
    "            'classification_report': class_report\n",
    "        }\n",
    "        \n",
    "        # Add aggregate metrics if available\n",
    "        if 'macro avg' in class_report:\n",
    "            results.update({\n",
    "                'macro_avg_precision': class_report['macro avg']['precision'] * 100,\n",
    "                'macro_avg_recall': class_report['macro avg']['recall'] * 100,\n",
    "                'macro_avg_f1': class_report['macro avg']['f1-score'] * 100,\n",
    "            })\n",
    "        \n",
    "        if 'weighted avg' in class_report:\n",
    "            results.update({\n",
    "                'weighted_avg_precision': class_report['weighted avg']['precision'] * 100,\n",
    "                'weighted_avg_recall': class_report['weighted avg']['recall'] * 100,\n",
    "                'weighted_avg_f1': class_report['weighted avg']['f1-score'] * 100,\n",
    "            })\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"\\\\nüìä EVALUATION RESULTS:\")\n",
    "        print(f\"üéØ Top-1 Accuracy: {top1_accuracy:.2f}%\")\n",
    "        print(f\"üìà Top-5 Accuracy: {top5_accuracy:.2f}%\")\n",
    "        if 'macro_avg_f1' in results:\n",
    "            print(f\"üìã Macro Avg F1-Score: {results['macro_avg_f1']:.2f}%\")\n",
    "        if 'weighted_avg_f1' in results:\n",
    "            print(f\"‚öñÔ∏è  Weighted Avg F1-Score: {results['weighted_avg_f1']:.2f}%\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _save_results(self, report_dict: Dict, save_dir: str):\n",
    "        \"\"\"Save classification report to JSON.\"\"\"\n",
    "        if report_dict:\n",
    "            report_path = os.path.join(save_dir, 'classification_report.json')\n",
    "            try:\n",
    "                with open(report_path, 'w') as f:\n",
    "                    json.dump(report_dict, f, indent=2)\n",
    "                print(f\"Classification report saved to: {report_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not save classification report: {e}\")\n",
    "    \n",
    "    def _save_confusion_matrix(self, cm: np.ndarray, class_names: List[str], save_dir: str):\n",
    "        \"\"\"Save confusion matrix plot.\"\"\"\n",
    "        try:\n",
    "            plt.figure(figsize=(max(10, len(class_names) * 0.5), max(8, len(class_names) * 0.4)))\n",
    "            sns.heatmap(\n",
    "                cm, \n",
    "                annot=True, \n",
    "                fmt='d', \n",
    "                cmap='Blues',\n",
    "                xticklabels=class_names,\n",
    "                yticklabels=class_names,\n",
    "                cbar_kws={'label': 'Count'}\n",
    "            )\n",
    "            plt.title('Confusion Matrix')\n",
    "            plt.xlabel('Predicted')\n",
    "            plt.ylabel('Actual')\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            plt.yticks(rotation=0)\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            cm_path = os.path.join(save_dir, 'confusion_matrix.png')\n",
    "            plt.savefig(cm_path, dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            print(f\"Confusion matrix saved to: {cm_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not save confusion matrix: {e}\")\n",
    "    \n",
    "    def _save_class_accuracies(self, report_dict: Dict, save_dir: str):\n",
    "        \"\"\"Save per-class accuracies plot.\"\"\"\n",
    "        if not report_dict:\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            class_names = []\n",
    "            f1_scores = []\n",
    "            \n",
    "            for class_name in self.class_names:\n",
    "                if class_name in report_dict:\n",
    "                    class_names.append(class_name)\n",
    "                    f1_scores.append(report_dict[class_name]['f1-score'] * 100)\n",
    "            \n",
    "            if not class_names:\n",
    "                print(\"Warning: No per-class data available for plotting\")\n",
    "                return\n",
    "            \n",
    "            plt.figure(figsize=(max(12, len(class_names) * 0.3), 8))\n",
    "            bars = plt.bar(range(len(class_names)), f1_scores, color='skyblue', alpha=0.7)\n",
    "            plt.xlabel('Fish Species')\n",
    "            plt.ylabel('F1-Score (%)')\n",
    "            plt.title('Per-Class F1-Scores')\n",
    "            plt.xticks(range(len(class_names)), class_names, rotation=45, ha='right')\n",
    "            plt.grid(axis='y', alpha=0.3)\n",
    "            \n",
    "            # Add value labels on bars\n",
    "            for bar, score in zip(bars, f1_scores):\n",
    "                height = bar.get_height()\n",
    "                plt.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "                        f'{score:.1f}%', ha='center', va='bottom', fontsize=8)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            acc_path = os.path.join(save_dir, 'class_f1_scores.png')\n",
    "            plt.savefig(acc_path, dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            print(f\"Class F1-scores plot saved to: {acc_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not save class accuracies plot: {e}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main evaluation script.\"\"\"\n",
    "    import argparse\n",
    "    \n",
    "    parser = argparse.ArgumentParser(description='Evaluate ViT-FishID model')\n",
    "    parser.add_argument('--data_dir', type=str, required=True, help='Path to fish dataset directory')\n",
    "    parser.add_argument('--model_path', type=str, required=True, help='Path to model checkpoint')\n",
    "    parser.add_argument('--batch_size', type=int, default=32, help='Batch size for evaluation')\n",
    "    parser.add_argument('--image_size', type=int, default=224, help='Input image size')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    print(f\"üîç Evaluating model: {args.model_path}\")\n",
    "    print(f\"üìä Data directory: {args.data_dir}\")\n",
    "    \n",
    "    device = get_device()\n",
    "    print(f\"üñ•Ô∏è  Using device: {device}\")\n",
    "    \n",
    "    # Load data\n",
    "    try:\n",
    "        train_loader, val_loader, test_loader, class_names = create_dataloaders(\n",
    "            data_dir=args.data_dir,\n",
    "            batch_size=args.batch_size,\n",
    "            image_size=args.image_size\n",
    "        )\n",
    "        print(f\"üìä Found {len(class_names)} total classes\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Data loading error: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Create model\n",
    "    try:\n",
    "        num_classes = len(class_names)\n",
    "        model = ViTForFishClassification(\n",
    "            num_classes=num_classes,\n",
    "            model_name='vit_small_patch16_224',\n",
    "            pretrained=False,\n",
    "            dropout_rate=0.1\n",
    "        ).to(device)\n",
    "        \n",
    "        # Load checkpoint\n",
    "        if os.path.exists(args.model_path):\n",
    "            print(f\"üì• Loading checkpoint: {args.model_path}\")\n",
    "            checkpoint = torch.load(args.model_path, map_location=device)\n",
    "            \n",
    "            if 'student_state_dict' in checkpoint:\n",
    "                model.load_state_dict(checkpoint['student_state_dict'])\n",
    "                print(\"‚úÖ Loaded student model weights\")\n",
    "                if 'best_accuracy' in checkpoint:\n",
    "                    print(f\"üìä Training best accuracy: {checkpoint['best_accuracy']:.2f}%\")\n",
    "            elif 'model_state_dict' in checkpoint:\n",
    "                model.load_state_dict(checkpoint['model_state_dict'])\n",
    "                print(\"‚úÖ Loaded model weights\")\n",
    "            else:\n",
    "                model.load_state_dict(checkpoint)\n",
    "                print(\"‚úÖ Loaded model weights\")\n",
    "        else:\n",
    "            print(f\"‚ùå Checkpoint not found: {args.model_path}\")\n",
    "            return\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Model loading error: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Create evaluator and run evaluation\n",
    "    try:\n",
    "        evaluator = ModelEvaluator(model, class_names, device)\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        print(f\"\\\\nüß™ Evaluating on test set...\")\n",
    "        test_results = evaluator.evaluate_dataset(test_loader, \"test_results\")\n",
    "        \n",
    "        # Evaluate on validation set for comparison\n",
    "        print(f\"\\\\nüîç Evaluating on validation set...\")\n",
    "        val_results = evaluator.evaluate_dataset(val_loader, \"validation_results\")\n",
    "        \n",
    "        # Final summary\n",
    "        print(f\"\\\\n\" + \"=\"*60)\n",
    "        print(f\"üéâ EVALUATION COMPLETED!\")\n",
    "        print(f\"=\"*60)\n",
    "        print(f\"üìä TEST SET RESULTS:\")\n",
    "        print(f\"  üéØ Top-1 Accuracy: {test_results['accuracy']:.2f}%\")\n",
    "        print(f\"  üìà Top-5 Accuracy: {test_results['top5_accuracy']:.2f}%\")\n",
    "        print(f\"\\\\nüìä VALIDATION SET RESULTS:\")\n",
    "        print(f\"  üéØ Top-1 Accuracy: {val_results['accuracy']:.2f}%\")\n",
    "        print(f\"  üìà Top-5 Accuracy: {val_results['top5_accuracy']:.2f}%\")\n",
    "        print(f\"\\\\nüìã Dataset Info:\")\n",
    "        print(f\"  Total classes: {test_results['total_classes']}\")\n",
    "        print(f\"  Classes in test set: {test_results['num_test_classes']}\")\n",
    "        print(f\"\\\\nüíæ Results saved to: test_results/ and validation_results/\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Evaluation error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "'''\n",
    "\n",
    "# Write the clean evaluate.py file\n",
    "with open('evaluate.py', 'w') as f:\n",
    "    f.write(clean_evaluate_py)\n",
    "\n",
    "print(\"‚úÖ Created clean, working evaluate.py!\")\n",
    "print(\"üîß Features of the new script:\")\n",
    "print(\"  ‚úÖ Robust class mismatch handling\")\n",
    "print(\"  ‚úÖ Proper error handling throughout\") \n",
    "print(\"  ‚úÖ Clean function scoping\")\n",
    "print(\"  ‚úÖ Both Top-1 and Top-5 accuracy\")\n",
    "print(\"  ‚úÖ Comprehensive result saving\")\n",
    "print(\"  ‚úÖ Validation and test set evaluation\")\n",
    "\n",
    "# Verify the file\n",
    "if os.path.exists('evaluate.py'):\n",
    "    file_size = os.path.getsize('evaluate.py')\n",
    "    print(f\"‚úÖ Clean script created ({file_size} bytes)\")\n",
    "    print(\"\\\\nüöÄ Ready to run evaluation without errors!\")\n",
    "else:\n",
    "    print(\"‚ùå File creation failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db698b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Test Clean Evaluation Script\n",
    "print(\"üß™ Testing the clean evaluation script...\")\n",
    "\n",
    "# Quick import test\n",
    "try:\n",
    "    import sys\n",
    "    sys.path.append('/content/ViT-FishID')\n",
    "    \n",
    "    from evaluate import ModelEvaluator\n",
    "    print(\"‚úÖ Successfully imported ModelEvaluator\")\n",
    "    \n",
    "    # Test if the script can run (argument check)\n",
    "    import subprocess\n",
    "    result = subprocess.run(['python', '/content/ViT-FishID/evaluate.py', '--help'], \n",
    "                          capture_output=True, text=True, cwd='/content/ViT-FishID')\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"‚úÖ Script runs without syntax errors\")\n",
    "        print(\"\\\\nüìã Available options:\")\n",
    "        print(result.stdout.split('\\\\n')[1:6])  # Show first few help lines\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Script has some issues:\")\n",
    "        print(result.stderr[:200])\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error testing script: {e}\")\n",
    "\n",
    "print(\"\\\\n\" + \"=\"*50)\n",
    "print(\"üéØ NOW RUN YOUR EVALUATION WITH:\")\n",
    "print(\"=\"*50)\n",
    "print(\"!cd /content/ViT-FishID && python evaluate.py \\\\\\\\\")\n",
    "print(\"    --data_dir /content/fish_cutouts \\\\\\\\\")\n",
    "print(\"    --model_path /content/drive/MyDrive/ViT-FishID/pretrained_checkpoints/model_best.pth \\\\\\\\\") \n",
    "print(\"    --batch_size 32 \\\\\\\\\")\n",
    "print(\"    --image_size 224\")\n",
    "\n",
    "print(\"\\\\nüéâ The clean script should handle all errors gracefully!\")\n",
    "print(\"üìä Expected output: Both test and validation accuracies\")\n",
    "print(\"üíæ Results will be saved to test_results/ and validation_results/ folders\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f9f3b5",
   "metadata": {},
   "source": [
    "# üöÄ How to Get the Clean Evaluation Script into Google Colab\n",
    "\n",
    "Follow these steps to get the fixed `evaluate.py` script working in your Google Colab:\n",
    "\n",
    "## Method 1: Run the Creation Cell (Recommended)\n",
    "\n",
    "1. **Scroll up** to find the cell titled **\"üÜï Create Clean, Working evaluate.py (Complete Replacement)\"** \n",
    "2. **Run that cell** - it will create the clean `evaluate.py` file directly in your Colab workspace\n",
    "3. **Run the test cell** below it to verify it works\n",
    "4. **Run your evaluation** with the provided command\n",
    "\n",
    "## Method 2: Manual Upload (Alternative)\n",
    "\n",
    "If Method 1 doesn't work:\n",
    "\n",
    "1. **Copy the script content** from the creation cell\n",
    "2. **Create a new file** in Colab:\n",
    "   ```python\n",
    "   # Create evaluate.py manually\n",
    "   with open('/content/ViT-FishID/evaluate.py', 'w') as f:\n",
    "       f.write(\"\"\"[paste the script content here]\"\"\")\n",
    "   ```\n",
    "\n",
    "## Method 3: Google Drive Upload\n",
    "\n",
    "1. **Save the script** to your local computer as `evaluate.py`\n",
    "2. **Upload to Google Drive** in your ViT-FishID folder  \n",
    "3. **Copy from Drive** in Colab:\n",
    "   ```python\n",
    "   !cp /content/drive/MyDrive/ViT-FishID/evaluate.py /content/ViT-FishID/\n",
    "   ```\n",
    "\n",
    "## ‚úÖ After Getting the Script in Colab:\n",
    "\n",
    "Run these commands in order:\n",
    "\n",
    "### Step 1: Verify the script exists\n",
    "```python\n",
    "!ls -la /content/ViT-FishID/evaluate.py\n",
    "```\n",
    "\n",
    "### Step 2: Test the script works\n",
    "```python\n",
    "!cd /content/ViT-FishID && python evaluate.py --help\n",
    "```\n",
    "\n",
    "### Step 3: Run the evaluation\n",
    "```python\n",
    "!cd /content/ViT-FishID && python evaluate.py \\\n",
    "    --data_dir /content/fish_cutouts \\\n",
    "    --model_path /content/drive/MyDrive/ViT-FishID/pretrained_checkpoints/model_best.pth \\\n",
    "    --batch_size 32 \\\n",
    "    --image_size 224\n",
    "```\n",
    "\n",
    "## üéØ Expected Results:\n",
    "- Top-1 and Top-5 accuracy on both test and validation sets\n",
    "- Per-class performance metrics\n",
    "- Confusion matrix and F1-score plots\n",
    "- Results saved to `test_results/` and `validation_results/` folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1250ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìã Step-by-Step: Get Evaluation Script Working in Colab\n",
    "\n",
    "print(\"üöÄ Setting up evaluation script in Google Colab...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Step 1: Ensure we're in the right directory\n",
    "print(\"üìÅ Step 1: Setting up directory\")\n",
    "%cd /content/ViT-FishID\n",
    "print(\"‚úÖ In ViT-FishID directory\")\n",
    "\n",
    "# Step 2: Check if evaluate.py exists\n",
    "import os\n",
    "if os.path.exists('evaluate.py'):\n",
    "    print(\"‚úÖ Step 2: evaluate.py already exists\")\n",
    "    file_size = os.path.getsize('evaluate.py')\n",
    "    print(f\"   File size: {file_size} bytes\")\n",
    "else:\n",
    "    print(\"‚ùå Step 2: evaluate.py not found\")\n",
    "    print(\"üí° Please run the 'üÜï Create Clean, Working evaluate.py' cell first!\")\n",
    "\n",
    "# Step 3: Test script syntax\n",
    "print(\"\\nüß™ Step 3: Testing script syntax\")\n",
    "try:\n",
    "    import subprocess\n",
    "    result = subprocess.run(['python', '-m', 'py_compile', 'evaluate.py'], \n",
    "                          capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(\"‚úÖ Script syntax is valid\")\n",
    "    else:\n",
    "        print(\"‚ùå Syntax errors found:\")\n",
    "        print(result.stderr)\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Could not test syntax: {e}\")\n",
    "\n",
    "# Step 4: Test imports\n",
    "print(\"\\nüì¶ Step 4: Testing imports\")\n",
    "try:\n",
    "    import sys\n",
    "    sys.path.append('/content/ViT-FishID')\n",
    "    from evaluate import ModelEvaluator\n",
    "    print(\"‚úÖ All imports work correctly\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import error: {e}\")\n",
    "    print(\"üí° Make sure all required modules are available\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Other error: {e}\")\n",
    "\n",
    "# Step 5: Check required paths\n",
    "print(\"\\nüîç Step 5: Checking required paths\")\n",
    "\n",
    "# Check data directory\n",
    "data_path = \"/content/fish_cutouts\"\n",
    "if os.path.exists(data_path):\n",
    "    print(f\"‚úÖ Data directory exists: {data_path}\")\n",
    "    subdirs = [d for d in os.listdir(data_path) if os.path.isdir(os.path.join(data_path, d))]\n",
    "    print(f\"   Found subdirectories: {len(subdirs)}\")\n",
    "else:\n",
    "    print(f\"‚ùå Data directory not found: {data_path}\")\n",
    "\n",
    "# Check model checkpoint\n",
    "model_path = \"/content/drive/MyDrive/ViT-FishID/pretrained_checkpoints/model_best.pth\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"‚úÖ Model checkpoint exists: model_best.pth\")\n",
    "    file_size = os.path.getsize(model_path) / (1024*1024)  # MB\n",
    "    print(f\"   Model size: {file_size:.1f} MB\")\n",
    "else:\n",
    "    print(f\"‚ùå Model checkpoint not found\")\n",
    "    print(\"üí° Update the path to your actual checkpoint location\")\n",
    "\n",
    "# Step 6: Show the command to run\n",
    "print(\"\\nüéØ Step 6: Ready to run evaluation!\")\n",
    "print(\"=\"*60)\n",
    "print(\"Copy and run this command:\")\n",
    "print()\n",
    "print(\"!cd /content/ViT-FishID && python evaluate.py \\\\\")\n",
    "print(\"    --data_dir /content/fish_cutouts \\\\\") \n",
    "print(\"    --model_path /content/drive/MyDrive/ViT-FishID/pretrained_checkpoints/model_best.pth \\\\\")\n",
    "print(\"    --batch_size 32 \\\\\")\n",
    "print(\"    --image_size 224\")\n",
    "print()\n",
    "print(\"üéâ This should work without errors and give you:\")\n",
    "print(\"   üìä Top-1 and Top-5 accuracy\")\n",
    "print(\"   üìã Per-class performance metrics\") \n",
    "print(\"   üìà Confusion matrix and plots\")\n",
    "print(\"   üíæ Results saved to test_results/ and validation_results/\")\n",
    "\n",
    "# Final status\n",
    "print(f\"\\n{'='*60}\")\n",
    "if os.path.exists('evaluate.py') and os.path.exists(data_path):\n",
    "    print(\"üéâ READY TO EVALUATE! Everything looks good!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è SETUP INCOMPLETE - Fix the issues above first\")\n",
    "print(f\"{'='*60}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
