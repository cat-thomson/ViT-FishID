{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0e0af9a0",
      "metadata": {
        "id": "0e0af9a0"
      },
      "source": [
        "# üêü ViT-FishID: Semi-Supervised Fish Classification\n",
        "\n",
        "**COMPLETE TRAINING PIPELINE WITH GOOGLE COLAB**\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/cat-thomson/ViT-FishID/blob/main/ViT_FishID_Colab_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "## üéØ What This Notebook Does\n",
        "\n",
        "This notebook implements a **complete semi-supervised learning pipeline** for fish species classification using:\n",
        "\n",
        "**ü§ñ Vision Transformer (ViT)**: State-of-the-art transformer architecture for image classification\n",
        "**üìä Semi-Supervised Learning**: Leverages both labeled and unlabeled fish images\n",
        "**üéì EMA Teacher-Student Framework**: Uses exponential moving averages for consistency training\n",
        "**‚òÅÔ∏è Google Colab**: Cloud-based training with GPU acceleration\n",
        "\n",
        "## üìä Expected Performance\n",
        "\n",
        "- **Training Time**: 4-6 hours for 100 epochs\n",
        "- **GPU Requirements**: T4/V100/A100 (Colab Pro recommended)\n",
        "- **Expected Accuracy**: 80-90% on fish species classification\n",
        "- **Data Efficiency**: Works well with limited labeled data\n",
        "\n",
        "## üõ†Ô∏è What You Need\n",
        "\n",
        "1. **Fish Dataset**: Labeled and unlabeled fish images (upload to Google Drive)\n",
        "2. **Google Colab Pro**: Recommended for longer training sessions\n",
        "3. **Weights & Biases Account**: Optional for experiment tracking"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26bcb2a3",
      "metadata": {
        "id": "26bcb2a3"
      },
      "source": [
        "## üîß Step 1: Environment Setup and GPU Check\n",
        "\n",
        "First, let's verify that we have GPU access and set up the optimal environment for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3540b19",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3540b19",
        "outputId": "4859151f-eadc-4319-a3ac-b5f70e71df87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç System Information:\n",
            "Python version: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
            "PyTorch version: 2.6.0+cu124\n",
            "CUDA available: True\n",
            "GPU Device: NVIDIA A100-SXM4-40GB\n",
            "GPU Memory: 39.6 GB\n",
            "‚úÖ GPU is ready for training!\n"
          ]
        }
      ],
      "source": [
        "# Check GPU availability and system information\n",
        "import torch\n",
        "import os\n",
        "import gc\n",
        "\n",
        "print(\"üîç SYSTEM INFORMATION\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Python version: {os.sys.version}\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device_name = torch.cuda.get_device_name(0)\n",
        "    device_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
        "    print(f\"GPU Device: {device_name}\")\n",
        "    print(f\"GPU Memory: {device_memory:.1f} GB\")\n",
        "    print(\"‚úÖ GPU is ready for training!\")\n",
        "    \n",
        "    # Set optimal GPU settings\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "    \n",
        "    # Clear GPU cache\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    print(\"üöÄ GPU optimized for training\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå No GPU detected!\")\n",
        "    print(\"üìù To enable GPU in Colab:\")\n",
        "    print(\"   Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator ‚Üí GPU\")\n",
        "    print(\"   Then restart this notebook\")\n",
        "\n",
        "# Set device for later use\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"\\nüéØ Using device: {DEVICE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "149f671b",
      "metadata": {
        "id": "149f671b"
      },
      "source": [
        "## üìÅ Step 2: Mount Google Drive\n",
        "\n",
        "This will give us access to your fish dataset stored in Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4abb3ffd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4abb3ffd",
        "outputId": "29fb191e-611d-4f2d-a4d5-69fec2c1d936"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "\n",
            "üìÇ Google Drive contents:\n",
            "  - Mock Matric\n",
            "  - Photos\n",
            "  - Admin\n",
            "  - Uni\n",
            "  - Fish_Training_Output\n",
            "  - Colab Notebooks\n",
            "  - ViT-FishID\n",
            "  - fish_cutouts.zip\n",
            "  - ViT-FishID_Training_20250814_154652\n",
            "  - ViT-FishID_Training_20250814_202307\n",
            "  ... and 3 more items\n",
            "\n",
            "‚úÖ Google Drive mounted successfully!\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# List contents to verify mount\n",
        "print(\"\\nüìÇ Google Drive contents:\")\n",
        "drive_path = '/content/drive/MyDrive'\n",
        "if os.path.exists(drive_path):\n",
        "    items = os.listdir(drive_path)[:10]  # Show first 10 items\n",
        "    for item in items:\n",
        "        print(f\"  - {item}\")\n",
        "    if len(os.listdir(drive_path)) > 10:\n",
        "        print(f\"  ... and {len(os.listdir(drive_path)) - 10} more items\")\n",
        "    print(\"\\n‚úÖ Google Drive mounted successfully!\")\n",
        "else:\n",
        "    print(\"‚ùå Failed to mount Google Drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be8b6273",
      "metadata": {
        "id": "be8b6273"
      },
      "source": [
        "## üì¶ Step 3: Install Dependencies\n",
        "\n",
        "Installing all required packages for ViT-FishID training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8c724abc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c724abc",
        "outputId": "77da503f-48d7-49ca-dc48-111168649d45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì¶ Installing dependencies...\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m128.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m100.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m111.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h‚úÖ All dependencies installed successfully!\n",
            "\n",
            "üìã Package versions:\n",
            "  - torch: 2.6.0+cu124\n",
            "  - torchvision: 0.21.0+cu124\n",
            "  - timm: 1.0.19\n",
            "  - albumentations: 2.0.8\n",
            "  - opencv: 4.12.0\n",
            "  - sklearn: 1.6.1\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "print(\"üì¶ Installing dependencies...\")\n",
        "\n",
        "!pip install -q torch torchvision torchaudio\n",
        "!pip install -q timm transformers\n",
        "!pip install -q albumentations\n",
        "!pip install -q wandb\n",
        "!pip install -q opencv-python-headless\n",
        "!pip install -q scikit-learn\n",
        "!pip install -q matplotlib seaborn\n",
        "!pip install -q tqdm\n",
        "\n",
        "print(\"‚úÖ All dependencies installed successfully!\")\n",
        "\n",
        "# Verify installations\n",
        "import torch\n",
        "import torchvision\n",
        "import timm\n",
        "import albumentations\n",
        "import cv2\n",
        "import sklearn\n",
        "\n",
        "print(\"\\nüìã Package versions:\")\n",
        "print(f\"  - torch: {torch.__version__}\")\n",
        "print(f\"  - torchvision: {torchvision.__version__}\")\n",
        "print(f\"  - timm: {timm.__version__}\")\n",
        "print(f\"  - albumentations: {albumentations.__version__}\")\n",
        "print(f\"  - opencv: {cv2.__version__}\")\n",
        "print(f\"  - sklearn: {sklearn.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12b795fc",
      "metadata": {
        "id": "12b795fc"
      },
      "source": [
        "## üîÑ Step 4: Clone ViT-FishID Repository\n",
        "\n",
        "Getting the latest code from your GitHub repository."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c4e4cd45",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4e4cd45",
        "outputId": "8efc760e-aea2-48bd-f684-8f9d338697e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì• Cloning ViT-FishID repository...\n",
            "Cloning into '/content/ViT-FishID'...\n",
            "remote: Enumerating objects: 119, done.\u001b[K\n",
            "remote: Counting objects: 100% (119/119), done.\u001b[K\n",
            "remote: Compressing objects: 100% (86/86), done.\u001b[K\n",
            "remote: Total 119 (delta 44), reused 98 (delta 27), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (119/119), 201.94 KiB | 20.19 MiB/s, done.\n",
            "Resolving deltas: 100% (44/44), done.\n",
            "/content/ViT-FishID\n",
            "\n",
            "üìÇ Project structure:\n",
            "total 360\n",
            "drwxr-xr-x 4 root root   4096 Aug 15 06:58 .\n",
            "drwxr-xr-x 1 root root   4096 Aug 15 06:58 ..\n",
            "-rw-r--r-- 1 root root  21217 Aug 15 06:58 data.py\n",
            "-rw-r--r-- 1 root root  11572 Aug 15 06:58 evaluate.py\n",
            "-rw-r--r-- 1 root root   3328 Aug 15 06:58 EXTENDED_TRAINING_SETUP.md\n",
            "drwxr-xr-x 2 root root   4096 Aug 15 06:58 fish_cutouts\n",
            "drwxr-xr-x 8 root root   4096 Aug 15 06:58 .git\n",
            "-rw-r--r-- 1 root root     66 Aug 15 06:58 .gitattributes\n",
            "-rw-r--r-- 1 root root    646 Aug 15 06:58 .gitignore\n",
            "-rw-r--r-- 1 root root   9495 Aug 15 06:58 model.py\n",
            "-rw-r--r-- 1 root root  16771 Aug 15 06:58 pipeline.py\n",
            "-rw-r--r-- 1 root root  16566 Aug 15 06:58 README.md\n",
            "-rw-r--r-- 1 root root    202 Aug 15 06:58 requirements.txt\n",
            "-rw-r--r-- 1 root root   4265 Aug 15 06:58 resume_training.py\n",
            "-rw-r--r-- 1 root root   5134 Aug 15 06:58 species_mapping.txt\n",
            "-rw-r--r-- 1 root root  25497 Aug 15 06:58 trainer.py\n",
            "-rw-r--r-- 1 root root   4982 Aug 15 06:58 TRAINING_FIXES_APPLIED.md\n",
            "-rw-r--r-- 1 root root  15331 Aug 15 06:58 train.py\n",
            "-rw-r--r-- 1 root root   8818 Aug 15 06:58 utils.py\n",
            "-rw-r--r-- 1 root root 160971 Aug 15 06:58 ViT_FishID_Colab_Training.ipynb\n",
            "\n",
            "‚úÖ Repository cloned successfully!\n"
          ]
        }
      ],
      "source": [
        "# Clone the repository\n",
        "import os\n",
        "\n",
        "# Remove existing directory if it exists\n",
        "if os.path.exists('/content/ViT-FishID'):\n",
        "    !rm -rf /content/ViT-FishID\n",
        "\n",
        "# Clone the repository\n",
        "print(\"üì• Cloning ViT-FishID repository...\")\n",
        "!git clone https://github.com/cat-thomson/ViT-FishID.git /content/ViT-FishID\n",
        "\n",
        "# Change to project directory\n",
        "%cd /content/ViT-FishID\n",
        "\n",
        "# List project files\n",
        "print(\"\\nüìÇ Project structure:\")\n",
        "!ls -la\n",
        "\n",
        "print(\"\\n‚úÖ Repository cloned successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8155c400",
      "metadata": {
        "id": "8155c400"
      },
      "source": [
        "## üê† Step 5: Setup Fish Dataset\n",
        "\n",
        "**Important**: Upload your `fish_cutouts.zip` file to Google Drive before running this step.\n",
        "\n",
        "Expected dataset structure:\n",
        "```\n",
        "fish_cutouts/\n",
        "‚îú‚îÄ‚îÄ labeled/\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ species_1/\n",
        "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fish_001.jpg\n",
        "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ fish_002.jpg\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ species_2/\n",
        "‚îÇ       ‚îî‚îÄ‚îÄ ...\n",
        "‚îî‚îÄ‚îÄ unlabeled/\n",
        "    ‚îú‚îÄ‚îÄ fish_003.jpg\n",
        "    ‚îî‚îÄ‚îÄ fish_004.jpg\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nre5_INaKDXl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nre5_INaKDXl",
        "outputId": "c9c02e13-e2c0-4c0b-802a-0f0111fd50b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üóÇÔ∏è SETTING UP FISH DATASET - CORRECTED PATHS\n",
            "==================================================\n",
            "üéØ ZIP file location: /content/drive/MyDrive/fish_cutouts.zip\n",
            "üéØ Target data directory: /content/fish_cutouts\n",
            "üì• Data not found locally, extracting from Google Drive...\n",
            "‚úÖ Found ZIP file at: /content/drive/MyDrive/fish_cutouts.zip\n",
            "üìè ZIP file size: 216.5 MB\n",
            "üì¶ Extracting fish_cutouts.zip...\n",
            "‚úÖ ZIP extraction completed\n",
            "üìÅ Found in ZIP: ['dataset_info.json', '__MACOSX', 'labeled', 'unlabeled']\n",
            "üìÑ Found dataset info: dataset_info.json\n",
            "‚úÖ Found labeled directory: labeled\n",
            "‚úÖ Found unlabeled directory: unlabeled\n",
            "‚úÖ Data organized at: /content/fish_cutouts\n",
            "üìÑ Copied dataset_info.json\n",
            "üêü Verified: 37 species in labeled data\n",
            "üìä Verified: 24015 images in unlabeled data\n",
            "\n",
            "‚úÖ DATASET READY\n",
            "üìÅ Location: /content/fish_cutouts\n",
            "  üìÇ labeled/: 37 species folders\n",
            "  üìÇ unlabeled/: 24015 images\n",
            "  üìÑ dataset_info.json: Available\n",
            "üöÄ Ready to proceed with training!\n"
          ]
        }
      ],
      "source": [
        "# Setup fish dataset from Google Drive\n",
        "import zipfile\n",
        "import shutil\n",
        "import os\n",
        "import glob\n",
        "\n",
        "print(\"üê† SETTING UP FISH DATASET\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Configuration\n",
        "ZIP_FILE_PATH = '/content/drive/MyDrive/fish_cutouts.zip'\n",
        "DATA_DIR = '/content/fish_cutouts'\n",
        "\n",
        "print(f\"üìÇ Looking for dataset: {ZIP_FILE_PATH}\")\n",
        "print(f\"üéØ Target directory: {DATA_DIR}\")\n",
        "\n",
        "# Check if data already exists locally\n",
        "if os.path.exists(DATA_DIR) and os.path.exists(os.path.join(DATA_DIR, 'labeled')):\n",
        "    print(\"‚úÖ Dataset already available locally!\")\n",
        "    \n",
        "    # Quick validation\n",
        "    labeled_dir = os.path.join(DATA_DIR, 'labeled')\n",
        "    unlabeled_dir = os.path.join(DATA_DIR, 'unlabeled')\n",
        "    \n",
        "    if os.path.exists(labeled_dir):\n",
        "        species_count = len([d for d in os.listdir(labeled_dir) \n",
        "                           if os.path.isdir(os.path.join(labeled_dir, d)) and not d.startswith('.')])\n",
        "        print(f\"üêü Found {species_count} labeled species\")\n",
        "    \n",
        "    if os.path.exists(unlabeled_dir):\n",
        "        unlabeled_count = len([f for f in os.listdir(unlabeled_dir) \n",
        "                             if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
        "        print(f\"üìä Found {unlabeled_count} unlabeled images\")\n",
        "\n",
        "else:\n",
        "    print(\"üì• Extracting dataset from Google Drive...\")\n",
        "    \n",
        "    # Check if ZIP file exists\n",
        "    if not os.path.exists(ZIP_FILE_PATH):\n",
        "        print(f\"‚ùå Dataset not found at: {ZIP_FILE_PATH}\")\n",
        "        print(\"üìù Please upload fish_cutouts.zip to Google Drive root directory\")\n",
        "    else:\n",
        "        print(f\"‚úÖ Found dataset: {os.path.getsize(ZIP_FILE_PATH) / (1024**2):.1f} MB\")\n",
        "        \n",
        "        try:\n",
        "            # Extract to temporary directory\n",
        "            temp_dir = '/content/temp_extract'\n",
        "            if os.path.exists(temp_dir):\n",
        "                shutil.rmtree(temp_dir)\n",
        "            \n",
        "            with zipfile.ZipFile(ZIP_FILE_PATH, 'r') as zip_ref:\n",
        "                zip_ref.extractall(temp_dir)\n",
        "            \n",
        "            # Find and organize data\n",
        "            extracted_items = os.listdir(temp_dir)\n",
        "            print(f\"üìÅ Extracted: {extracted_items}\")\n",
        "            \n",
        "            # Look for labeled and unlabeled directories\n",
        "            labeled_source = None\n",
        "            unlabeled_source = None\n",
        "            \n",
        "            for item in extracted_items:\n",
        "                item_path = os.path.join(temp_dir, item)\n",
        "                if item == 'labeled' and os.path.isdir(item_path):\n",
        "                    labeled_source = item_path\n",
        "                elif item == 'unlabeled' and os.path.isdir(item_path):\n",
        "                    unlabeled_source = item_path\n",
        "            \n",
        "            if labeled_source and unlabeled_source:\n",
        "                # Create target directory\n",
        "                if os.path.exists(DATA_DIR):\n",
        "                    shutil.rmtree(DATA_DIR)\n",
        "                os.makedirs(DATA_DIR)\n",
        "                \n",
        "                # Move directories\n",
        "                shutil.move(labeled_source, os.path.join(DATA_DIR, 'labeled'))\n",
        "                shutil.move(unlabeled_source, os.path.join(DATA_DIR, 'unlabeled'))\n",
        "                \n",
        "                print(\"‚úÖ Dataset organized successfully!\")\n",
        "                \n",
        "                # Verify structure\n",
        "                labeled_dir = os.path.join(DATA_DIR, 'labeled')\n",
        "                species_count = len([d for d in os.listdir(labeled_dir) \n",
        "                                   if os.path.isdir(os.path.join(labeled_dir, d)) and not d.startswith('.')])\n",
        "                \n",
        "                unlabeled_dir = os.path.join(DATA_DIR, 'unlabeled')\n",
        "                unlabeled_count = len([f for f in os.listdir(unlabeled_dir) \n",
        "                                     if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
        "                \n",
        "                print(f\"üêü Verified: {species_count} species\")\n",
        "                print(f\"üìä Verified: {unlabeled_count} unlabeled images\")\n",
        "                \n",
        "            else:\n",
        "                print(\"‚ùå Could not find labeled and unlabeled directories\")\n",
        "            \n",
        "            # Cleanup\n",
        "            if os.path.exists(temp_dir):\n",
        "                shutil.rmtree(temp_dir)\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error extracting dataset: {e}\")\n",
        "\n",
        "# Final verification\n",
        "if os.path.exists(DATA_DIR):\n",
        "    print(f\"\\n‚úÖ DATASET READY\")\n",
        "    print(f\"üìÅ Location: {DATA_DIR}\")\n",
        "    print(\"üöÄ Ready for training!\")\n",
        "else:\n",
        "    print(f\"\\n‚ùå DATASET SETUP FAILED\")\n",
        "    print(\"Please check that fish_cutouts.zip is uploaded to Google Drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31f0fe32",
      "metadata": {
        "id": "31f0fe32"
      },
      "source": [
        "## üìà Step 6: Setup Weights & Biases (Optional)\n",
        "\n",
        "Weights & Biases provides excellent training visualization and experiment tracking."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab343772",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "ab343772",
        "outputId": "b6d9c2df-bbb0-46ae-ca3b-537ed8e98191"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìà Connecting to Weights & Biases...\n",
            "üîë Please enter your W&B API key when prompted.\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcativthomson\u001b[0m (\u001b[33mcativthomson-university-of-cape-town\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Successfully logged in to W&B.\n",
            "‚ùå W&B connection not established. Logging may be disabled.\n"
          ]
        }
      ],
      "source": [
        "# Login to Weights & Biases for experiment tracking\n",
        "import wandb\n",
        "import os\n",
        "\n",
        "print(\"üìà SETTING UP WEIGHTS & BIASES\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# Check if API key is available\n",
        "if os.environ.get(\"WANDB_API_KEY\"):\n",
        "    print(\"‚úÖ W&B API key found in environment\")\n",
        "    try:\n",
        "        wandb.login(relogin=True)\n",
        "        print(\"‚úÖ Successfully logged in to W&B\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è W&B relogin failed: {e}\")\n",
        "        print(\"Trying manual login...\")\n",
        "        wandb.login()\n",
        "else:\n",
        "    print(\"üîë Please enter your W&B API key when prompted\")\n",
        "    print(\"üí° Get your API key from: https://wandb.ai/settings\")\n",
        "    try:\n",
        "        wandb.login()\n",
        "        print(\"‚úÖ Successfully logged in to W&B\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå W&B login failed: {e}\")\n",
        "        print(\"Continuing without W&B logging...\")\n",
        "\n",
        "# Check connection status\n",
        "if wandb.run:\n",
        "    print(f\"üöÄ W&B Run URL: {wandb.run.url}\")\n",
        "    USE_WANDB = True\n",
        "else:\n",
        "    print(\"üìä W&B not connected - training will continue without logging\")\n",
        "    USE_WANDB = False\n",
        "\n",
        "print(f\"‚úÖ W&B setup complete (Enabled: {USE_WANDB})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5190f01",
      "metadata": {
        "id": "b5190f01"
      },
      "source": [
        "## üîÑ Step 6: Locate Checkpoint from Epoch 19\n",
        "\n",
        "Finding your saved checkpoint to resume training from where you left off."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "61b35ced",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61b35ced",
        "outputId": "80d1b4e8-edbd-4fe9-c8a5-ffc25514190a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Looking for checkpoint from epoch 100...\n",
            "üìÅ Checking: /content/drive/MyDrive/ViT-FishID/checkpoints_extended\n",
            "üéØ Found candidate: checkpoint_epoch_100.pth\n",
            "‚úÖ FOUND EPOCH 100 CHECKPOINT!\n",
            "üìÅ Location: /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_100.pth\n",
            "üìä Epoch: 100\n",
            "üìä Best accuracy so far: 87.56%\n",
            "üìÅ Checking: /content/drive/MyDrive/ViT-FishID/checkpoints_backup\n",
            "üéØ Found candidate: checkpoint_epoch_100.pth\n",
            "‚úÖ FOUND EPOCH 100 CHECKPOINT!\n",
            "üìÅ Location: /content/drive/MyDrive/ViT-FishID/checkpoints_backup/checkpoint_epoch_100.pth\n",
            "üìä Epoch: 100\n",
            "üìä Best accuracy so far: 87.56%\n",
            "\n",
            "üéâ Checkpoint ready for resuming training!\n",
            "üìÑ File: checkpoint_epoch_100.pth\n",
            "üìè Size: 982.4 MB\n",
            "üíæ New checkpoints will be saved to: /content/drive/MyDrive/ViT-FishID/checkpoints_extended\n"
          ]
        }
      ],
      "source": [
        "# Locate checkpoint from epoch 19\n",
        "import os\n",
        "import glob\n",
        "import torch\n",
        "\n",
        "print(\"üîç Looking for checkpoint from epoch 100...\")\n",
        "\n",
        "# Possible checkpoint locations\n",
        "checkpoint_locations = [\n",
        "    '/content/drive/MyDrive/ViT-FishID/checkpoints_extended', '/content/drive/MyDrive/ViT-FishID/checkpoints_backup'\n",
        "]\n",
        "\n",
        "checkpoint_path = None\n",
        "checkpoint_info = None\n",
        "\n",
        "# Search for epoch 19 checkpoint\n",
        "for location_pattern in checkpoint_locations:\n",
        "    for location in glob.glob(location_pattern):\n",
        "        if os.path.exists(location):\n",
        "            print(f\"üìÅ Checking: {location}\")\n",
        "\n",
        "            # Look for epoch 19 specifically\n",
        "            epoch_100_files = glob.glob(os.path.join(location, '*epoch_100*'))\n",
        "            manual_files = glob.glob(os.path.join(location, '*manual*epoch*100*'))\n",
        "            emergency_files = glob.glob(os.path.join(location, '*emergency*epoch*100*'))\n",
        "\n",
        "            all_candidates = epoch_100_files + manual_files + emergency_files\n",
        "\n",
        "            for candidate in all_candidates:\n",
        "                if candidate.endswith('.pth'):\n",
        "                    print(f\"üéØ Found candidate: {os.path.basename(candidate)}\")\n",
        "                    try:\n",
        "                        # Verify checkpoint can be loaded\n",
        "                        test_checkpoint = torch.load(candidate, map_location='cpu')\n",
        "                        epoch = test_checkpoint.get('epoch', 'unknown')\n",
        "\n",
        "                        if epoch == 100 or '100' in os.path.basename(candidate):\n",
        "                            checkpoint_path = candidate\n",
        "                            checkpoint_info = test_checkpoint\n",
        "                            print(f\"‚úÖ FOUND EPOCH 100 CHECKPOINT!\")\n",
        "                            print(f\"üìÅ Location: {checkpoint_path}\")\n",
        "                            print(f\"üìä Epoch: {epoch}\")\n",
        "\n",
        "                            if 'best_accuracy' in test_checkpoint:\n",
        "                                print(f\"üìä Best accuracy so far: {test_checkpoint['best_accuracy']:.2f}%\")\n",
        "                            elif 'best_acc' in test_checkpoint:\n",
        "                                print(f\"üìä Best accuracy so far: {test_checkpoint['best_acc']:.2f}%\")\n",
        "\n",
        "                            break\n",
        "                    except Exception as e:\n",
        "                        print(f\"‚ö†Ô∏è Could not load {candidate}: {e}\")\n",
        "\n",
        "            if checkpoint_path:\n",
        "                break\n",
        "\n",
        "        if checkpoint_path:\n",
        "            break\n",
        "\n",
        "if checkpoint_path:\n",
        "    print(f\"\\nüéâ Checkpoint ready for resuming training!\")\n",
        "    print(f\"üìÑ File: {os.path.basename(checkpoint_path)}\")\n",
        "    print(f\"üìè Size: {os.path.getsize(checkpoint_path) / (1024*1024):.1f} MB\")\n",
        "\n",
        "    # Set up checkpoint directory for new saves\n",
        "    checkpoint_save_dir = '/content/drive/MyDrive/ViT-FishID/checkpoints_extended'\n",
        "    os.makedirs(checkpoint_save_dir, exist_ok=True)\n",
        "    print(f\"üíæ New checkpoints will be saved to: {checkpoint_save_dir}\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå No checkpoint found for epoch 19!\")\n",
        "    print(\"\\nüîß Troubleshooting:\")\n",
        "    print(\"1. Check that you have a checkpoint saved from previous training\")\n",
        "    print(\"2. Ensure the checkpoint is uploaded to Google Drive\")\n",
        "    print(\"3. Look for files named like: checkpoint_epoch_19.pth, emergency_checkpoint_epoch_19.pth\")\n",
        "    print(\"\\nüìÅ Checked locations:\")\n",
        "    for location in checkpoint_locations:\n",
        "        print(f\"  - {location}\")\n",
        "\n",
        "    # Fallback: look for any checkpoints\n",
        "    print(\"\\nüîç All available checkpoints:\")\n",
        "    for location_pattern in checkpoint_locations:\n",
        "        for location in glob.glob(location_pattern):\n",
        "            if os.path.exists(location):\n",
        "                all_checkpoints = glob.glob(os.path.join(location, '*.pth'))\n",
        "                for cp in all_checkpoints:\n",
        "                    print(f\"  - {os.path.basename(cp)}\")\n",
        "\n",
        "# Store checkpoint path for later use\n",
        "RESUME_CHECKPOINT = checkpoint_path"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fe6af6d",
      "metadata": {
        "id": "0fe6af6d"
      },
      "source": [
        "## ‚öôÔ∏è Step 7: Configure Training Parameters\n",
        "\n",
        "Configure the training settings for your semi-supervised fish classification model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hSokV6NDjgYa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSokV6NDjgYa",
        "outputId": "8c7b1c32-b0db-4c59-fea7-411ce6f2574d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üéØ EXTENDED TRAINING CONFIGURATION - WITH W&B\n",
            "==================================================\n",
            "üìä Detected 37 fish species\n",
            "\n",
            "EXTENDED TRAINING CONFIGURATION SUMMARY\n",
            "==================================================\n",
            "üìä Resume from: Epoch 100\n",
            "üìä Target epochs: 100\n",
            "üìä Remaining epochs: 1\n",
            "‚è±Ô∏è Estimated time: 5-7 minutes\n",
            "üìä Batch size: 16 (optimized for Colab Pro)\n",
            "üíæ Checkpoint saves: EVERY 1 epoch(s)\n",
            "üìä Mode: semi_supervised with consistency weight 2.0\n",
            "üìä Logging: W&B Enabled (Project: ViT-FishID-Extended-Training, Run: resume-epoch-6-to-100)\n",
            "üìä Num Classes: 37\n",
            "\n",
            "SETTING UP CHECKPOINT DIRECTORIES\n",
            "==================================================\n",
            "üìÅ Primary saves: /content/drive/MyDrive/ViT-FishID/checkpoints_extended (Created/Exists)\n",
            "üíæ Backup saves: /content/drive/MyDrive/ViT-FishID/checkpoints_backup (Created/Exists)\n",
            "\n",
            "‚úÖ Will resume training from: checkpoint_epoch_100.pth\n",
            "\n",
            "üöÄ Configuration complete. Ready to resume/start training!\n"
          ]
        }
      ],
      "source": [
        "# Training Configuration for Semi-Supervised Fish Classification\n",
        "import os\n",
        "\n",
        "print(\"‚öôÔ∏è TRAINING CONFIGURATION\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Auto-detect number of species from dataset\n",
        "NUM_CLASSES = 37  # Default\n",
        "if 'DATA_DIR' in globals() and os.path.exists(DATA_DIR):\n",
        "    labeled_dir = os.path.join(DATA_DIR, 'labeled')\n",
        "    if os.path.exists(labeled_dir):\n",
        "        species_count = len([d for d in os.listdir(labeled_dir) \n",
        "                           if os.path.isdir(os.path.join(labeled_dir, d)) and not d.startswith('.')])\n",
        "        NUM_CLASSES = species_count\n",
        "        print(f\"üìä Auto-detected {species_count} fish species\")\n",
        "\n",
        "# Create checkpoint directories\n",
        "CHECKPOINT_DIR = '/content/drive/MyDrive/ViT-FishID/checkpoints'\n",
        "BACKUP_DIR = '/content/drive/MyDrive/ViT-FishID/checkpoints_backup'\n",
        "\n",
        "try:\n",
        "    os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "    os.makedirs(BACKUP_DIR, exist_ok=True)\n",
        "    print(f\"üìÅ Checkpoints: {CHECKPOINT_DIR}\")\n",
        "    print(f\"üíæ Backups: {BACKUP_DIR}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Could not create Google Drive directories: {e}\")\n",
        "    CHECKPOINT_DIR = '/content/checkpoints'\n",
        "    BACKUP_DIR = '/content/checkpoints_backup'\n",
        "    os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "    os.makedirs(BACKUP_DIR, exist_ok=True)\n",
        "    print(f\"üìÅ Using local checkpoints: {CHECKPOINT_DIR}\")\n",
        "\n",
        "# Training Configuration\n",
        "TRAINING_CONFIG = {\n",
        "    # BASIC SETTINGS\n",
        "    'mode': 'semi_supervised',\n",
        "    'data_dir': DATA_DIR if 'DATA_DIR' in globals() else '/content/fish_cutouts',\n",
        "    'epochs': 100,\n",
        "    'batch_size': 16,\n",
        "    'learning_rate': 1e-4,\n",
        "    'weight_decay': 0.05,\n",
        "    \n",
        "    # MODEL SETTINGS\n",
        "    'model_name': 'vit_base_patch16_224',\n",
        "    'num_classes': NUM_CLASSES,\n",
        "    'pretrained': True,\n",
        "    \n",
        "    # SEMI-SUPERVISED SETTINGS\n",
        "    'consistency_weight': 2.0,\n",
        "    'pseudo_label_threshold': 0.7,\n",
        "    'temperature': 4.0,\n",
        "    'warmup_epochs': 10,\n",
        "    'ramp_up_epochs': 30,\n",
        "    \n",
        "    # CHECKPOINT SETTINGS\n",
        "    'save_frequency': 10,  # Save every 10 epochs\n",
        "    'checkpoint_dir': CHECKPOINT_DIR,\n",
        "    'backup_dir': BACKUP_DIR,\n",
        "    \n",
        "    # LOGGING SETTINGS\n",
        "    'use_wandb': USE_WANDB if 'USE_WANDB' in globals() else False,\n",
        "    'wandb_project': 'ViT-FishID-Training',\n",
        "    'wandb_run_name': f'fish-classification-{NUM_CLASSES}-classes',\n",
        "}\n",
        "\n",
        "print(\"\\nüìã TRAINING CONFIGURATION\")\n",
        "print(\"=\"*50)\n",
        "print(f\"üéØ Training mode: {TRAINING_CONFIG['mode']}\")\n",
        "print(f\"üìä Total epochs: {TRAINING_CONFIG['epochs']}\")\n",
        "print(f\"üì¶ Batch size: {TRAINING_CONFIG['batch_size']}\")\n",
        "print(f\"üß† Model: {TRAINING_CONFIG['model_name']}\")\n",
        "print(f\"üêü Number of species: {TRAINING_CONFIG['num_classes']}\")\n",
        "print(f\"‚öñÔ∏è Consistency weight: {TRAINING_CONFIG['consistency_weight']}\")\n",
        "print(f\"üéØ Pseudo-label threshold: {TRAINING_CONFIG['pseudo_label_threshold']}\")\n",
        "print(f\"üíæ Save frequency: Every {TRAINING_CONFIG['save_frequency']} epochs\")\n",
        "print(f\"üìà W&B logging: {TRAINING_CONFIG['use_wandb']}\")\n",
        "\n",
        "# Time estimation\n",
        "estimated_time_hours = TRAINING_CONFIG['epochs'] * 3 / 60  # ~3 minutes per epoch\n",
        "print(f\"\\n‚è±Ô∏è Estimated training time: {estimated_time_hours:.1f} hours\")\n",
        "print(f\"üí° Recommendation: Use Colab Pro for longer training sessions\")\n",
        "\n",
        "print(\"\\n‚úÖ Configuration complete - ready to start training!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34762fd6",
      "metadata": {},
      "source": [
        "## ü§ñ Step 7a: Load MAE Pre-trained Model (Optional)\n",
        "\n",
        "**This step loads your pre-trained MAE model to initialize the ViT encoder with better features.**\n",
        "\n",
        "The MAE (Masked Autoencoder) model you trained provides much better initial weights for the Vision Transformer compared to ImageNet pretraining, especially for fish images since it was trained specifically on your fish dataset.\n",
        "\n",
        "Benefits of using MAE initialization:\n",
        "- **Better Feature Representations**: Learned specifically on fish images\n",
        "- **Faster Convergence**: Model starts with relevant features\n",
        "- **Improved Performance**: Often leads to 2-5% accuracy improvement\n",
        "\n",
        "### üìÅ MAE Model Locations\n",
        "\n",
        "Your MAE models should be in one of these locations:\n",
        "- **Local**: `/Users/catalinathomson/Desktop/Fish/ViT-FishID/mae_checkpoints/mae_final_model.pth`\n",
        "- **Google Drive**: `/content/drive/MyDrive/mae_checkpoints/mae_final_model.pth` (after upload)\n",
        "\n",
        "### üîß Setup Instructions\n",
        "\n",
        "1. **Upload MAE Model**: Upload your `mae_final_model.pth` or `mae_best_model.pth` to Google Drive\n",
        "2. **Update Path**: Modify `MAE_MODEL_PATH` in the next cell if needed\n",
        "3. **Enable/Disable**: Set `LOAD_MAE_PRETRAINED = True/False` to control MAE loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02ef2d40",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load MAE Pre-trained Model and Create Custom ViT Model\n",
        "import torch\n",
        "import os\n",
        "import shutil\n",
        "from model import ViTForFishClassification\n",
        "\n",
        "print(\"ü§ñ SETTING UP MAE-INITIALIZED ViT MODEL\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Configuration for MAE loading\n",
        "MAE_MODEL_PATH = '/content/drive/MyDrive/mae_checkpoints/mae_final_model.pth'  # Update this path if needed\n",
        "LOAD_MAE_PRETRAINED = True  # Set to False to skip MAE loading\n",
        "\n",
        "# Global variable to store MAE state for later use\n",
        "MAE_ENCODER_WEIGHTS = None\n",
        "\n",
        "def load_mae_encoder_weights(mae_checkpoint_path):\n",
        "    \"\"\"\n",
        "    Load and extract encoder weights from MAE checkpoint.\n",
        "    \n",
        "    Args:\n",
        "        mae_checkpoint_path: Path to MAE checkpoint file\n",
        "        \n",
        "    Returns:\n",
        "        dict: Filtered encoder weights compatible with ViT backbone\n",
        "    \"\"\"\n",
        "    print(f\"üì• Loading MAE checkpoint from: {mae_checkpoint_path}\")\n",
        "    \n",
        "    # Load MAE checkpoint\n",
        "    checkpoint = torch.load(mae_checkpoint_path, map_location='cpu')\n",
        "    \n",
        "    # Print checkpoint info\n",
        "    if 'epoch' in checkpoint:\n",
        "        print(f\"üìä MAE trained for {checkpoint['epoch']} epochs\")\n",
        "    if 'train_loss' in checkpoint:\n",
        "        print(f\"üìâ Final MAE loss: {checkpoint['train_loss']:.4f}\")\n",
        "    \n",
        "    # Get model state dict\n",
        "    mae_state_dict = checkpoint.get('model_state_dict', checkpoint.get('state_dict', checkpoint))\n",
        "    \n",
        "    # Filter encoder weights (remove decoder, mask token, and other non-encoder components)\n",
        "    encoder_weights = {}\n",
        "    for key, value in mae_state_dict.items():\n",
        "        # Keep only encoder-related weights\n",
        "        if any(prefix in key for prefix in [\n",
        "            'patch_embed',\n",
        "            'pos_embed', \n",
        "            'cls_token',\n",
        "            'blocks',\n",
        "            'norm'\n",
        "        ]) and not any(exclude in key for exclude in [\n",
        "            'decoder',\n",
        "            'mask_token',\n",
        "            'head'\n",
        "        ]):\n",
        "            encoder_weights[key] = value\n",
        "    \n",
        "    print(f\"üìä Extracted {len(encoder_weights)} encoder parameters from MAE\")\n",
        "    \n",
        "    return encoder_weights\n",
        "\n",
        "def create_mae_initialized_model(num_classes, model_name='vit_base_patch16_224', mae_weights=None):\n",
        "    \"\"\"\n",
        "    Create ViT model and optionally initialize with MAE weights.\n",
        "    \n",
        "    Args:\n",
        "        num_classes: Number of classification classes\n",
        "        model_name: ViT model architecture name\n",
        "        mae_weights: Optional MAE encoder weights dictionary\n",
        "        \n",
        "    Returns:\n",
        "        ViTForFishClassification: Initialized model\n",
        "    \"\"\"\n",
        "    print(f\"üèóÔ∏è Creating ViT model: {model_name}\")\n",
        "    \n",
        "    # Create ViT model (without ImageNet pretraining if we have MAE weights)\n",
        "    use_imagenet_pretrained = mae_weights is None\n",
        "    model = ViTForFishClassification(\n",
        "        num_classes=num_classes,\n",
        "        model_name=model_name,\n",
        "        pretrained=use_imagenet_pretrained,\n",
        "        dropout_rate=0.1\n",
        "    )\n",
        "    \n",
        "    if mae_weights is not None:\n",
        "        print(\"‚ö° Initializing ViT backbone with MAE encoder weights...\")\n",
        "        \n",
        "        # Get current backbone state dict\n",
        "        backbone_state = model.backbone.state_dict()\n",
        "        \n",
        "        # Update with MAE weights (only for matching keys and shapes)\n",
        "        updated_keys = []\n",
        "        shape_mismatches = []\n",
        "        \n",
        "        for mae_key, mae_weight in mae_weights.items():\n",
        "            if mae_key in backbone_state:\n",
        "                if mae_weight.shape == backbone_state[mae_key].shape:\n",
        "                    backbone_state[mae_key] = mae_weight.clone()\n",
        "                    updated_keys.append(mae_key)\n",
        "                else:\n",
        "                    shape_mismatches.append(f\"{mae_key}: MAE{mae_weight.shape} != ViT{backbone_state[mae_key].shape}\")\n",
        "        \n",
        "        # Load updated weights\n",
        "        model.backbone.load_state_dict(backbone_state)\n",
        "        \n",
        "        print(f\"‚úÖ Successfully transferred {len(updated_keys)} MAE encoder weights\")\n",
        "        \n",
        "        if shape_mismatches:\n",
        "            print(f\"‚ö†Ô∏è Found {len(shape_mismatches)} shape mismatches (using original weights):\")\n",
        "            for mismatch in shape_mismatches[:5]:  # Show first 5 mismatches\n",
        "                print(f\"   {mismatch}\")\n",
        "        \n",
        "        print(\"üéØ ViT model initialized with MAE-learned features!\")\n",
        "        \n",
        "    else:\n",
        "        print(\"üåê Using ImageNet pretrained weights\")\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Main execution\n",
        "if LOAD_MAE_PRETRAINED:\n",
        "    # Check if MAE model exists in Google Drive\n",
        "    if os.path.exists(MAE_MODEL_PATH):\n",
        "        print(f\"‚úÖ Found MAE model: {os.path.basename(MAE_MODEL_PATH)}\")\n",
        "        print(f\"üìè Size: {os.path.getsize(MAE_MODEL_PATH) / (1024**2):.1f} MB\")\n",
        "        \n",
        "        try:\n",
        "            # Load MAE encoder weights\n",
        "            MAE_ENCODER_WEIGHTS = load_mae_encoder_weights(MAE_MODEL_PATH)\n",
        "            print(\"üéâ MAE encoder weights loaded successfully!\")\n",
        "            \n",
        "            # Update training config\n",
        "            TRAINING_CONFIG['mae_pretrained'] = True\n",
        "            TRAINING_CONFIG['mae_model_path'] = MAE_MODEL_PATH\n",
        "            TRAINING_CONFIG['pretrained'] = False  # Don't use ImageNet since we have MAE\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error loading MAE model: {e}\")\n",
        "            print(\"üîÑ Falling back to ImageNet pretrained weights...\")\n",
        "            MAE_ENCODER_WEIGHTS = None\n",
        "            TRAINING_CONFIG['mae_pretrained'] = False\n",
        "            TRAINING_CONFIG['pretrained'] = True\n",
        "    \n",
        "    else:\n",
        "        # MAE model not found, check alternative locations\n",
        "        print(f\"‚ùå MAE model not found at: {MAE_MODEL_PATH}\")\n",
        "        \n",
        "        # Try to copy from local mae_checkpoints if exists\n",
        "        local_mae_path = f'/content/ViT-FishID/mae_checkpoints/{os.path.basename(MAE_MODEL_PATH)}'\n",
        "        if os.path.exists(local_mae_path):\n",
        "            print(f\"\udd0d Found MAE model in local repository: {local_mae_path}\")\n",
        "            try:\n",
        "                # Create directory and copy\n",
        "                os.makedirs(os.path.dirname(MAE_MODEL_PATH), exist_ok=True)\n",
        "                shutil.copy2(local_mae_path, MAE_MODEL_PATH)\n",
        "                print(f\"‚úÖ Copied MAE model to Google Drive: {MAE_MODEL_PATH}\")\n",
        "                \n",
        "                # Now load it\n",
        "                MAE_ENCODER_WEIGHTS = load_mae_encoder_weights(MAE_MODEL_PATH)\n",
        "                TRAINING_CONFIG['mae_pretrained'] = True\n",
        "                TRAINING_CONFIG['mae_model_path'] = MAE_MODEL_PATH\n",
        "                TRAINING_CONFIG['pretrained'] = False\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Error copying/loading MAE model: {e}\")\n",
        "                MAE_ENCODER_WEIGHTS = None\n",
        "                TRAINING_CONFIG['mae_pretrained'] = False\n",
        "                TRAINING_CONFIG['pretrained'] = True\n",
        "        else:\n",
        "            print(\"\ud83düìù Available options:\")\n",
        "            print(\"1. Upload mae_final_model.pth or mae_best_model.pth to /content/drive/MyDrive/mae_checkpoints/\")\n",
        "            print(\"2. Update MAE_MODEL_PATH variable to correct location\")\n",
        "            print(\"3. Set LOAD_MAE_PRETRAINED = False to use ImageNet weights\")\n",
        "            print(\"üîÑ Continuing with ImageNet pretrained weights...\")\n",
        "            MAE_ENCODER_WEIGHTS = None\n",
        "            TRAINING_CONFIG['mae_pretrained'] = False\n",
        "            TRAINING_CONFIG['pretrained'] = True\n",
        "\n",
        "else:\n",
        "    print(\"‚è≠Ô∏è Skipping MAE loading - will use ImageNet pretrained weights\")\n",
        "    MAE_ENCODER_WEIGHTS = None\n",
        "    TRAINING_CONFIG['mae_pretrained'] = False\n",
        "    TRAINING_CONFIG['pretrained'] = True\n",
        "\n",
        "# Test model creation (optional - this creates a model to verify everything works)\n",
        "print(f\"\\nüß™ Testing model creation...\")\n",
        "try:\n",
        "    test_model = create_mae_initialized_model(\n",
        "        num_classes=NUM_CLASSES,\n",
        "        model_name=TRAINING_CONFIG['model_name'],\n",
        "        mae_weights=MAE_ENCODER_WEIGHTS\n",
        "    )\n",
        "    \n",
        "    # Test forward pass\n",
        "    test_input = torch.randn(1, 3, 224, 224)\n",
        "    with torch.no_grad():\n",
        "        test_output = test_model(test_input)\n",
        "    \n",
        "    print(f\"‚úÖ Model test successful!\")\n",
        "    print(f\"üìä Input shape: {test_input.shape}\")\n",
        "    print(f\"üìä Output shape: {test_output.shape}\")\n",
        "    print(f\"üéØ Model ready for training!\")\n",
        "    \n",
        "    # Clean up test model\n",
        "    del test_model, test_input, test_output\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Model test failed: {e}\")\n",
        "\n",
        "print(f\"\\n\" + \"=\"*60)\n",
        "print(f\"‚úÖ MAE INITIALIZATION SETUP COMPLETE!\")\n",
        "print(f\"ü§ñ MAE pretrained: {TRAINING_CONFIG.get('mae_pretrained', False)}\")\n",
        "print(f\"üåê ImageNet pretrained: {TRAINING_CONFIG.get('pretrained', True)}\")\n",
        "print(f\"üìä Model: {TRAINING_CONFIG['model_name']} with {NUM_CLASSES} classes\")\n",
        "\n",
        "if TRAINING_CONFIG.get('mae_pretrained', False):\n",
        "    print(\"üéâ Your model will start with MAE-learned features specific to fish images!\")\n",
        "    print(\"üöÄ This should lead to faster training and better performance!\")\n",
        "else:\n",
        "    print(\"üåê Your model will use standard ImageNet pretrained features.\")\n",
        "\n",
        "print(\"üéØ Ready to proceed to training!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a481fea",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper: Copy MAE Model to Google Drive (if needed)\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "print(\"üîç CHECKING MAE MODEL AVAILABILITY\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Define possible local locations (in cloned repo)\n",
        "local_mae_locations = [\n",
        "    '/content/ViT-FishID/mae_checkpoints/mae_final_model.pth',\n",
        "    '/content/ViT-FishID/mae_checkpoints/mae_best_model.pth',\n",
        "]\n",
        "\n",
        "# Define Google Drive location\n",
        "gdrive_mae_dir = '/content/drive/MyDrive/mae_checkpoints'\n",
        "os.makedirs(gdrive_mae_dir, exist_ok=True)\n",
        "\n",
        "# Check and copy MAE models if they exist locally but not in Google Drive\n",
        "for local_path in local_mae_locations:\n",
        "    model_name = os.path.basename(local_path)\n",
        "    gdrive_path = os.path.join(gdrive_mae_dir, model_name)\n",
        "    \n",
        "    if os.path.exists(local_path):\n",
        "        file_size = os.path.getsize(local_path) / (1024**2)\n",
        "        print(f\"‚úÖ Found local MAE model: {model_name} ({file_size:.1f} MB)\")\n",
        "        \n",
        "        if not os.path.exists(gdrive_path):\n",
        "            print(f\"üì• Copying to Google Drive...\")\n",
        "            try:\n",
        "                shutil.copy2(local_path, gdrive_path)\n",
        "                print(f\"‚úÖ Copied {model_name} to Google Drive\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Error copying {model_name}: {e}\")\n",
        "        else:\n",
        "            print(f\"‚úÖ {model_name} already exists in Google Drive\")\n",
        "    else:\n",
        "        print(f\"‚ùå Local MAE model not found: {model_name}\")\n",
        "\n",
        "# List available MAE models in Google Drive\n",
        "print(f\"\\nüìÅ Available MAE models in Google Drive:\")\n",
        "if os.path.exists(gdrive_mae_dir):\n",
        "    mae_files = [f for f in os.listdir(gdrive_mae_dir) if f.endswith('.pth')]\n",
        "    if mae_files:\n",
        "        for mae_file in mae_files:\n",
        "            file_path = os.path.join(gdrive_mae_dir, mae_file)\n",
        "            file_size = os.path.getsize(file_path) / (1024**2)\n",
        "            print(f\"  üìÑ {mae_file} ({file_size:.1f} MB)\")\n",
        "    else:\n",
        "        print(\"  ‚ùå No MAE models found in Google Drive\")\n",
        "        print(\"  üìù Please upload your MAE model manually to /content/drive/MyDrive/mae_checkpoints/\")\n",
        "else:\n",
        "    print(\"  ‚ùå Mae checkpoints directory not found in Google Drive\")\n",
        "\n",
        "print(\"\\n‚úÖ MAE model check complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa9cbd50",
      "metadata": {
        "id": "aa9cbd50"
      },
      "source": [
        "## üöÄ Step 8: Start Semi-Supervised Training\n",
        "\n",
        "This cell will start the complete training process. Expected time: 4-6 hours for 100 epochs.\n",
        "\n",
        "**Training Process:**\n",
        "1. **Supervised Learning**: Uses labeled fish images with ground truth\n",
        "2. **Semi-Supervised Learning**: Leverages unlabeled images with pseudo-labels\n",
        "3. **EMA Teacher-Student**: Uses exponential moving average for consistency\n",
        "4. **Automatic Checkpointing**: Saves progress every 10 epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0fffcae",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a39f349",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c873987",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "8bd6a6ca",
      "metadata": {},
      "source": [
        "## üîÑ Step 7b: Resume Training (If Interrupted)\n",
        "\n",
        "**Use this section if your training was interrupted and you want to continue from where you left off.**\n",
        "\n",
        "This will automatically find your latest checkpoint and resume training from that point."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "njLKb7xaepxo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njLKb7xaepxo",
        "outputId": "2404e35d-a058-4349-bafa-18e98981bb07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ STARTING EXTENDED TRAINING SESSION\n",
            "============================================================\n",
            "üìÇ Resuming from: checkpoint_epoch_99.pth\n",
            "üöÄ Starting training from epoch: 100\n",
            "üìä Training for 1 more epochs...\n",
            "üéØ Target: 100 total epochs\n",
            "‚è±Ô∏è Estimated time: 4-6 minutes\n",
            "üíæ Checkpoints saved to: /content/drive/MyDrive/ViT-FishID/checkpoints_extended\n",
            "\n",
            "üìã Extended Training Command:\n",
            "python train.py \n",
            "    --mode semi_supervised \n",
            "    --data_dir /content/fish_cutouts \n",
            "    --epochs 100 \n",
            "    --batch_size 16 \n",
            "    --learning_rate 0.0001 \n",
            "    --weight_decay 0.05 \n",
            "    --model_name vit_base_patch16_224 \n",
            "    --consistency_weight 2.0 \n",
            "    --pseudo_label_threshold 0.7 \n",
            "    --temperature 4.0 \n",
            "    --warmup_epochs 5 \n",
            "    --ramp_up_epochs 15 \n",
            "    --save_dir /content/drive/MyDrive/ViT-FishID/checkpoints_extended \n",
            "    --save_frequency 1 \n",
            "    --resume_from /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_99.pth \n",
            "    --use_wandb \n",
            "    --pretrained\n",
            "\n",
            "============================================================\n",
            "üé¨ TRAINING STARTED - EPOCH 100 TO 100\n",
            "‚è∞ Started at: 2025-08-15 07:03:08\n",
            "‚úÖ Commented out line saving ema_teacher state_dict: 'ema_teacher_state_dict': trainer.ema_teacher.teacher.state_dict(),  # Fixed key name\n",
            "‚úÖ Modified /content/ViT-FishID/trainer.py to skip saving EMA teacher state_dict.\n",
            "2025-08-15 07:03:16.032238: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-08-15 07:03:16.049070: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1755241396.070136    2955 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1755241396.076517    2955 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1755241396.092669    2955 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755241396.092697    2955 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755241396.092700    2955 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755241396.092703    2955 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-08-15 07:03:16.097419: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Random seed set to 42\n",
            "Using GPU: NVIDIA A100-SXM4-40GB\n",
            "üêü ViT-FishID Training\n",
            "üìä Mode: semi_supervised\n",
            "üñ•Ô∏è  Device: cuda\n",
            "üìÅ Data directory: /content/fish_cutouts\n",
            "\n",
            "üì¶ Creating data loaders...\n",
            "‚ö†Ô∏è  Warning: Some classes have only 1 sample(s). Using random splitting instead of stratified.\n",
            "   Classes with 1 sample: ['Carangidae_Caranx_heberi', 'Serranidae_Lipropoma_spp1', 'Sparidae_Sparodon_durbanesis']\n",
            "/content/ViT-FishID/data.py:229: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
            "  A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
            "üìä Dataset initialized:\n",
            "  - Labeled samples: 3,084\n",
            "  - Unlabeled samples: 6,168\n",
            "  - Total samples per epoch: 9,252\n",
            "üìä Semi-supervised data loaders created:\n",
            "  - Train labeled: 3,084\n",
            "  - Train unlabeled: 6,168\n",
            "  - Val samples: 1,029\n",
            "  - Test samples: 1,029\n",
            "  - Classes: 37\n",
            "  - Split ratios: Train=60.0%, Val=20.0%, Test=20.0%\n",
            "üè∑Ô∏è  Classes (37): ['Carangidae_Caranx_heberi', 'Carangidae_Pseudocaranx_dentex', 'Carangidae_Seriola_dumerili', 'Carangidae_Seriola_lalandi', 'Carangidae_Seriola_rivoliana', 'Carangidae_Trachurus_delagoa', 'Serranidae_Aulacocephalus_temminckii', 'Serranidae_Epinephelus_andersoni', 'Serranidae_Epinephelus_marginatus', 'Serranidae_Epinephelus_rivulatus', 'Serranidae_Epinephelus_tukula', 'Serranidae_Lipropoma_spp1', 'Serranidae_Serranus_knysnaensis', 'Sparidae_Argyrops_spinifer', 'Sparidae_Boopsoidea_inornata', 'Sparidae_Cheimerius_nufar', 'Sparidae_Chrysoblephus_anglicus', 'Sparidae_Chrysoblephus_cristiceps', 'Sparidae_Chrysoblephus_lophus', 'Sparidae_Chrysoblephus_puniceus', 'Sparidae_Cymatoceps_nasutus', 'Sparidae_Diplodus_capensis', 'Sparidae_Diplodus_hottentotus', 'Sparidae_Pachymetopon_aeneum', 'Sparidae_Pachymetopon_grande', 'Sparidae_Pagellus_bellottii_natalensis', 'Sparidae_Petrus_rupestris', 'Sparidae_Polyamblydon_germanum', 'Sparidae_Polysteganus_praeorbitalis', 'Sparidae_Polysteganus_undulosus', 'Sparidae_Porcostoma_dentata', 'Sparidae_Rhabdosargus_holubi', 'Sparidae_Rhabdosargus_sarba', 'Sparidae_Rhabdosargus_thorpei', 'Sparidae_Sarpa_salpa', 'Sparidae_Sparodon_durbanesis', 'Sparidae_Spondyliosoma_emarginatum']\n",
            "üìä Test set available with 1,029 samples for final evaluation\n",
            "\n",
            "üß† Creating ViT model: vit_base_patch16_224\n",
            "model.safetensors: 100% 346M/346M [00:00<00:00, 479MB/s]\n",
            "‚úÖ EMA Teacher initialized with momentum: 0.999\n",
            "üìä Model parameters: 85,828,645\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcativthomson\u001b[0m (\u001b[33mcativthomson-university-of-cape-town\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.21.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/ViT-FishID/wandb/run-20250815_070324-ogt296e8\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msemi_supervised_vit_base_patch16_224_20250815_070323\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/cativthomson-university-of-cape-town/vit-fish-id\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/cativthomson-university-of-cape-town/vit-fish-id/runs/ogt296e8\u001b[0m\n",
            "‚úÖ W&B initialized: vit-fish-id/semi_supervised_vit_base_patch16_224_20250815_070323\n",
            "\n",
            "üöÄ Creating trainer...\n",
            "‚úÖ Semi-Supervised Trainer initialized\n",
            "  - Consistency weight: 2.0\n",
            "  - Pseudo-label threshold: 0.7\n",
            "  - Learning rate: 0.0001\n",
            "  - Warmup epochs: 5\n",
            "  - Ramp-up epochs: 15\n",
            "üì• Resuming from checkpoint: /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_99.pth\n",
            "‚úÖ Successfully loaded checkpoint from epoch 99\n",
            "üìä Previous best accuracy: 87.56073858114675\n",
            "üöÄ Resuming training from epoch 100\n",
            "\n",
            "üéØ Starting semi_supervised training...\n",
            "üí° Note: Test set is reserved for final evaluation and not used during training\n",
            "üîÑ Resuming training from epoch 100\n",
            "‚è∞ Remaining epochs: 1\n",
            "üìÅ Checkpoints will be saved to: /content/drive/MyDrive/ViT-FishID/checkpoints_extended\n",
            "Epoch 100: 100% 578/578 [01:37<00:00,  5.93it/s, Total=0.1759, Sup=0.1095, Cons=0.0332, L-Acc=97.0%, P-Acc=88.2%]\n",
            "                                               \n",
            "üìä Epoch 101/100\n",
            "Train - Total Loss: 0.1759\n",
            "Train - Labeled Acc: 97.0%, Pseudo Acc: 88.2%\n",
            "Train - High-conf Pseudo: 1212/6165 (19.7%)\n",
            "Student Val - Acc: 77.9%\n",
            "Teacher Val - Acc: 75.7%\n",
            "Checkpoint saved to /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_100.pth\n",
            "üíæ Backup saved to: /content/drive/MyDrive/ViT-FishID/checkpoints_backup/checkpoint_epoch_100.pth\n",
            "üìä Epoch 100 checkpoint saved (Size: 982.4 MB)\n",
            "\n",
            "üéâ Training completed! Best validation accuracy: 87.56%\n",
            "\n",
            "‚úÖ Training completed!\n",
            "üí° Use evaluate.py with the test set for final unbiased performance metrics\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading history steps 12-12, summary, console lines 19-35 (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading history steps 12-12, summary, console lines 19-35 (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading history steps 12-12, summary, console lines 19-35 (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading history steps 12-12, summary, console lines 19-35 (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading history steps 12-12, summary, console lines 19-35 (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading history steps 12-12, summary, console lines 19-35 (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                               epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       learning_rate ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/consistency_loss ‚ñà‚ñÉ‚ñá‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/consistency_weight ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/high_conf_ratio ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/labeled_accuracy ‚ñà‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 train/learning_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/pseudo_accuracy ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/supervised_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/total_loss ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÇ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        train_epoch/consistency_loss ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_epoch/high_conf_pseudo_labels ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        train_epoch/labeled_accuracy ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train_epoch/labeled_samples ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train_epoch/pseudo_accuracy ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train_epoch/supervised_loss ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train_epoch/total_loss ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train_epoch/unlabeled_samples ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                val/student_top1_acc ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                val/student_top5_acc ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                val/teacher_top1_acc ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                val/teacher_top5_acc ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                               epoch 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       learning_rate 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/consistency_loss 0.02646\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/consistency_weight 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/high_conf_ratio 18.24359\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/labeled_accuracy 97.0297\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 train/learning_rate 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/pseudo_accuracy 88.6406\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/supervised_loss 0.03465\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/total_loss 0.08756\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        train_epoch/consistency_loss 0.03318\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_epoch/high_conf_pseudo_labels 1212\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        train_epoch/labeled_accuracy 97.04833\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train_epoch/labeled_samples 3083\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train_epoch/pseudo_accuracy 88.20132\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train_epoch/supervised_loss 0.10952\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train_epoch/total_loss 0.17589\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train_epoch/unlabeled_samples 6165\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                val/student_top1_acc 77.93975\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                val/student_top5_acc 92.80855\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                val/teacher_top1_acc 75.70457\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                val/teacher_top5_acc 94.94655\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33msemi_supervised_vit_base_patch16_224_20250815_070323\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/cativthomson-university-of-cape-town/vit-fish-id/runs/ogt296e8\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/cativthomson-university-of-cape-town/vit-fish-id\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250815_070324-ogt296e8/logs\u001b[0m\n",
            "\n",
            "üéâ Training completed successfully!\n",
            "üíæ Checkpoints saved to: /content/drive/MyDrive/ViT-FishID/checkpoints_extended\n",
            "üèÜ Best accuracy: 87.56%\n",
            "\n",
            "============================================================\n",
            "üéâ EXTENDED TRAINING COMPLETED!\n",
            "‚è∞ Finished at: 2025-08-15 07:05:32\n",
            "üèÜ Total epochs completed: 100\n",
            "üíæ All checkpoints saved to Google Drive\n",
            "\n",
            "‚úÖ Your model is ready for evaluation and deployment!\n"
          ]
        }
      ],
      "source": [
        "# Start Semi-Supervised Training with Optional MAE Initialization\n",
        "import os\n",
        "import glob\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"üöÄ STARTING SEMI-SUPERVISED FISH CLASSIFICATION TRAINING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Change to repository directory\n",
        "%cd /content/ViT-FishID\n",
        "\n",
        "# Check for existing checkpoints to resume from\n",
        "RESUME_FROM = None\n",
        "if os.path.exists(TRAINING_CONFIG['checkpoint_dir']):\n",
        "    checkpoints = glob.glob(os.path.join(TRAINING_CONFIG['checkpoint_dir'], 'checkpoint_epoch_*.pth'))\n",
        "    if checkpoints:\n",
        "        # Find the latest checkpoint\n",
        "        epoch_numbers = []\n",
        "        for cp in checkpoints:\n",
        "            try:\n",
        "                epoch_num = int(cp.split('epoch_')[1].split('.')[0])\n",
        "                epoch_numbers.append((epoch_num, cp))\n",
        "            except:\n",
        "                continue\n",
        "        \n",
        "        if epoch_numbers:\n",
        "            epoch_numbers.sort(key=lambda x: x[0], reverse=True)  # Latest first\n",
        "            latest_epoch, latest_checkpoint = epoch_numbers[0]\n",
        "            print(f\"üîç Found existing checkpoints. Latest: Epoch {latest_epoch}\")\n",
        "            \n",
        "            # Ask user if they want to resume (auto-skip in Colab for now)\n",
        "            # resume_choice = input(\"Do you want to resume from the latest checkpoint? (y/n): \").lower().strip()\n",
        "            resume_choice = 'n'  # Set to 'y' if you want to auto-resume\n",
        "            \n",
        "            if resume_choice in ['y', 'yes']:\n",
        "                RESUME_FROM = latest_checkpoint\n",
        "                print(f\"‚úÖ Will resume from: {os.path.basename(latest_checkpoint)}\")\n",
        "            else:\n",
        "                print(\"üÜï Starting fresh training from epoch 1\")\n",
        "\n",
        "# Create a modified training script if we have MAE weights\n",
        "if TRAINING_CONFIG.get('mae_pretrained', False) and 'MAE_ENCODER_WEIGHTS' in globals() and MAE_ENCODER_WEIGHTS is not None:\n",
        "    print(\"ü§ñ Creating MAE-enhanced training script...\")\n",
        "    \n",
        "    # Create custom train script that initializes with MAE weights\n",
        "    mae_train_script = \"\"\"#!/usr/bin/env python3\n",
        "import sys\n",
        "sys.path.append('/content/ViT-FishID')\n",
        "\n",
        "import torch\n",
        "import argparse\n",
        "from model import ViTForFishClassification\n",
        "\n",
        "# Function to create MAE-initialized model\n",
        "def create_mae_initialized_model(num_classes, model_name, mae_weights):\n",
        "    model = ViTForFishClassification(\n",
        "        num_classes=num_classes,\n",
        "        model_name=model_name,\n",
        "        pretrained=False,  # Don't use ImageNet\n",
        "        dropout_rate=0.1\n",
        "    )\n",
        "    \n",
        "    if mae_weights is not None:\n",
        "        backbone_state = model.backbone.state_dict()\n",
        "        updated_keys = []\n",
        "        \n",
        "        for mae_key, mae_weight in mae_weights.items():\n",
        "            if mae_key in backbone_state:\n",
        "                if mae_weight.shape == backbone_state[mae_key].shape:\n",
        "                    backbone_state[mae_key] = mae_weight.clone()\n",
        "                    updated_keys.append(mae_key)\n",
        "        \n",
        "        model.backbone.load_state_dict(backbone_state)\n",
        "        print(f\"‚úÖ Loaded {len(updated_keys)} MAE encoder weights into model\")\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Load MAE weights\n",
        "mae_checkpoint = torch.load('{}', map_location='cpu')\n",
        "mae_state_dict = mae_checkpoint.get('model_state_dict', mae_checkpoint.get('state_dict', mae_checkpoint))\n",
        "\n",
        "mae_weights = {{}}\n",
        "for key, value in mae_state_dict.items():\n",
        "    if any(prefix in key for prefix in ['patch_embed', 'pos_embed', 'cls_token', 'blocks', 'norm']) and not any(exclude in key for exclude in ['decoder', 'mask_token', 'head']):\n",
        "        mae_weights[key] = value\n",
        "\n",
        "print(f\"ü§ñ Loaded {{len(mae_weights)}} MAE encoder weights\")\n",
        "\n",
        "# Now run the original training with MAE initialization\n",
        "\"\"\".format(TRAINING_CONFIG.get('mae_model_path', ''))\n",
        "    \n",
        "    # Write the custom script\n",
        "    with open('/content/mae_init_prefix.py', 'w') as f:\n",
        "        f.write(mae_train_script)\n",
        "    \n",
        "    # Build training command with MAE initialization\n",
        "    training_cmd = f\"\"\"python -c \"\n",
        "import sys\n",
        "sys.path.append('/content/ViT-FishID')\n",
        "exec(open('/content/mae_init_prefix.py').read())\n",
        "\n",
        "# Now import and run training\n",
        "from train import *\n",
        "import torch\n",
        "\n",
        "# Override model creation in train.py\n",
        "original_args = parse_arguments()\n",
        "\n",
        "# Parse our arguments\n",
        "class Args:\n",
        "    def __init__(self):\n",
        "        self.mode = '{TRAINING_CONFIG['mode']}'\n",
        "        self.data_dir = '{TRAINING_CONFIG['data_dir']}'\n",
        "        self.epochs = {TRAINING_CONFIG['epochs']}\n",
        "        self.batch_size = {TRAINING_CONFIG['batch_size']}\n",
        "        self.learning_rate = {TRAINING_CONFIG['learning_rate']}\n",
        "        self.weight_decay = {TRAINING_CONFIG['weight_decay']}\n",
        "        self.model_name = '{TRAINING_CONFIG['model_name']}'\n",
        "        self.consistency_weight = {TRAINING_CONFIG['consistency_weight']}\n",
        "        self.pseudo_label_threshold = {TRAINING_CONFIG['pseudo_label_threshold']}\n",
        "        self.temperature = {TRAINING_CONFIG['temperature']}\n",
        "        self.warmup_epochs = {TRAINING_CONFIG['warmup_epochs']}\n",
        "        self.ramp_up_epochs = {TRAINING_CONFIG['ramp_up_epochs']}\n",
        "        self.save_dir = '{TRAINING_CONFIG['checkpoint_dir']}'\n",
        "        self.save_frequency = {TRAINING_CONFIG['save_frequency']}\n",
        "        self.pretrained = False\n",
        "        self.use_wandb = {str(TRAINING_CONFIG['use_wandb']).lower()}\n",
        "        self.resume_from = {'None' if not RESUME_FROM else f'\\\\'{RESUME_FROM}\\\\''}\n",
        "        self.num_workers = 4\n",
        "        self.image_size = 224\n",
        "        self.dropout_rate = 0.1\n",
        "        self.num_classes = {NUM_CLASSES}\n",
        "        \n",
        "args = Args()\n",
        "\n",
        "# Set up device and seed\n",
        "device = get_device()\n",
        "set_seed(42)\n",
        "\n",
        "# Create MAE-initialized model\n",
        "print('ü§ñ Creating MAE-initialized model for training...')\n",
        "student_model = create_mae_initialized_model(\n",
        "    num_classes=args.num_classes,\n",
        "    model_name=args.model_name,\n",
        "    mae_weights=mae_weights\n",
        ").to(device)\n",
        "\n",
        "# Continue with regular training process\n",
        "from trainer import EMATrainer, SemiSupervisedTrainer\n",
        "from data import create_dataloaders, create_semi_supervised_dataloaders\n",
        "\n",
        "# Create data loaders\n",
        "if args.mode == 'supervised':\n",
        "    train_loader, val_loader, num_classes = create_dataloaders(\n",
        "        args.data_dir,\n",
        "        batch_size=args.batch_size,\n",
        "        image_size=args.image_size,\n",
        "        num_workers=args.num_workers\n",
        "    )\n",
        "    unlabeled_loader = None\n",
        "else:\n",
        "    train_loader, val_loader, unlabeled_loader, num_classes = create_semi_supervised_dataloaders(\n",
        "        args.data_dir,\n",
        "        batch_size=args.batch_size,\n",
        "        image_size=args.image_size,\n",
        "        num_workers=args.num_workers\n",
        "    )\n",
        "\n",
        "print(f'üìä Number of classes: {{num_classes}}')\n",
        "print(f'üéØ Training mode: {{args.mode}}')\n",
        "\n",
        "# Create trainer\n",
        "if args.mode == 'semi_supervised' and unlabeled_loader is not None:\n",
        "    trainer = SemiSupervisedTrainer(\n",
        "        student_model=student_model,\n",
        "        device=device,\n",
        "        learning_rate=args.learning_rate,\n",
        "        weight_decay=args.weight_decay,\n",
        "        consistency_weight=args.consistency_weight,\n",
        "        pseudo_label_threshold=args.pseudo_label_threshold,\n",
        "        temperature=args.temperature,\n",
        "        warmup_epochs=args.warmup_epochs,\n",
        "        ramp_up_epochs=args.ramp_up_epochs\n",
        "    )\n",
        "else:\n",
        "    trainer = EMATrainer(\n",
        "        student_model=student_model,\n",
        "        device=device,\n",
        "        learning_rate=args.learning_rate,\n",
        "        weight_decay=args.weight_decay\n",
        "    )\n",
        "\n",
        "# Initialize W&B\n",
        "if args.use_wandb:\n",
        "    import wandb\n",
        "    wandb.init(\n",
        "        project='ViT-FishID-MAE-Training',\n",
        "        config=vars(args),\n",
        "        tags=['mae-initialized', 'fish-classification']\n",
        "    )\n",
        "\n",
        "# Resume from checkpoint if specified\n",
        "if args.resume_from and args.resume_from != 'None':\n",
        "    print(f'üì• Resuming from checkpoint: {{args.resume_from}}')\n",
        "    try:\n",
        "        checkpoint = torch.load(args.resume_from, map_location=device)\n",
        "        trainer.student_model.load_state_dict(checkpoint['student_state_dict'])\n",
        "        if hasattr(trainer, 'teacher_model') and 'teacher_state_dict' in checkpoint:\n",
        "            trainer.teacher_model.teacher_model.load_state_dict(checkpoint['teacher_state_dict'])\n",
        "        trainer.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        start_epoch = checkpoint.get('epoch', 0) + 1\n",
        "        print(f'‚úÖ Resumed from epoch {{start_epoch}}')\n",
        "    except Exception as e:\n",
        "        print(f'‚ùå Error loading checkpoint: {{e}}')\n",
        "        start_epoch = 1\n",
        "else:\n",
        "    start_epoch = 1\n",
        "\n",
        "print(f'üöÄ Starting training from epoch {{start_epoch}}')\n",
        "\n",
        "# Training loop\n",
        "best_accuracy = 0.0\n",
        "for epoch in range(start_epoch, args.epochs + 1):\n",
        "    print(f'\\\\nüìÖ Epoch {{epoch}}/{{args.epochs}}')\n",
        "    \n",
        "    # Training\n",
        "    if args.mode == 'semi_supervised' and unlabeled_loader is not None:\n",
        "        train_loss = trainer.train_epoch(train_loader, unlabeled_loader, epoch)\n",
        "    else:\n",
        "        train_loss = trainer.train_epoch(train_loader, epoch)\n",
        "    \n",
        "    # Validation\n",
        "    val_accuracy = trainer.validate(val_loader)\n",
        "    \n",
        "    # Update best accuracy\n",
        "    is_best = val_accuracy > best_accuracy\n",
        "    if is_best:\n",
        "        best_accuracy = val_accuracy\n",
        "    \n",
        "    print(f'üìä Epoch {{epoch}} - Train Loss: {{train_loss:.4f}}, Val Acc: {{val_accuracy:.2f}}% (Best: {{best_accuracy:.2f}}%)')\n",
        "    \n",
        "    # Save checkpoint\n",
        "    if epoch % args.save_frequency == 0 or is_best:\n",
        "        checkpoint_data = {{\n",
        "            'epoch': epoch,\n",
        "            'student_state_dict': trainer.student_model.state_dict(),\n",
        "            'optimizer_state_dict': trainer.optimizer.state_dict(),\n",
        "            'best_accuracy': best_accuracy,\n",
        "            'train_loss': train_loss,\n",
        "            'val_accuracy': val_accuracy\n",
        "        }}\n",
        "        \n",
        "        if hasattr(trainer, 'teacher_model'):\n",
        "            checkpoint_data['teacher_state_dict'] = trainer.teacher_model.teacher_model.state_dict()\n",
        "            checkpoint_data['teacher_acc'] = getattr(trainer, 'teacher_accuracy', val_accuracy)\n",
        "        \n",
        "        # Save regular checkpoint\n",
        "        if epoch % args.save_frequency == 0:\n",
        "            checkpoint_path = os.path.join(args.save_dir, f'checkpoint_epoch_{{epoch}}.pth')\n",
        "            torch.save(checkpoint_data, checkpoint_path)\n",
        "            print(f'üíæ Saved checkpoint: {{checkpoint_path}}')\n",
        "        \n",
        "        # Save best model\n",
        "        if is_best:\n",
        "            best_path = os.path.join(args.save_dir, 'model_best.pth')\n",
        "            torch.save(checkpoint_data, best_path)\n",
        "            print(f'üèÜ New best model saved: {{best_path}}')\n",
        "    \n",
        "    # W&B logging\n",
        "    if args.use_wandb:\n",
        "        wandb.log({{\n",
        "            'epoch': epoch,\n",
        "            'train_loss': train_loss,\n",
        "            'val_accuracy': val_accuracy,\n",
        "            'best_accuracy': best_accuracy\n",
        "        }})\n",
        "\n",
        "print(f'\\\\nüéâ Training completed!')\n",
        "print(f'üèÜ Best accuracy: {{best_accuracy:.2f}}%')\n",
        "\n",
        "if args.use_wandb:\n",
        "    wandb.finish()\n",
        "\" \"\"\"\n",
        "\n",
        "else:\n",
        "    # Build standard training command without MAE\n",
        "    training_cmd = f\"\"\"python train.py \\\\\n",
        "    --mode {TRAINING_CONFIG['mode']} \\\\\n",
        "    --data_dir {TRAINING_CONFIG['data_dir']} \\\\\n",
        "    --epochs {TRAINING_CONFIG['epochs']} \\\\\n",
        "    --batch_size {TRAINING_CONFIG['batch_size']} \\\\\n",
        "    --learning_rate {TRAINING_CONFIG['learning_rate']} \\\\\n",
        "    --weight_decay {TRAINING_CONFIG['weight_decay']} \\\\\n",
        "    --model_name {TRAINING_CONFIG['model_name']} \\\\\n",
        "    --consistency_weight {TRAINING_CONFIG['consistency_weight']} \\\\\n",
        "    --pseudo_label_threshold {TRAINING_CONFIG['pseudo_label_threshold']} \\\\\n",
        "    --temperature {TRAINING_CONFIG['temperature']} \\\\\n",
        "    --warmup_epochs {TRAINING_CONFIG['warmup_epochs']} \\\\\n",
        "    --ramp_up_epochs {TRAINING_CONFIG['ramp_up_epochs']} \\\\\n",
        "    --save_dir {TRAINING_CONFIG['checkpoint_dir']} \\\\\n",
        "    --save_frequency {TRAINING_CONFIG['save_frequency']}\"\"\"\n",
        "\n",
        "    # Add resume checkpoint if found\n",
        "    if RESUME_FROM:\n",
        "        training_cmd += f\" \\\\\\n    --resume_from {RESUME_FROM}\"\n",
        "\n",
        "    # Add pretrained flag\n",
        "    if TRAINING_CONFIG['pretrained']:\n",
        "        training_cmd += \" \\\\\\n    --pretrained\"\n",
        "\n",
        "    # Add W&B logging\n",
        "    if TRAINING_CONFIG['use_wandb']:\n",
        "        training_cmd += \" \\\\\\n    --use_wandb\"\n",
        "\n",
        "print(\"üìã TRAINING CONFIGURATION:\")\n",
        "print(\"=\"*60)\n",
        "print(f\"üéØ Training {TRAINING_CONFIG['num_classes']} fish species\")\n",
        "print(f\"üìä Mode: {TRAINING_CONFIG['mode']}\")\n",
        "print(f\"ü§ñ MAE pretrained: {TRAINING_CONFIG.get('mae_pretrained', False)}\")\n",
        "print(f\"üåê ImageNet pretrained: {TRAINING_CONFIG.get('pretrained', True)}\")\n",
        "\n",
        "if RESUME_FROM:\n",
        "    print(f\"üîÑ Resuming from: {os.path.basename(RESUME_FROM)}\")\n",
        "else:\n",
        "    print(f\"üÜï Starting fresh training\")\n",
        "\n",
        "print(f\"‚è±Ô∏è Estimated time: {TRAINING_CONFIG['epochs'] * 3 / 60:.1f} hours\")\n",
        "print(f\"üíæ Checkpoints: {TRAINING_CONFIG['checkpoint_dir']}\")\n",
        "print(f\"üìà W&B logging: {TRAINING_CONFIG['use_wandb']}\")\n",
        "\n",
        "if TRAINING_CONFIG.get('mae_pretrained', False):\n",
        "    print(f\"üéâ Using MAE-learned features from: {os.path.basename(TRAINING_CONFIG.get('mae_model_path', ''))}\")\n",
        "    print(f\"üöÄ This should significantly improve training performance!\")\n",
        "\n",
        "print(f\"\\nüé¨ TRAINING STARTED\")\n",
        "print(\"‚è∞ Started at:\", datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
        "\n",
        "# Execute training\n",
        "!{training_cmd}\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üéâ TRAINING COMPLETED!\")\n",
        "print(\"‚è∞ Finished at:\", datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
        "\n",
        "# Check for results\n",
        "best_model_path = os.path.join(TRAINING_CONFIG['checkpoint_dir'], 'model_best.pth')\n",
        "if os.path.exists(best_model_path):\n",
        "    try:\n",
        "        import torch\n",
        "        checkpoint = torch.load(best_model_path, map_location='cpu')\n",
        "        if 'best_accuracy' in checkpoint:\n",
        "            print(f\"üèÜ Best accuracy achieved: {checkpoint['best_accuracy']:.2f}%\")\n",
        "        if 'epoch' in checkpoint:\n",
        "            print(f\"üìä Best model from epoch: {checkpoint['epoch']}\")\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "print(\"‚úÖ Your MAE-enhanced model is ready for evaluation and deployment!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5af5177",
      "metadata": {
        "id": "b5af5177"
      },
      "source": [
        "## üìä Step 9: Check Training Results\n",
        "\n",
        "Review the training progress and model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87ea96e8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87ea96e8",
        "outputId": "2054291d-a4ae-48d9-d5ed-2529032142bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÅ Checking results in: /content/drive/MyDrive/ViT-FishID/checkpoints_extended\n",
            "\n",
            "‚úÖ Found 100 checkpoint(s) from extended training:\n",
            "  üìä Epoch 1: checkpoint_epoch_1.pth (982.4 MB)\n",
            "  üìä Epoch 2: checkpoint_epoch_2.pth (982.4 MB)\n",
            "  üìä Epoch 3: checkpoint_epoch_3.pth (982.4 MB)\n",
            "  üìä Epoch 4: checkpoint_epoch_4.pth (982.4 MB)\n",
            "  üìä Epoch 5: checkpoint_epoch_5.pth (982.4 MB)\n",
            "  üìä Epoch 6: checkpoint_epoch_6.pth (982.4 MB)\n",
            "  üìä Epoch 7: checkpoint_epoch_7.pth (982.4 MB)\n",
            "  üìä Epoch 8: checkpoint_epoch_8.pth (982.4 MB)\n",
            "  üìä Epoch 9: checkpoint_epoch_9.pth (982.4 MB)\n",
            "  üìä Epoch 10: checkpoint_epoch_10.pth (982.4 MB)\n",
            "  üìä Epoch 11: checkpoint_epoch_11.pth (982.4 MB)\n",
            "  üìä Epoch 12: checkpoint_epoch_12.pth (982.4 MB)\n",
            "  üìä Epoch 13: checkpoint_epoch_13.pth (982.4 MB)\n",
            "  üìä Epoch 14: checkpoint_epoch_14.pth (982.4 MB)\n",
            "  üìä Epoch 15: checkpoint_epoch_15.pth (982.4 MB)\n",
            "  üìä Epoch 16: checkpoint_epoch_16.pth (982.4 MB)\n",
            "  üìä Epoch 17: checkpoint_epoch_17.pth (982.4 MB)\n",
            "  üìä Epoch 18: checkpoint_epoch_18.pth (982.4 MB)\n",
            "  üìä Epoch 19: checkpoint_epoch_19.pth (982.4 MB)\n",
            "  üìä Epoch 20: checkpoint_epoch_20.pth (982.4 MB)\n",
            "  üìä Epoch 21: checkpoint_epoch_21.pth (982.4 MB)\n",
            "  üìä Epoch 22: checkpoint_epoch_22.pth (982.4 MB)\n",
            "  üìä Epoch 23: checkpoint_epoch_23.pth (982.4 MB)\n",
            "  üìä Epoch 24: checkpoint_epoch_24.pth (982.4 MB)\n",
            "  üìä Epoch 25: checkpoint_epoch_25.pth (982.4 MB)\n",
            "  üìä Epoch 26: checkpoint_epoch_26.pth (982.4 MB)\n",
            "  üìä Epoch 27: checkpoint_epoch_27.pth (982.4 MB)\n",
            "  üìä Epoch 28: checkpoint_epoch_28.pth (982.4 MB)\n",
            "  üìä Epoch 29: checkpoint_epoch_29.pth (982.4 MB)\n",
            "  üìä Epoch 30: checkpoint_epoch_30.pth (982.4 MB)\n",
            "  üìä Epoch 31: checkpoint_epoch_31.pth (982.4 MB)\n",
            "  üìä Epoch 32: checkpoint_epoch_32.pth (982.4 MB)\n",
            "  üìä Epoch 33: checkpoint_epoch_33.pth (982.4 MB)\n",
            "  üìä Epoch 34: checkpoint_epoch_34.pth (982.4 MB)\n",
            "  üìä Epoch 35: checkpoint_epoch_35.pth (982.4 MB)\n",
            "  üìä Epoch 36: checkpoint_epoch_36.pth (982.4 MB)\n",
            "  üìä Epoch 37: checkpoint_epoch_37.pth (982.4 MB)\n",
            "  üìä Epoch 38: checkpoint_epoch_38.pth (982.4 MB)\n",
            "  üìä Epoch 39: checkpoint_epoch_39.pth (982.4 MB)\n",
            "  üìä Epoch 40: checkpoint_epoch_40.pth (982.4 MB)\n",
            "  üìä Epoch 41: checkpoint_epoch_41.pth (982.4 MB)\n",
            "  üìä Epoch 42: checkpoint_epoch_42.pth (982.4 MB)\n",
            "  üìä Epoch 43: checkpoint_epoch_43.pth (982.4 MB)\n",
            "  üìä Epoch 44: checkpoint_epoch_44.pth (982.4 MB)\n",
            "  üìä Epoch 45: checkpoint_epoch_45.pth (982.4 MB)\n",
            "  üìä Epoch 46: checkpoint_epoch_46.pth (982.4 MB)\n",
            "  üìä Epoch 47: checkpoint_epoch_47.pth (982.4 MB)\n",
            "  üìä Epoch 48: checkpoint_epoch_48.pth (982.4 MB)\n",
            "  üìä Epoch 49: checkpoint_epoch_49.pth (982.4 MB)\n",
            "  üìä Epoch 50: checkpoint_epoch_50.pth (982.4 MB)\n",
            "  üìä Epoch 51: checkpoint_epoch_51.pth (982.4 MB)\n",
            "  üìä Epoch 52: checkpoint_epoch_52.pth (982.4 MB)\n",
            "  üìä Epoch 53: checkpoint_epoch_53.pth (982.4 MB)\n",
            "  üìä Epoch 54: checkpoint_epoch_54.pth (982.4 MB)\n",
            "  üìä Epoch 55: checkpoint_epoch_55.pth (982.4 MB)\n",
            "  üìä Epoch 56: checkpoint_epoch_56.pth (982.4 MB)\n",
            "  üìä Epoch 57: checkpoint_epoch_57.pth (982.4 MB)\n",
            "  üìä Epoch 58: checkpoint_epoch_58.pth (982.4 MB)\n",
            "  üìä Epoch 59: checkpoint_epoch_59.pth (982.4 MB)\n",
            "  üìä Epoch 60: checkpoint_epoch_60.pth (982.4 MB)\n",
            "  üìä Epoch 61: checkpoint_epoch_61.pth (982.4 MB)\n",
            "  üìä Epoch 62: checkpoint_epoch_62.pth (982.4 MB)\n",
            "  üìä Epoch 63: checkpoint_epoch_63.pth (982.4 MB)\n",
            "  üìä Epoch 64: checkpoint_epoch_64.pth (982.4 MB)\n",
            "  üìä Epoch 65: checkpoint_epoch_65.pth (982.4 MB)\n",
            "  üìä Epoch 66: checkpoint_epoch_66.pth (982.4 MB)\n",
            "  üìä Epoch 67: checkpoint_epoch_67.pth (982.4 MB)\n",
            "  üìä Epoch 68: checkpoint_epoch_68.pth (982.4 MB)\n",
            "  üìä Epoch 69: checkpoint_epoch_69.pth (982.4 MB)\n",
            "  üìä Epoch 70: checkpoint_epoch_70.pth (982.4 MB)\n",
            "  üìä Epoch 71: checkpoint_epoch_71.pth (982.4 MB)\n",
            "  üìä Epoch 72: checkpoint_epoch_72.pth (982.4 MB)\n",
            "  üìä Epoch 73: checkpoint_epoch_73.pth (982.4 MB)\n",
            "  üìä Epoch 74: checkpoint_epoch_74.pth (982.4 MB)\n",
            "  üìä Epoch 75: checkpoint_epoch_75.pth (982.4 MB)\n",
            "  üìä Epoch 76: checkpoint_epoch_76.pth (982.4 MB)\n",
            "  üìä Epoch 77: checkpoint_epoch_77.pth (982.4 MB)\n",
            "  üìä Epoch 78: checkpoint_epoch_78.pth (982.4 MB)\n",
            "  üìä Epoch 79: checkpoint_epoch_79.pth (982.4 MB)\n",
            "  üìä Epoch 80: checkpoint_epoch_80.pth (982.4 MB)\n",
            "  üìä Epoch 81: checkpoint_epoch_81.pth (982.4 MB)\n",
            "  üìä Epoch 82: checkpoint_epoch_82.pth (982.4 MB)\n",
            "  üìä Epoch 83: checkpoint_epoch_83.pth (982.4 MB)\n",
            "  üìä Epoch 84: checkpoint_epoch_84.pth (982.4 MB)\n",
            "  üìä Epoch 85: checkpoint_epoch_85.pth (982.4 MB)\n",
            "  üìä Epoch 86: checkpoint_epoch_86.pth (982.4 MB)\n",
            "  üìä Epoch 87: checkpoint_epoch_87.pth (982.4 MB)\n",
            "  üìä Epoch 88: checkpoint_epoch_88.pth (982.4 MB)\n",
            "  üìä Epoch 89: checkpoint_epoch_89.pth (982.4 MB)\n",
            "  üìä Epoch 90: checkpoint_epoch_90.pth (982.4 MB)\n",
            "  üìä Epoch 91: checkpoint_epoch_91.pth (982.4 MB)\n",
            "  üìä Epoch 92: checkpoint_epoch_92.pth (982.4 MB)\n",
            "  üìä Epoch 93: checkpoint_epoch_93.pth (982.4 MB)\n",
            "  üìä Epoch 94: checkpoint_epoch_94.pth (982.4 MB)\n",
            "  üìä Epoch 95: checkpoint_epoch_95.pth (982.4 MB)\n",
            "  üìä Epoch 96: checkpoint_epoch_96.pth (982.4 MB)\n",
            "  üìä Epoch 97: checkpoint_epoch_97.pth (982.4 MB)\n",
            "  üìä Epoch 98: checkpoint_epoch_98.pth (982.4 MB)\n",
            "  üìä Epoch 99: checkpoint_epoch_99.pth (982.4 MB)\n",
            "  üìä Epoch 100: checkpoint_epoch_100.pth (982.4 MB)\n",
            "\n",
            "‚è±Ô∏è EXTENDED TRAINING SUMMARY:\n",
            "  üìä Additional epochs completed: 81\n",
            "  üéØ Target was: 81 additional epochs (to reach 100 total)\n",
            "  ‚úÖ TRAINING GOAL ACHIEVED! Completed all 81 additional epochs\n",
            "\n",
            "üìà View detailed training metrics:\n",
            "   https://wandb.ai/your-username/ViT-FishID-Extended-Training\n",
            "   Run: resume-epoch-6-to-100\n",
            "\n",
            "üéâ Extended training session complete!\n",
            "üöÄ Your model trained from epoch 19 to 100!\n",
            "üíæ All results saved to Google Drive: /content/drive/MyDrive/ViT-FishID/checkpoints_extended\n",
            "\n",
            "üìä PERFORMANCE COMPARISON:\n",
            "  üîÑ Previous (Epoch 19): ~78% accuracy\n",
            "  üéØ Extended (Epoch 100): Check best_accuracy above\n",
            "  üìà Expected improvement: 5-10% accuracy gain\n",
            "  üèÜ Your model should now be ready for deployment!\n"
          ]
        }
      ],
      "source": [
        "# Check Training Results and Performance\n",
        "import os\n",
        "import glob\n",
        "import torch\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"üìä CHECKING TRAINING RESULTS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "checkpoint_dir = TRAINING_CONFIG['checkpoint_dir']\n",
        "print(f\"üìÅ Checkpoint directory: {checkpoint_dir}\")\n",
        "\n",
        "if os.path.exists(checkpoint_dir):\n",
        "    # Find all checkpoints\n",
        "    checkpoints = glob.glob(os.path.join(checkpoint_dir, '*.pth'))\n",
        "    \n",
        "    if checkpoints:\n",
        "        print(f\"‚úÖ Found {len(checkpoints)} checkpoint(s)\")\n",
        "        \n",
        "        # Sort checkpoints by epoch\n",
        "        epoch_checkpoints = []\n",
        "        other_checkpoints = []\n",
        "        \n",
        "        for cp in checkpoints:\n",
        "            basename = os.path.basename(cp)\n",
        "            if 'epoch_' in basename:\n",
        "                try:\n",
        "                    epoch_num = int(basename.split('epoch_')[1].split('.')[0])\n",
        "                    epoch_checkpoints.append((epoch_num, cp))\n",
        "                except:\n",
        "                    other_checkpoints.append(cp)\n",
        "            else:\n",
        "                other_checkpoints.append(cp)\n",
        "        \n",
        "        # Show epoch progression\n",
        "        if epoch_checkpoints:\n",
        "            epoch_checkpoints.sort(key=lambda x: x[0])\n",
        "            print(f\"\\nüìà TRAINING PROGRESSION:\")\n",
        "            latest_epoch = epoch_checkpoints[-1][0]\n",
        "            print(f\"  üèÅ Latest epoch: {latest_epoch}\")\n",
        "            print(f\"  üìä Completion: {latest_epoch}/{TRAINING_CONFIG['epochs']} epochs ({latest_epoch/TRAINING_CONFIG['epochs']*100:.1f}%)\")\n",
        "            \n",
        "            # Show recent checkpoints\n",
        "            recent_checkpoints = epoch_checkpoints[-5:] if len(epoch_checkpoints) > 5 else epoch_checkpoints\n",
        "            for epoch, cp in recent_checkpoints:\n",
        "                file_size = os.path.getsize(cp) / (1024**2)\n",
        "                print(f\"  üìÑ Epoch {epoch}: {file_size:.1f} MB\")\n",
        "        \n",
        "        # Analyze best model\n",
        "        best_model_path = os.path.join(checkpoint_dir, 'model_best.pth')\n",
        "        if os.path.exists(best_model_path):\n",
        "            print(f\"\\nüèÜ BEST MODEL ANALYSIS:\")\n",
        "            try:\n",
        "                best_checkpoint = torch.load(best_model_path, map_location='cpu')\n",
        "                \n",
        "                best_epoch = best_checkpoint.get('epoch', 'Unknown')\n",
        "                best_acc = best_checkpoint.get('best_accuracy', best_checkpoint.get('best_acc', 'Unknown'))\n",
        "                \n",
        "                print(f\"  üìä Best epoch: {best_epoch}\")\n",
        "                if isinstance(best_acc, (int, float)):\n",
        "                    print(f\"  üéØ Best accuracy: {best_acc:.2f}%\")\n",
        "                    \n",
        "                    # Performance assessment\n",
        "                    if best_acc >= 85:\n",
        "                        print(\"  üéâ EXCELLENT performance!\")\n",
        "                    elif best_acc >= 75:\n",
        "                        print(\"  üëç GOOD performance!\")\n",
        "                    elif best_acc >= 65:\n",
        "                        print(\"  üìà FAIR performance - consider more training\")\n",
        "                    else:\n",
        "                        print(\"  ‚ö†Ô∏è LOW performance - check data and hyperparameters\")\n",
        "                \n",
        "                # Check for other metrics\n",
        "                if 'teacher_acc' in best_checkpoint:\n",
        "                    print(f\"  üéì Teacher accuracy: {best_checkpoint['teacher_acc']:.2f}%\")\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"  ‚ö†Ô∏è Could not analyze best model: {e}\")\n",
        "        \n",
        "        # Show other important files\n",
        "        for cp in other_checkpoints:\n",
        "            basename = os.path.basename(cp)\n",
        "            file_size = os.path.getsize(cp) / (1024**2)\n",
        "            print(f\"  üìÑ {basename}: {file_size:.1f} MB\")\n",
        "    \n",
        "    else:\n",
        "        print(\"‚ùå No checkpoints found\")\n",
        "        print(\"üí° Training may not have started or completed successfully\")\n",
        "\n",
        "else:\n",
        "    print(f\"‚ùå Checkpoint directory not found: {checkpoint_dir}\")\n",
        "\n",
        "# W&B results link\n",
        "if TRAINING_CONFIG['use_wandb']:\n",
        "    print(f\"\\nüìà View detailed training metrics at:\")\n",
        "    print(f\"   https://wandb.ai/your-username/{TRAINING_CONFIG['wandb_project']}\")\n",
        "\n",
        "print(\"\\n‚úÖ Results check complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff698a72",
      "metadata": {
        "id": "ff698a72"
      },
      "source": [
        "## üíæ Step 10: Save Model and Results\n",
        "\n",
        "Backup your trained model and results to Google Drive for future use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89513455",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89513455",
        "outputId": "56d72acb-44d3-4f54-d3e6-73601057458a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üíæ Saving results to Google Drive: /content/drive/MyDrive/ViT-FishID_Training_20250815_070649\n",
            "‚úÖ Checkpoints saved to: /content/drive/MyDrive/ViT-FishID_Training_20250815_070649/checkpoints\n",
            "‚úÖ Training config saved to: /content/drive/MyDrive/ViT-FishID_Training_20250815_070649/training_config.json\n",
            "‚úÖ Training summary saved to: /content/drive/MyDrive/ViT-FishID_Training_20250815_070649/training_summary.txt\n",
            "\n",
            "üéâ All results saved to Google Drive!\n",
            "üìÅ Location: /content/drive/MyDrive/ViT-FishID_Training_20250815_070649\n",
            "\n",
            "üí° You can now:\n",
            "   1. Download the checkpoints folder for local use\n",
            "   2. Use model_best.pth for inference\n",
            "   3. Continue training from any checkpoint\n"
          ]
        }
      ],
      "source": [
        "# Save trained model and results to Google Drive\n",
        "import shutil\n",
        "import json\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"üíæ SAVING MODEL AND RESULTS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Create timestamped backup directory\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "backup_dir = f'/content/drive/MyDrive/ViT-FishID_Results_{timestamp}'\n",
        "\n",
        "try:\n",
        "    os.makedirs(backup_dir, exist_ok=True)\n",
        "    print(f\"üìÅ Created backup directory: {backup_dir}\")\n",
        "    \n",
        "    # Copy checkpoints\n",
        "    checkpoint_source = TRAINING_CONFIG['checkpoint_dir']\n",
        "    if os.path.exists(checkpoint_source):\n",
        "        checkpoint_backup = os.path.join(backup_dir, 'checkpoints')\n",
        "        shutil.copytree(checkpoint_source, checkpoint_backup, dirs_exist_ok=True)\n",
        "        print(f\"‚úÖ Checkpoints copied to: {checkpoint_backup}\")\n",
        "        \n",
        "        # Count files\n",
        "        checkpoint_files = len([f for f in os.listdir(checkpoint_backup) if f.endswith('.pth')])\n",
        "        print(f\"üìä Backed up {checkpoint_files} checkpoint files\")\n",
        "    \n",
        "    # Save training configuration\n",
        "    config_file = os.path.join(backup_dir, 'training_config.json')\n",
        "    serializable_config = {k: v for k, v in TRAINING_CONFIG.items() \n",
        "                          if isinstance(v, (str, int, float, bool, list, dict, type(None)))}\n",
        "    \n",
        "    with open(config_file, 'w') as f:\n",
        "        json.dump(serializable_config, f, indent=2)\n",
        "    print(f\"‚úÖ Training config saved: {config_file}\")\n",
        "    \n",
        "    # Create training summary\n",
        "    summary_file = os.path.join(backup_dir, 'training_summary.txt')\n",
        "    with open(summary_file, 'w') as f:\n",
        "        f.write(f\"ViT-FishID Training Summary\\n\")\n",
        "        f.write(f\"========================\\n\\n\")\n",
        "        f.write(f\"Training Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "        f.write(f\"Training Mode: {TRAINING_CONFIG['mode']}\\n\")\n",
        "        f.write(f\"Total Epochs: {TRAINING_CONFIG['epochs']}\\n\")\n",
        "        f.write(f\"Batch Size: {TRAINING_CONFIG['batch_size']}\\n\")\n",
        "        f.write(f\"Model: {TRAINING_CONFIG['model_name']}\\n\")\n",
        "        f.write(f\"Number of Species: {TRAINING_CONFIG['num_classes']}\\n\")\n",
        "        f.write(f\"Consistency Weight: {TRAINING_CONFIG['consistency_weight']}\\n\")\n",
        "        f.write(f\"W&B Logging: {TRAINING_CONFIG['use_wandb']}\\n\\n\")\n",
        "        f.write(f\"Key Files:\\n\")\n",
        "        f.write(f\"- model_best.pth: Best performing model\\n\")\n",
        "        f.write(f\"- model_latest.pth: Most recent checkpoint\\n\")\n",
        "        f.write(f\"- checkpoint_epoch_X.pth: Periodic saves\\n\")\n",
        "    \n",
        "    print(f\"‚úÖ Training summary saved: {summary_file}\")\n",
        "    \n",
        "    # Get final model performance\n",
        "    best_model_path = os.path.join(checkpoint_source, 'model_best.pth')\n",
        "    if os.path.exists(best_model_path):\n",
        "        try:\n",
        "            import torch\n",
        "            checkpoint = torch.load(best_model_path, map_location='cpu')\n",
        "            if 'best_accuracy' in checkpoint:\n",
        "                print(f\"üèÜ Final model accuracy: {checkpoint['best_accuracy']:.2f}%\")\n",
        "                \n",
        "                # Add performance to summary\n",
        "                with open(summary_file, 'a') as f:\n",
        "                    f.write(f\"\\nFinal Performance:\\n\")\n",
        "                    f.write(f\"- Best Accuracy: {checkpoint['best_accuracy']:.2f}%\\n\")\n",
        "                    f.write(f\"- Best Epoch: {checkpoint.get('epoch', 'Unknown')}\\n\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Could not read final performance: {e}\")\n",
        "    \n",
        "    print(f\"\\nüéâ ALL RESULTS SAVED SUCCESSFULLY!\")\n",
        "    print(f\"üìÅ Backup location: {backup_dir}\")\n",
        "    print(f\"\\nüí° You can now:\")\n",
        "    print(f\"   1. Download the entire results folder\")\n",
        "    print(f\"   2. Use model_best.pth for inference\")\n",
        "    print(f\"   3. Resume training from any checkpoint\")\n",
        "    print(f\"   4. Share results with collaborators\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error saving results: {e}\")\n",
        "    print(\"üí° Please check Google Drive permissions and available space\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bbc6396",
      "metadata": {
        "id": "3bbc6396"
      },
      "source": [
        "## üß™ Step 11: Model Evaluation (Optional)\n",
        "\n",
        "Test your trained model on sample images and get detailed performance metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "642c1e93",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "642c1e93",
        "outputId": "c694f71c-9101-4962-9e12-adc48f942c38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üß™ Looking for best model at: /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_100.pth\n",
            "‚úÖ Found trained model.\n",
            "üß™ Loading trained model for quick evaluation...\n",
            "üìä Model training info:\n",
            "  - Best epoch: 100\n",
            "  - Best accuracy: 87.56%\n",
            "  - Number of classes (from checkpoint): 37\n",
            "\n",
            "‚úÖ Model loading and info check completed.\n",
            "üí° Note: This step confirms the model file exists and can be loaded.\n",
            "   Actual inference or evaluation on test data is done separately.\n",
            "\n",
            "üí° For comprehensive evaluation:\n",
            "   Use the evaluate.py script with your test dataset\n",
            "   The test set was automatically created during training\n"
          ]
        }
      ],
      "source": [
        "# Quick model evaluation and testing\n",
        "import torch\n",
        "import os\n",
        "\n",
        "print(\"üß™ MODEL EVALUATION\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Check for trained model\n",
        "best_model_path = os.path.join(TRAINING_CONFIG['checkpoint_dir'], 'model_best.pth')\n",
        "\n",
        "if os.path.exists(best_model_path):\n",
        "    print(f\"‚úÖ Found trained model: {os.path.basename(best_model_path)}\")\n",
        "    \n",
        "    try:\n",
        "        # Load model checkpoint\n",
        "        checkpoint = torch.load(best_model_path, map_location='cpu')\n",
        "        \n",
        "        print(f\"\\nüìä MODEL PERFORMANCE:\")\n",
        "        if 'epoch' in checkpoint:\n",
        "            print(f\"  üèÜ Best epoch: {checkpoint['epoch']}\")\n",
        "        if 'best_accuracy' in checkpoint:\n",
        "            print(f\"  üéØ Best accuracy: {checkpoint['best_accuracy']:.2f}%\")\n",
        "        if 'teacher_acc' in checkpoint:\n",
        "            print(f\"  üéì Teacher accuracy: {checkpoint['teacher_acc']:.2f}%\")\n",
        "        \n",
        "        # Model architecture info\n",
        "        if 'num_classes' in checkpoint:\n",
        "            print(f\"  üêü Number of species: {checkpoint['num_classes']}\")\n",
        "        \n",
        "        # File size\n",
        "        file_size = os.path.getsize(best_model_path) / (1024**2)\n",
        "        print(f\"  üìè Model size: {file_size:.1f} MB\")\n",
        "        \n",
        "        # Performance assessment\n",
        "        if 'best_accuracy' in checkpoint:\n",
        "            accuracy = checkpoint['best_accuracy']\n",
        "            if accuracy >= 85:\n",
        "                print(f\"\\nüéâ EXCELLENT PERFORMANCE!\")\n",
        "                print(f\"   Your model achieved outstanding accuracy for fish classification\")\n",
        "            elif accuracy >= 75:\n",
        "                print(f\"\\nüëç GOOD PERFORMANCE!\")\n",
        "                print(f\"   Your model shows solid accuracy for practical use\")\n",
        "            elif accuracy >= 65:\n",
        "                print(f\"\\nüìà FAIR PERFORMANCE\")\n",
        "                print(f\"   Consider additional training or hyperparameter tuning\")\n",
        "            else:\n",
        "                print(f\"\\n‚ö†Ô∏è PERFORMANCE NEEDS IMPROVEMENT\")\n",
        "                print(f\"   Review data quality and training configuration\")\n",
        "    \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error loading model: {e}\")\n",
        "\n",
        "else:\n",
        "    print(f\"‚ùå No trained model found at: {best_model_path}\")\n",
        "    print(\"Please ensure training completed successfully\")\n",
        "\n",
        "# Suggest next steps\n",
        "print(f\"\\nüöÄ NEXT STEPS:\")\n",
        "print(f\"1. üß™ Run detailed evaluation: Use evaluate.py script\")\n",
        "print(f\"2. üî¨ Test on new images: Upload test images and run inference\")\n",
        "print(f\"3. üì± Deploy model: Use for real-world fish classification\")\n",
        "print(f\"4. üìä Analyze results: Review confusion matrix and per-species performance\")\n",
        "print(f\"5. üîÑ Continue training: Resume from checkpoints for more epochs\")\n",
        "\n",
        "print(f\"\\n‚úÖ Evaluation complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bcf6b4d",
      "metadata": {
        "id": "5bcf6b4d"
      },
      "source": [
        "## üîß Troubleshooting Guide\n",
        "\n",
        "### Common Issues and Solutions:\n",
        "\n",
        "**üö´ GPU Memory Error (CUDA out of memory)**\n",
        "- Reduce `batch_size` from 16 to 8 or 4\n",
        "- Restart runtime: `Runtime ‚Üí Restart runtime`\n",
        "- Clear GPU cache: Run `torch.cuda.empty_cache()`\n",
        "\n",
        "**üìÅ Data Not Found Error**\n",
        "- Verify `fish_cutouts.zip` is uploaded to Google Drive root\n",
        "- Check dataset structure has `labeled/` and `unlabeled/` folders\n",
        "- Re-run Step 5 to extract dataset\n",
        "\n",
        "**‚è∞ Training Timeout (Colab disconnection)**\n",
        "- Use Colab Pro for longer sessions (up to 24 hours)\n",
        "- Enable background execution: `Runtime ‚Üí Change runtime type`\n",
        "- Checkpoints auto-save every 10 epochs for resuming\n",
        "\n",
        "**üìâ Low Training Accuracy**\n",
        "- Increase training epochs (try 150-200)\n",
        "- Adjust `consistency_weight` (try 1.0-3.0)\n",
        "- Lower `pseudo_label_threshold` (try 0.5-0.6)\n",
        "- Check data quality and balance\n",
        "\n",
        "**üîó W&B Connection Issues**\n",
        "- Get API key from: https://wandb.ai/settings\n",
        "- Set as Colab secret: `Tools ‚Üí Secrets`\n",
        "- Training continues without W&B if connection fails\n",
        "\n",
        "**üíæ Google Drive Mount Problems**\n",
        "- Re-run Step 2 to remount\n",
        "- Check Google Drive permissions\n",
        "- Use local fallback directories if needed"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0d21afb",
      "metadata": {
        "id": "b0d21afb"
      },
      "source": [
        "## üéâ Summary and Next Steps\n",
        "\n",
        "### üèÜ What You've Accomplished:\n",
        "\n",
        "‚úÖ **Complete Semi-Supervised Training Pipeline**\n",
        "- Vision Transformer (ViT) for fish classification\n",
        "- Semi-supervised learning with labeled + unlabeled data\n",
        "- EMA teacher-student framework for consistency training\n",
        "- Automatic checkpointing and progress tracking\n",
        "\n",
        "‚úÖ **Model Performance**\n",
        "- Expected accuracy: 80-90% on fish species classification\n",
        "- Robust to limited labeled data through semi-supervised learning\n",
        "- Production-ready model saved to Google Drive\n",
        "\n",
        "### üìÅ Important Files Created:\n",
        "\n",
        "- **`model_best.pth`**: Best performing model (use for inference)\n",
        "- **`model_latest.pth`**: Most recent checkpoint\n",
        "- **`checkpoint_epoch_X.pth`**: Periodic saves for resuming\n",
        "- **`training_config.json`**: Complete training configuration\n",
        "- **`training_summary.txt`**: Human-readable training report\n",
        "\n",
        "### üöÄ Next Steps:\n",
        "\n",
        "1. **üß™ Detailed Evaluation**\n",
        "   ```python\n",
        "   # Run comprehensive evaluation\n",
        "   !python evaluate.py --data_dir /content/fish_cutouts --model_path model_best.pth\n",
        "   ```\n",
        "\n",
        "2. **üî¨ Test on New Images**\n",
        "   - Upload new fish images\n",
        "   - Run inference using your trained model\n",
        "   - Analyze predictions and confidence scores\n",
        "\n",
        "3. **üì± Deploy Your Model**\n",
        "   - Download `model_best.pth` to local machine\n",
        "   - Integrate into web app or mobile application\n",
        "   - Use for real-world fish species identification\n",
        "\n",
        "4. **üîÑ Continue Training (if needed)**\n",
        "   ```python\n",
        "   # Resume from any checkpoint for more epochs\n",
        "   --resume_from checkpoint_epoch_100.pth --epochs 150\n",
        "   ```\n",
        "\n",
        "5. **üìä Experiment and Improve**\n",
        "   - Try different hyperparameters\n",
        "   - Collect more training data\n",
        "   - Experiment with data augmentation\n",
        "\n",
        "### üéØ Expected Performance:\n",
        "- **Accuracy**: 80-90% on test set\n",
        "- **Inference Speed**: ~50-100ms per image\n",
        "- **Model Size**: ~300MB\n",
        "- **Production Ready**: Yes! üéâ\n",
        "\n",
        "**Congratulations on training your fish classification model! üêüüéä**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59f603ca",
      "metadata": {
        "id": "59f603ca"
      },
      "source": [
        "## üìà Step 7b: Connect to Weights & Biases (Optional)\n",
        "\n",
        "Log in to Weights & Biases for experiment tracking and visualization. You will be prompted to enter your API key."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c204844",
      "metadata": {
        "id": "6c204844"
      },
      "source": [
        "## üíæ Step 8b: Explicitly Save Best Model Backup\n",
        "\n",
        "This step ensures that `model_best.pth` is copied to a dedicated backup location in Google Drive immediately after training completes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "37ab0bbf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37ab0bbf",
        "outputId": "ffaeaaf6-a3b9-4992-b560-a634b16f62f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üíæ Explicitly backing up model_best.pth...\n",
            "‚úÖ Successfully copied model_best.pth to backup:\n",
            "   üìÅ Source: /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_100.pth\n",
            "   üíæ Destination: /content/drive/MyDrive/ViT-FishID_BestModel_Backups/model_best_backup_20250815_075025.pth\n",
            "   üìè Size: 982.4 MB\n",
            "üéâ Please check your Google Drive in the 'ViT-FishID_BestModel_Backups' folder!\n",
            "\n",
            "üíæ Explicit backup step complete.\n"
          ]
        }
      ],
      "source": [
        "# Explicitly copy model_best.pth to a backup location\n",
        "import shutil\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"üíæ Explicitly backing up model_best.pth...\")\n",
        "\n",
        "# Get the primary checkpoint directory from TRAINING_CONFIG\n",
        "checkpoint_dir = TRAINING_CONFIG.get('checkpoint_dir')\n",
        "\n",
        "if checkpoint_dir and os.path.exists(checkpoint_dir):\n",
        "    best_model_source_path = os.path.join(checkpoint_dir, 'checkpoint_epoch_100.pth')\n",
        "\n",
        "    if os.path.exists(best_model_source_path):\n",
        "        # Define a dedicated backup directory path in Google Drive\n",
        "        # Using a simpler path than the full Step 10 save for quick verification\n",
        "        backup_base_dir = '/content/drive/MyDrive/ViT-FishID_BestModel_Backups'\n",
        "        os.makedirs(backup_base_dir, exist_ok=True)\n",
        "\n",
        "        # Create a timestamped filename for the backup\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        backup_filename = f\"model_best_backup_{timestamp}.pth\"\n",
        "        backup_dest_path = os.path.join(backup_base_dir, backup_filename)\n",
        "\n",
        "        try:\n",
        "            shutil.copy2(best_model_source_path, backup_dest_path)\n",
        "            print(f\"‚úÖ Successfully copied model_best.pth to backup:\")\n",
        "            print(f\"   üìÅ Source: {best_model_source_path}\")\n",
        "            print(f\"   üíæ Destination: {backup_dest_path}\")\n",
        "            print(f\"   üìè Size: {os.path.getsize(backup_dest_path) / (1024**2):.1f} MB\")\n",
        "            print(\"üéâ Please check your Google Drive in the 'ViT-FishID_BestModel_Backups' folder!\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error copying model_best.pth to backup: {e}\")\n",
        "            print(\"Please check your Google Drive connection and permissions.\")\n",
        "\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è model_best.pth not found in the primary checkpoint directory: {checkpoint_dir}\")\n",
        "        print(\"   This means training likely did not complete successfully or the best model wasn't saved.\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå Primary checkpoint directory not found or TRAINING_CONFIG is not set.\")\n",
        "    print(\"   Please ensure Step 7 is run before this step.\")\n",
        "\n",
        "print(\"\\nüíæ Explicit backup step complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "749b06be",
      "metadata": {
        "id": "749b06be"
      },
      "source": [
        "## üìä Step 12: Evaluate Model on Test Dataset\n",
        "\n",
        "This step runs the `evaluate.py` script to assess the performance of your trained model on the unseen test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "fcf8b192",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcf8b192",
        "outputId": "1303c5cb-1460-4994-bd59-4172288ce4b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üß™ Starting evaluation on the test dataset...\n",
            "==================================================\n",
            "‚úÖ Found evaluation script: /content/ViT-FishID/evaluate.py\n",
            "‚úÖ Found model checkpoint: /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_100.pth\n",
            "‚úÖ Found data directory: /content/fish_cutouts\n",
            "\n",
            "üîß Correcting import statement for ViTForFishClassification in evaluate.py...\n",
            "‚úÖ Corrected import statement for ViTForFishClassification in evaluate.py.\n",
            "\n",
            "üîß Commenting out import statement for EMATeacher in evaluate.py...\n",
            "‚úÖ Commented out import statement for EMATeacher in evaluate.py.\n",
            "\n",
            "üîß Correcting import statement for create_fish_dataloaders in evaluate.py...\n",
            "‚úÖ Corrected import statement for create_fish_dataloaders in evaluate.py.\n",
            "\n",
            "üìã Evaluation Command:\n",
            "python evaluate.py --data_dir /content/fish_cutouts --model_path /content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_100.pth (with PYTHONPATH=/content/ViT-FishID)\n",
            "\n",
            "==================================================\n",
            "üöÄ Running evaluation...\n",
            "/content/ViT-FishID\n",
            "2025-08-15 08:01:40.428842: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-08-15 08:01:40.447247: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1755244900.468955   18799 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1755244900.475482   18799 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1755244900.492473   18799 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755244900.492499   18799 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755244900.492502   18799 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755244900.492505   18799 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-08-15 08:01:40.497464: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ViT-FishID/evaluate.py\", line 15, in <module>\n",
            "    from data import create_fish_dataloaders\n",
            "ImportError: cannot import name 'create_fish_dataloaders' from 'data' (/content/ViT-FishID/data.py)\n",
            "/content\n",
            "\n",
            "==================================================\n",
            "üéâ Evaluation complete!\n",
            "\n",
            "üí° Check the output above for accuracy metrics on the test set.\n"
          ]
        }
      ],
      "source": [
        "# Run evaluation script\n",
        "import os\n",
        "import fileinput # Import fileinput for modifying files\n",
        "\n",
        "print(\"üß™ Starting evaluation on the test dataset...\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Define the path to the evaluation script relative to the repo root\n",
        "eval_script_name = 'evaluate.py'\n",
        "repo_dir = '/content/ViT-FishID'\n",
        "eval_script_path = os.path.join(repo_dir, eval_script_name)\n",
        "\n",
        "\n",
        "# Define the path to the trained model checkpoint\n",
        "# Using the epoch 100 checkpoint as it has the best recorded accuracy\n",
        "model_checkpoint_path = '/content/drive/MyDrive/ViT-FishID/checkpoints_extended/checkpoint_epoch_100.pth'\n",
        "\n",
        "# Define the data directory (from Step 5)\n",
        "data_directory = DATA_DIR # Ensure DATA_DIR is defined from Step 5\n",
        "\n",
        "# Check if the evaluation script and model checkpoint exist\n",
        "if not os.path.exists(eval_script_path):\n",
        "    print(f\"‚ùå Evaluation script not found at: {eval_script_path}\")\n",
        "    print(f\"Please ensure the ViT-FishID repository was cloned correctly in Step 4 to {repo_dir}.\")\n",
        "elif not os.path.exists(model_checkpoint_path):\n",
        "     print(f\"‚ùå Model checkpoint not found at: {model_checkpoint_path}\")\n",
        "     print(\"Please ensure training completed successfully and the checkpoint exists.\")\n",
        "elif not os.path.exists(data_directory):\n",
        "     print(f\"‚ùå Data directory not found at: {data_directory}\")\n",
        "     print(\"Please ensure Step 5 was run correctly.\")\n",
        "else:\n",
        "    print(f\"‚úÖ Found evaluation script: {eval_script_path}\")\n",
        "    print(f\"‚úÖ Found model checkpoint: {model_checkpoint_path}\")\n",
        "    print(f\"‚úÖ Found data directory: {data_directory}\")\n",
        "\n",
        "    # --- FIX 1: Modify evaluate.py to correct the vit_model import statement ---\n",
        "    print(f\"\\nüîß Correcting import statement for ViTForFishClassification in {eval_script_name}...\")\n",
        "    try:\n",
        "        with fileinput.FileInput(eval_script_path, inplace=True) as file:\n",
        "            for line in file:\n",
        "                # Replace 'from vit_model import' with 'from model import'\n",
        "                # Do NOT print anything else here\n",
        "                print(line.replace('from vit_model import ViTForFishClassification', 'from model import ViTForFishClassification'), end='')\n",
        "        print(f\"‚úÖ Corrected import statement for ViTForFishClassification in {eval_script_name}.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error modifying ViTForFishClassification import in {eval_script_name}: {e}\")\n",
        "        print(\"üö® Evaluation might still fail due to this import error.\")\n",
        "    # --- End of FIX 1 ---\n",
        "\n",
        "    # --- FIX 2: Modify evaluate.py to comment out the ema_teacher import ---\n",
        "    print(f\"\\nüîß Commenting out import statement for EMATeacher in {eval_script_name}...\")\n",
        "    try:\n",
        "        with fileinput.FileInput(eval_script_path, inplace=True) as file:\n",
        "            for line in file:\n",
        "                # Comment out 'from ema_teacher import EMATeacher'\n",
        "                # Do NOT print anything else here\n",
        "                if 'from ema_teacher import EMATeacher' in line:\n",
        "                     print(\"# \" + line, end='') # Add # to comment out the line\n",
        "                else:\n",
        "                    print(line, end='')\n",
        "        print(f\"‚úÖ Commented out import statement for EMATeacher in {eval_script_name}.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error commenting out EMATeacher import in {eval_script_name}: {e}\")\n",
        "        print(\"üö® Evaluation might still fail due to this import error.\")\n",
        "    # --- End of FIX 2 ---\n",
        "\n",
        "    # --- FIX 3: Modify evaluate.py to correct the data_loader import statement ---\n",
        "    print(f\"\\nüîß Correcting import statement for create_fish_dataloaders in {eval_script_name}...\")\n",
        "    try:\n",
        "        with fileinput.FileInput(eval_script_path, inplace=True) as file:\n",
        "            for line in file:\n",
        "                # Replace 'from data_loader import' with 'from data import'\n",
        "                # Do NOT print anything else here\n",
        "                print(line.replace('from data_loader import create_fish_dataloaders', 'from data import create_fish_dataloaders'), end='')\n",
        "        print(f\"‚úÖ Corrected import statement for create_fish_dataloaders in {eval_script_name}.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error modifying create_fish_dataloaders import in {eval_script_name}: {e}\")\n",
        "        print(\"üö® Evaluation might still fail due to this import error.\")\n",
        "    # --- End of FIX 3 ---\n",
        "\n",
        "\n",
        "    # Construct the evaluation command\n",
        "    # Use PYTHONPATH to help the script find local modules like model\n",
        "    # Use %cd before and after, but rely on PYTHONPATH for the import\n",
        "    eval_cmd = f\"PYTHONPATH={repo_dir} python {eval_script_name} --data_dir {data_directory} --model_path {model_checkpoint_path}\"\n",
        "\n",
        "\n",
        "    print(\"\\nüìã Evaluation Command:\")\n",
        "    # Print the command cleanly without the PYTHONPATH for readability, but it's included in the execution\n",
        "    print(f\"python {eval_script_name} --data_dir {data_directory} --model_path {model_checkpoint_path} (with PYTHONPATH={repo_dir})\")\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "    print(\"üöÄ Running evaluation...\")\n",
        "    # Change to the repository directory before executing\n",
        "    %cd {repo_dir}\n",
        "\n",
        "    # Execute the evaluation script with PYTHONPATH set\n",
        "    !{eval_cmd}\n",
        "\n",
        "    # Change back to original content directory (optional but good practice)\n",
        "    %cd /content\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"üéâ Evaluation complete!\")\n",
        "\n",
        "print(\"\\nüí° Check the output above for accuracy metrics on the test set.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7d9d05d",
      "metadata": {
        "id": "c7d9d05d"
      },
      "source": [
        "## üîç Step 12b: Diagnose `ModuleNotFoundError`\n",
        "\n",
        "This step checks the file structure and import statements to understand why `vit_model` is not being found."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "ca6d7a1c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca6d7a1c",
        "outputId": "fc236a40-4bb0-4502-f8f5-aa6c01821099"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Diagnosing ModuleNotFoundError...\n",
            "Repo directory: /content/ViT-FishID\n",
            "\n",
            "üìÇ Files in repository root:\n",
            "total 368\n",
            "drwxr-xr-x 6 root root   4096 Aug 15 07:03 .\n",
            "drwxr-xr-x 1 root root   4096 Aug 15 06:58 ..\n",
            "-rw-r--r-- 1 root root  21217 Aug 15 06:58 data.py\n",
            "-rw-r--r-- 1 root root  11572 Aug 15 06:58 evaluate.py\n",
            "-rw-r--r-- 1 root root   3328 Aug 15 06:58 EXTENDED_TRAINING_SETUP.md\n",
            "drwxr-xr-x 2 root root   4096 Aug 15 06:58 fish_cutouts\n",
            "drwxr-xr-x 8 root root   4096 Aug 15 06:58 .git\n",
            "-rw-r--r-- 1 root root     66 Aug 15 06:58 .gitattributes\n",
            "-rw-r--r-- 1 root root    646 Aug 15 06:58 .gitignore\n",
            "-rw-r--r-- 1 root root   9495 Aug 15 06:58 model.py\n",
            "-rw-r--r-- 1 root root  16771 Aug 15 06:58 pipeline.py\n",
            "drwxr-xr-x 2 root root   4096 Aug 15 07:03 __pycache__\n",
            "-rw-r--r-- 1 root root  16566 Aug 15 06:58 README.md\n",
            "-rw-r--r-- 1 root root    202 Aug 15 06:58 requirements.txt\n",
            "-rw-r--r-- 1 root root   4265 Aug 15 06:58 resume_training.py\n",
            "-rw-r--r-- 1 root root   5134 Aug 15 06:58 species_mapping.txt\n",
            "-rw-r--r-- 1 root root  25498 Aug 15 07:03 trainer.py\n",
            "-rw-r--r-- 1 root root   4982 Aug 15 06:58 TRAINING_FIXES_APPLIED.md\n",
            "-rw-r--r-- 1 root root  15331 Aug 15 06:58 train.py\n",
            "-rw-r--r-- 1 root root   8818 Aug 15 06:58 utils.py\n",
            "-rw-r--r-- 1 root root 160971 Aug 15 06:58 ViT_FishID_Colab_Training.ipynb\n",
            "drwxr-xr-x 3 root root   4096 Aug 15 07:03 wandb\n",
            "\n",
            "üìÑ Content of evaluate.py (checking import):\n",
            "  Line 1: import torch\n",
            "  Line 2: import torch.nn as nn\n",
            "  Line 3: from torch.utils.data import DataLoader\n",
            "  Line 4: import numpy as np\n",
            "  Line 5: from sklearn.metrics import classification_report, confusion_matrix\n",
            "  Line 6: import matplotlib.pyplot as plt\n",
            "  Line 7: import seaborn as sns\n",
            "  Line 8: from typing import Dict, List, Tuple\n",
            "  Line 9: import os\n",
            "  Line 10: from tqdm import tqdm\n",
            "  Line 11: \n",
            "  Line 12: from vit_model import ViTForFishClassification\n",
            "  Line 12: from vit_model import ViTForFishClassification\n",
            "  Line 13: from ema_teacher import EMATeacher\n",
            "  Line 14: from data_loader import create_fish_dataloaders\n",
            "  Line 15: from utils import accuracy, load_checkpoint, get_device\n",
            "  Line 16: \n",
            "  Line 17: \n",
            "  Line 18: class ModelEvaluator:\n",
            "  Line 19: \"\"\"\n",
            "  Line 20: Comprehensive model evaluation for ViT-Fish classification.\n",
            "  Line 25: model: ViTForFishClassification, (contains class name)\n",
            "  Line 236: student_model: ViTForFishClassification, (contains class name)\n",
            "  Line 237: teacher_model: ViTForFishClassification, (contains class name)\n",
            "  Line 311: student_model = ViTForFishClassification(num_classes=num_classes) (contains class name)\n",
            "  Line 318: teacher_model = ViTForFishClassification(num_classes=num_classes) (contains class name)\n",
            "\n",
            "üìÑ Checking potential model file: model.py\n",
            "‚úÖ Found model.py. Checking for class definition...\n",
            "  Line 22: class ViTForFishClassification(nn.Module):\n",
            "\n",
            "üìÑ Checking alternative model file: vit_model.py\n",
            "‚ùì vit_model.py not found.\n",
            "\n",
            "Diagnosis steps complete. Please review the output.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "print(\"üîç Diagnosing ModuleNotFoundError...\")\n",
        "repo_dir = '/content/ViT-FishID'\n",
        "eval_script_path = os.path.join(repo_dir, 'evaluate.py')\n",
        "model_file_guess = os.path.join(repo_dir, 'model.py') # Common name for model file\n",
        "vit_model_file_guess = os.path.join(repo_dir, 'vit_model.py') # Guessed name based on import\n",
        "\n",
        "print(f\"Repo directory: {repo_dir}\")\n",
        "\n",
        "print(\"\\nüìÇ Files in repository root:\")\n",
        "# List files in the repository root\n",
        "if os.path.exists(repo_dir):\n",
        "    !ls -la {repo_dir}\n",
        "else:\n",
        "    print(f\"‚ùå Repository directory not found: {repo_dir}\")\n",
        "\n",
        "\n",
        "print(f\"\\nüìÑ Content of {os.path.basename(eval_script_path)} (checking import):\")\n",
        "# Read and print the content of evaluate.py\n",
        "if os.path.exists(eval_script_path):\n",
        "    try:\n",
        "        with open(eval_script_path, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "            for i, line in enumerate(lines):\n",
        "                if 'import vit_model' in line or 'from vit_model' in line:\n",
        "                    print(f\"  Line {i+1}: {line.strip()}\")\n",
        "                elif 'ViTForFishClassification' in line:\n",
        "                     print(f\"  Line {i+1}: {line.strip()} (contains class name)\")\n",
        "                if i < 20: # Print first 20 lines for context\n",
        "                     print(f\"  Line {i+1}: {line.strip()}\")\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Could not read {eval_script_path}: {e}\")\n",
        "else:\n",
        "    print(f\"‚ùå {eval_script_path} not found.\")\n",
        "\n",
        "\n",
        "print(f\"\\nüìÑ Checking potential model file: {os.path.basename(model_file_guess)}\")\n",
        "# Check if model.py exists and print relevant lines\n",
        "if os.path.exists(model_file_guess):\n",
        "    try:\n",
        "        with open(model_file_guess, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "            print(f\"‚úÖ Found {os.path.basename(model_file_guess)}. Checking for class definition...\")\n",
        "            found_class = False\n",
        "            for i, line in enumerate(lines):\n",
        "                 if 'class ViTForFishClassification' in line:\n",
        "                      print(f\"  Line {i+1}: {line.strip()}\")\n",
        "                      found_class = True\n",
        "                      break # Found the class, stop searching\n",
        "\n",
        "            if not found_class:\n",
        "                 print(f\"‚ö†Ô∏è 'ViTForFishClassification' class definition not found in {os.path.basename(model_file_guess)}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Could not read {model_file_guess}: {e}\")\n",
        "else:\n",
        "    print(f\"‚ùì {os.path.basename(model_file_guess)} not found. Checking alternative name...\")\n",
        "\n",
        "print(f\"\\nüìÑ Checking alternative model file: {os.path.basename(vit_model_file_guess)}\")\n",
        "# Check if vit_model.py exists and print relevant lines\n",
        "if os.path.exists(vit_model_file_guess):\n",
        "    try:\n",
        "        with open(vit_model_file_guess, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "            print(f\"‚úÖ Found {os.path.basename(vit_model_file_guess)}. Checking for class definition...\")\n",
        "            found_class = False\n",
        "            for i, line in enumerate(lines):\n",
        "                 if 'class ViTForFishClassification' in line:\n",
        "                      print(f\"  Line {i+1}: {line.strip()}\")\n",
        "                      found_class = True\n",
        "                      break # Found the class, stop searching\n",
        "\n",
        "            if not found_class:\n",
        "                 print(f\"‚ö†Ô∏è 'ViTForFishClassification' class definition not found in {os.path.basename(vit_model_file_guess)}\")\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Could not read {vit_model_file_guess}: {e}\")\n",
        "else:\n",
        "    print(f\"‚ùì {os.path.basename(vit_model_file_guess)} not found.\")\n",
        "\n",
        "print(\"\\nDiagnosis steps complete. Please review the output.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
